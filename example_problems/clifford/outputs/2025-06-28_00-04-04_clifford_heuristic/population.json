[
  {
    "id": 1,
    "parent_id": null,
    "solution": "def heuristic(matrix):\n    \"\"\"Simple sum of all matrix entries.\"\"\"\n    import numpy as np\n    return float(np.sum(matrix))\n",
    "evaluation": {
      "fitness": 0.7461313165891074,
      "additional_data": {
        "spearman_correlation": "0.746131",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": null
  },
  {
    "id": 2,
    "parent_id": null,
    "solution": "def heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums (H_prod metric).\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    col_sums = np.maximum(col_sums, 1e-10)  # Avoid log(0)\n    return float(np.sum(np.log(col_sums)))\n",
    "evaluation": {
      "fitness": 0.7848499863267082,
      "additional_data": {
        "spearman_correlation": "0.784850",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 13,
    "creation_info": null
  },
  {
    "id": 3,
    "parent_id": null,
    "solution": "def heuristic(matrix):\n    \"\"\"Vector heuristic based on sorted column sums.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    return tuple(sorted(col_sums))\n",
    "evaluation": {
      "fitness": 0.7776224989903747,
      "additional_data": {
        "spearman_correlation": "0.777622",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 9,
    "creation_info": null
  },
  {
    "id": 4,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8658840755208309,
      "additional_data": {
        "spearman_correlation": "0.865884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 17,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 10,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 5,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Vector heuristic based on log-transformed sorted column sums.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    epsilon = 1e-10\n    log_col_sums = np.log(col_sums + epsilon)\n    return tuple(sorted(log_col_sums))\n",
    "evaluation": {
      "fitness": 0.7776224989903747,
      "additional_data": {
        "spearman_correlation": "0.777622",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 6,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 6,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined row and column sum product heuristic.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    return np.sum(col_sums * row_sums)\n",
    "evaluation": {
      "fitness": 0.7285147130179891,
      "additional_data": {
        "spearman_correlation": "0.728515",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 5,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 7,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse/transpose variants.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": -0.16898660351655273,
      "additional_data": {
        "spearman_correlation": "-0.168987",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 3,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 8,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering both original and transpose.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    return min(original_heuristic, transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.7989405925201386,
      "additional_data": {
        "spearman_correlation": "0.798941",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 4,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 9,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Multi-perspective logarithmic sum heuristic (original, inverse, transpose).\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return (float(np.sum(np.log(col_sums))), float(np.sum(np.log(row_sums)))\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix) % 2\n    except:\n        inv_matrix = matrix\n        \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(inv_matrix),\n        compute_metric(matrix.T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 11)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 7,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 10,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Multi-faceted heuristic considering matrix, inverse, and transpose variants.\"\"\"\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        log_prod = np.sum(np.log(col_sums))\n        total_sum = np.sum(m)\n        col_metrics = tuple(sorted(col_sums))\n        return (log_prod, total_sum, *col_metrics)\n    \n    original_metrics = compute_metrics(matrix)\n    inv_metrics = compute_metrics(np.linalg.inv(matrix))\n    trans_metrics = compute_metrics(matrix.T)\n    \n    return min(original_metrics, inv_metrics, trans_metrics)\n",
    "evaluation": {
      "fitness": -0.1890388724379646,
      "additional_data": {
        "spearman_correlation": "-0.189039",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 15,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 11,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums and row sums as tuple.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    col_sums = np.maximum(col_sums, 1e-10)\n    col_heuristic = np.sum(np.log(col_sums))\n    \n    row_sums = np.sum(matrix, axis=1)\n    row_sums = np.maximum(row_sums, 1e-10)\n    row_heuristic = np.sum(np.log(row_sums))\n    \n    return (float(col_heuristic), float(row_heuristic))\n",
    "evaluation": {
      "fitness": 0.7903202317551506,
      "additional_data": {
        "spearman_correlation": "0.790320",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 14,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 12,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse and transpose.\"\"\"\n    import numpy as np\n    def compute_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    h = compute_heuristic(matrix)\n    h_inv = compute_heuristic(np.linalg.inv(matrix))\n    h_trans = compute_heuristic(matrix.T)\n    return min(h, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": -0.16898660351655273,
      "additional_data": {
        "spearman_correlation": "-0.168987",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 13,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 13,
    "parent_id": 1,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums and matrix transpose.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        weighted_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        return weighted_sum\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    min_heuristic = min(original_heuristic, transposed_heuristic)\n    \n    return (min_heuristic, original_heuristic)\n",
    "evaluation": {
      "fitness": 0.7991142475594821,
      "additional_data": {
        "spearman_correlation": "0.799114",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 8,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 14,
    "parent_id": 1,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column weights, inverses, and transposes.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        simple_sum = np.sum(m)\n        return min(simple_sum, log_sum)\n    \n    original = evaluate(matrix)\n    try:\n        inverse = evaluate(np.linalg.inv(matrix).astype(int) % 2)\n    except:\n        inverse = float('inf')\n    transpose = evaluate(matrix.T)\n    \n    return (original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.7954950195118634,
      "additional_data": {
        "spearman_correlation": "0.795495",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 12,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 15,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced vector heuristic considering multiple matrix properties.\"\"\"\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.log(np.maximum(col_sums, 1))\n        log_row = np.log(np.maximum(row_sums, 1))\n        return tuple(sorted(col_sums)) + tuple(sorted(row_sums)) + tuple(sorted(log_col)) + tuple(sorted(log_row))\n    \n    metrics = [\n        compute_metrics(matrix),\n        compute_metrics(matrix.T),\n        compute_metrics(np.linalg.inv(matrix)),\n        compute_metrics(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.15339397826096343,
      "additional_data": {
        "spearman_correlation": "-0.153394",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 2,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 16,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_terms(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_term = np.sum(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_term = np.sum(np.log(row_sums))\n        \n        sum_term = np.sum(m)\n        return (col_term, row_term, sum_term)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    except:\n        inv_matrix = matrix\n    \n    original_terms = compute_terms(matrix)\n    inverse_terms = compute_terms(inv_matrix)\n    \n    return min(original_terms + inverse_terms)\n",
    "evaluation": {
      "fitness": 0.7223808542791019,
      "additional_data": {
        "spearman_correlation": "0.722381",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 11,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 17,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sparsity = np.sum(m)\n        return (log_col, log_row, sparsity)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7110171495445274,
      "additional_data": {
        "spearman_correlation": "0.711017",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 1,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 18,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        \n        main_metric = log_col * log_row * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)))\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    \n    return (min_main, min_secondary)\n",
    "evaluation": {
      "fitness": 0.8234585683208072,
      "additional_data": {
        "spearman_correlation": "0.823459",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 9,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 19,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Average of logarithms of column sums across original, inverse, and transpose.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original + inverse + transpose) / 3\n",
    "evaluation": {
      "fitness": 0.8540018281205309,
      "additional_data": {
        "spearman_correlation": "0.854002",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 18,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 20,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Average of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original + inverse + transpose) / 3\n",
    "evaluation": {
      "fitness": 0.8540018281205309,
      "additional_data": {
        "spearman_correlation": "0.854002",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 6,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 21,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 21,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Average of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original + inverse + transpose) / 3\n",
    "evaluation": {
      "fitness": 0.8540018281205309,
      "additional_data": {
        "spearman_correlation": "0.854002",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 22,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 22,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic considering both rows and columns and matrix transpose.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    option1 = tuple(sorted(col_sums + row_sums))\n    option2 = tuple(sorted(trans_col_sums + trans_row_sums))\n    return min(option1, option2)\n",
    "evaluation": {
      "fitness": 0.740136877157673,
      "additional_data": {
        "spearman_correlation": "0.740137",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 20,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 23,
    "parent_id": 5,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Vector heuristic combining log-transformed sorted column and row sums.\"\"\"\n    import numpy as np\n    epsilon = 1e-10\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    log_col_sums = np.log(col_sums + epsilon)\n    log_row_sums = np.log(row_sums + epsilon)\n    combined = np.concatenate([log_col_sums, log_row_sums])\n    return tuple(sorted(combined))\n",
    "evaluation": {
      "fitness": 0.8205538850674933,
      "additional_data": {
        "spearman_correlation": "0.820554",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 19,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 24,
    "parent_id": 5,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both row and column completion metrics.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        epsilon = 1e-10\n        row_metric = np.sum(np.abs(row_sums - 1))\n        col_metric = np.sum(np.abs(col_sums - 1))\n        return (row_metric, col_metric)\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    \n    metrics = [original, transposed, inverted, inv_transposed]\n    metrics.sort()\n    return metrics[0]\n",
    "evaluation": {
      "fitness": 0.31142477081021963,
      "additional_data": {
        "spearman_correlation": "0.311425",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 17,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 25,
    "parent_id": 8,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering original, transpose and inverse.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums + 0.1)))\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    return min(original_heuristic, transpose_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7190930929924041,
      "additional_data": {
        "spearman_correlation": "0.719093",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 26,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 26,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        return (col_log + row_log, col_linear + row_linear)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8740312768287192,
      "additional_data": {
        "spearman_correlation": "0.874031",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 7,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 24,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 27,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_metric = np.sum(np.log(col_sums))\n        row_metric = np.sum(np.log(row_sums))\n        \n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = max(diag, anti_diag) / m.shape[0]\n        \n        return (col_metric, row_metric, -diag_metric)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8724505277310688,
      "additional_data": {
        "spearman_correlation": "0.872451",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 16,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 28,
    "parent_id": 8,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering original, transpose and inverse.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-12)\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-12)\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)))\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix).astype(int) % 2)\n    return min(original_heuristic, transpose_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7245377712902134,
      "additional_data": {
        "spearman_correlation": "0.724538",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 23,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 29,
    "parent_id": 5,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic considering both matrix and transpose.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-10\n    log_col_sums = np.log(col_sums + epsilon)\n    log_row_sums = np.log(row_sums + epsilon)\n    return tuple(sorted(log_col_sums)) + tuple(sorted(log_row_sums))\n",
    "evaluation": {
      "fitness": 0.7849406438597368,
      "additional_data": {
        "spearman_correlation": "0.784941",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 25,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 30,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined column and row sum logarithms, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(0.7 * np.sum(np.log(col_sums)) + 0.3 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8712222394001866,
      "additional_data": {
        "spearman_correlation": "0.871222",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 29,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 31,
    "parent_id": 15,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        return np.sum(np.sum(m, axis=0))\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix),\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(compute_metric(m) for m in variants)\n",
    "evaluation": {
      "fitness": -0.2792271273234173,
      "additional_data": {
        "spearman_correlation": "-0.279227",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 30,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 32,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        spread = np.sum(np.abs(np.diff(m, axis=0))) + np.sum(np.abs(np.diff(m, axis=1)))\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8723972384987168,
      "additional_data": {
        "spearman_correlation": "0.872397",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 27,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 33,
    "parent_id": 13,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering columns, rows, inverse, and transpose.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sum_col = np.sum(col_sums)\n        sum_row = np.sum(row_sums)\n        return (log_col, log_row, sum_col, sum_row)\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    inverse = matrix_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inv_transposed = matrix_metrics(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    min_log_col = min(original[0], transposed[0], inverse[0], inv_transposed[0])\n    min_sum_col = min(original[2], transposed[2], inverse[2], inv_transposed[2])\n    max_log_row = max(original[1], transposed[1], inverse[1], inv_transposed[1])\n    \n    return (min_log_col, min_sum_col, max_log_row)\n",
    "evaluation": {
      "fitness": 0.7172406075075101,
      "additional_data": {
        "spearman_correlation": "0.717241",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 28,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 34,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining inverse/transpose alternatives and row information.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + 0.1 * float(np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original + inverse + transpose) / 3\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 10)"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 33,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 35,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.trace(m)\n        total_nonzero = np.count_nonzero(m)\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        h1 = float(np.sum(np.log(col_sums)))\n        h2 = float(np.sum(np.log(row_sums)))\n        h3 = float(total_nonzero)\n        h4 = float(diag_sum)\n        return (h1, h2, h3, h4)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8680702386029537,
      "additional_data": {
        "spearman_correlation": "0.868070",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 34,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 36,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums, with min across matrix variants.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    \n    return (float(original), float(min(transposed, inverted)))\n",
    "evaluation": {
      "fitness": 0.7907980254340959,
      "additional_data": {
        "spearman_correlation": "0.790798",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 38,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 37,
    "parent_id": 17,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        log_col = np.sum(np.log(col_sums[col_sums > 0])) if non_zero_cols > 0 else 0\n        log_row = np.sum(np.log(row_sums[row_sums > 0])) if non_zero_rows > 0 else 0\n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        max_row = np.max(row_sums) if row_sums.size > 0 else 0\n        sparsity = np.sum(m)\n        return (log_col, log_row, -non_zero_cols, -non_zero_rows, max_col, max_row, sparsity)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7128952375856952,
      "additional_data": {
        "spearman_correlation": "0.712895",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 31,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 38,
    "parent_id": 11,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_heuristic = np.sum(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_heuristic = np.sum(np.log(row_sums))\n        \n        diag = np.diag(m)\n        diag = np.maximum(np.abs(diag), 1e-10)\n        diag_heuristic = np.sum(np.log(diag))\n        \n        return col_heuristic, row_heuristic, diag_heuristic\n    \n    original = compute_metrics(matrix)\n    try:\n        inv = compute_metrics(np.linalg.inv(matrix))\n    except:\n        inv = (float('inf'),)*3\n    trans = compute_metrics(matrix.T)\n    \n    return min(original, inv, trans)\n",
    "evaluation": {
      "fitness": -0.12755165649794734,
      "additional_data": {
        "spearman_correlation": "-0.127552",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 32,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 39,
    "parent_id": 20,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Average of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original + inverse + transpose) / 3\n",
    "evaluation": {
      "fitness": 0.8540018281205309,
      "additional_data": {
        "spearman_correlation": "0.854002",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 36,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 40,
    "parent_id": 16,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_terms(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_term_sum = np.sum(np.log(col_sums))\n        col_term_max = np.max(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_term_sum = np.sum(np.log(row_sums))\n        row_term_max = np.max(np.log(row_sums))\n        \n        sum_term = np.sum(m)\n        sparsity_term = np.sum(m != 0)\n        return (col_term_sum, row_term_sum, sum_term, sparsity_term, col_term_max, row_term_max)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    except:\n        inv_matrix = matrix\n    \n    trans_matrix = matrix.T\n    \n    original_terms = compute_terms(matrix)\n    inverse_terms = compute_terms(inv_matrix)\n    trans_terms = compute_terms(trans_matrix)\n    \n    return min(original_terms + inverse_terms + trans_terms)\n",
    "evaluation": {
      "fitness": 0.42409764204650235,
      "additional_data": {
        "spearman_correlation": "0.424098",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 35,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 41,
    "parent_id": 14,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining column and row metrics with robust inverse handling.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        simple_sum = np.sum(m)\n        return 0.5*simple_sum + 0.3*log_col + 0.2*log_row\n    \n    original = evaluate(matrix)\n    try:\n        inv_matrix = np.linalg.pinv(matrix).round().astype(int) % 2\n        inverse = evaluate(inv_matrix)\n    except:\n        inverse = float('inf')\n    transpose = evaluate(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.7409065921176853,
      "additional_data": {
        "spearman_correlation": "0.740907",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 41,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 42,
    "parent_id": 7,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of non-zero entries across all matrix variants.\"\"\"\n    import numpy as np\n    \n    def count_nonzeros(m):\n        return np.count_nonzero(m)\n    \n    h_original = count_nonzeros(matrix)\n    h_inverse = count_nonzeros(np.linalg.inv(matrix))\n    h_transpose = count_nonzeros(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8749956633326059,
      "additional_data": {
        "spearman_correlation": "0.874996",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 43,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 43,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums, basis vector counts and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        # Count number of columns/rows that are already basis vectors (weight=1)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        \n        return (col_log + row_log, col_linear + row_linear, -basis_cols - basis_rows)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8740034291559838,
      "additional_data": {
        "spearman_correlation": "0.874003",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 37,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 44,
    "parent_id": 25,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Composite heuristic considering column sums, row sums, and their interactions.\"\"\"\n    import numpy as np\n    \n    def col_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums + 0.1))\n    \n    def row_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return np.sum(np.log(row_sums + 0.1))\n    \n    def interaction_heuristic(m):\n        col_nonzeros = np.sum(m, axis=0)\n        row_nonzeros = np.sum(m, axis=1)\n        interaction = np.sum(col_nonzeros * row_nonzeros)\n        return np.log(interaction + 0.1) if interaction > 0 else 0\n    \n    original_col = col_heuristic(matrix)\n    original_row = row_heuristic(matrix)\n    original_inter = interaction_heuristic(matrix)\n    \n    transposed = matrix.T\n    transposed_col = col_heuristic(transposed)\n    transposed_row = row_heuristic(transposed)\n    transposed_inter = interaction_heuristic(transposed)\n    \n    inverse = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    inverse_col = col_heuristic(inverse)\n    inverse_row = row_heuristic(inverse)\n    inverse_inter = interaction_heuristic(inverse)\n    \n    min_col = min(original_col, transposed_col, inverse_col)\n    min_row = min(original_row, transposed_row, inverse_row)\n    min_inter = min(original_inter, transposed_inter, inverse_inter)\n    \n    return (min_col, min_row, min_inter)\n",
    "evaluation": {
      "fitness": 0.7202533955038778,
      "additional_data": {
        "spearman_correlation": "0.720253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 39,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 45,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        # Weighted combination favoring the logarithmic metric more\n        return (0.7 * (col_log + row_log) + 0.3 * (col_linear + row_linear),)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8716763259706536,
      "additional_data": {
        "spearman_correlation": "0.871676",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 40,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 46,
    "parent_id": 22,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic considering product of rows and columns and matrix transpose.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    option1 = tuple(sorted(col_sums * row_sums))\n    option2 = tuple(sorted(trans_col_sums * trans_row_sums))\n    return min(option1, option2)\n",
    "evaluation": {
      "fitness": 0.7591955728206541,
      "additional_data": {
        "spearman_correlation": "0.759196",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 49,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 47,
    "parent_id": 17,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sparsity = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        # Weighted combination based on empirical performance\n        return 0.4*log_col + 0.3*log_row + 0.2*sparsity + 0.05*col_var + 0.05*row_var\n    \n    n = matrix.shape[0]\n    best_score = float('inf')\n    \n    # Consider all row permutations\n    for perm in permutations(range(n)):\n        permuted = matrix[list(perm), :]\n        \n        # Consider original and transposed\n        variants = [\n            permuted,\n            permuted.T,\n            np.linalg.inv(permuted.astype(float)).astype(int) % 2,\n            np.linalg.inv(permuted.T.astype(float)).astype(int) % 2\n        ]\n        \n        for variant in variants:\n            score = evaluate(variant)\n            if score < best_score:\n                best_score = score\n                \n    return best_score\n",
    "evaluation": {
      "fitness": 0.5254231021038911,
      "additional_data": {
        "spearman_correlation": "0.525423",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 44,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 48,
    "parent_id": 30,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined column and row sum logarithms, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1.0)\n        row_sums = np.maximum(row_sums, 1.0)\n        return float(0.65 * np.sum(np.log(col_sums)) + 0.35 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.871724925385099,
      "additional_data": {
        "spearman_correlation": "0.871725",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 54,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 49,
    "parent_id": 28,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering weight-1 columns/rows and non-zero elements.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        # Only consider columns/rows with weight > 1\n        col_contrib = np.sum(np.log(col_sums[col_sums > 1])) if np.any(col_sums > 1) else 0\n        row_contrib = np.sum(np.log(row_sums[row_sums > 1])) if np.any(row_sums > 1) else 0\n        # Add small term for total non-zero elements\n        non_zero = np.sum(m != 0)\n        return float(col_contrib + row_contrib + 0.1 * non_zero)\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix).astype(int) % 2)\n    return min(original_heuristic, transpose_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7245126925347362,
      "additional_data": {
        "spearman_correlation": "0.724513",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 50,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 50,
    "parent_id": 42,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined heuristic using non-zero count and column sum metrics.\"\"\"\n    import numpy as np\n    \n    def count_nonzeros(m):\n        return np.count_nonzero(m)\n    \n    def column_metric(m):\n        col_sums = np.sum(m, axis=0)\n        # Avoid log(0) by replacing 0 with 1 (log(1)=0 doesn't affect sum)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        return np.sum(np.log2(col_sums))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T\n    ]\n    \n    h_nz = min(count_nonzeros(v) for v in variants)\n    h_col = min(column_metric(v) for v in variants)\n    \n    return (h_nz, h_col)\n",
    "evaluation": {
      "fitness": 0.8689352287895028,
      "additional_data": {
        "spearman_correlation": "0.868935",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 55,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 51,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic linear and log metrics\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        linear = np.sum(col_sums) + np.sum(row_sums)\n        \n        # Near-complete column/row metrics\n        near_col = np.sum((col_sums >= n-1) | (col_sums <= 1))\n        near_row = np.sum((row_sums >= n-1) | (row_sums <= 1))\n        \n        # Hamming weight distribution metric\n        col_entropy = -np.sum((col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        row_entropy = -np.sum((row_sums/n) * np.log2(np.maximum(row_sums/n, 1e-10)))\n        \n        # Return tuple prioritizing structural simplicity\n        return (col_entropy + row_entropy, \n                -(near_col + near_row), \n                col_log + row_log, \n                linear)\n    \n    # Generate all permutation variants (row and column permutations)\n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Also consider row/column permutations of inverse and transpose\n    best = min(original, inverse, transpose)\n    \n    # For small matrices, check some permutations\n    n = matrix.shape[0]\n    if n <= 4:\n        from itertools import permutations\n        for p in permutations(range(n)):\n            perm_matrix = matrix[np.array(p), :]\n            current = calculate_metrics(perm_matrix)\n            best = min(best, current)\n            \n            perm_matrix = matrix[:, np.array(p)]\n            current = calculate_metrics(perm_matrix)\n            best = min(best, current)\n    \n    return best\n",
    "evaluation": {
      "fitness": -0.5576546126019964,
      "additional_data": {
        "spearman_correlation": "-0.557655",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 51,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 52,
    "parent_id": 32,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # New metrics\n        identity_dist = np.sum(m != np.eye(n))\n        col_completion = np.sum(col_sums == 1)\n        row_completion = np.sum(row_sums == 1)\n        col_interactions = np.sum(np.logical_and(m[:, :, None], m[:, None, :]), axis=0).sum()\n        \n        return (log_cols + log_rows, \n                abs_cols + abs_rows, \n                -identity_dist,\n                -col_completion - row_completion,\n                -col_interactions)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8728112667472098,
      "additional_data": {
        "spearman_correlation": "0.872811",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 46,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 53,
    "parent_id": 18,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        hamming = np.sum(m)\n        max_col = np.max(col_sums)\n        \n        main_metric = log_col * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)) + max_col)\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    \n    return (min_main, min_secondary)\n",
    "evaluation": {
      "fitness": 0.7185523238971232,
      "additional_data": {
        "spearman_correlation": "0.718552",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 48,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 54,
    "parent_id": 25,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def col_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        non_zero = np.where(col_sums == 0, 1, col_sums)\n        log_terms = np.log2(non_zero + 1)\n        sqrt_terms = np.sqrt(col_sums)\n        return tuple(sorted(log_terms * sqrt_terms))\n    \n    def row_heuristics(m):\n        row_sums = np.sum(m, axis=1)\n        non_zero = np.where(row_sums == 0, 1, row_sums)\n        log_terms = np.log2(non_zero + 1)\n        sqrt_terms = np.sqrt(row_sums)\n        return tuple(sorted(log_terms * sqrt_terms))\n    \n    def get_all_heuristics(m):\n        original_col = col_heuristics(m)\n        original_row = row_heuristics(m)\n        transposed_col = col_heuristics(m.T)\n        transposed_row = row_heuristics(m.T)\n        inv = np.linalg.inv(m.astype(float)).astype(int) % 2\n        inv_col = col_heuristics(inv)\n        inv_row = row_heuristics(inv)\n        return min(original_col + original_row, \n                  transposed_col + transposed_row,\n                  inv_col + inv_row)\n    \n    return get_all_heuristics(matrix)\n",
    "evaluation": {
      "fitness": 0.6974411037156214,
      "additional_data": {
        "spearman_correlation": "0.697441",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 45,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 55,
    "parent_id": 25,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering original, transpose and inverse.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-5)\n        return float(np.sum(np.log(col_sums + 0.05)))\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    inverse_heuristic = calculate_heuristic(inverse)\n    inverse_transpose_heuristic = calculate_heuristic(inverse.T)\n    return min(original_heuristic, transpose_heuristic, inverse_heuristic, inverse_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.7238073804518289,
      "additional_data": {
        "spearman_correlation": "0.723807",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 47,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 56,
    "parent_id": 42,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_metric = np.sum(np.log(col_sums + 1))\n        row_metric = np.sum(np.log(row_sums + 1))\n        return (col_metric, row_metric)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    best_heuristic = min(column_heuristic(m) for m in variants)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 52,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 57,
    "parent_id": 42,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums and variants.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        # Sort column sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        # Add small term for column weight distribution\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, col_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8817377970298539,
      "additional_data": {
        "spearman_correlation": "0.881738",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 11,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 53,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 58,
    "parent_id": 20,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Minimum of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8658840755208309,
      "additional_data": {
        "spearman_correlation": "0.865884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 57,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 59,
    "parent_id": 42,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using column sums and logarithms.\"\"\"\n    import numpy as np\n    \n    def calculate_metric(m):\n        col_sums = np.sum(m, axis=0)\n        # Add small epsilon to avoid log(1) = 0 when column has single 1\n        epsilon = 1e-10\n        log_sums = np.log(col_sums + epsilon)\n        return np.sum(np.abs(log_sums))\n    \n    h_original = calculate_metric(matrix)\n    h_inverse = calculate_metric(np.linalg.inv(matrix))\n    h_transpose = calculate_metric(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.794408737408039,
      "additional_data": {
        "spearman_correlation": "0.794409",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 56,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 60,
    "parent_id": 25,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.log(col_sums + 1/np.max(col_sums))\n        log_row = np.log(row_sums + 1/np.max(row_sums))\n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)))\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    features.append(get_features(np.linalg.inv(matrix.astype(float)).astype(int) % 2))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7496047616347242,
      "additional_data": {
        "spearman_correlation": "0.749605",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 59,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 61,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering row/column dependencies and linear algebra properties.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Consider both column and row sum distributions\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Measure linear dependence via rank deficiency\n        rank_deficiency = m.shape[0] - rank\n        \n        # Measure interaction between rows and columns\n        interaction = np.sum(np.outer(row_sums, col_sums) * m)\n        \n        return (nonzeros, rank_deficiency, interaction, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8699841261094551,
      "additional_data": {
        "spearman_correlation": "0.869984",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 60,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 62,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering column/row basis proximity and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column completion: how close each column is to a basis vector\n        col_completion = np.sum([min(np.sum(col), np.sum(1-col)) for col in m.T])\n        \n        # Row completion similarly\n        row_completion = np.sum([min(np.sum(row), np.sum(1-row)) for row in m])\n        \n        # Interaction term: measures how columns overlap\n        interaction = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        # Column distribution (prioritize nearly-complete columns)\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        # Nonzeros with logarithmic weighting (smaller changes matter more near completion)\n        log_nonzeros = np.sum(np.log(np.count_nonzero(m, axis=0) + 1))\n        \n        return (col_completion + row_completion, interaction, log_nonzeros, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        matrix @ matrix.T,\n        np.linalg.inv(matrix @ matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.6835389610081907,
      "additional_data": {
        "spearman_correlation": "-0.683539",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 61,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 63,
    "parent_id": 44,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic incorporating rank, permutation distance, and weighted interactions.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        # Column metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_prod = np.prod(col_sums + (col_sums == 0))\n        \n        # Row metrics\n        row_sums = np.sum(m, axis=1)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_prod = np.prod(row_sums + (row_sums == 0))\n        \n        # Interaction terms\n        col_row_interaction = np.sum(col_sums * row_sums)\n        nnz_interaction = np.sum(col_nonzeros * row_nonzeros)\n        \n        # Distance from permutation matrix\n        perm_distance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        \n        # Matrix rank (binary rank)\n        rank = np.linalg.matrix_rank(m)\n        \n        return (\n            np.log(col_prod + 0.1),\n            np.log(row_prod + 0.1),\n            np.log(col_row_interaction + 0.1),\n            np.log(nnz_interaction + 0.1),\n            perm_distance,\n            -rank  # Lower rank is easier to synthesize\n        )\n    \n    # Original matrix metrics\n    orig_metrics = matrix_metrics(matrix)\n    \n    # Transposed matrix metrics\n    trans_metrics = matrix_metrics(matrix.T)\n    \n    # Inverse matrix metrics (if invertible)\n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        inv_metrics = matrix_metrics(inv_matrix)\n    except np.linalg.LinAlgError:\n        inv_metrics = (0, 0, 0, 0, float('inf'), 0)\n    \n    # Weighted combination of all variants\n    combined = tuple(\n        0.4 * min(o, t, i) + 0.3 * (o + t + i) / 3 + 0.3 * max(o, t, i)\n        for o, t, i in zip(orig_metrics, trans_metrics, inv_metrics)\n    )\n    \n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 64,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 64,
    "parent_id": 53,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def analyze_matrix(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic metrics\n        hamming = float(np.sum(m))\n        log_col = float(np.sum(np.log(np.maximum(col_sums, 1))))\n        log_row = float(np.sum(np.log(np.maximum(row_sums, 1))))\n        \n        # Column/row distribution metrics\n        col_nonzero = float(np.sum(col_sums > 0))\n        row_nonzero = float(np.sum(row_sums > 0))\n        col_entropy = -np.sum((col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        row_entropy = -np.sum((row_sums/n) * np.log2(np.maximum(row_sums/n, 1e-10)))\n        \n        # Diagonal analysis\n        diag = np.diag(m)\n        diag_sum = float(np.sum(diag))\n        off_diag_sum = hamming - diag_sum\n        \n        # Pairwise correlations\n        col_corr = float(np.sum(np.corrcoef(m, rowvar=False)[np.triu_indices(n, 1)]))\n        row_corr = float(np.sum(np.corrcoef(m, rowvar=True)[np.triu_indices(n, 1)]))\n        \n        # Weighted combination of metrics\n        main_metric = (0.4*hamming + 0.3*log_col + 0.2*col_entropy + 0.1*col_nonzero)\n        secondary_metric = (0.3*log_row + 0.2*row_entropy + 0.2*row_nonzero + \n                           0.1*diag_sum + 0.1*off_diag_sum + 0.1*(col_corr + row_corr))\n        \n        return main_metric, secondary_metric\n    \n    original = analyze_matrix(matrix)\n    transposed = analyze_matrix(matrix.T)\n    inverted = analyze_matrix(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    \n    return (min_main, min_secondary)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 62,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 65,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering row/column interactions and inverse/transpose.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        interaction = np.sum(np.abs(m @ m.T))\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        return (interaction, log_cols, tuple(sorted(col_sums + row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    transposed = calculate_heuristic(matrix.T)\n    inverted = calculate_heuristic(np.linalg.inv(matrix).astype(int) % 2)\n    \n    return min(original, transposed, inverted)\n",
    "evaluation": {
      "fitness": 0.6950652110475515,
      "additional_data": {
        "spearman_correlation": "0.695065",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 66,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 66,
    "parent_id": 58,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering all transformations and combining metrics.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums))) / 2\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inv_trans = calculate_heuristic(np.linalg.inv(matrix.T) % 2)\n    return min(original, inverse, transpose, inv_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 10)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 68,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 67,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional row metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        diag_sum = np.sum(np.diag(m))\n        \n        return (nonzeros, col_imbalance + row_imbalance, diag_sum, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8765909724249598,
      "additional_data": {
        "spearman_correlation": "0.876591",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 69,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 68,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add small terms for weight distribution\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance, row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823310788347797,
      "additional_data": {
        "spearman_correlation": "0.882331",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 72,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 69,
    "parent_id": 13,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums, transpose and inverse.\"\"\"\n    import numpy as np\n    from numpy.linalg import inv\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        weighted_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        return weighted_sum\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    try:\n        inverse_heuristic = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse_heuristic = float('inf')\n    min_heuristic = min(original_heuristic, transposed_heuristic, inverse_heuristic)\n    \n    return (min_heuristic, original_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7236995615096656,
      "additional_data": {
        "spearman_correlation": "0.723700",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 74,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 70,
    "parent_id": 45,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)  # Count of non-zero elements\n        \n        # Adjusted weights with small sparsity term\n        return (0.6 * (col_log + row_log) + 0.35 * (col_linear + row_linear) + 0.05 * sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8715545282823,
      "additional_data": {
        "spearman_correlation": "0.871555",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 73,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 71,
    "parent_id": 11,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums and row sums, plus inverse matrix column sums.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    col_sums = np.maximum(col_sums, 1)\n    col_heuristic = np.sum(np.log(col_sums))\n    \n    row_sums = np.sum(matrix, axis=1)\n    row_sums = np.maximum(row_sums, 1)\n    row_heuristic = np.sum(np.log(row_sums))\n    \n    inv_matrix = np.linalg.inv(matrix)\n    inv_col_sums = np.sum(inv_matrix, axis=0)\n    inv_col_sums = np.maximum(inv_col_sums, 1)\n    inv_col_heuristic = np.sum(np.log(inv_col_sums))\n    \n    return (float(col_heuristic), float(row_heuristic), float(inv_col_heuristic))\n",
    "evaluation": {
      "fitness": 0.7904678667445753,
      "additional_data": {
        "spearman_correlation": "0.790468",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 75,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 72,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823339493277182,
      "additional_data": {
        "spearman_correlation": "0.882334",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 14,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 71,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 73,
    "parent_id": 6,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined row and column sum product heuristic with transpose consideration.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    original_score = np.sum(col_sums * row_sums)\n    transposed_score = np.sum(col_sums * row_sums)\n    return (original_score, transposed_score)\n",
    "evaluation": {
      "fitness": 0.7285147130179891,
      "additional_data": {
        "spearman_correlation": "0.728515",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 78,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 74,
    "parent_id": 31,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        sum_part = np.sum(col_sums)\n        log_part = np.sum(np.log2(col_sums + 1))\n        return (sum_part, log_part)\n    \n    variants = [\n        matrix,\n        matrix.T,\n    ]\n    \n    try:\n        inv = np.linalg.inv(matrix)\n        if np.all(inv == inv.astype(int)):\n            variants.extend([inv, inv.T])\n    except:\n        pass\n    \n    return min(compute_metric(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 77,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 75,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional term for columns/rows with sum=1.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with sum exactly 1\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, cols_done + rows_done, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.857564829955204,
      "additional_data": {
        "spearman_correlation": "0.857565",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 80,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 76,
    "parent_id": 8,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering original, transpose, and inverses.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else float('inf')\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else float('inf')\n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.8725265272009427,
      "additional_data": {
        "spearman_correlation": "0.872527",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 79,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 77,
    "parent_id": 30,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with tuned weights and added matrix sum component.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-12)\n        row_sums = np.maximum(row_sums, 1e-12)\n        log_sum = 0.6 * np.sum(np.log(col_sums)) + 0.2 * np.sum(np.log(row_sums))\n        total_sum = 0.2 * np.sum(m)\n        return float(log_sum + total_sum)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8698573599469007,
      "additional_data": {
        "spearman_correlation": "0.869857",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 81,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 78,
    "parent_id": 29,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-10\n    \n    # Weighted column and row terms\n    weighted_col = np.sum(col_sums * np.log(col_sums + epsilon))\n    weighted_row = np.sum(row_sums * np.log(row_sums + epsilon))\n    \n    # Interaction terms between columns and rows\n    col_nonzeros = np.sum(matrix > 0, axis=0)\n    row_nonzeros = np.sum(matrix > 0, axis=1)\n    col_spread = np.sum(col_nonzeros * col_sums)\n    row_spread = np.sum(row_nonzeros * row_sums)\n    \n    # Combined heuristic components\n    h1 = weighted_col * weighted_row\n    h2 = col_spread + row_spread\n    h3 = np.sum(matrix)  # Total sum as tiebreaker\n    \n    return (h1, h2, h3)\n",
    "evaluation": {
      "fitness": 0.695707873596232,
      "additional_data": {
        "spearman_correlation": "0.695708",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 82,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 79,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weight-1 column/row counting.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with exactly one non-zero\n        col_weight1 = np.sum(col_sums == 1)\n        row_weight1 = np.sum(row_sums == 1)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, col_weight1 + row_weight1, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8730915715594452,
      "additional_data": {
        "spearman_correlation": "0.873092",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 84,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 80,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using squared deviations for column imbalance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        col_imbalance = np.sum((col_sums - 1) ** 2)  # Squared L2 norm\n        return (nonzeros, col_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8732927652425087,
      "additional_data": {
        "spearman_correlation": "0.873293",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 53,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 57,
      "exploited_organism_fitness": 0.8817377970298539,
      "child_number": 6
    }
  },
  {
    "id": 81,
    "parent_id": 63,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic incorporating rank, permutation distance, and weighted interactions.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        # Column metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_prod = np.prod(col_sums + (col_sums == 0))\n        \n        # Row metrics\n        row_sums = np.sum(m, axis=1)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_prod = np.prod(row_sums + (row_sums == 0))\n        \n        # Interaction terms\n        col_row_interaction = np.sum(col_sums * row_sums)\n        nnz_interaction = np.sum(col_nonzeros * row_nonzeros)\n        \n        # Distance from permutation matrix\n        perm_distance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        \n        # Matrix rank (binary rank)\n        rank = np.linalg.matrix_rank(m)\n        \n        return (\n            np.log(col_prod + 0.1),\n            np.log(row_prod + 0.1),\n            np.log(col_row_interaction + 0.1),\n            np.log(nnz_interaction + 0.1),\n            perm_distance,\n            -rank  # Lower rank is easier to synthesize\n        )\n    \n    # Original matrix metrics\n    orig_metrics = matrix_metrics(matrix)\n    \n    # Transposed matrix metrics\n    trans_metrics = matrix_metrics(matrix.T)\n    \n    # Inverse matrix metrics (if invertible)\n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        inv_metrics = matrix_metrics(inv_matrix)\n    except np.linalg.LinAlgError:\n        inv_metrics = (0.0, 0.0, 0.0, 0.0, float('inf'), 0.0)\n    \n    # Combine metrics from original, transposed, and inverse matrices\n    combined = []\n    for o, t, i in zip(orig_metrics, trans_metrics, inv_metrics):\n        combined.append(0.4 * min(o, t, i) + 0.3 * (o + t + i) / 3 + 0.3 * max(o, t, i))\n    \n    return tuple(combined)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 85,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 82,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better sensitivity to nearly-complete columns.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count number of perfect columns/rows\n        perfect_cols = np.sum(col_sums == 1)\n        perfect_rows = np.sum(row_sums == 1)\n        # Use log sums for better sensitivity\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = np.sum(np.log2(np.maximum(row_sums, 1)))\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, -perfect_cols-perfect_rows, log_col_sums+log_row_sums, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8813252822927019,
      "additional_data": {
        "spearman_correlation": "0.881325",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 86,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 83,
    "parent_id": 21,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Minimum of logarithms of column sums across transformations plus matrix sum.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums[col_sums == 0] = 1\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    matrix_sum = np.sum(matrix)\n    return (min(original, inverse, transpose), matrix_sum)\n",
    "evaluation": {
      "fitness": 0.867394505819075,
      "additional_data": {
        "spearman_correlation": "0.867395",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 87,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 84,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        return (col_log + row_log, col_sq + row_sq)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8588223254043595,
      "additional_data": {
        "spearman_correlation": "0.858822",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 42,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 85,
    "parent_id": 7,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using average of variants and including row sums.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    \n    return (h_original + h_inverse + h_transpose) / 3\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 8)"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 89,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 86,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using spectral properties and pattern analysis.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Pattern analysis metrics\n        spectral_radius = np.max(np.abs(np.linalg.eigvals(m)))\n        diag_dominance = np.sum(np.abs(m.diagonal())) / (nonzeros + 1e-9)\n        cluster_metric = np.sum(np.abs(m - np.roll(m, 1, axis=0))) + np.sum(np.abs(m - np.roll(m, 1, axis=1)))\n        \n        # Column/row structure metrics\n        col_entropy = np.sum(-col_sums * np.log(col_sums + 1e-9))\n        row_entropy = np.sum(-row_sums * np.log(row_sums + 1e-9))\n        \n        # Combined heuristic tuple\n        return (nonzeros, \n                spectral_radius, \n                -diag_dominance, \n                cluster_metric,\n                col_entropy + row_entropy)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 88,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 87,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inv_transpose = calculate_heuristic(np.linalg.inv(matrix.T) % 2)\n    return min(original, inverse, transpose, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8714564973852014,
      "additional_data": {
        "spearman_correlation": "0.871456",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 90,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 88,
    "parent_id": 73,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced column-sum logarithmic heuristic with inverse/transpose consideration.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        sorted_cols = np.sort(col_sums)[::-1]\n        log_scores = np.where(sorted_cols > 0, np.log2(sorted_cols), 0)\n        col_score = np.sum(log_scores)\n        row_score = np.sum(np.sum(m, axis=1))\n        return (col_score, row_score)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.T).astype(int) % 2)\n    \n    return min(original, transposed, inverse)\n",
    "evaluation": {
      "fitness": 0.7181826754529771,
      "additional_data": {
        "spearman_correlation": "0.718183",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 91,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 89,
    "parent_id": 17,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        log_col = np.sum(np.log(col_sums))\n        sparsity = np.sum(m)\n        return (log_col, sparsity)\n    \n    # Compute inverse with rounding for numerical stability\n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inv_matrix = np.linalg.inv(matrix.astype(float))\n    inv_matrix_rounded = np.round(inv_matrix).astype(int) % 2\n    inverse = evaluate(inv_matrix_rounded)\n    inv_transposed = np.linalg.inv(matrix.T.astype(float))\n    inv_transposed_rounded = np.round(inv_transposed).astype(int) % 2\n    inverse_transposed = evaluate(inv_transposed_rounded)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 67,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 90,
    "parent_id": 60,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.log(col_sums + 1/np.max(col_sums))\n        log_row = np.log(row_sums + 1/np.max(row_sums))\n        \n        # Count columns/rows with sum=1\n        cols1 = np.sum(col_sums == 1)\n        rows1 = np.sum(row_sums == 1)\n        \n        # Find minimum pairwise Hamming distance between columns/rows\n        min_col_dist = min(hamming(m[:,i], m[:,j]) for i in range(m.shape[1]) \n                          for j in range(i+1, m.shape[1])) if m.shape[1] > 1 else 0\n        min_row_dist = min(hamming(m[i,:], m[j,:]) for i in range(m.shape[0])\n                          for j in range(i+1, m.shape[0])) if m.shape[0] > 1 else 0\n        \n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)),\n                float(cols1), float(rows1), float(min_col_dist), float(min_row_dist))\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    features.append(get_features(np.linalg.inv(matrix.astype(float)).astype(int) % 2))\n    \n    # Also consider row/column permutations\n    for _ in range(2):\n        perm = np.random.permutation(matrix.shape[0])\n        features.append(get_features(matrix[perm,:]))\n        features.append(get_features(matrix[:,perm]))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7502757937738685,
      "additional_data": {
        "spearman_correlation": "0.750276",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 93,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 91,
    "parent_id": 33,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic considering diagonal patterns, spread, and overlapping entries.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.sum(np.diag(m))\n        anti_diag_sum = np.sum(np.diag(np.fliplr(m)))\n        \n        # Measure of how concentrated the 1s are\n        col_overlap = sum(np.sum(m[:,i] & m[:,j]) for i in range(n) for j in range(i+1, n))\n        row_overlap = sum(np.sum(m[i,:] & m[j,:]) for i in range(n) for j in range(i+1, n))\n        \n        # Distance from diagonal patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)), np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Combined metrics\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        lin_col = np.sum(col_sums)\n        overlap_metric = col_overlap + row_overlap\n        \n        return (diag_dist, overlap_metric, log_col, lin_col, diag_sum, anti_diag_sum)\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    inverse = matrix_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inv_transposed = matrix_metrics(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    \n    # Select best metrics across all variants\n    best_diag_dist = min(m[0] for m in metrics)\n    best_overlap = min(m[1] for m in metrics)\n    best_log_col = min(m[2] for m in metrics)\n    best_lin_col = min(m[3] for m in metrics)\n    best_diag_sum = max(m[4] for m in metrics)\n    best_anti_diag = max(m[5] for m in metrics)\n    \n    return (best_diag_dist, best_overlap, best_log_col, best_lin_col, best_diag_sum, best_anti_diag)\n",
    "evaluation": {
      "fitness": 0.41460875233212596,
      "additional_data": {
        "spearman_correlation": "0.414609",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 92,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 92,
    "parent_id": 53,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        unique_cols = len(np.unique(m, axis=1))\n        \n        col_complexity = np.sum(np.log(np.maximum(col_sums, 1))) + (m.shape[1] - unique_cols)\n        row_complexity = np.sum(np.log(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        \n        main_metric = col_complexity\n        secondary_metric = (row_complexity, max_col)\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary_row = min(original[1][0], transposed[1][0], inverted[1][0])\n    min_secondary_max = min(original[1][1], transposed[1][1], inverted[1][1])\n    \n    return (min_main, (min_secondary_row, min_secondary_max))\n",
    "evaluation": {
      "fitness": 0.7192150489560452,
      "additional_data": {
        "spearman_correlation": "0.719215",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 94,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 93,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional term for columns/rows with sum=1.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with sum=1\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, cols_done + rows_done, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.857564829955204,
      "additional_data": {
        "spearman_correlation": "0.857565",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 95,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 94,
    "parent_id": 39,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def col_log_sum(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        return np.sum(np.log(col_sums))\n    \n    def row_log_sum(m):\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1)\n        return np.sum(np.log(row_sums))\n    \n    def total_entries(m):\n        return np.sum(m)\n    \n    original_col = col_log_sum(matrix)\n    original_row = row_log_sum(matrix)\n    inverse_col = col_log_sum(np.linalg.inv(matrix) % 2)\n    transpose_col = col_log_sum(matrix.T)\n    total = total_entries(matrix)\n    \n    return (original_col, original_row, inverse_col, transpose_col, total)\n",
    "evaluation": {
      "fitness": 0.7930058212463202,
      "additional_data": {
        "spearman_correlation": "0.793006",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 96,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 95,
    "parent_id": 20,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.hstack([matrix, np.eye(n, dtype=int)])\n    for col in range(n):\n        pivot = np.where(aug[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            raise ValueError(\"Matrix is singular\")\n        pivot = pivot[0] + col\n        if pivot != col:\n            aug[[col, pivot]] = aug[[pivot, col]]\n        for r in range(n):\n            if r != col and aug[r, col]:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:]\n\ndef heuristic(matrix):\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(gf2_inv(matrix))\n    transpose = calculate_heuristic(matrix.T)\n    return tuple(sorted([original, inverse, transpose]))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 76,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 96,
    "parent_id": 83,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering multiple matrix transformations and features.\"\"\"\n    import numpy as np\n    \n    def compute_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums[col_sums == 0] = 1\n        row_sums[row_sums == 0] = 1\n        \n        log_cols = np.sum(np.log2(col_sums))\n        log_rows = np.sum(np.log2(row_sums))\n        near_cols = np.sum(col_sums == 1)\n        near_rows = np.sum(row_sums == 1)\n        total_sum = np.sum(m)\n        \n        return (log_cols + log_rows, -near_cols - near_rows, total_sum)\n    \n    transformations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix @ matrix.T % 2,\n        matrix.T @ matrix % 2\n    ]\n    \n    best_heuristic = min(compute_features(m) for m in transformations)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.2991361539909636,
      "additional_data": {
        "spearman_correlation": "0.299136",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 97,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 97,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional term for columns/rows with weight=1.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with weight exactly 1\n        weight_one_cols = np.sum(col_sums == 1)\n        weight_one_rows = np.sum(row_sums == 1)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, weight_one_cols + weight_one_rows, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8730915715594452,
      "additional_data": {
        "spearman_correlation": "0.873092",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 98,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 98,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Improved column term using logarithms\n        col_imbalance = np.sum(np.abs(np.log2(np.maximum(col_sums, 1))))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8821836928061644,
      "additional_data": {
        "spearman_correlation": "0.882184",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 99,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 99,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column sums and done columns count.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count number of already done columns/rows\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        # Logarithmic terms for columns close to done\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824198101895542,
      "additional_data": {
        "spearman_correlation": "0.882420",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 10,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 100,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 100,
    "parent_id": 17,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        weighted_sparsity = np.sum(m * np.arange(1, m.shape[0]+1)[:, np.newaxis])\n        return (log_col, log_row, non_zero_cols, non_zero_rows, weighted_sparsity)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7105327879020863,
      "additional_data": {
        "spearman_correlation": "0.710533",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 101,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 101,
    "parent_id": 78,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-5\n    \n    # Weighted column and row terms with adjusted epsilon\n    weighted_col = np.sum(col_sums * np.log(col_sums + epsilon))\n    weighted_row = np.sum(row_sums * np.log(row_sums + epsilon))\n    \n    # Enhanced interaction terms\n    col_nonzeros = np.sum(matrix > 0, axis=0)\n    row_nonzeros = np.sum(matrix > 0, axis=1)\n    min_col = np.min(col_sums + (col_sums == 0))\n    min_row = np.min(row_sums + (row_sums == 0))\n    col_spread = np.sum(col_nonzeros * col_sums) / min_col\n    row_spread = np.sum(row_nonzeros * row_sums) / min_row\n    \n    # Rebalanced heuristic components\n    h1 = weighted_col + weighted_row\n    h2 = col_spread + row_spread\n    h3 = np.sum(matrix)  # Total sum as tiebreaker\n    \n    return (h1, h2, h3)\n",
    "evaluation": {
      "fitness": 0.69568621084619,
      "additional_data": {
        "spearman_correlation": "0.695686",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 104,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 102,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Separate column and row imbalances with different weights\n        col_imbalance = np.sum(np.abs(col_sums - 1)) * 1.5\n        row_imbalance = np.sum(np.abs(row_sums - 1)) * 0.5\n        max_col = max(col_sums)\n        return (nonzeros, col_imbalance + row_imbalance, max_col, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8783097350311523,
      "additional_data": {
        "spearman_correlation": "0.878310",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 103,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 103,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column basis distances and mutual information.\"\"\"\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        basis = np.eye(n)\n        \n        # Column distances to nearest basis vector\n        col_distances = [min([hamming(m[:,i], basis[:,j]) for j in range(n)]) \n                        for i in range(n)]\n        total_col_dist = sum(col_distances)\n        \n        # Mutual information between columns\n        mutual_info = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                mutual_info += np.sum(m[:,i] & m[:,j])\n        \n        # Row-based metrics\n        row_sums = np.sum(m, axis=1)\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Column-based metrics\n        col_sums = np.sum(m, axis=0)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        \n        # Combine metrics with weights\n        return (total_col_dist, mutual_info, col_imbalance, row_imbalance)\n    \n    # Generate all 6 possible matrix variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        np.linalg.inv(matrix).T,\n        matrix.T.dot(np.linalg.inv(matrix))\n    ]\n    \n    # Return minimum heuristic across all variants\n    return min(get_heuristic(v) for v in variants if not np.isnan(v).any())\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 102,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 104,
    "parent_id": 85,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using minimum of variants and including row sums.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.35636150090110386,
      "additional_data": {
        "spearman_correlation": "0.356362",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 105,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 105,
    "parent_id": 29,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining raw sums and logarithmic terms.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-15\n    log_col_sums = np.log(col_sums + epsilon)\n    log_row_sums = np.log(row_sums + epsilon)\n    return (np.sum(matrix),) + tuple(sorted(log_col_sums)) + tuple(sorted(log_row_sums))\n",
    "evaluation": {
      "fitness": 0.7742032010392207,
      "additional_data": {
        "spearman_correlation": "0.774203",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 107,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 106,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural logs and squared imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824000552756744,
      "additional_data": {
        "spearman_correlation": "0.882400",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 106,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 107,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column sums and done columns count.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824000552756744,
      "additional_data": {
        "spearman_correlation": "0.882400",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 109,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 108,
    "parent_id": 75,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with more column focus and almost-done terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        cols_almost = np.sum(col_sums == 2)\n        sorted_cols = tuple(sorted(col_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, cols_done, rows_done, cols_almost, col_imbalance, row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8532566618514634,
      "additional_data": {
        "spearman_correlation": "0.853257",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 110,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 109,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural logarithmic column sums and done columns count.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count number of already done columns/rows\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        # Natural logarithmic terms for columns close to done\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824028238874156,
      "additional_data": {
        "spearman_correlation": "0.882403",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 111,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 110,
    "parent_id": 41,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        return (total_ones - n, n - col1_count, n - row1_count)\n    \n    candidates = []\n    # Original matrix features\n    candidates.append(get_features(matrix))\n    # Transpose features (swaps row/column metrics)\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse mod2 features (if computable)\n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    return min(candidates)  # Lexicographic min\n",
    "evaluation": {
      "fitness": 0.7361117408474325,
      "additional_data": {
        "spearman_correlation": "0.736112",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 58,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 111,
    "parent_id": 4,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    \n    def log_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        return float(np.sum(np.log(col_sums)))\n    \n    def ones_heuristic(m):\n        total_ones = np.sum(m)\n        return total_ones - n\n    \n    candidates = []\n    \n    # Original matrix\n    log_orig = log_heuristic(matrix)\n    ones_orig = ones_heuristic(matrix)\n    candidates.append((log_orig, ones_orig))\n    \n    # Inverse matrix\n    inv_real = np.linalg.inv(matrix)\n    inv_int = np.round(inv_real).astype(int)\n    inv_gf2 = inv_int % 2\n    log_inv = log_heuristic(inv_gf2)\n    ones_inv = ones_heuristic(inv_gf2)\n    candidates.append((log_inv, ones_inv))\n    \n    # Transpose matrix\n    trans = matrix.T\n    log_trans = log_heuristic(trans)\n    ones_trans = ones_heuristic(trans)\n    candidates.append((log_trans, ones_trans))\n    \n    return min(candidates, key=lambda x: (x[0], x[1]))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 10,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 4,
      "exploited_organism_fitness": 0.8658840755208309,
      "child_number": 11
    }
  },
  {
    "id": 112,
    "parent_id": 42,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.append(inv_mat)\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        h_val = np.sum(np.log2(col_weights))\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8673200736647143,
      "additional_data": {
        "spearman_correlation": "0.867320",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 43,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 42,
      "exploited_organism_fitness": 0.8749956633326059,
      "child_number": 5
    }
  },
  {
    "id": 113,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural log and max sum terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827838302711529,
      "additional_data": {
        "spearman_correlation": "0.882784",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 13,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 112,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 114,
    "parent_id": 68,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = next((r for r in range(col, n) if aug[r, col] == 1), None)\n            if pivot is None:\n                return mat.copy()\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance, row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(gf2_inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'next' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 72,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 68,
      "exploited_organism_fitness": 0.8823310788347797,
      "child_number": 1
    }
  },
  {
    "id": 115,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on matrix structure and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Interaction metrics\n        interaction = np.sum(m @ m.T)  # Measures row overlaps\n        col_interaction = np.sum(m.T @ m)  # Measures column overlaps\n        \n        # Rank-based metrics\n        rank = np.linalg.matrix_rank(m)\n        submatrix_ranks = sum(np.linalg.matrix_rank(m[:i, :i]) for i in range(1, n+1))\n        \n        # Structural metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        return (nonzeros, \n                -interaction, \n                -col_interaction, \n                n*n - rank*n, \n                -submatrix_ranks, \n                tri_diff, \n                -done_cols - done_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8700928948023736,
      "additional_data": {
        "spearman_correlation": "0.870093",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 113,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 116,
    "parent_id": 35,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_nonzero = np.count_nonzero(m)\n        max_col = float(np.max(col_sums))\n        \n        col_sums = np.maximum(col_sums, 1e-5)  # Slightly larger epsilon\n        row_sums = np.maximum(row_sums, 1e-5)\n        \n        h1 = float(np.sum(np.log(col_sums)))\n        h2 = float(np.sum(np.log(row_sums)))\n        h3 = float(total_nonzero)\n        h4 = max_col\n        return (h1, h2, h3, h4)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8680343618433753,
      "additional_data": {
        "spearman_correlation": "0.868034",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 114,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 117,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        # Use squared deviations to penalize higher weights more\n        col_imbalance = np.sum((col_sums - 1) ** 2)\n        # Sort column sums for consistent ordering\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8732927652425087,
      "additional_data": {
        "spearman_correlation": "0.873293",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 6,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 70,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 118,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column/row clustering and spectral properties.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Spectral properties\n        _, s, _ = np.linalg.svd(m)\n        spectral_entropy = -np.sum(s * np.log2(s + 1e-10))\n        \n        # Column/row clustering metrics\n        col_clusters = np.sum(np.abs(np.outer(col_sums, col_sums) - np.dot(m.T, m)))\n        row_clusters = np.sum(np.abs(np.outer(row_sums, row_sums) - np.dot(m, m.T)))\n        \n        # Distance from nearest permutation matrix\n        perm_dist = np.sum(np.minimum(m, 1-m))\n        \n        # Column/row interaction terms\n        col_inter = np.sum(np.log2(np.maximum(col_sums, 1)) * (col_sums > 1))\n        row_inter = np.sum(np.log2(np.maximum(row_sums, 1)) * (row_sums > 1))\n        \n        # Non-linear combinations\n        weighted_nonzeros = np.sum(m * (1 + 0.5 * (col_sums - 1)[None,:]))\n        \n        return (spectral_entropy, col_clusters + row_clusters, perm_dist, \n                weighted_nonzeros, col_inter + row_inter, *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": -0.8049852279742643,
      "additional_data": {
        "spearman_correlation": "-0.804985",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 115,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 119,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    matrix = matrix.astype(int)\n    \n    def is_permutation(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        return np.all(row_sums == 1) and np.all(col_sums == 1)\n    \n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        return (col_log + row_log, col_linear + row_linear)\n    \n    orig = matrix\n    inv = gf2_inv(orig)\n    trans = orig.T\n    inv_trans = inv.T\n    candidates = [orig, inv, trans, inv_trans]\n    \n    for cand in candidates:\n        if is_permutation(cand):\n            return (0.0, 0.0)\n    \n    metrics = [calculate_metrics(cand) for cand in candidates]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8746468169602185,
      "additional_data": {
        "spearman_correlation": "0.874647",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 24,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 26,
      "exploited_organism_fitness": 0.8740312768287192,
      "child_number": 5
    }
  },
  {
    "id": 120,
    "parent_id": 86,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column/row patterns and nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = np.sum(-col_sums * np.log(col_sums + 1e-9))\n        row_entropy = np.sum(-row_sums * np.log(row_sums + 1e-9))\n        return (nonzeros, col_entropy + row_entropy)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 118,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 121,
    "parent_id": 112,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.append(inv_mat)\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)  # avoid log(0)\n        h_val = np.sum(np.log(col_weights))  # changed from log2 to natural log\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8666245809809193,
      "additional_data": {
        "spearman_correlation": "0.866625",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 117,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 122,
    "parent_id": 47,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Handle near-zero sums to avoid log issues\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Focus on columns/rows that are almost done (sum near 1)\n        col_proximity = np.sum(np.abs(col_sums - 1))\n        row_proximity = np.sum(np.abs(row_sums - 1))\n        \n        # Count problematic columns/rows (sum > 1)\n        problematic_cols = np.sum(col_sums > 1)\n        problematic_rows = np.sum(row_sums > 1)\n        \n        # Measure of total work needed\n        total_work = np.sum(m)\n        \n        # Interaction term between columns and rows\n        interaction = np.sum(m @ m.T)\n        \n        # Combine terms non-linearly\n        score = (total_work * (problematic_cols + problematic_rows + 1) * \n                (col_proximity + row_proximity + 1) / \n                (interaction + 1))\n        \n        return score\n    \n    n = matrix.shape[0]\n    best_score = float('inf')\n    \n    # Consider all row permutations\n    for perm in permutations(range(min(n, 5))):  # Limit permutations for speed\n        permuted = matrix[list(perm), :]\n        \n        # Consider original, transposed, and inverses\n        variants = [\n            permuted,\n            permuted.T,\n            np.linalg.inv(permuted.astype(float)).astype(int) % 2,\n            np.linalg.inv(permuted.T.astype(float)).astype(int) % 2\n        ]\n        \n        for variant in variants:\n            try:\n                score = evaluate(variant)\n                if score < best_score:\n                    best_score = score\n            except:\n                continue\n                \n    return best_score\n",
    "evaluation": {
      "fitness": 0.4946568981567263,
      "additional_data": {
        "spearman_correlation": "0.494657",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 116,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 123,
    "parent_id": 76,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column and row sums, considering original, transpose, and inverses.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)))\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else float('inf')\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else float('inf')\n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.8746192847101879,
      "additional_data": {
        "spearman_correlation": "0.874619",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 121,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 124,
    "parent_id": 70,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with adjusted weights and epsilon.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.sum(np.diag(m))\n        col_sums = np.maximum(col_sums, 1e-5)\n        row_sums = np.maximum(row_sums, 1e-5)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)\n        \n        return (0.55 * (col_log + row_log) + 0.4 * (col_linear + row_linear) + 0.05 * sparsity - 0.01 * diag_sum,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8706525985726903,
      "additional_data": {
        "spearman_correlation": "0.870653",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 120,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 125,
    "parent_id": 7,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    h_col_orig = calculate_heuristic(matrix)\n    h_row_orig = calculate_heuristic(matrix.T)\n    inv_matrix = np.linalg.inv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    h_col_inv = calculate_heuristic(inv_matrix)\n    h_row_inv = calculate_heuristic(inv_matrix.T)\n    \n    return max(h_col_orig, h_row_orig, h_col_inv, h_row_inv)\n",
    "evaluation": {
      "fitness": 0.7754139982348915,
      "additional_data": {
        "spearman_correlation": "0.775414",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 63,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 126,
    "parent_id": 45,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m != 0)\n        \n        # Adjusted weights with additional sparsity term\n        return (0.65 * (col_log + row_log) + 0.25 * (col_linear + row_linear) + 0.1 * sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8722803999110319,
      "additional_data": {
        "spearman_correlation": "0.872280",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 123,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 127,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional column/row distribution features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        prod_cols = np.prod(np.maximum(col_sums, 1))\n        var_cols = np.var(col_sums)\n        min_col = np.min(col_sums)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                prod_cols, var_cols, min_col, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827393502907324,
      "additional_data": {
        "spearman_correlation": "0.882739",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 122,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 128,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        full_cols = np.sum(col_sums == m.shape[0])\n        full_rows = np.sum(row_sums == m.shape[1])\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        var_col = np.var(col_sums)\n        var_row = np.var(row_sums)\n        return (nonzeros, -done_cols-done_rows-zero_cols-zero_rows-full_cols-full_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, min_col + min_row, var_col + var_row,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.878077135470793,
      "additional_data": {
        "spearman_correlation": "0.878077",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 119,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 129,
    "parent_id": 100,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-5)\n        row_sums = np.maximum(row_sums, 1e-5)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        weighted_sparsity = np.sum(m * (2 ** np.arange(m.shape[0]))[:, np.newaxis])\n        total_sum = np.sum(m)\n        return (log_col, log_row, non_zero_cols, non_zero_rows, weighted_sparsity, total_sum)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    \n    try:\n        inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n        inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n        return min(original, transposed, inverse, inverse_transposed)\n    except:\n        return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.710480099203799,
      "additional_data": {
        "spearman_correlation": "0.710480",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 125,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 130,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with log2 and weighted imbalance terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2 * np.sum(np.abs(col_sums - 1))  # Weighted\n        row_imbalance = 2 * np.sum(np.abs(row_sums - 1))  # Weighted\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828008598681549,
      "additional_data": {
        "spearman_correlation": "0.882801",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 6,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 124,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 131,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with multiplied log terms and correct count terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        log_product = log_cols * log_rows\n        correct_total = correct_cols + correct_rows\n        return (nonzeros, -correct_total, log_product, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882786781755246,
      "additional_data": {
        "spearman_correlation": "0.882787",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 128,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 132,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic with advanced column/row analysis and structural metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Advanced column/row analysis\n        col_weights = np.sort(col_sums)[::-1]\n        row_weights = np.sort(row_sums)[::-1]\n        col_entropy = -np.sum(col_sums * np.log(np.where(col_sums > 0, col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log(np.where(row_sums > 0, row_sums, 1)))\n        \n        # Structural metrics\n        triangularity = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                triangularity += m[i,j]\n        \n        # Dependency metrics\n        col_deps = np.sum(m[:,:,None] * m[:,None,:], axis=0).sum()\n        row_deps = np.sum(m[None,:,:] * m[:,None,:], axis=2).sum()\n        \n        # Combined metrics\n        imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        log_weights = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        \n        return (nonzeros, -done_cols-done_rows, log_weights, imbalance,\n                col_entropy + row_entropy, triangularity, col_deps + row_deps,\n                *col_weights, *row_weights)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8822443656654954,
      "additional_data": {
        "spearman_correlation": "0.882244",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 126,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 133,
    "parent_id": 103,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column basis distances.\"\"\"\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_heuristic(m):\n        # Convert to binary matrix (0/1)\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        basis = np.eye(n, dtype=int)\n        \n        # Column distances to nearest basis vector\n        col_distances = [min([hamming(m[:,i], basis[:,j]) for j in range(n)]) \n                        for i in range(n)]\n        total_col_dist = sum(col_distances)\n        \n        # Row-based metrics\n        row_sums = np.sum(m, axis=1)\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Column-based metrics\n        col_sums = np.sum(m, axis=0)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        \n        return (total_col_dist, col_imbalance, row_imbalance)\n    \n    # Generate all 6 possible matrix variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        np.linalg.inv(matrix).T,\n        matrix.T.dot(np.linalg.inv(matrix))\n    ]\n    \n    # Filter valid variants and convert to binary\n    valid_variants = []\n    for v in variants:\n        try:\n            v_bin = (v % 2).astype(int)\n            if not np.isnan(v_bin).any():\n                valid_variants.append(v_bin)\n        except:\n            continue\n    \n    return min(get_heuristic(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.4742759104144891,
      "additional_data": {
        "spearman_correlation": "0.474276",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 131,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 134,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        prod_cols = np.prod(np.maximum(col_sums, 1))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        var_col = np.var(col_sums)\n        return (nonzeros, -done_cols-done_rows-zero_cols-zero_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, prod_cols, var_col, min_col,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8781173885806756,
      "additional_data": {
        "spearman_correlation": "0.878117",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 127,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 135,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column/row matches.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count matching column pairs\n        cols = m.T\n        col_pairs = sum(np.array_equal(cols[i], cols[j]) \n                       for i in range(len(cols)) \n                       for j in range(i+1, len(cols)))\n        \n        # Count matching row pairs\n        rows = m\n        row_pairs = sum(np.array_equal(rows[i], rows[j])\n                       for i in range(len(rows))\n                       for j in range(i+1, len(rows)))\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -(col_pairs + row_pairs), *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823339493277182,
      "additional_data": {
        "spearman_correlation": "0.882334",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 132,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 136,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with pairwise interactions and binary log terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Calculate pairwise column and row overlaps\n        col_overlaps = np.sum((m.T @ m) > 0) - n\n        row_overlaps = np.sum((m @ m.T) > 0) - n\n        \n        # Count lonely 1s (single 1s with no overlaps)\n        lonely_cols = np.sum((col_sums == 1) & (np.sum(m @ m.T, axis=1) == 1))\n        lonely_rows = np.sum((row_sums == 1) & (np.sum(m.T @ m, axis=1) == 1))\n        \n        # Use log2 instead of natural log\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Column/row imbalance metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Max terms\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Sorted terms\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, -col_overlaps-row_overlaps, -lonely_cols-lonely_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, max_col + max_row,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.7148911477584682,
      "additional_data": {
        "spearman_correlation": "0.714891",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 129,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 137,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column-focused metrics\n        unique_cols = len(set(tuple(col) for col in m.T))\n        basis_cols = np.linalg.matrix_rank(m)\n        col_overlaps = sum(np.dot(m[:,i], m[:,j]) for i in range(m.shape[1]) for j in range(i+1, m.shape[1]))\n        \n        # Advanced column metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        # Column completion metrics\n        col_completion = sum(1 for s in col_sums if s == 1)\n        col_near_completion = sum(1/(1+abs(s-1)) for s in col_sums)\n        \n        # Combined metrics\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        max_col = np.max(col_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                upper_tri_nonzeros,\n                col_overlaps,\n                log_cols,\n                col_imbalance,\n                max_col,\n                -col_near_completion,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 130,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 138,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        total_ones = np.sum(m)\n        return float(total_ones), float(np.sum(np.log(col_sums)))\n    \n    # Original matrix\n    candidate0 = calculate_heuristic(matrix)\n    \n    # Transpose of original matrix\n    candidate2 = calculate_heuristic(matrix.T)\n    \n    # Correct inverse mod2 using adjugate method\n    det = np.linalg.det(matrix)\n    adj = np.round(det * np.linalg.inv(matrix)).astype(int)\n    inv_matrix = adj % 2\n    candidate1 = calculate_heuristic(inv_matrix)\n    \n    return min(candidate0, candidate1, candidate2)\n",
    "evaluation": {
      "fitness": 0.8672980321790988,
      "additional_data": {
        "spearman_correlation": "0.867298",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 83,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 139,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        n = len(col_sums)\n        weight = 0\n        log_weight = 0\n        ones = 0\n        dist = 0\n        \n        for s in col_sums:\n            if s == 1:\n                ones += 1\n            else:\n                weight += s\n                log_weight += np.log(s) if s > 0 else 0\n                dist += abs(s - 1)\n        \n        col_entropy = -np.sum([(s/n)*np.log(s/n) for s in col_sums if s > 0])\n        sorted_sums = tuple(sorted(col_sums))\n        \n        return (weight, -ones, log_weight, dist, col_entropy, *sorted_sums)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(column_metrics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 133,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 140,
    "parent_id": 34,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining inverse/transpose alternatives and row information.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + 0.1 * float(np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 10)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 134,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 141,
    "parent_id": 36,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums, with min across all matrix variants.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    \n    return (float(original), float(min(transposed, inverted, inv_transposed)))\n",
    "evaluation": {
      "fitness": 0.7896411424381622,
      "additional_data": {
        "spearman_correlation": "0.789641",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 135,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 142,
    "parent_id": 104,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using minimum of variants and including row sums.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    h_inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.35636150090110386,
      "additional_data": {
        "spearman_correlation": "0.356362",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 136,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 143,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining multiple metrics and considering variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        return (log_col, log_row, sum_total)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8730732746104316,
      "additional_data": {
        "spearman_correlation": "0.873073",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 138,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 144,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Combine column and row imbalances\n        imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        return (nonzeros, imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823339493277182,
      "additional_data": {
        "spearman_correlation": "0.882334",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 139,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 145,
    "parent_id": 56,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_metric = np.sum(np.log(col_sums + 1))\n        row_metric = np.sum(np.log(row_sums + 1))\n        return col_metric + row_metric\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    best_heuristic = min(column_heuristic(m) for m in variants)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": -0.06070223842947512,
      "additional_data": {
        "spearman_correlation": "-0.060702",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 142,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 146,
    "parent_id": 69,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering multiple matrix properties.\"\"\"\n    import numpy as np\n    \n    def matrix_properties(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (total_ones, weighted_col, weighted_row, col_variance + row_variance)\n    \n    original_props = matrix_properties(matrix)\n    transposed_props = matrix_properties(matrix.T)\n    \n    return min(original_props, transposed_props)\n",
    "evaluation": {
      "fitness": 0.7809953110444684,
      "additional_data": {
        "spearman_correlation": "0.780995",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 137,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 147,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Multi-metric heuristic considering original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        log_sum = np.sum(np.log(col_sums))\n        element_sum = np.sum(m)\n        return (log_sum, element_sum)\n    \n    original_metrics = compute_metrics(matrix)\n    inv_metrics = compute_metrics(np.linalg.inv(matrix))\n    trans_metrics = compute_metrics(matrix.T)\n    \n    return min(original_metrics, inv_metrics, trans_metrics)\n",
    "evaluation": {
      "fitness": -0.18870734847506096,
      "additional_data": {
        "spearman_correlation": "-0.188707",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 141,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 148,
    "parent_id": 46,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    if n == 0:\n        return (0,)\n\n    # Function to compute GF(2) inverse\n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n_inv, dtype=int)))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                pivot = col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n        candidates = [matrix, matrix.T, inv_matrix, inv_matrix.T]\n    except:\n        candidates = [matrix, matrix.T]\n\n    best_tuple = None\n    for cand in candidates:\n        total_ones = np.sum(cand)\n        row_sums = np.sum(cand, axis=1)\n        col_sums = np.sum(cand, axis=0)\n        error_vector = [abs(row_sums[i]-1) * abs(col_sums[i]-1) for i in range(n)]\n        error_vector_sorted = sorted(error_vector)\n        cand_tuple = (total_ones,) + tuple(error_vector_sorted)\n        \n        if best_tuple is None or cand_tuple < best_tuple:\n            best_tuple = cand_tuple\n            \n    return best_tuple\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 65,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 149,
    "parent_id": 130,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted log and imbalance weights.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 1.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827838302711529,
      "additional_data": {
        "spearman_correlation": "0.882784",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 140,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 150,
    "parent_id": 73,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with proper transposed matrix handling and logarithmic weighting.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    original_score = np.sum(np.log1p(col_sums) * np.sum(np.log1p(row_sums))\n    transposed_matrix = matrix.T\n    trans_col_sums = np.sum(transposed_matrix, axis=0)\n    trans_row_sums = np.sum(transposed_matrix, axis=1)\n    transposed_score = np.sum(np.log1p(trans_col_sums)) * np.sum(np.log1p(trans_row_sums))\n    return (original_score, transposed_score)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 7)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 149,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 151,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic based on proximity to column sum of 1.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    proximity = [1/(abs(s-1)+0.01) for s in col_sums]  # +0.01 to avoid division by zero\n    return tuple(sorted(proximity))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 151,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 152,
    "parent_id": 46,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import det, matrix_rank, svd\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_cols = np.log(col_sums + 1)\n        log_rows = np.log(row_sums + 1)\n        _, singular_values, _ = svd(m)\n        rank = matrix_rank(m)\n        det_val = abs(det(m)) if m.shape[0] == m.shape[1] else 1\n        \n        primary = np.sum(log_cols * log_rows)\n        secondary = rank * np.sum(singular_values)\n        tertiary = det_val if det_val != 0 else 1\n        return (primary, secondary, tertiary)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 146,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 153,
    "parent_id": 13,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums with adjusted weighting.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return 0.7 * weighted_col + 0.3 * weighted_row\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    min_heuristic = min(original_heuristic, transposed_heuristic)\n    \n    return (min_heuristic, original_heuristic)\n",
    "evaluation": {
      "fitness": 0.7965274910707586,
      "additional_data": {
        "spearman_correlation": "0.796527",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 150,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 154,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, inverse transpose, and logarithmic imbalance.\"\"\"\n    import numpy as np\n\n    def gf2_inv(matrix):\n        \"\"\"Compute inverse of binary matrix over GF(2).\"\"\"\n        n = matrix.shape[0]\n        mat_int = matrix.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for i in range(n):\n            if aug[i, i] == 0:\n                for j in range(i+1, n):\n                    if aug[j, i] == 1:\n                        aug[[i, j]] = aug[[j, i]]\n                        break\n                else:\n                    raise ValueError(\"Matrix is singular.\")\n            for j in range(n):\n                if j != i and aug[j, i] == 1:\n                    aug[j] = (aug[j] + aug[i]) % 2\n        return aug[:, n:].astype(int)\n\n    def get_heuristic(m):\n        \"\"\"Compute heuristic tuple for a single matrix.\"\"\"\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Logarithmic imbalance (prioritizes near-complete columns/rows)\n        log_imbalance = np.sum(np.log(col_sums)) + np.sum(np.log(row_sums))\n        # Absolute deviation from ideal weight (1)\n        abs_imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        # Sorted distributions\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, log_imbalance, abs_imbalance, *sorted_cols, *sorted_rows)\n    \n    # Generate candidate matrices\n    try:\n        inv_matrix = gf2_inv(matrix)\n        candidates = [\n            matrix,\n            matrix.T,\n            inv_matrix,\n            inv_matrix.T\n        ]\n    except:\n        candidates = [matrix, matrix.T]\n    \n    # Return minimal heuristic across candidates\n    return min(get_heuristic(cand) for cand in candidates)\n",
    "evaluation": {
      "fitness": 0.8719706329633053,
      "additional_data": {
        "spearman_correlation": "0.871971",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 71,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 72,
      "exploited_organism_fitness": 0.8823339493277182,
      "child_number": 12
    }
  },
  {
    "id": 155,
    "parent_id": 115,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on hierarchical column interactions and decomposition complexity.\"\"\"\n    import numpy as np\n    \n    def matrix_complexity(m):\n        n = m.shape[0]\n        if n == 0:\n            return (0,)\n        \n        # Column interaction metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(col_sums)\n        row_nonzeros = np.count_nonzero(row_sums)\n        \n        # Hierarchical decomposition metrics\n        upper = np.triu(m, k=1)\n        lower = np.tril(m, k=-1)\n        diag = np.diag(m)\n        \n        upper_nnz = np.count_nonzero(upper)\n        lower_nnz = np.count_nonzero(lower)\n        diag_nnz = np.count_nonzero(diag)\n        \n        # Column dependency metrics\n        col_deps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                col_deps.append(overlap)\n        \n        avg_col_dep = np.mean(col_deps) if col_deps else 0\n        max_col_dep = max(col_deps) if col_deps else 0\n        \n        # Row dependency metrics\n        row_deps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[i,:] & m[j,:])\n                row_deps.append(overlap)\n        \n        avg_row_dep = np.mean(row_deps) if row_deps else 0\n        max_row_dep = max(row_deps) if row_deps else 0\n        \n        # Block decomposition metrics\n        half = n // 2\n        tl = m[:half, :half]\n        tr = m[:half, half:]\n        bl = m[half:, :half]\n        br = m[half:, half:]\n        \n        block_complexity = (np.count_nonzero(tl) + np.count_nonzero(tr) +\n                           np.count_nonzero(bl) + np.count_nonzero(br))\n        \n        return (np.count_nonzero(m),\n                -col_nonzeros,\n                -row_nonzeros,\n                upper_nnz + lower_nnz,\n                -diag_nnz,\n                avg_col_dep,\n                max_col_dep,\n                avg_row_dep,\n                max_row_dep,\n                block_complexity)\n    \n    h_original = matrix_complexity(matrix)\n    try:\n        h_inverse = matrix_complexity(np.linalg.inv(matrix))\n    except:\n        h_inverse = float('inf')\n    h_transpose = matrix_complexity(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'float' and 'tuple'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 143,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 156,
    "parent_id": 130,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column metrics\n        col_dependencies = np.sum(m @ m.T > 0) - m.shape[0]\n        col_overlaps = np.sum((m.T @ m) > 1)\n        col_completion = np.sum(col_sums == 1)\n        col_operations = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        \n        # Row metrics\n        row_completion = np.sum(row_sums == 1)\n        row_operations = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Interaction metrics\n        col_interactions = np.sum((m.T @ m) * (1 - np.eye(m.shape[1])))\n        row_interactions = np.sum((m @ m.T) * (1 - np.eye(m.shape[0])))\n        \n        # Column sequences\n        col_sequences = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_sequences += np.any(m[:,i] & m[:,j])\n        \n        return (nonzeros, \n                -col_completion-row_completion,\n                col_operations + row_operations,\n                col_imbalance + row_imbalance,\n                col_dependencies,\n                col_overlaps,\n                col_interactions,\n                row_interactions,\n                col_sequences)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 144,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 157,
    "parent_id": 69,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both row and column sums, transpose and inverse.\"\"\"\n    import numpy as np\n    from numpy.linalg import inv\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_weight = np.sum(np.log2(np.maximum(col_sums, 1)))\n        row_weight = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return min(col_weight, row_weight)\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    try:\n        inverse_heuristic = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse_heuristic = float('inf')\n    min_heuristic = min(original_heuristic, transposed_heuristic, inverse_heuristic)\n    \n    return (min_heuristic, original_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7266600054696384,
      "additional_data": {
        "spearman_correlation": "0.726660",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 152,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 158,
    "parent_id": 92,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column-based metrics\n        col_nonzero = np.count_nonzero(col_sums)\n        col_entropy = -np.sum((col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        \n        # Row-based metrics\n        row_nonzero = np.count_nonzero(row_sums)\n        \n        # Matrix structure metrics\n        rank = np.linalg.matrix_rank(m)\n        identity_diff = np.sum(m != np.eye(n))\n        \n        # Column similarity\n        unique_cols = len(np.unique(m, axis=1))\n        col_correlations = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_correlations += np.sum(m[:,i] != m[:,j])\n        \n        main_metric = col_entropy + (n - rank)\n        secondary_metric = (identity_diff, col_nonzero)\n        tertiary_metric = (col_correlations, unique_cols)\n        \n        return main_metric, secondary_metric, tertiary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary_diff = min(original[1][0], transposed[1][0], inverted[1][0])\n    min_secondary_nonzero = min(original[1][1], transposed[1][1], inverted[1][1])\n    min_tertiary_corr = min(original[2][0], transposed[2][0], inverted[2][0])\n    min_tertiary_unique = min(original[2][1], transposed[2][1], inverted[2][1])\n    \n    return (min_main, (min_secondary_diff, min_secondary_nonzero), (min_tertiary_corr, min_tertiary_unique))\n",
    "evaluation": {
      "fitness": -0.4114822402797338,
      "additional_data": {
        "spearman_correlation": "-0.411482",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 147,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 159,
    "parent_id": 137,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        col_completion = sum(1 for s in col_sums if s == 1)\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                log_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8824026700296522,
      "additional_data": {
        "spearman_correlation": "0.882403",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 158,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 160,
    "parent_id": 130,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural log and adjusted weights.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 1.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row,\n                done_cols + done_rows, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827838302711529,
      "additional_data": {
        "spearman_correlation": "0.882784",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 153,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 161,
    "parent_id": 69,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import inv, matrix_power\n    \n    def matrix_entropy(m):\n        m = m.astype(float)\n        total = np.sum(m)\n        if total == 0:\n            return 0\n        prob = m / total\n        prob = prob[prob > 0]\n        return -np.sum(prob * np.log2(prob))\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        entropy = matrix_entropy(m)\n        return (weighted_col + weighted_row) / 2 + entropy\n    \n    original = calculate_heuristic(matrix)\n    transposed = calculate_heuristic(matrix.T)\n    try:\n        inverse = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse = float('inf')\n    try:\n        product = calculate_heuristic((matrix @ matrix.T) % 2)\n    except:\n        product = float('inf')\n    \n    min_h = min(original, transposed, inverse, product)\n    max_h = max(original, transposed, inverse, product)\n    mean_h = np.mean([h for h in [original, transposed, inverse, product] if h != float('inf')])\n    \n    return (min_h, mean_h, max_h, matrix_entropy(matrix), np.sum(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 38)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 155,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 162,
    "parent_id": 130,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.5 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Weight columns more\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.5 * np.sum(np.abs(col_sums - 1))  # Increased weight\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))  # Adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,  # Added positive correct term\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882809815719059,
      "additional_data": {
        "spearman_correlation": "0.882810",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 13,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 154,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 163,
    "parent_id": 121,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.maximum(row_weights, 1)\n        \n        log_col = np.sum(np.log(col_weights))\n        log_row = np.sum(np.log(row_weights))\n        sum_weights = np.sum(m)\n        \n        h_val = 0.5 * log_col + 0.3 * log_row + 0.2 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.87208589077508,
      "additional_data": {
        "spearman_correlation": "0.872086",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 157,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 164,
    "parent_id": 34,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering min of original/inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + 0.1 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8692053449788205,
      "additional_data": {
        "spearman_correlation": "0.869205",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 160,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 165,
    "parent_id": 98,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better row terms and all matrix variants.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Improved column term using logarithms\n        col_imbalance = np.sum(np.abs(np.log2(np.maximum(col_sums, 1))))\n        # Better row term counting non-unit rows\n        row_imbalance = np.sum(row_sums != 1)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, col_imbalance + row_imbalance, max_col, max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8810130544918161,
      "additional_data": {
        "spearman_correlation": "0.881013",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 159,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 166,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use absolute deviations for both columns and rows\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # Sort both column and row sums for more information\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823339493277182,
      "additional_data": {
        "spearman_correlation": "0.882334",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 162,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 167,
    "parent_id": 46,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic keeping row and column sums separate and including both matrix and transpose.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    option1 = tuple(col_sums) + tuple(row_sums)\n    option2 = tuple(trans_col_sums) + tuple(trans_row_sums)\n    return min(option1, option2)\n",
    "evaluation": {
      "fitness": 0.5050660960030456,
      "additional_data": {
        "spearman_correlation": "0.505066",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 164,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 168,
    "parent_id": 84,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        non_zero = np.sum(m != 0)\n        return (col_log + row_log, non_zero)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8588360056329968,
      "additional_data": {
        "spearman_correlation": "0.858836",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 163,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 169,
    "parent_id": 141,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums, with min across all matrix variants.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    transposed_inverted = compute_metric(np.linalg.inv(matrix.T))\n    \n    return (float(original), float(min(transposed, inverted, inv_transposed, transposed_inverted)))\n",
    "evaluation": {
      "fitness": 0.7896411432296002,
      "additional_data": {
        "spearman_correlation": "0.789641",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 168,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 170,
    "parent_id": 115,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional column proximity and uniqueness metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        near_done_cols = np.sum(np.abs(col_sums - 1) < 0.5)\n        \n        # Interaction metrics\n        interaction = np.sum(m @ m.T)\n        col_interaction = np.sum(m.T @ m)\n        \n        # Rank-based metrics\n        rank = np.linalg.matrix_rank(m)\n        submatrix_ranks = sum(np.linalg.matrix_rank(m[:i, :i]) for i in range(1, n+1))\n        \n        # Structural metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        # Uniqueness metrics\n        unique_rows = len(set(tuple(row) for row in m))\n        unique_cols = len(set(tuple(col) for col in m.T))\n        \n        # Column sum log metrics\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        return (nonzeros, \n                -interaction, \n                -col_interaction, \n                n*n - rank*n, \n                -submatrix_ranks, \n                tri_diff, \n                -done_cols - done_rows,\n                -near_done_cols,\n                -unique_rows - unique_cols,\n                log_col_sums)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 165,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 171,
    "parent_id": 87,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining row/column sums, non-zero counts, and inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        non_zero = np.count_nonzero(m)\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)) + non_zero)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inv_transpose = calculate_heuristic(np.linalg.inv(matrix.T) % 2)\n    return min(original, inverse, transpose, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8729832713175648,
      "additional_data": {
        "spearman_correlation": "0.872983",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 169,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 172,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        # Basic metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Advanced metrics\n        rank = np.linalg.matrix_rank(m)\n        triu = np.triu(m, k=1)\n        tril = np.tril(m, k=-1)\n        upper_complexity = np.sum(triu)\n        lower_complexity = np.sum(tril)\n        \n        # Dependency metrics\n        col_deps = np.sum(np.logical_and(m[:,:,None], m[:,None,:]), axis=0)\n        row_deps = np.sum(np.logical_and(m[:,:,None], m[None,:,:]), axis=2)\n        dep_score = np.sum(col_deps * (col_deps - 1)) + np.sum(row_deps * (row_deps - 1))\n        \n        # Structural metrics\n        diag = np.diag(m)\n        diag_score = np.sum(diag != 1)\n        block_score = 0\n        n = len(m)\n        for i in range(n):\n            for j in range(n):\n                if m[i,j] and m[j,i]:\n                    block_score += 1\n        \n        return (\n            nonzeros,\n            -rank,\n            upper_complexity + lower_complexity,\n            dep_score,\n            diag_score,\n            block_score,\n            np.sum(np.abs(col_sums - 1)),\n            np.sum(np.abs(row_sums - 1)),\n            *sorted(col_sums),\n            *sorted(row_sums)\n        )\n    \n    h_original = matrix_metrics(matrix)\n    h_inverse = matrix_metrics(np.linalg.inv(matrix))\n    h_transpose = matrix_metrics(matrix.T)\n    h_inverse_transpose = matrix_metrics(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8728878293868174,
      "additional_data": {
        "spearman_correlation": "0.872888",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 167,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 173,
    "parent_id": 134,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic with structural analysis.\"\"\"\n    import numpy as np\n    \n    def analyze(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row patterns\n        unique_cols = len({tuple(col) for col in m.T})\n        unique_rows = len({tuple(row) for row in m})\n        col_diversity = sum(len(set(col)) for col in m.T)\n        row_diversity = sum(len(set(row)) for row in m)\n        \n        # Distance metrics\n        col_dist = sum(min(sum(abs(col - target)) for target in np.eye(n).T) for col in m.T)\n        row_dist = sum(min(sum(abs(row - target)) for target in np.eye(n)) for row in m)\n        \n        # Structural metrics\n        block_score = 0\n        for k in range(2, n//2 + 1):\n            if np.all(m[:k,:k] == np.eye(k)) and np.all(m[k:,k:] == np.eye(n-k))):\n                block_score = k*(n-k)\n                break\n        \n        # Advanced metrics\n        col_correlations = np.sum(np.corrcoef(m.T))\n        row_correlations = np.sum(np.corrcoef(m))\n        col_entropy = -np.sum(np.where(col_sums > 0, col_sums/n * np.log(col_sums/n), 0))\n        row_entropy = -np.sum(np.where(row_sums > 0, row_sums/n * np.log(row_sums/n), 0))\n        \n        return (nonzeros, -block_score, col_dist + row_dist, \n                -unique_cols - unique_rows, col_entropy + row_entropy,\n                col_diversity + row_diversity, col_correlations + row_correlations,\n                *sorted(col_sums), *sorted(row_sums))\n    \n    # Generate all permutation variants\n    variants = []\n    for p in [matrix, np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix).T]:\n        variants.append(analyze(p))\n        # Add row/column permutations\n        for _ in range(2):  # Sample a couple permutations\n            perm = np.random.permutation(np.eye(n, dtype=int))\n            variants.append(analyze(perm @ p))\n            variants.append(analyze(p @ perm))\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unmatched ')' (<string>, line 25)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 166,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 174,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and log base.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.5 * np.sum(np.log(np.maximum(col_sums, 1)))  # Changed to natural log\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))  # Increased weight\n        row_imbalance = 1.0 * np.sum(np.abs(row_sums - 1))  # Adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct = np.sum(col_sums == 1) + np.sum(row_sums == 1)\n        return (nonzeros, -correct, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827971273347365,
      "additional_data": {
        "spearman_correlation": "0.882797",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 170,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 175,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, squared deviations and almost-done tracking.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        log_sum = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        squared_dev = np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2)\n        max_sum = np.max(col_sums) + np.max(row_sums)\n        return (nonzeros, \n                -(done_cols + done_rows + 0.5*(almost_done_cols + almost_done_rows)),\n                log_sum,\n                squared_dev,\n                max_sum)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(gf2_inv(matrix))\n        h_inverse_transpose = get_heuristic(gf2_inv(matrix).T)\n    except:\n        h_inverse = h_original\n        h_inverse_transpose = h_original\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8732070745615563,
      "additional_data": {
        "spearman_correlation": "0.873207",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 112,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 113,
      "exploited_organism_fitness": 0.8827838302711529,
      "child_number": 10
    }
  },
  {
    "id": 176,
    "parent_id": 76,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering row/column sums, ranks, and variance.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        rank = np.linalg.matrix_rank(m)\n        total_ones = np.sum(m)\n        \n        return (log_cols + log_rows, \n                -rank, \n                col_var + row_var, \n                total_ones)\n    \n    metrics = calculate_metrics(matrix)\n    trans_metrics = calculate_metrics(matrix.T)\n    \n    return min(metrics, trans_metrics)\n",
    "evaluation": {
      "fitness": 0.793605659459112,
      "additional_data": {
        "spearman_correlation": "0.793606",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 174,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 177,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column and row features\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Measure of clustering - average distance between ones\n        ones_pos = np.argwhere(m == 1)\n        if len(ones_pos) > 1:\n            avg_dist = np.mean([np.abs(x1-x2)+np.abs(y1-y2) \n                              for (x1,y1), (x2,y2) in zip(ones_pos[:-1], ones_pos[1:])])\n        else:\n            avg_dist = 0\n        \n        # Interaction between rows and columns\n        row_col_interaction = np.sum(m @ m.T)\n        \n        # Column permutation invariant features\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        # Column-wise binary features\n        col_features = []\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_features.append(np.sum(m[:,i] & m[:,j]))\n        \n        return (nonzeros, \n                -unique_cols, \n                -unique_rows,\n                log_cols + log_rows,\n                -avg_dist,\n                row_col_interaction,\n                *sorted(col_features, reverse=True))\n    \n    # Generate all column permutations\n    n = matrix.shape[0]\n    best_h = None\n    for perm in permutations(range(n)):\n        permuted = matrix[:, list(perm)]\n        current_h = get_heuristic(permuted)\n        if best_h is None or current_h < best_h:\n            best_h = current_h\n    \n    return best_h\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 171,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 178,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.6 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Slightly adjusted weight\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))  # Adjusted weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.6 * np.sum(np.abs(col_sums - 1))  # Slightly increased weight\n        row_imbalance = 1.4 * np.sum(np.abs(row_sums - 1))  # Adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.3 * np.var(col_sums)  # Added small variance term\n        row_variance = 0.3 * np.var(row_sums)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882842398151853,
      "additional_data": {
        "spearman_correlation": "0.882842",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 9,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 172,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 179,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.6 * np.sum(np.log(np.maximum(col_sums, 1)))  # Adjusted weight and natural log\n        log_rows = 1.1 * np.sum(np.log(np.maximum(row_sums, 1)))  # Adjusted weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.6 * np.sum(np.abs(col_sums - 1))  # Slightly adjusted weight\n        row_imbalance = 1.6 * np.sum(np.abs(row_sums - 1))  # Slightly adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, -done_cols-done_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828022797467504,
      "additional_data": {
        "spearman_correlation": "0.882802",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 173,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 180,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Triangularity metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = min(np.sum(upper_tri != 0), np.sum(lower_tri != 0))\n        \n        # Linear algebra metrics\n        rank = np.linalg.matrix_rank(m)\n        det = np.abs(np.linalg.det(m))\n        \n        # Interaction terms\n        row_col_interaction = np.sum(np.outer(row_sums, col_sums) * m)\n        col_dot = np.sum(np.dot(m.T, m))\n        row_dot = np.sum(np.dot(m, m.T))\n        \n        # Advanced metrics\n        eigenvals = np.abs(np.linalg.eigvals(m))\n        eigen_metric = np.sum(eigenvals) - np.max(eigenvals)\n        \n        return (nonzeros, \n                -rank,\n                tri_diff,\n                -np.log2(det + 1),\n                row_col_interaction,\n                col_dot + row_dot,\n                eigen_metric,\n                np.sum(np.abs(col_sums - 1))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 28)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 175,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 181,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and simplified features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = 2.0 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 2.0 * np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827801327950694,
      "additional_data": {
        "spearman_correlation": "0.882780",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 176,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 182,
    "parent_id": 141,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version considering both row and column sums with matrix variants.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        sums = np.concatenate([col_sums, row_sums])\n        sums = np.maximum(sums, 1e-10)\n        return np.sum(np.log(sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    \n    return (float(original), float(min(transposed, inverted, inv_transposed)))\n",
    "evaluation": {
      "fitness": 0.7953178710235421,
      "additional_data": {
        "spearman_correlation": "0.795318",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 177,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 183,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column and row features\n        col_entropy = np.sum(-(col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        row_entropy = np.sum(-(row_sums/n) * np.log2(np.maximum(row_sums/n, 1e-10)))\n        \n        # Interaction terms between columns and rows\n        col_row_interaction = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        # Diagonal dominance\n        diag_dominance = np.sum(np.abs(np.diag(m) - 1))\n        \n        # Singular value based features\n        svals = np.linalg.svd(m, compute_uv=False)\n        sval_entropy = np.sum(-(svals/n) * np.log2(np.maximum(svals/n, 1e-10)))\n        \n        # Block structure detection\n        block_score = 0\n        for k in range(1, n//2 + 1):\n            block_score += np.sum(np.abs(m[:k,:k] @ m[k:,k:] - m[:k,k:] @ m[k:,:k]))\n        \n        # Return as a tuple with carefully ordered components\n        return (\n            np.count_nonzero(m),\n            col_entropy + row_entropy,\n            col_row_interaction,\n            diag_dominance,\n            sval_entropy,\n            block_score,\n            *sorted(col_sums, reverse=True),\n            *sorted(row_sums, reverse=True)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T,\n        matrix @ matrix.T,\n        matrix.T @ matrix\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 30)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 178,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 184,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering element-wise minimum across inverse/transpose.\"\"\"\n    import numpy as np\n    def get_col_sums(m):\n        return np.sum(m, axis=0)\n    \n    col_sums = get_col_sums(matrix)\n    col_sums_inv = get_col_sums(np.linalg.inv(matrix) % 2)\n    col_sums_trans = get_col_sums(matrix.T)\n    min_col_sums = np.minimum.reduce([col_sums, col_sums_inv, col_sums_trans])\n    min_col_sums = np.maximum(min_col_sums, 1e-10)\n    return float(np.sum(np.log(min_col_sums)))\n",
    "evaluation": {
      "fitness": 0.7616516427474967,
      "additional_data": {
        "spearman_correlation": "0.761652",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 182,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 14
    }
  },
  {
    "id": 185,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Slightly increased weight\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))  # Slightly decreased weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.2 * np.sum(np.abs(col_sums - 1))  # Slightly decreased weight\n        row_imbalance = 1.8 * np.sum(np.abs(row_sums - 1))  # Slightly increased weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, min_col + min_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827716444924477,
      "additional_data": {
        "spearman_correlation": "0.882772",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 179,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 186,
    "parent_id": 154,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, inverse transpose, and logarithmic imbalance.\"\"\"\n    import numpy as np\n\n    def gf2_inv(matrix):\n        \"\"\"Compute inverse of binary matrix over GF(2).\"\"\"\n        n = matrix.shape[0]\n        mat_int = matrix.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for i in range(n):\n            if aug[i, i] == 0:\n                for j in range(i+1, n):\n                    if aug[j, i] == 1:\n                        aug[[i, j]] = aug[[j, i]]\n                        break\n                else:\n                    raise ValueError(\"Matrix is singular.\")\n            for j in range(n):\n                if j != i and aug[j, i] == 1:\n                    aug[j] = (aug[j] + aug[i]) % 2\n        return aug[:, n:].astype(int)\n\n    def get_heuristic(m):\n        \"\"\"Compute heuristic tuple for a single matrix.\"\"\"\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Logarithmic imbalance with handling for zeros\n        log_imbalance = np.sum(np.log(col_sums + 0.1)) + np.sum(np.log(row_sums + 0.1))\n        # Weighted absolute imbalance\n        abs_imbalance = 0.7*np.sum(np.abs(col_sums - 1)) + 0.3*np.sum(np.abs(row_sums - 1))\n        # Variance of column/row sums\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        # Sorted distributions\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, log_imbalance, abs_imbalance, col_var, row_var, *sorted_cols, *sorted_rows)\n    \n    # Generate candidate matrices\n    try:\n        inv_matrix = gf2_inv(matrix)\n        candidates = [\n            matrix,\n            matrix.T,\n            inv_matrix,\n            inv_matrix.T\n        ]\n    except:\n        candidates = [matrix, matrix.T]\n    \n    # Return minimal heuristic across candidates\n    return min(get_heuristic(cand) for cand in candidates)\n",
    "evaluation": {
      "fitness": 0.8713487519789931,
      "additional_data": {
        "spearman_correlation": "0.871349",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 180,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 187,
    "parent_id": 130,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with summary statistics replacing sorted sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 2 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        col_sum_sq = np.sum(col_sums ** 2)\n        row_sum_sq = np.sum(row_sums ** 2)\n        return (nonzeros, \n                -(done_cols + done_rows), \n                log_cols + log_rows, \n                col_imbalance + row_imbalance, \n                max_col + max_row, \n                min_col, \n                min_row,\n                col_sum_sq,\n                row_sum_sq)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828199745556097,
      "additional_data": {
        "spearman_correlation": "0.882820",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 124,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 130,
      "exploited_organism_fitness": 0.8828008598681549,
      "child_number": 5
    }
  },
  {
    "id": 188,
    "parent_id": 18,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        matrix_rank = np.linalg.matrix_rank(m)\n        \n        main_metric = 0.4*hamming + 0.3*log_col + 0.3*log_row + 0.2*col_var + 0.2*row_var + 0.1*matrix_rank\n        secondary_metric = float(np.max(col_sums) + np.max(row_sums)\n        tertiary_metric = float(np.sum(col_sums % 2) + np.sum(row_sums % 2))\n        return main_metric, secondary_metric, tertiary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inv_transposed = calculate_metrics(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    metrics = [original, transposed, inverted, inv_transposed]\n    min_main = min(m[0] for m in metrics)\n    min_secondary = min(m[1] for m in metrics)\n    min_tertiary = min(m[2] for m in metrics)\n    \n    return (min_main, min_secondary, min_tertiary)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 181,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 189,
    "parent_id": 137,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(1 for s in col_sums if s == 1)\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8825295482467196,
      "additional_data": {
        "spearman_correlation": "0.882530",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 184,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 190,
    "parent_id": 60,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.log(col_sums + 1/np.max(col_sums))\n        log_row = np.log(row_sums + 1/np.max(row_sums))\n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)))\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    features.append(get_features(inv_matrix))\n    features.append(get_features(inv_matrix.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.755451382599002,
      "additional_data": {
        "spearman_correlation": "0.755451",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 186,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 191,
    "parent_id": 60,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        epsilon = 1/(np.max(col_sums)+1)\n        log_col = np.log(col_sums + epsilon)\n        log_row = np.log(row_sums + epsilon)\n        nnz = float(np.count_nonzero(m))\n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)), nnz)\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    features.append(get_features(inv_matrix))\n    features.append(get_features(inv_matrix.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7206949456015793,
      "additional_data": {
        "spearman_correlation": "0.720695",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 188,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 192,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.4 * np.var(col_sums)\n        row_variance = 0.4 * np.var(row_sums)\n        sum_diff = 0.2 * np.abs(np.sum(col_sums) - np.sum(row_sums))\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, col_variance + row_variance, sum_diff, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828111065644614,
      "additional_data": {
        "spearman_correlation": "0.882811",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 185,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 193,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] ^= aug[col]\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        weight2_cols = np.sum(col_sums == 2)\n        weight2_rows = np.sum(row_sums == 2)\n        weight3plus_cols = np.sum(col_sums >= 3)\n        weight3plus_rows = np.sum(row_sums >= 3)\n        col_sq_dev = np.sum((col_sums - 1) ** 2)\n        row_sq_dev = np.sum((row_sums - 1) ** 2)\n        return (nonzeros, \n                -(done_cols + done_rows),\n                -(weight2_cols + weight2_rows),\n                weight3plus_cols + weight3plus_rows,\n                col_sq_dev + row_sq_dev)\n\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    try:\n        inv_matrix = gf2_inv(matrix)\n        if inv_matrix is None:\n            h_inverse = (10**18, 10**18, 10**18, 10**18, 10**18)\n        else:\n            h_inverse = get_heuristic(inv_matrix)\n    except:\n        h_inverse = (10**18, 10**18, 10**18, 10**18, 10**18)\n\n    return min(h_original, h_transpose, h_inverse)\n",
    "evaluation": {
      "fitness": 0.8716069314679621,
      "additional_data": {
        "spearman_correlation": "0.871607",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 100,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 99,
      "exploited_organism_fitness": 0.8824198101895542,
      "child_number": 7
    }
  },
  {
    "id": 194,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.4 * np.var(col_sums)\n        row_variance = 0.4 * np.var(row_sums)\n        diagonal = 0.5 * np.sum(np.diag(m) == 1)\n        identical_pairs = 0.3 * sum(np.array_equal(m[:,i], m[:,j]) for i in range(m.shape[1]) for j in range(i+1, m.shape[1]))\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, col_variance + row_variance, diagonal, identical_pairs, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8819907931336043,
      "additional_data": {
        "spearman_correlation": "0.881991",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 189,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 195,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column interaction metrics\n        col_interactions = 0\n        unique_cols = len({tuple(col) for col in m.T})\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        # Row interaction metrics\n        row_interactions = 0\n        unique_rows = len({tuple(row) for row in m})\n        for i in range(n):\n            for j in range(i+1, n):\n                row_interactions += np.sum(m[i,:] & m[j,:])\n        \n        # Triangularity measure\n        lower_tri = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                lower_tri += m[i,j]\n        \n        # Column completion metrics\n        col_completion = 0\n        for j in range(n):\n            if col_sums[j] == 1:\n                for i in range(n):\n                    if m[i,j]:\n                        col_completion += np.sum(m[i,:]) - 1\n        \n        # Row completion metrics\n        row_completion = 0\n        for i in range(n):\n            if row_sums[i] == 1:\n                row_completion += np.sum(m[:,i]) - 1\n        \n        # Column spread metrics\n        col_spread = 0\n        for j in range(n):\n            if col_sums[j] > 1:\n                col_spread += np.sum(np.sum(m[:,j:], axis=1) > 1)\n        \n        return (\n            nonzeros,\n            -unique_cols - unique_rows,\n            col_interactions + row_interactions,\n            lower_tri,\n            col_completion + row_completion,\n            col_spread,\n            *sorted(col_sums),\n            *sorted(row_sums),\n            *[int(x) for x in m.flatten()]\n        )\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 190,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 196,
    "parent_id": 149,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with log2 adjustment.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 1.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828008598681549,
      "additional_data": {
        "spearman_correlation": "0.882801",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 191,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 197,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering row/column interactions and diagonal dominance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Measure of how close columns are to basis vectors\n        col_completion = np.sum(np.minimum(col_sums, 1))\n        \n        # Measure of row-column interaction complexity\n        interaction = np.sum(np.abs(m @ m.T - np.eye(m.shape[0])))\n        \n        # Diagonal dominance measure\n        diag_dom = np.sum(np.abs(np.diag(m) - 1))\n        \n        # Sorted structural features\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, interaction, col_completion, diag_dom, *sorted_cols, *sorted_rows)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix @ matrix.T,\n        matrix.T @ matrix\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8572758402163,
      "additional_data": {
        "spearman_correlation": "0.857276",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 193,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 198,
    "parent_id": 20,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Minimum of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8658840755208309,
      "additional_data": {
        "spearman_correlation": "0.865884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 194,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 199,
    "parent_id": 45,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        basis_dist = 0\n        interaction = 0\n        diagonal_score = 0\n        \n        # Calculate basis distances and interactions\n        for i in range(n):\n            col = m[:, i]\n            basis_dist += min(np.sum(col), np.sum(1 - col))  # Distance to nearest basis vector\n            \n            # Interaction score (how many other columns affect this one)\n            for j in range(n):\n                if i != j and m[i, j] == 1:\n                    interaction += 1\n        \n        # Calculate diagonal score (1 if perfect diagonal, 0 if no diagonal elements)\n        diagonal_score = np.sum(np.diag(m)) / n\n        \n        # Column sum metrics (original approach but weighted differently)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        \n        # Combined metric with adjusted weights\n        return (0.4 * (col_log + row_log) + \n                0.3 * basis_dist + \n                0.2 * interaction + \n                0.1 * diagonal_score,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.7430158112426805,
      "additional_data": {
        "spearman_correlation": "0.743016",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 192,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 200,
    "parent_id": 125,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        return (log_col, log_row, total_ones)\n    \n    metrics_orig = calculate_metrics(matrix)\n    metrics_trans = calculate_metrics(matrix.T)\n    inv_matrix = np.linalg.inv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    metrics_inv = calculate_metrics(inv_matrix)\n    metrics_inv_trans = calculate_metrics(inv_matrix.T)\n    \n    # Combine all metrics with weights favoring column metrics\n    combined = [\n        0.4 * metrics_orig[0] + 0.2 * metrics_orig[1] + 0.1 * metrics_orig[2],\n        0.4 * metrics_trans[0] + 0.2 * metrics_trans[1] + 0.1 * metrics_trans[2],\n        0.4 * metrics_inv[0] + 0.2 * metrics_inv[1] + 0.1 * metrics_inv[2],\n        0.4 * metrics_inv_trans[0] + 0.2 * metrics_inv_trans[1] + 0.1 * metrics_inv_trans[2]\n    ]\n    \n    return max(combined)\n",
    "evaluation": {
      "fitness": 0.7781678196708496,
      "additional_data": {
        "spearman_correlation": "0.778168",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 196,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 201,
    "parent_id": 75,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with squared imbalance and almost-done terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with sum exactly 1\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        # Count columns/rows with sum exactly 2\n        cols_almost = np.sum(col_sums == 2)\n        rows_almost = np.sum(row_sums == 2)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Use squared differences for imbalance\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        return (nonzeros, cols_done + rows_done, cols_almost + rows_almost, \n                col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.851764336898365,
      "additional_data": {
        "spearman_correlation": "0.851764",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 197,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 202,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        hamming = np.sum(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Distance from basis vectors (columns)\n        basis_dist = 0\n        for col in m.T:\n            basis_dist += min(np.sum(col), np.sum(1-col))\n            \n        # Column and row metrics\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        # Combined metrics\n        return (\n            rank + basis_dist,\n            hamming,\n            col_log + row_log,\n            col_linear + row_linear\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_metrics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.23592589608684023,
      "additional_data": {
        "spearman_correlation": "0.235926",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 198,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 203,
    "parent_id": 43,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums))\n        log_sum_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        t = (log_sum_col, log_sum_row, total_ones, -basis_cols, -basis_rows)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8741911927125229,
      "additional_data": {
        "spearman_correlation": "0.874191",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 108,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 204,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column and row pattern analysis\n        col_patterns = [tuple(m[:,i]) for i in range(m.shape[1])]\n        row_patterns = [tuple(m[i,:]) for i in range(m.shape[0])]\n        \n        # Pattern similarity metrics\n        col_similarity = sum(sum(a==b for a,b in zip(c1,c2)) \n                           for i,c1 in enumerate(col_patterns) \n                           for j,c2 in enumerate(col_patterns) if i < j)\n        row_similarity = sum(sum(a==b for a,b in zip(r1,r2)) \n                           for i,r1 in enumerate(row_patterns) \n                           for j,r2 in enumerate(row_patterns) if i < j)\n        \n        # Column/row dependencies\n        col_deps = sum(np.sum(m[:,i] & m[:,j]) for i in range(m.shape[1]) \n                      for j in range(i+1, m.shape[1]))\n        row_deps = sum(np.sum(m[i,:] & m[j,:]) for i in range(m.shape[0]) \n                      for j in range(i+1, m.shape[0]))\n        \n        # Advanced metrics\n        col_xor = sum(np.sum(np.bitwise_xor.reduce([m[:,i] for i in combo])) \n                     for combo in zip(*[iter(range(m.shape[1]))]*2))\n        row_xor = sum(np.sum(np.bitwise_xor.reduce([m[i,:] for i in combo])) \n                     for combo in zip(*[iter(range(m.shape[0]))]*2))\n        \n        # Combined metrics\n        return (nonzeros, \n                -col_similarity - row_similarity,\n                col_deps + row_deps,\n                col_xor + row_xor,\n                np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1)),\n                np.sum(np.log2(np.maximum(col_sums, 1))) + np.sum(np.log2(np.maximum(row_sums, 1))),\n                *sorted(col_sums),\n                *sorted(row_sums))\n    \n    # Consider all isomorphic variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T,\n        np.flip(matrix, axis=0),\n        np.flip(matrix, axis=1),\n        np.rot90(matrix)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 195,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 205,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and ordering.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, -cols_two, -done_cols-done_rows, done_cols+done_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8696472342166236,
      "additional_data": {
        "spearman_correlation": "0.869647",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 199,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 206,
    "parent_id": 44,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved composite heuristic with better interaction term and element count.\"\"\"\n    import numpy as np\n    \n    def col_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums + 0.5))\n    \n    def row_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return np.sum(np.log(row_sums + 0.5))\n    \n    def interaction_heuristic(m):\n        col_nonzeros = np.sum(m, axis=0)\n        row_nonzeros = np.sum(m, axis=1)\n        interaction = np.sum(np.minimum(col_nonzeros, row_nonzeros))\n        return np.log(interaction + 0.5) if interaction > 0 else 0\n    \n    def element_count(m):\n        return np.sum(m)\n    \n    original_col = col_heuristic(matrix)\n    original_row = row_heuristic(matrix)\n    original_inter = interaction_heuristic(matrix)\n    original_elem = element_count(matrix)\n    \n    transposed = matrix.T\n    transposed_col = col_heuristic(transposed)\n    transposed_row = row_heuristic(transposed)\n    transposed_inter = interaction_heuristic(transposed)\n    transposed_elem = element_count(transposed)\n    \n    inverse = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    inverse_col = col_heuristic(inverse)\n    inverse_row = row_heuristic(inverse)\n    inverse_inter = interaction_heuristic(inverse)\n    inverse_elem = element_count(inverse)\n    \n    min_col = min(original_col, transposed_col, inverse_col)\n    min_row = min(original_row, transposed_row, inverse_row)\n    min_inter = min(original_inter, transposed_inter, inverse_inter)\n    min_elem = min(original_elem, transposed_elem, inverse_elem)\n    \n    return (min_col, min_row, min_inter, min_elem)\n",
    "evaluation": {
      "fitness": 0.7202997027670861,
      "additional_data": {
        "spearman_correlation": "0.720300",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 200,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 207,
    "parent_id": 34,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def col_based_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        non_zero_cols = np.count_nonzero(col_sums)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        return (non_zero_cols, -log_cols)\n    \n    def row_based_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        return np.sum(np.log(np.maximum(row_sums, 1)))\n    \n    original_col = col_based_heuristic(matrix)\n    inverse_col = col_based_heuristic(np.linalg.inv(matrix) % 2)\n    transpose_col = col_based_heuristic(matrix.T)\n    \n    original_row = row_based_heuristic(matrix)\n    inverse_row = row_based_heuristic(np.linalg.inv(matrix) % 2)\n    transpose_row = row_based_heuristic(matrix.T)\n    \n    best_col = min(original_col, inverse_col, transpose_col)\n    best_row = min(original_row, inverse_row, transpose_row)\n    \n    return best_col + (best_row,)\n",
    "evaluation": {
      "fitness": -0.7621624548565373,
      "additional_data": {
        "spearman_correlation": "-0.762162",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 202,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 208,
    "parent_id": 184,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both column and row sums with element-wise minimum across variants.\"\"\"\n    import numpy as np\n    def get_col_sums(m):\n        return np.sum(m, axis=0)\n    def get_row_sums(m):\n        return np.sum(m, axis=1)\n    \n    col_sums = get_col_sums(matrix)\n    row_sums = get_row_sums(matrix)\n    col_sums_inv = get_col_sums(np.linalg.inv(matrix) % 2\n    row_sums_inv = get_row_sums(np.linalg.inv(matrix) % 2)\n    col_sums_trans = get_col_sums(matrix.T)\n    row_sums_trans = get_row_sums(matrix.T)\n    \n    min_col_sums = np.minimum.reduce([col_sums, col_sums_inv, col_sums_trans])\n    min_row_sums = np.minimum.reduce([row_sums, row_sums_inv, row_sums_trans])\n    \n    min_col_sums = np.maximum(min_col_sums, 1e-10)\n    min_row_sums = np.maximum(min_row_sums, 1e-10)\n    \n    return float(np.sum(np.log(min_col_sums)) + np.sum(np.log(min_row_sums)))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 12)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 203,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 209,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Combine absolute and squared deviations for columns and rows\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + 0.5 * np.sum((col_sums - 1) ** 2)\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + 0.5 * np.sum((row_sums - 1) ** 2)\n        # Sort column sums for consistent ordering\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.869568189465423,
      "additional_data": {
        "spearman_correlation": "0.869568",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 206,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 210,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.4 * np.var(col_sums)\n        row_variance = 0.4 * np.var(row_sums)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827762685359137,
      "additional_data": {
        "spearman_correlation": "0.882776",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 201,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 211,
    "parent_id": 189,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(1 for s in col_sums if s <= 2)\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8832644302245143,
      "additional_data": {
        "spearman_correlation": "0.883264",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 25,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 205,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 212,
    "parent_id": 123,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column and row sums plus variance term, considering original, transpose, and inverses.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_var = np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)) + col_var + row_var\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else float('inf')\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else float('inf')\n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 12)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 207,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 213,
    "parent_id": 91,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance to identity/anti-identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                        np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Overlap between columns and rows\n        col_overlap = sum(np.sum(m[:,i] & m[:,j]) \n                         for i in range(n) for j in range(i+1, n))\n        row_overlap = sum(np.sum(m[i,:] & m[j,:]) \n                         for i in range(n) for j in range(i+1, n))\n        overlap_metric = col_overlap + row_overlap\n        \n        # Logarithmic column weight penalty\n        log_col = np.sum(np.log2(col_sums))  # Safe since invertible matrices have no zero columns\n        \n        # Deviation from ideal number of ones (n)\n        lin_col_dev = total_ones - n\n        \n        return (diag_dist, overlap_metric, log_col, lin_col_dev)\n    \n    # Compute metrics for variants\n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_metrics(inv_matrix)\n    inv_transposed = matrix_metrics(inv_matrix.T)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    \n    # Select best (min) for each metric across variants\n    best_diag_dist = min(m[0] for m in metrics)\n    best_overlap = min(m[1] for m in metrics)\n    best_log_col = min(m[2] for m in metrics)\n    best_lin_col_dev = min(m[3] for m in metrics)\n    \n    return (best_diag_dist, best_overlap, best_log_col, best_lin_col_dev)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 148,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 214,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weighted column imbalance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        # Weight deviations quadratically to prioritize larger imbalances\n        col_imbalance = np.sum((col_sums - 1)**2)\n        return (nonzeros, col_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8732927652425087,
      "additional_data": {
        "spearman_correlation": "0.873293",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 209,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 215,
    "parent_id": 166,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use squared deviations for both columns and rows\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        # Count number of correct columns and rows\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        # Sort column sums for more information\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance + row_imbalance, -correct_cols - correct_rows, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8693913959119896,
      "additional_data": {
        "spearman_correlation": "0.869391",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 210,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 216,
    "parent_id": 11,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering matrix variations and multiple properties.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_log = np.sum(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_log = np.sum(np.log(row_sums))\n        \n        total_sum = np.sum(m)\n        nonzero = np.count_nonzero(m)\n        \n        return (float(col_log + row_log), float(total_sum), float(nonzero))\n    \n    try:\n        inv = np.linalg.inv(matrix)\n    except:\n        inv = matrix\n        \n    h_matrix = calculate_heuristic(matrix)\n    h_inv = calculate_heuristic(inv)\n    h_trans = calculate_heuristic(matrix.T)\n    \n    return min(h_matrix, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": -0.09161576691826279,
      "additional_data": {
        "spearman_correlation": "-0.091616",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 212,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 217,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count columns with sum 1 and 2 separately\n        col_completion_1 = sum(1 for s in col_sums if s == 1)\n        col_completion_2 = sum(1 for s in col_sums if s == 2)\n        \n        # Add row completion metrics\n        row_completion_1 = sum(1 for s in row_sums if s == 1)\n        row_completion_2 = sum(1 for s in row_sums if s == 2)\n        \n        return (nonzeros, \n                -col_completion_1,\n                -col_completion_2,\n                -row_completion_1,\n                -row_completion_2,\n                -basis_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8830521052977091,
      "additional_data": {
        "spearman_correlation": "0.883052",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 213,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 218,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect = (n - correct_cols) + (n - correct_rows)\n        log_cols = 1.6 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.6 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.4 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_variance = 0.3 * np.var(col_sums)\n        row_variance = 0.3 * np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, incorrect, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882842398151853,
      "additional_data": {
        "spearman_correlation": "0.882842",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 183,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 219,
    "parent_id": 200,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        return (log_col, log_row, total_ones)\n    \n    metrics_orig = calculate_metrics(matrix)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n        metrics_inv = calculate_metrics(inv_matrix)\n        metrics_inv_trans = calculate_metrics(inv_matrix.T)\n    except:\n        metrics_inv = metrics_orig\n        metrics_inv_trans = metrics_trans\n    \n    combined = [\n        0.45 * metrics_orig[0] + 0.15 * metrics_orig[1] + 0.15 * metrics_orig[2],\n        0.45 * metrics_trans[0] + 0.15 * metrics_trans[1] + 0.15 * metrics_trans[2],\n        0.45 * metrics_inv[0] + 0.15 * metrics_inv[1] + 0.15 * metrics_inv[2],\n        0.45 * metrics_inv_trans[0] + 0.15 * metrics_inv_trans[1] + 0.15 * metrics_inv_trans[2]\n    ]\n    \n    return min(combined)\n",
    "evaluation": {
      "fitness": 0.7443825489731418,
      "additional_data": {
        "spearman_correlation": "0.744383",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 215,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 220,
    "parent_id": 134,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic counts\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Column/row distribution metrics\n        col_weights = np.exp(-0.5 * (col_sums - 1)**2)\n        row_weights = np.exp(-0.5 * (row_sums - 1)**2)\n        weighted_col_sum = np.sum(col_sums * col_weights)\n        weighted_row_sum = np.sum(row_sums * row_weights)\n        \n        # Interaction metrics\n        col_overlaps = np.sum(m.T @ m)\n        row_overlaps = np.sum(m @ m.T)\n        \n        # Variance metrics\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        # Distance metrics\n        col_dist = np.sum(np.abs(col_sums - 1))\n        row_dist = np.sum(np.abs(row_sums - 1))\n        \n        # Combined score\n        score = (\n            0.4 * nonzeros / n**2 +\n            0.3 * (weighted_col_sum + weighted_row_sum) / (2*n) +\n            0.2 * (col_overlaps + row_overlaps) / (2*n**2) +\n            0.1 * (col_dist + row_dist) / (2*n) -\n            0.5 * (done_cols + done_rows) / (2*n)\n        )\n        \n        return score\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_metrics(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.6994477887710341,
      "additional_data": {
        "spearman_correlation": "0.699448",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 216,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 221,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(2-s for s in col_sums if s <= 2)\n        row_symmetry = -np.sum(np.abs(row_sums - np.mean(row_sums)))\n        col_sum_norm = np.sum(col_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                row_symmetry,\n                -basis_cols,\n                -unique_cols,\n                col_sum_norm)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8809779056186029,
      "additional_data": {
        "spearman_correlation": "0.880978",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 217,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 222,
    "parent_id": 46,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic considering product of rows and columns, matrix transpose, and inverse.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    try:\n        inv_matrix = np.linalg.matrix_power(matrix, -1) % 2\n        inv_col_sums = np.sum(inv_matrix, axis=0)\n        inv_row_sums = np.sum(inv_matrix, axis=1)\n        option3 = tuple(sorted(inv_col_sums * inv_row_sums))\n    except:\n        option3 = (float('inf'),)\n    option1 = tuple(sorted(col_sums * row_sums))\n    option2 = tuple(sorted(trans_col_sums * trans_row_sums))\n    return min(option1, option2, option3)\n",
    "evaluation": {
      "fitness": 0.7995025581622001,
      "additional_data": {
        "spearman_correlation": "0.799503",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 218,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 223,
    "parent_id": 22,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    log_cols = np.sum(np.log1p(col_sums))\n    log_rows = np.sum(np.log1p(row_sums))\n    \n    trans = matrix.T\n    trans_col_sums = np.sum(trans, axis=0)\n    trans_row_sums = np.sum(trans, axis=1)\n    trans_log_cols = np.sum(np.log1p(trans_col_sums))\n    trans_log_rows = np.sum(np.log1p(trans_row_sums))\n    \n    weighted_cols = np.sum(col_sums * np.exp(-col_sums))\n    weighted_rows = np.sum(row_sums * np.exp(-row_sums))\n    weighted_trans_cols = np.sum(trans_col_sums * np.exp(-trans_col_sums))\n    weighted_trans_rows = np.sum(trans_row_sums * np.exp(-trans_row_sums))\n    \n    features = [\n        log_cols + log_rows,\n        trans_log_cols + trans_log_rows,\n        weighted_cols + weighted_rows,\n        weighted_trans_cols + weighted_trans_rows,\n        np.sum(matrix) + np.sum(trans)\n    ]\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": -0.764689186104611,
      "additional_data": {
        "spearman_correlation": "-0.764689",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 219,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 224,
    "parent_id": 139,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        total_sum = np.sum(m)\n        log_cols = sum(np.log(s) if s > 1 else 0 for s in col_sums)\n        near_one = sum(1 for s in col_sums if 0 < s <= 1)\n        return (total_sum, -log_cols, -near_one)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_metrics(m) for m in variants)\n",
    "evaluation": {
      "fitness": -0.27061189826837795,
      "additional_data": {
        "spearman_correlation": "-0.270612",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 220,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 225,
    "parent_id": 220,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_distance(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Calculate how many columns need to be XORed to simplify each column\n        col_deps = np.zeros(n)\n        for i in range(n):\n            if col_sums[i] == 1:\n                continue\n            for j in range(n):\n                if m[j,i] == 1:\n                    col_deps[i] += col_sums[j] - 1\n        \n        # Calculate base cost for each column\n        col_costs = np.zeros(n)\n        for i in range(n):\n            if col_sums[i] == 1:\n                continue\n            # Cost is based on sum plus dependencies\n            col_costs[i] = (col_sums[i] - 1) * (1 + 0.5 * col_deps[i] / n)\n        \n        # Calculate row costs similarly\n        row_costs = np.zeros(n)\n        for i in range(n):\n            if row_sums[i] == 1:\n                continue\n            row_costs[i] = (row_sums[i] - 1) * (1 + 0.5 * np.sum(m[i,:]) / n)\n        \n        # Combine with preference for columns closer to completion\n        total_cost = np.sum(col_costs * np.exp(-0.5 * (col_sums - 1))) + \\\n                     np.sum(row_costs * np.exp(-0.5 * (row_sums - 1)))\n        \n        return total_cost / (2 * n)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(column_distance(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.21154128698202954,
      "additional_data": {
        "spearman_correlation": "-0.211541",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 221,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 226,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse and removed redundant term.\"\"\"\n    import numpy as np\n\n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        A = np.round(matrix).astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                raise ValueError(\"Matrix is singular.\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        m = np.round(m).astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.5 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, \n                col_imbalance+row_imbalance, max_col+max_row, \n                *sorted_cols, *sorted_rows)\n    \n    inv = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8717092650412521,
      "additional_data": {
        "spearman_correlation": "0.871709",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 154,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 162,
      "exploited_organism_fitness": 0.882809815719059,
      "child_number": 11
    }
  },
  {
    "id": 227,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    import math\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_sum_metric = sum(math.log2(s + 1) for s in col_sums if s > 0)\n        \n        return (nonzeros, \n                col_sum_metric,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8812379194303396,
      "additional_data": {
        "spearman_correlation": "0.881238",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 223,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 228,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(np.log2(s) if s > 0 else 0 for s in col_sums)\n        row_completion = sum(np.log2(s) if s > 0 else 0 for s in row_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8537767148111265,
      "additional_data": {
        "spearman_correlation": "0.853777",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 224,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 229,
    "parent_id": 36,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logs of column sums, with min across matrix variants and second best as tiebreaker.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums))\n    \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(matrix.T),\n        compute_metric(np.linalg.inv(matrix))\n    ]\n    sorted_metrics = sorted(metrics)\n    \n    return (float(sorted_metrics[0]), float(sorted_metrics[1]))\n",
    "evaluation": {
      "fitness": 0.08632333903964155,
      "additional_data": {
        "spearman_correlation": "0.086323",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 227,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 230,
    "parent_id": 220,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        lower_tri = np.tril(m, -1)\n        \n        # Primary metric: sum of log column sums (emphasizes nearly-done columns)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Secondary metric: nonzeros below diagonal (direct elimination cost)\n        lower_nonzeros = np.count_nonzero(lower_tri)\n        \n        # Tertiary metric: column sum variance (work imbalance)\n        col_var = np.var(col_sums)\n        \n        # Combine metrics with log_cols as primary factor\n        return (log_cols, lower_nonzeros, col_var)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_score(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.5404727094657397,
      "additional_data": {
        "spearman_correlation": "0.540473",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 226,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 231,
    "parent_id": 130,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, sum of squares, and non-orthogonal pairs.\"\"\"\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Sum of squares of weights\n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        total_sq = col_sq + row_sq\n        \n        # Non-orthogonal pairs\n        row_gram = (m @ m.T) % 2\n        np.fill_diagonal(row_gram, 0)\n        row_nonorth = np.sum(np.triu(row_gram))\n        col_gram = (m.T @ m) % 2\n        np.fill_diagonal(col_gram, 0)\n        col_nonorth = np.sum(np.triu(col_gram))\n        total_nonorth = row_nonorth + col_nonorth\n        \n        return (nonzeros, \n                -done_cols - done_rows, \n                log_cols + log_rows,\n                max_col + max_row,\n                total_sq,\n                total_nonorth,\n                *sorted_cols,\n                *sorted_rows)\n    \n    # Compute variants\n    m_orig = matrix.astype(int)\n    m_trans = m_orig.T\n    m_inv = gf2_inv(m_orig)\n    if m_inv is None:  # Fallback if inversion fails\n        return get_heuristic(m_orig)\n    m_inv_trans = m_inv.T\n    \n    # Return minimal heuristic across variants\n    return min(\n        get_heuristic(m_orig),\n        get_heuristic(m_trans),\n        get_heuristic(m_inv),\n        get_heuristic(m_inv_trans)\n    )\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 145,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 232,
    "parent_id": 155,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on hierarchical column interactions and decomposition complexity.\"\"\"\n    import numpy as np\n    \n    def matrix_complexity(m):\n        n = m.shape[0]\n        if n == 0:\n            return (0,)\n        \n        # Column interaction metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(col_sums)\n        row_nonzeros = np.count_nonzero(row_sums)\n        \n        # Hierarchical decomposition metrics\n        upper = np.triu(m, k=1)\n        lower = np.tril(m, k=-1)\n        diag = np.diag(m)\n        \n        upper_nnz = np.count_nonzero(upper)\n        lower_nnz = np.count_nonzero(lower)\n        diag_nnz = np.count_nonzero(diag)\n        \n        # Column dependency metrics\n        col_deps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                col_deps.append(overlap)\n        \n        avg_col_dep = np.mean(col_deps) if col_deps else 0\n        max_col_dep = max(col_deps) if col_deps else 0\n        \n        # Row dependency metrics\n        row_deps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[i,:] & m[j,:])\n                row_deps.append(overlap)\n        \n        avg_row_dep = np.mean(row_deps) if row_deps else 0\n        max_row_dep = max(row_deps) if row_deps else 0\n        \n        # Block decomposition metrics\n        half = n // 2\n        tl = m[:half, :half]\n        tr = m[:half, half:]\n        bl = m[half:, :half]\n        br = m[half:, half:]\n        \n        block_complexity = (np.count_nonzero(tl) + np.count_nonzero(tr) +\n                           np.count_nonzero(bl) + np.count_nonzero(br))\n        \n        return (np.count_nonzero(m),\n                -col_nonzeros,\n                -row_nonzeros,\n                upper_nnz + lower_nnz,\n                -diag_nnz,\n                avg_col_dep,\n                max_col_dep,\n                avg_row_dep,\n                max_row_dep,\n                block_complexity)\n    \n    h_original = matrix_complexity(matrix)\n    h_inverse = (float('inf'),)\n    try:\n        inv = np.linalg.inv(matrix)\n        if np.allclose(matrix @ inv, np.eye(matrix.shape[0])):\n            h_inverse = matrix_complexity(inv)\n    except:\n        pass\n    h_transpose = matrix_complexity(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7234964155082692,
      "additional_data": {
        "spearman_correlation": "0.723496",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 225,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 233,
    "parent_id": 37,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        log_col = np.sum(np.log(col_sums[col_sums > 0])) if non_zero_cols > 0 else 0\n        log_row = np.sum(np.log(row_sums[row_sums > 0])) if non_zero_rows > 0 else 0\n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        max_row = np.max(row_sums) if row_sums.size > 0 else 0\n        sparsity = np.sum(m)\n        cols_with_1 = np.sum(col_sums == 1)\n        rows_with_1 = np.sum(row_sums == 1)\n        prod_col = np.prod(col_sums[col_sums > 0]) if non_zero_cols > 0 else 1\n        return (log_col, log_row, -non_zero_cols, -non_zero_rows, max_col, max_row, sparsity, -cols_with_1, -rows_with_1, -prod_col)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7128952375856952,
      "additional_data": {
        "spearman_correlation": "0.712895",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 228,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 234,
    "parent_id": 110,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        col2_count = np.count_nonzero(col_sums <= 2)\n        return (total_ones - n, n - col1_count, n - row1_count, n - col2_count)\n    \n    candidates = []\n    # Original matrix features\n    candidates.append(get_features(matrix))\n    # Transpose features (swaps row/column metrics)\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse mod2 features (if computable)\n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    return min(candidates)  # Lexicographic min\n",
    "evaluation": {
      "fitness": 0.7382173064309653,
      "additional_data": {
        "spearman_correlation": "0.738217",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 229,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 235,
    "parent_id": 120,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column/row patterns and nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = np.sum(-col_sums * np.log(col_sums + 1e-9))\n        row_entropy = np.sum(-row_sums * np.log(row_sums + 1e-9))\n        return col_entropy + row_entropy\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": -0.6957052618622752,
      "additional_data": {
        "spearman_correlation": "-0.695705",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 231,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 236,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse and simplified tuple.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        \"\"\"Compute inverse in GF(2) using Gaussian elimination.\"\"\"\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect = 2 * n - (correct_cols + correct_rows)\n        log_cols = 1.6 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.6 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.4 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_variance = 0.3 * np.var(col_sums)\n        row_variance = 0.3 * np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, incorrect, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row,\n                col_variance + row_variance, *sorted_cols, *sorted_rows)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix  # Fallback for singular (shouldn't occur for GL)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8716814599578976,
      "additional_data": {
        "spearman_correlation": "0.871681",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 172,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 178,
      "exploited_organism_fitness": 0.882842398151853,
      "child_number": 7
    }
  },
  {
    "id": 237,
    "parent_id": 91,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        lin_col = np.sum(col_sums)\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)), np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        return (diag_dist, log_col, lin_col)\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    inverse = matrix_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inv_transposed = matrix_metrics(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    \n    best_diag_dist = min(m[0] for m in metrics)\n    best_log_col = min(m[1] for m in metrics)\n    best_lin_col = min(m[2] for m in metrics)\n    \n    return (best_diag_dist, best_log_col, best_lin_col)\n",
    "evaluation": {
      "fitness": 0.4247382522162087,
      "additional_data": {
        "spearman_correlation": "0.424738",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 232,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 238,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # More granular column completion metric\n        col_completion = sum(2 - s for s in col_sums if s <= 2)\n        row_completion = sum(2 - s for s in row_sums if s <= 2)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8792971906449311,
      "additional_data": {
        "spearman_correlation": "0.879297",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 234,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 239,
    "parent_id": 93,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = aug[r] ^ aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        done_penalty = 2 * n - (cols_done + rows_done)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        total_dev = col_imbalance + row_imbalance\n        col_devs = np.abs(col_sums - 1)\n        row_devs = np.abs(row_sums - 1)\n        sorted_col_devs = sorted(col_devs, reverse=True)\n        sorted_row_devs = sorted(row_devs, reverse=True)\n        return (nonzeros, done_penalty, total_dev, *sorted_col_devs, *sorted_row_devs)\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        h_inv = get_heuristic(inv_matrix)\n        return min(h_orig, h_inv, h_trans)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.8599293631572635,
      "additional_data": {
        "spearman_correlation": "0.859929",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 156,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 240,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        l1_norm = np.sum(np.abs(m))\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(1 - 1/s if s > 0 else 0 for s in col_sums)\n        row_completion = sum(1 - 1/s if s > 0 else 0 for s in row_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                l1_norm)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.854355025224277,
      "additional_data": {
        "spearman_correlation": "0.854355",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 235,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 241,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        log_sum = np.sum(np.log2(col_sums))\n        col_completion = np.sum(col_sums <= 2)\n        return (log_sum, -col_completion)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 205,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 211,
      "exploited_organism_fitness": 0.8832644302245143,
      "child_number": 7
    }
  },
  {
    "id": 242,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(1 for s in col_sums if s == 1)\n        row_completion = sum(1 for s in row_sums if s == 1)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8818300730081986,
      "additional_data": {
        "spearman_correlation": "0.881830",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 237,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 243,
    "parent_id": 165,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        aug = (aug % 2).astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum(np.log2(np.maximum(col_sums, 1)))\n        row_imbalance = np.sum(np.log2(np.maximum(row_sums, 1)))\n        total_imbalance = col_imbalance + row_imbalance\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, total_imbalance, max_col, max_row, *sorted_cols, *sorted_rows)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix) if inv_matrix is not None else h_original\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T) if inv_matrix is not None else h_original\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8722555018743007,
      "additional_data": {
        "spearman_correlation": "0.872256",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 187,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 244,
    "parent_id": 209,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        off_diag = np.sum(m) - np.trace(m)\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + 0.3 * np.sum((col_sums - 1) ** 2)\n        row_imbalance = 0.5 * np.sum(np.abs(row_sums - 1))\n        sorted_cols = tuple(sorted(col_sums, reverse=True))\n        return (nonzeros, col_imbalance + row_imbalance, off_diag, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8718267447228282,
      "additional_data": {
        "spearman_correlation": "0.871827",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 240,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 245,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        col_weights = [np.sum(np.abs(col)) for col in m.T]\n        col_completion = sum(np.log(s + 1) for s in col_weights if s > 0)\n        col_variety = len(set(tuple(col) for col in m.T))\n        \n        # Row metrics\n        row_weights = [np.sum(np.abs(row)) for row in m]\n        row_completion = sum(np.log(s + 1) for s in row_weights if s > 0)\n        \n        # Interaction metrics\n        col_row_balance = abs(np.sum(col_sums) - np.sum(row_sums))\n        col_row_correlation = np.sum(np.corrcoef(m)[:m.shape[0], m.shape[0]:])\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                col_row_balance,\n                -col_row_correlation)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 238,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 246,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column features\n        col_log_sums = sum(log2(max(s, 1)) for s in col_sums)\n        col_completion = sum(1 for s in col_sums if s <= 1)\n        col_variance = np.var(col_sums)\n        \n        # Row features\n        row_log_sums = sum(log2(max(s, 1)) for s in row_sums)\n        row_completion = sum(1 for s in row_sums if s <= 1)\n        \n        # Position features\n        diagonal_ones = sum(m[i,i] for i in range(n))\n        off_diagonal = np.sum(m) - diagonal_ones\n        \n        # Matrix structure features\n        rank = np.linalg.matrix_rank(m)\n        upper_tri = np.sum(np.triu(m))\n        \n        return (np.sum(m), \n                -col_completion,\n                -row_completion,\n                col_log_sums,\n                row_log_sums,\n                -diagonal_ones,\n                off_diagonal,\n                -rank,\n                upper_tri)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": -0.22933712426782513,
      "additional_data": {
        "spearman_correlation": "-0.229337",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 239,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 247,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(s for s in col_sums if s <= 2)\n        row_completion = sum(s for s in row_sums if s <= 2)\n        \n        l1_norm = np.sum(np.abs(m))\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                l1_norm)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8641348036311776,
      "additional_data": {
        "spearman_correlation": "0.864135",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 241,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 248,
    "parent_id": 212,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        col_log_sum = np.sum(np.log2(col_sums))\n        row_log_sum = np.sum(np.log2(row_sums))\n        col_var = np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        return (col_log_sum, row_log_sum, col_var + row_var)\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*3\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*3\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.874828749402044,
      "additional_data": {
        "spearman_correlation": "0.874829",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 242,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 249,
    "parent_id": 56,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_metric = np.sum(np.log(col_sums + 1))\n        row_metric = np.sum(np.log(row_sums + 1))\n        return col_metric + row_metric\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    best_heuristic = min(matrix_heuristic(m) for m in variants)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": -0.06070223842947512,
      "additional_data": {
        "spearman_correlation": "-0.060702",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 246,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 250,
    "parent_id": 213,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_cost(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance to identity/anti-identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                        np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Logarithmic column weight penalty\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))  # Avoid log(0)\n        \n        # Combine metrics with weights\n        return 0.5 * diag_dist + 0.3 * log_col + 0.2 * (total_ones - n)\n    \n    # Compute cost for all variants\n    original = matrix_cost(matrix)\n    transposed = matrix_cost(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_cost(inv_matrix)\n    inv_transposed = matrix_cost(inv_matrix.T)\n    \n    # Return the minimum cost across all variants\n    return min(original, transposed, inverse, inv_transposed)\n",
    "evaluation": {
      "fitness": 0.5889175965045138,
      "additional_data": {
        "spearman_correlation": "0.588918",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 243,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 251,
    "parent_id": 35,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_nonzero = np.count_nonzero(m)\n        \n        # Avoid log(0) by clipping small values\n        safe_col_sums = np.maximum(col_sums, 1e-10)\n        safe_row_sums = np.maximum(row_sums, 1e-10)\n        \n        h1 = float(np.sum(np.log(safe_col_sums)))\n        h2 = float(np.sum(np.log(safe_row_sums)))\n        h3 = float(total_nonzero)\n        \n        # Count completed rows/cols (exactly one 1)\n        n_done_rows = np.count_nonzero(row_sums == 1)\n        n_done_cols = np.count_nonzero(col_sums == 1)\n        h4 = float(2 * n - n_done_rows - n_done_cols)\n        \n        return (h1, h2, h3, h4)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8680343593587964,
      "additional_data": {
        "spearman_correlation": "0.868034",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 204,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 252,
    "parent_id": 135,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with squared imbalance and near-matches.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count matching and near-matching column pairs\n        cols = m.T\n        col_pairs = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                if diff == 0:\n                    col_pairs += 2  # exact match\n                elif diff == 1:\n                    col_pairs += 1  # near-match\n        \n        # Count matching and near-matching row pairs\n        rows = m\n        row_pairs = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                if diff == 0:\n                    row_pairs += 2  # exact match\n                elif diff == 1:\n                    row_pairs += 1  # near-match\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -(col_pairs + row_pairs), *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8701741981406901,
      "additional_data": {
        "spearman_correlation": "0.870174",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 245,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 253,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s == 1)\n        col_overlaps = sum(np.dot(m[:,i], m[:,j]) for i in range(n) for j in range(i+1, n))\n        \n        # Row metrics\n        unique_rows = len({tuple(row) for row in m})\n        row_completion = sum(1 for s in row_sums if s == 1)\n        \n        # Diagonal progress\n        diag = np.diag(m)\n        diag_completion = sum(diag)\n        off_diag = np.sum(m) - diag_completion\n        \n        # Triangular progress\n        upper_tri = np.sum(np.triu(m, k=1))\n        lower_tri = np.sum(np.tril(m, k=-1))\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                -unique_rows,\n                col_overlaps,\n                off_diag,\n                upper_tri + lower_tri)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8796471425053966,
      "additional_data": {
        "spearman_correlation": "0.879647",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 244,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 254,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        # Weighted column completion\n        col_completion = sum(1/s if s > 0 else 0 for s in col_sums)\n        \n        # Row sum symmetry\n        row_sum_diff = np.sum(np.abs(row_sums - np.mean(row_sums)))\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                row_sum_diff)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8740373765427877,
      "additional_data": {
        "spearman_correlation": "0.874037",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 247,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 255,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # LU decomposition metrics\n        P, L, U = lu(m)\n        L_nonzeros = np.count_nonzero(L - np.diag(np.diag(L)))\n        U_nonzeros = np.count_nonzero(U - np.diag(np.diag(U)))\n        \n        # Column metrics\n        unique_cols = len(set(tuple(col) for col in m.T))\n        col_completion = sum(np.exp(-s) for s in col_sums)\n        \n        # Distance to identity\n        diff = m - np.eye(m.shape[0], dtype=int)\n        distance = np.sum(np.abs(diff))\n        \n        return (distance,\n                nonzeros,\n                -col_completion,\n                L_nonzeros + U_nonzeros,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 248,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 14
    }
  },
  {
    "id": 256,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def column_entropy(col):\n        n = len(col)\n        if n == 0: return 0\n        p = sum(col)/n\n        if p == 0 or p == 1: return 0\n        return -p*log2(p) - (1-p)*log2(1-p)\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column metrics\n        col_entropies = [column_entropy(m[:,i]) for i in range(n)]\n        avg_col_entropy = sum(col_entropies)/n\n        col_completion = sum(1 - s/n for s in col_sums)\n        col_variance = np.var(col_sums)\n        \n        # Row metrics\n        row_entropies = [column_entropy(m[i,:]) for i in range(n)]\n        avg_row_entropy = sum(row_entropies)/n\n        row_completion = sum(1 - s/n for s in row_sums)\n        row_variance = np.var(row_sums)\n        \n        # Structural metrics\n        rank = np.linalg.matrix_rank(m)\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        return (avg_col_entropy + avg_row_entropy,\n                -col_completion - row_completion,\n                col_variance + row_variance,\n                -rank,\n                -(unique_cols + unique_rows))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 249,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 15
    }
  },
  {
    "id": 257,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        log_col_sums = sum(log2(s + 1) for s in col_sums)\n        col_completion = sum(1/(s + 1) for s in col_sums)\n        col_variance = np.var(col_sums)\n        \n        # Row metrics\n        unique_rows = len({tuple(row) for row in m})\n        log_row_sums = sum(log2(s + 1) for s in row_sums)\n        row_completion = sum(1/(s + 1) for s in row_sums)\n        row_variance = np.var(row_sums)\n        \n        return (nonzeros,\n                -log_col_sums,\n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                -log_row_sums,\n                -row_completion,\n                -unique_rows,\n                col_variance,\n                row_variance)\n    \n    # Consider all isomorphic variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T,\n        matrix[:, ::-1],  # column permutation\n        matrix[::-1, :],  # row permutation\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 250,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 16
    }
  },
  {
    "id": 258,
    "parent_id": 173,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on key structural metrics.\"\"\"\n    import numpy as np\n    \n    def analyze(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row distance to identity\n        col_dist = sum(min(sum(abs(col - target)) for target in np.eye(n).T) for col in m.T)\n        row_dist = sum(min(sum(abs(row - target)) for target in np.eye(n)) for row in m)\n        \n        # Block structure detection\n        block_score = 0\n        for k in range(1, n):\n            if (np.all(m[:k,:k] == np.eye(k)) and (np.all(m[k:,k:] == np.eye(n-k))):\n                block_score = k*(n-k)\n                break\n        \n        # Column/row patterns\n        unique_cols = len({tuple(col) for col in m.T})\n        unique_rows = len({tuple(row) for row in m})\n        \n        return (nonzeros, -block_score, col_dist + row_dist, -unique_cols - unique_rows)\n    \n    # Generate all variants\n    variants = []\n    n = matrix.shape[0]\n    for p in [matrix, np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix).T]:\n        variants.append(analyze(p))\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 251,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 259,
    "parent_id": 142,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(m):\n        n = m.shape[0]\n        m_int = m.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((m_int, I))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return np.zeros_like(m)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        col_log_sum = np.sum(np.log(col_sums))\n        row_log_sum = np.sum(np.log(row_sums))\n        return (col_log_sum, row_log_sum)\n\n    variants = [\n        matrix,\n        gf2_inv(matrix),\n        matrix.T,\n        gf2_inv(matrix).T\n    ]\n    \n    candidates = [calculate_heuristic(m) for m in variants]\n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.873184075565956,
      "additional_data": {
        "spearman_correlation": "0.873184",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 161,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 260,
    "parent_id": 81,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums and permutation distance.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        perm_distance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        col_prod = np.prod(col_sums + (col_sums == 0))\n        return (np.log(col_prod + 0.1), perm_distance\n    \n    orig_metrics = matrix_metrics(matrix)\n    trans_metrics = matrix_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        inv_metrics = matrix_metrics(inv_matrix)\n    except:\n        inv_metrics = (float('inf'), float('inf'))\n    \n    combined = []\n    for i in range(2):\n        combined.append(min(orig_metrics[i], trans_metrics[i], inv_metrics[i]))\n    \n    return tuple(combined)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 11)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 255,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 261,
    "parent_id": 211,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n    for col in range(n):\n        pivot = col\n        while pivot < n and aug[pivot, col] == 0:\n            pivot += 1\n        if pivot == n:\n            raise np.linalg.LinAlgError(\"Singular matrix\")\n        if pivot != col:\n            aug[[col, pivot]] = aug[[pivot, col]]\n        for r in range(n):\n            if r != col and aug[r, col] == 1:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:]\n\ndef heuristic(matrix):\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        col_log_sum = np.sum(np.log2(col_sums))\n        return (nonzeros, col_log_sum)\n    \n    inv = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'gf2_inv' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 214,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 17
    }
  },
  {
    "id": 262,
    "parent_id": 163,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n        variants.append((matrix @ inv_mat) % 2)\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.maximum(row_weights, 1)\n        \n        log_col = np.sum(np.sqrt(col_weights))\n        log_row = np.sum(np.log(row_weights))\n        sum_weights = np.sum(m)\n        \n        h_val = 0.6 * log_col + 0.25 * log_row + 0.15 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.000000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 253,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 263,
    "parent_id": 132,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on most predictive metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Core metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Weighted metrics\n        col_weights = np.sort(col_sums)[::-1]\n        row_weights = np.sort(row_sums)[::-1]\n        log_weights = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        \n        # Simplified imbalance\n        imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        \n        return (nonzeros, -done_cols-done_rows, log_weights, imbalance, *col_weights, *row_weights)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827793372898055,
      "additional_data": {
        "spearman_correlation": "0.882779",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 254,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 264,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_metrics(m):\n        # Column metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_entropy = [-sum(p*log2(p) if p > 0 else 0 for p in col/np.sum(col))) for col in m.T]\n        \n        # Row metrics\n        row_sums = np.sum(m, axis=1)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_entropy = [-sum(p*log2(p) if p > 0 else 0 for p in row/np.sum(row))) for row in m]\n        \n        # Global metrics\n        total_nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        is_lower_tri = np.allclose(m, np.tril(m))\n        is_upper_tri = np.allclose(m, np.triu(m))\n        \n        # Column completion metrics\n        col_completion = sum(1 for s in col_sums if s <= 1)\n        row_completion = sum(1 for s in row_sums if s <= 1)\n        \n        # Unique columns/rows\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        # Combined metrics\n        col_complexity = sum(log2(s+1) for s in col_sums)\n        row_complexity = sum(log2(s+1) for s in row_sums)\n        \n        return (total_nonzeros,\n                -col_completion,\n                -row_completion,\n                -rank,\n                -unique_cols,\n                -unique_rows,\n                col_complexity,\n                row_complexity,\n                is_lower_tri,\n                is_upper_tri,\n                np.mean(col_entropy),\n                np.mean(row_entropy))\n    \n    # Generate all variants efficiently\n    variants = [matrix]\n    try:\n        variants.append(np.linalg.inv(matrix))\n    except:\n        pass\n    variants.append(matrix.T)\n    try:\n        variants.append(np.linalg.inv(matrix).T)\n    except:\n        pass\n    \n    # Return minimum across all valid variants\n    return min(get_metrics(m) for m in variants if isinstance(m, np.ndarray))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "closing parenthesis ')' does not match opening parenthesis '[' (<string>, line 10)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 252,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 18
    }
  },
  {
    "id": 265,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(col_sums)\n        row_completion = sum(row_sums)\n        \n        return (nonzeros, \n                col_completion,\n                row_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8777260935999132,
      "additional_data": {
        "spearman_correlation": "0.877726",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 258,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 19
    }
  },
  {
    "id": 266,
    "parent_id": 57,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums and variants.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Sort column sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        # More sensitive column and row imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        max_col = max(col_sums)\n        return (nonzeros, col_imbalance, row_imbalance, max_col, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8700523386997271,
      "additional_data": {
        "spearman_correlation": "0.870052",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 259,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 267,
    "parent_id": 203,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + 1e-10))\n        log_sum_row = np.sum(np.log(row_sums + 1e-10))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        rows_two = np.sum(row_sums == 2)\n        t = (log_sum_col, log_sum_row, total_ones, -cols_two, -rows_two, -basis_cols, -basis_rows)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8741360714154593,
      "additional_data": {
        "spearman_correlation": "0.874136",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 256,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 268,
    "parent_id": 109,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with better metrics and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Squared imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824246069167337,
      "additional_data": {
        "spearman_correlation": "0.882425",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 257,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 269,
    "parent_id": 27,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Basic metrics\n        col_metric = np.sum(np.log(col_sums))\n        row_metric = np.sum(np.log(row_sums))\n        \n        # Diagonal metrics\n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = max(diag, anti_diag) / n\n        \n        # New metrics\n        basis_proximity = np.sum(np.minimum(col_sums, np.ones(n) * (n-1)))\n        rank_metric = np.linalg.matrix_rank(m) / n\n        \n        # Pairwise column interactions\n        col_pair_metric = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_pair_metric += np.sum(m[:,i] & m[:,j])\n        col_pair_metric /= (n*(n-1)/2) if n > 1 else 1\n        \n        return (col_metric, row_metric, -diag_metric, -basis_proximity, -rank_metric, -col_pair_metric)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 262,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 270,
    "parent_id": 252,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with absolute imbalance and refined matching.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count exact and near matches separately\n        cols = m.T\n        exact_col_pairs = 0\n        near_col_pairs = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                if diff == 0:\n                    exact_col_pairs += 1\n                elif diff == 1:\n                    near_col_pairs += 1\n        \n        rows = m\n        exact_row_pairs = 0\n        near_row_pairs = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                if diff == 0:\n                    exact_row_pairs += 1\n                elif diff == 1:\n                    near_row_pairs += 1\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(col_sums == 0) + np.sum(col_sums == len(col_sums))\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + np.sum(row_sums == 0) + np.sum(row_sums == len(row_sums))\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -exact_col_pairs, -near_col_pairs,\n                -exact_row_pairs, -near_row_pairs,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8833166762905816,
      "additional_data": {
        "spearman_correlation": "0.883317",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 6,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 261,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 271,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Column metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_max = np.max(m, axis=0)\n        col_min = np.min(m, axis=0)\n        \n        # Row metrics\n        row_sums = np.sum(m, axis=1)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_max = np.max(m, axis=1)\n        row_min = np.min(m, axis=1)\n        \n        # Interaction metrics\n        diag = np.diag(m)\n        anti_diag = np.diag(np.fliplr(m))\n        trace = np.sum(diag)\n        anti_trace = np.sum(anti_diag)\n        \n        # Composite metrics\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        diag_completion = np.sum(diag == 1)\n        anti_diag_completion = np.sum(anti_diag == 1)\n        \n        # Return as tuple with carefully ordered metrics\n        return (\n            np.sum(col_nonzeros),  # Total column nonzeros\n            np.sum(row_nonzeros),  # Total row nonzeros\n            -diag_completion,     # Progress toward diagonal\n            -anti_diag_completion, # Progress toward anti-diagonal\n            np.sum(col_sums != 1), # Columns not matching identity\n            np.sum(row_sums != 1), # Rows not matching identity\n            col_variance,         # Column sum variance\n            row_variance,         # Row sum variance\n            -trace,               # Progress toward identity trace\n            -anti_trace           # Progress toward anti-identity trace\n        )\n    \n    # Generate all 8 equivalent matrix forms\n    matrices = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix),\n        np.linalg.inv(matrix).T,\n        np.fliplr(matrix),\n        np.fliplr(matrix).T,\n        np.linalg.inv(np.fliplr(matrix)),\n        np.linalg.inv(np.fliplr(matrix)).T\n    ]\n    \n    # Return the minimum heuristic across all forms\n    return min(get_heuristic(m) for m in matrices)\n",
    "evaluation": {
      "fitness": 0.8610016429429407,
      "additional_data": {
        "spearman_correlation": "0.861002",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 260,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 20
    }
  },
  {
    "id": 272,
    "parent_id": 254,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # LU decomposition metrics\n        P, L, U = lu(m)\n        L_nnz = np.count_nonzero(L) - m.shape[0]  # subtract diagonal\n        U_nnz = np.count_nonzero(U)\n        lu_complexity = L_nnz + U_nnz\n        \n        # Column variance and covariance\n        col_var = np.var(col_sums)\n        col_cov = np.sum(np.cov(m))\n        \n        # Row pattern complexity\n        unique_rows = len({tuple(row) for row in m})\n        row_pattern_var = np.var([sum(row) for row in m])\n        \n        # Column interdependence\n        col_dep = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_dep += np.sum(m[:,i] & m[:,j])\n        \n        return (nonzeros,\n                -lu_complexity,\n                col_var,\n                col_cov,\n                -unique_rows,\n                row_pattern_var,\n                col_dep)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 265,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 273,
    "parent_id": 133,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def matrix_metrics(m):\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        \n        # Column and row basis distances\n        basis = np.eye(n, dtype=int)\n        col_dist = sum(min(hamming(m[:,i], basis[:,j]) for j in range(n)) for i in range(n))\n        row_dist = sum(min(hamming(m[i,:], basis[j,:]) for j in range(n)) for i in range(n))\n        \n        # Combined row-column correlation\n        rowcol_corr = sum(sum(m[i,:] != m[:,i]) for i in range(n))\n        \n        # Spread metric (sum of pairwise column distances)\n        spread = sum(hamming(m[:,i], m[:,j]) for i in range(n) for j in range(i+1, n))\n        \n        # Singular values metric\n        _, s, _ = np.linalg.svd(m)\n        sv_metric = sum(abs(s - 1))\n        \n        return (col_dist + row_dist, rowcol_corr, spread, sv_metric)\n    \n    # Generate more variants including powers\n    variants = [matrix]\n    try:\n        variants += [\n            np.linalg.inv(matrix),\n            matrix.T,\n            np.linalg.inv(matrix.T),\n            np.linalg.inv(matrix).T,\n            np.dot(matrix, matrix) % 2,\n            np.dot(matrix.T, matrix) % 2,\n            np.dot(np.linalg.inv(matrix), matrix) % 2\n        ]\n    except:\n        pass\n    \n    valid_variants = []\n    for v in variants:\n        try:\n            v = np.array(v, dtype=float)\n            if not np.isnan(v).any():\n                valid_variants.append(v)\n        except:\n            continue\n    \n    return min(matrix_metrics(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 264,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 274,
    "parent_id": 45,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        m = m % 2\n        n = m.shape[0]\n        \n        # Column and row metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Interaction metrics - how columns relate to each other\n        col_interactions = np.sum(np.abs(np.corrcoef(m.T)) - n\n        row_interactions = np.sum(np.abs(np.corrcoef(m))) - n\n        \n        # Dynamic weights based on matrix properties\n        sparsity = 1 - np.sum(m) / (n*n)\n        log_weight = 0.5 + 0.4 * sparsity\n        \n        # Combine metrics\n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        base_metric = (log_weight * (col_log + row_log) + \n                      (1-log_weight) * (col_linear + row_linear))\n        \n        # Normalize interaction metrics by matrix size\n        interaction_metric = (col_interactions + row_interactions) / (2*n)\n        \n        # Combine base and interaction metrics\n        return (base_metric + 0.2 * interaction_metric,)\n    \n    # Consider multiple transformations\n    transformations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        matrix @ matrix.T % 2,\n        np.linalg.inv(matrix).T % 2\n    ]\n    \n    return min(calculate_metrics(m) for m in transformations)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 16)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 266,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 275,
    "parent_id": 165,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_complexity(m):\n        rank = np.linalg.matrix_rank(m)\n        n = m.shape[0]\n        \n        # Column-based metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_terms = np.sum(np.log2(np.maximum(col_sums, 1))) + np.sum(col_nonzeros > 1)\n        \n        # Row-based metrics\n        row_sums = np.sum(m, axis=1)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_terms = np.sum(np.log2(np.maximum(row_sums, 1))) + np.sum(row_nonzeros > 1)\n        \n        # Structural metrics\n        upper_tri = np.triu(m, k=1)\n        lower_tri = np.tril(m, k=-1)\n        tri_terms = np.count_nonzero(upper_tri) + np.count_nonzero(lower_tri)\n        \n        # Linearity metrics\n        linear_deps = n - rank\n        \n        return (linear_deps, tri_terms, col_terms + row_terms, rank)\n    \n    variants = [\n        matrix_complexity(matrix),\n        matrix_complexity(np.linalg.inv(matrix)),\n        matrix_complexity(matrix.T),\n        matrix_complexity(np.linalg.inv(matrix).T)\n    ]\n    \n    # Return the best variant based on lexicographical order\n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.7773069715070141,
      "additional_data": {
        "spearman_correlation": "0.777307",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 268,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 276,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s <= 2)\n        col_variance = np.var(col_sums)\n        col_basis_proximity = sum(min(np.sum(np.abs(col - basis)) for col in m.T for basis in np.eye(m.shape[0]))\n        \n        # Row metrics\n        row_variance = np.var(row_sums)\n        row_basis_proximity = sum(min(np.sum(np.abs(row - basis)) for row in m for basis in np.eye(m.shape[1]))\n        \n        # Dependency metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        return (nonzeros,\n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                col_variance,\n                row_variance,\n                -upper_tri_nonzeros,\n                col_basis_proximity,\n                row_basis_proximity)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 16)"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 269,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 21
    }
  },
  {
    "id": 277,
    "parent_id": 236,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with pattern-based metrics and weighted variants.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def pattern_metrics(m):\n        n = m.shape[0]\n        col_patterns = [tuple(m[:,i]) for i in range(n)]\n        row_patterns = [tuple(m[i,:]) for i in range(n)]\n        \n        unique_cols = len(set(col_patterns))\n        unique_rows = len(set(row_patterns))\n        col_overlaps = sum(np.sum(m[:,i] & m[:,j]) for i in range(n) for j in range(i+1,n))\n        row_overlaps = sum(np.sum(m[i,:] & m[j,:]) for i in range(n) for j in range(i+1,n))\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = -np.sum(col_sums * np.log2(np.maximum(col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log2(np.maximum(row_sums, 1)))\n        \n        return (\n            np.sum(m),  # Total nonzeros\n            unique_cols + unique_rows,  # Pattern uniqueness\n            col_overlaps + row_overlaps,  # Overlapping patterns\n            col_entropy + row_entropy,  # Entropy measure\n            *sorted(col_sums, reverse=True),  # Sorted column sums\n            *sorted(row_sums, reverse=True)   # Sorted row sums\n        )\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    variants = [\n        (1.0, matrix),          # Original\n        (0.9, inv_matrix),      # Inverse (usually simpler)\n        (0.8, matrix.T),        # Transpose\n        (0.7, inv_matrix.T)     # Inverse-transpose (often simplest)\n    ]\n    \n    best_heuristic = None\n    for weight, variant in variants:\n        current = pattern_metrics(variant)\n        weighted = (current[0]*weight, current[1]*weight, \n                   current[2], current[3],  # Don't weight pattern-based metrics\n                   *current[4:])  # Keep sorted sums unweighted\n        if best_heuristic is None or weighted < best_heuristic:\n            best_heuristic = weighted\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 267,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 278,
    "parent_id": 231,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        return (np.sum(col_sums), np.sum(row_sums), np.sum(np.log2(np.maximum(col_sums, 1))))\n    \n    m_orig = matrix.astype(int)\n    m_trans = m_orig.T\n    m_inv = gf2_inv(m_orig)\n    \n    variants = [m_orig, m_trans]\n    if m_inv is not None:\n        variants.extend([m_inv, m_inv.T])\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 272,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 279,
    "parent_id": 191,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 1/(np.max(col_sums)+1)\n        log_col = np.log(col_sums + epsilon)\n        log_row = np.log(row_sums + epsilon)\n        nnz = float(np.count_nonzero(m))\n        diag_match = float(np.sum(np.diag(m)))\n        col_var = float(np.var(col_sums))\n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)), nnz, diag_match, col_var)\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    features.append(get_features(inv_matrix))\n    features.append(get_features(inv_matrix.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7202342298365584,
      "additional_data": {
        "spearman_correlation": "0.720234",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 271,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 280,
    "parent_id": 90,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.log(col_sums + 1/np.max(col_sums))\n        log_row = np.log(row_sums + 1/np.max(row_sums))\n        \n        cols1 = np.sum(col_sums == 1)\n        rows1 = np.sum(row_sums == 1)\n        \n        # Count maximum identical columns/rows\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        max_identical_cols = m.shape[1] - unique_cols + 1\n        max_identical_rows = m.shape[0] - unique_rows + 1\n        \n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)),\n                float(cols1), float(rows1), float(max_identical_cols), float(max_identical_rows))\n    \n    def get_best_permutation(m, axis):\n        if axis == 0:\n            sums = np.sum(m, axis=0)\n            order = np.argsort(sums)\n            return m[:, order]\n        else:\n            sums = np.sum(m, axis=1)\n            order = np.argsort(sums)\n            return m[order, :]\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    features.append(get_features(np.linalg.inv(matrix.astype(float)).astype(int) % 2))\n    \n    # Use targeted permutations instead of random ones\n    features.append(get_features(get_best_permutation(matrix, 0)))\n    features.append(get_features(get_best_permutation(matrix, 1)))\n    features.append(get_features(get_best_permutation(matrix.T, 0)))\n    features.append(get_features(get_best_permutation(matrix.T, 1)))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 270,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 281,
    "parent_id": 48,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and added total sum term.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        col_sums = np.maximum(col_sums, 1.0)\n        row_sums = np.maximum(row_sums, 1.0)\n        return float(0.6 * np.sum(np.log(col_sums)) + 0.3 * np.sum(np.log(row_sums)) + 0.1 * total_sum)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8708272271249596,
      "additional_data": {
        "spearman_correlation": "0.870827",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 275,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 282,
    "parent_id": 214,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with both row and column imbalance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        # Combine linear and quadratic column imbalances\n        col_imbalance = np.sum((col_sums - 1)**2) + np.sum(np.abs(col_sums - 1))\n        # Add row imbalance component\n        row_imbalance = np.sum((row_sums - 1)**2) + np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8695679619079155,
      "additional_data": {
        "spearman_correlation": "0.869568",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 276,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 283,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional spread metrics and optimized matching.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Vectorized matching calculation\n        cols = m.T\n        col_diffs = np.sum(cols[:, None, :] != cols[None, :, :], axis=2)\n        exact_col_pairs = np.sum(col_diffs == 0) // 2\n        near_col_pairs = np.sum(col_diffs == 1) // 2\n        \n        rows = m\n        row_diffs = np.sum(rows[:, None, :] != rows[None, :, :], axis=2)\n        exact_row_pairs = np.sum(row_diffs == 0) // 2\n        near_row_pairs = np.sum(row_diffs == 1) // 2\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + 2*np.sum(col_sums == 0) + 2*np.sum(col_sums == len(col_sums))\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + 2*np.sum(row_sums == 0) + 2*np.sum(row_sums == len(row_sums))\n        \n        # Additional spread metrics\n        col_spread = np.std(col_sums)\n        row_spread = np.std(row_sums)\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -exact_col_pairs, -near_col_pairs,\n                -exact_row_pairs, -near_row_pairs,\n                col_spread, row_spread,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8726663344974469,
      "additional_data": {
        "spearman_correlation": "0.872666",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 274,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 284,
    "parent_id": 239,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = aug[r] ^ aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        col_overlaps = np.sum(np.dot(m.T, m) - np.diag(col_sums))\n        row_overlaps = np.sum(np.dot(m, m.T) - np.diag(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        total_dev = col_imbalance + row_imbalance\n        col_devs = np.abs(col_sums - 1)\n        row_devs = np.abs(row_sums - 1)\n        sorted_col_devs = sorted(col_devs, reverse=True)\n        sorted_row_devs = sorted(row_devs, reverse=True)\n        rank = np.linalg.matrix_rank(m)\n        return (nonzeros, done_penalty, total_dev, col_overlaps, row_overlaps, rank, *sorted_col_devs, *sorted_row_devs)\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        h_inv = get_heuristic(inv_matrix)\n        return min(h_orig, h_inv, h_trans)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'done_penalty' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 273,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 285,
    "parent_id": 62,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified column-focused heuristic with aggressive logarithmic scaling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with logarithmic weighting (prioritize nearly-complete columns)\n        col_completion = np.sum(np.log(col_nonzeros + 1))\n        \n        # Column distribution penalty (how far from single non-zero per column)\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8835222683809771,
      "additional_data": {
        "spearman_correlation": "0.883522",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 9,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 277,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 286,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = 1.6 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 2.6 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.4 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        sum_sq = col_sq + row_sq\n        \n        return (nonzeros, incorrect_total, logs, imbalance, max_sum, sum_sq)\n    \n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:\n        h_original = get_heuristic(matrix)\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_transpose)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8716232908173697,
      "additional_data": {
        "spearman_correlation": "0.871623",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 208,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 287,
    "parent_id": 203,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + 1e-10))\n        log_sum_row = np.sum(np.log(row_sums + 1e-10))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        cols_with_two = np.sum(col_sums == 2)\n        rows_with_two = np.sum(row_sums == 2)\n        t = (log_sum_col, log_sum_row, total_ones, -basis_cols, -basis_rows, -cols_with_two, -rows_with_two)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8741360714154593,
      "additional_data": {
        "spearman_correlation": "0.874136",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 279,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 288,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with combined column/row matching and inverse pairs.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = len(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Combined column and row matching\n        exact_pairs = 0\n        near_pairs = 0\n        inverse_pairs = 0\n        elements = list(m.T) + list(m)\n        \n        for i in range(len(elements)):\n            for j in range(i+1, len(elements)):\n                diff = np.sum(elements[i] != elements[j])\n                if diff == 0:\n                    exact_pairs += 1\n                elif diff == 1:\n                    near_pairs += 1\n                elif diff == n:\n                    inverse_pairs += 1\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Weighted imbalance calculation\n        col_imbalance = (np.sum(np.abs(col_sums - 1)) + \n                         2*np.sum(col_sums == 0) + \n                         2*np.sum(col_sums == n))\n        row_imbalance = (np.sum(np.abs(row_sums - 1)) + \n                        2*np.sum(row_sums == 0) + \n                        2*np.sum(row_sums == n))\n        \n        return (nonzeros, col_imbalance + row_imbalance,\n                -exact_pairs, -near_pairs, -inverse_pairs,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8638519415526611,
      "additional_data": {
        "spearman_correlation": "0.863852",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 278,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 289,
    "parent_id": 58,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combine sum and log-sum metrics across all matrix variants.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        log_sum = float(np.sum(np.log(col_sums)))\n        total_sum = float(np.sum(m))\n        return (log_sum, total_sum)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix.T @ matrix % 2,\n        matrix @ matrix.T % 2\n    ]\n    \n    return min(calculate_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.34659016484232485,
      "additional_data": {
        "spearman_correlation": "0.346590",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 281,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 290,
    "parent_id": 262,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        log_col = np.sum(np.log2(col_weights))\n        sum_weights = np.sum(m)\n        h_val = log_col + sum_weights/10.0\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8735999592762017,
      "additional_data": {
        "spearman_correlation": "0.873600",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 282,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 291,
    "parent_id": 221,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column basis similarity\n        basis_similarity = 0\n        for i in range(n):\n            basis_similarity += max(np.sum(m[:,i] == np.eye(n)[:,j]) for j in range(n))\n        \n        # Triangularity metrics\n        L, U = lu(m, permute_l=True)[:2]\n        lower_tri = np.sum(np.tril(L, -1))\n        upper_tri = np.sum(np.triu(U, 1))\n        tri_metric = lower_tri + upper_tri\n        \n        # Column independence\n        _, diag = np.linalg.qr(m)\n        diag_abs = np.abs(diag)\n        col_independence = np.sum(diag_abs < 1e-8)\n        \n        # Column completion (prioritize nearly complete columns)\n        col_completion = sum(1/(s+0.1) for s in col_sums if s > 0)\n        \n        return (tri_metric,\n                -basis_similarity,\n                col_independence,\n                col_completion,\n                nonzeros)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": -0.046332221445771704,
      "additional_data": {
        "spearman_correlation": "-0.046332",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 280,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 292,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using spectral properties and global statistics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Basic statistics\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Spectral properties\n        _, s, _ = np.linalg.svd(m)\n        rank = np.sum(s > 1e-10)\n        spectral_entropy = -np.sum((s/np.sum(s)) * np.log(s/np.sum(s) + 1e-10))\n        \n        # Linear dependencies\n        col_deps = n - np.linalg.matrix_rank(m)\n        row_deps = n - np.linalg.matrix_rank(m.T)\n        \n        # Column/row imbalances\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Global patterns\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        return (nonzeros, \n                n - rank,\n                spectral_entropy,\n                col_imbalance + row_imbalance,\n                -unique_cols,\n                -unique_rows,\n                col_deps + row_deps)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 283,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 293,
    "parent_id": 88,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic considering column interactions and combined matrix properties.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        sorted_cols = np.sort(col_sums)[::-1]\n        log_cols = np.where(sorted_cols > 0, np.log2(sorted_cols + 1), 0)\n        \n        # Measure column dependencies\n        dep_score = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                dep_score += np.sum(m[:,i] & m[:,j])\n        \n        # Row structure score\n        row_sums = np.sum(m, axis=1)\n        row_score = np.sum(np.log2(row_sums + 1)) if np.any(row_sums) else 0\n        \n        # Combined metrics\n        col_interaction = np.sum(log_cols) + 0.5 * dep_score\n        return (col_interaction, row_score)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.T).astype(int) % 2\n    ]\n    \n    scores = [evaluate(v) for v in variants]\n    return min(scores)\n",
    "evaluation": {
      "fitness": 0.695752271039462,
      "additional_data": {
        "spearman_correlation": "0.695752",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 285,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 294,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with binary-log weighting and exact column weight check.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # More aggressive binary log weighting for column completion\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Exact count of columns not having weight 1 (more precise than distance)\n        col_dist = np.sum(col_nonzeros != 1)\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8804786623444117,
      "additional_data": {
        "spearman_correlation": "0.880479",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 287,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 295,
    "parent_id": 230,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        lower_tri = np.tril(m, -1)\n        upper_tri = np.triu(m, 1)\n        \n        # Primary metrics for columns and rows\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        linear_cols = np.sum(col_sums)\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        linear_rows = np.sum(row_sums)\n        \n        # Elimination cost metrics\n        lower_elim = np.count_nonzero(lower_tri)\n        upper_elim = np.count_nonzero(upper_tri)\n        \n        # Triangularity metrics\n        tri_score = (np.count_nonzero(lower_tri) - np.count_nonzero(upper_tri))\n        \n        # Combine metrics with emphasis on column operations first\n        return (log_cols, linear_cols, lower_elim, log_rows, linear_rows, upper_elim, tri_score)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_score(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.028901412088109053,
      "additional_data": {
        "spearman_correlation": "-0.028901",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 286,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 296,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with better weighting and row consideration.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Enhanced column completion with better weighting for single-nonzero columns\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, np.log(col_nonzeros)))\n        \n        # Squared column distribution penalty for more sensitivity\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Small row nonzeros term for tie-breaking\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_penalty = 0.01 * np.sum(row_nonzeros)\n        \n        return (col_completion, col_dist, row_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8832840302598126,
      "additional_data": {
        "spearman_correlation": "0.883284",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 288,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 297,
    "parent_id": 286,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.2 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 2.8 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.8 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        return (nonzeros, incorrect_total, logs, imbalance, max_sum)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = get_heuristic(inv_matrix)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8717099815698298,
      "additional_data": {
        "spearman_correlation": "0.871710",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 284,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 298,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Row-column interaction heuristic with dynamic weighting.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Interaction term: measures how row and column nonzeros correlate\n        interaction = np.sum(np.outer(row_nonzeros, col_nonzeros) * m)\n        \n        # Row and column completion terms with dynamic weighting\n        row_term = np.sum(np.log(row_nonzeros + 1))\n        col_term = np.sum(np.log(col_nonzeros + 1))\n        \n        # Balance between row and column terms based on matrix sparsity\n        sparsity = np.count_nonzero(m) / (n*n)\n        balance = sparsity * row_term + (1-sparsity) * col_term\n        \n        return (interaction, balance)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.37985081412469035,
      "additional_data": {
        "spearman_correlation": "0.379851",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 290,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 299,
    "parent_id": 176,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        total_ones = np.sum(m)\n        \n        non_single_cols = np.sum(col_sums != 1)\n        non_single_rows = np.sum(row_sums != 1)\n        non_single = non_single_cols + non_single_rows\n        \n        return (non_single, total_ones, col_var + row_var, log_cols + log_rows)\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] % 2 == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r == col:\n                    continue\n                if aug[r, col] % 2 == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        inv = aug[:, n:] % 2\n        return inv\n\n    metrics_orig = calculate_metrics(matrix)\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        if inv_matrix is not None:\n            metrics_inv = calculate_metrics(inv_matrix)\n        else:\n            metrics_inv = metrics_orig\n    except Exception:\n        metrics_inv = metrics_orig\n        \n    return min(metrics_orig, metrics_inv)\n",
    "evaluation": {
      "fitness": 0.8359311400582344,
      "additional_data": {
        "spearman_correlation": "0.835931",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 211,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 300,
    "parent_id": 95,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.hstack([matrix, np.eye(n, dtype=int)])\n    for col in range(n):\n        pivot = np.where(aug[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            raise ValueError(\"Matrix is singular\")\n        pivot = pivot[0] + col\n        if pivot != col:\n            aug[[col, pivot]] = aug[[pivot, col]]\n        for r in range(n):\n            if r != col and aug[r, col]:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:]\n\ndef heuristic(matrix):\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        h1 = np.sum(col_sums)\n        h2 = np.sum(np.log2(np.maximum(col_sums, 1)))\n        h3 = np.sum(row_sums)\n        h4 = np.sum(np.log2(np.maximum(row_sums, 1)))\n        h5 = np.sum(col_nonzero * row_nonzero)\n        \n        return (h1, h2, h3, h4, h5)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(gf2_inv(matrix))\n    transpose = calculate_heuristic(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 289,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 301,
    "parent_id": 150,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    original_score = np.sum(np.log1p(col_sums)) * np.sum(np.log1p(row_sums))\n    transposed_matrix = matrix.T\n    trans_col_sums = np.sum(transposed_matrix, axis=0)\n    trans_row_sums = np.sum(transposed_matrix, axis=1)\n    transposed_score = np.sum(np.log1p(trans_col_sums)) * np.sum(np.log1p(trans_row_sums))\n    inverse_matrix = np.linalg.inv(matrix).astype(int) % 2\n    inv_col_sums = np.sum(inverse_matrix, axis=0)\n    inv_row_sums = np.sum(inverse_matrix, axis=1)\n    inverse_score = np.sum(np.log1p(inv_col_sums)) * np.sum(np.log1p(inv_row_sums))\n    return min(original_score, transposed_score, inverse_score)\n",
    "evaluation": {
      "fitness": 0.7229787119625551,
      "additional_data": {
        "spearman_correlation": "0.722979",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 296,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 302,
    "parent_id": 157,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weighted log sums and element count.\"\"\"\n    import numpy as np\n    from numpy.linalg import inv\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        col_weight = np.sum(np.log2(np.maximum(col_sums, 1)) * np.sum(col_nonzero)\n        row_weight = np.sum(np.log2(np.maximum(row_sums, 1)) * np.sum(row_nonzero)\n        element_count = np.sum(m)\n        return min(col_weight, row_weight), element_count\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    try:\n        inverse_heuristic = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse_heuristic = (float('inf'), float('inf'))\n    \n    min_heuristic = min(original_heuristic, transposed_heuristic, inverse_heuristic)\n    return (min_heuristic[0], original_heuristic[0], inverse_heuristic[0], min_heuristic[1])\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 12)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 293,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 303,
    "parent_id": 106,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic using rank-based metrics and column/row interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Column/row interaction metrics\n        col_overlaps = np.sum(m.T @ m) - np.sum(col_sums)\n        row_overlaps = np.sum(m @ m.T) - np.sum(row_sums)\n        \n        # Rank-based metrics\n        rank = np.linalg.matrix_rank(m)\n        nullity = n - rank\n        \n        # Distance to basis vectors\n        col_dist = np.sum(np.minimum(col_sums, np.abs(col_sums - 1)))\n        row_dist = np.sum(np.minimum(row_sums, np.abs(row_sums - 1)))\n        \n        # Column/row clustering\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, -done_cols-done_rows, nullity, col_overlaps + row_overlaps, \n                col_dist + row_dist, rank, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8583024728518179,
      "additional_data": {
        "spearman_correlation": "0.858302",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 291,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 304,
    "parent_id": 218,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect = (n - correct_cols) + (n - correct_rows)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.4 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.2 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_variance = 0.4 * np.var(col_sums)\n        row_variance = 0.2 * np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, incorrect, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882775956858172,
      "additional_data": {
        "spearman_correlation": "0.882776",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 295,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 305,
    "parent_id": 287,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    def get_permuted(mat, perm):\n        return mat[np.ix_(perm, perm)]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    # Generate all possible permutations for small matrices (n <= 4)\n    perms = list(permutations(range(n))) if n <= 4 else [tuple(range(n))]\n    \n    tuples = []\n    for m in matrices:\n        for perm in perms:\n            pm = get_permuted(m, perm)\n            col_sums = np.sum(pm, axis=0)\n            row_sums = np.sum(pm, axis=1)\n            log_sum_col = np.sum(np.log(col_sums + 1e-10))\n            log_sum_row = np.sum(np.log(row_sums + 1e-10))\n            total_ones = np.sum(col_sums)\n            basis_cols = np.sum(col_sums == 1)\n            basis_rows = np.sum(row_sums == 1)\n            cols_with_two = np.sum(col_sums == 2)\n            rows_with_two = np.sum(row_sums == 2)\n            rank = np.linalg.matrix_rank(pm)\n            basis_diff = abs(basis_cols - basis_rows)\n            col_var = np.var(col_sums)\n            row_var = np.var(row_sums)\n            t = (log_sum_col + log_sum_row, \n                 total_ones, \n                 -basis_cols - basis_rows,\n                 -cols_with_two - rows_with_two,\n                 -rank,\n                 basis_diff,\n                 col_var + row_var)\n            tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 292,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 306,
    "parent_id": 84,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        num_col1 = np.sum(col_sums == 1)\n        num_row1 = np.sum(row_sums == 1)\n        return (col_log + row_log, col_sq + row_sq, -(num_col1 + num_row1))\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8588223254043595,
      "additional_data": {
        "spearman_correlation": "0.858822",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 230,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 307,
    "parent_id": 193,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] ^= aug[col]\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        weight2_cols = np.sum(col_sums == 2)\n        weight2_rows = np.sum(row_sums == 2)\n        weight3_cols = np.sum(col_sums == 3)\n        weight3_rows = np.sum(row_sums == 3)\n        weight4plus_cols = np.sum(col_sums >= 4)\n        weight4plus_rows = np.sum(row_sums >= 4)\n        col_sq_dev = np.sum((col_sums - 1) ** 2)\n        row_sq_dev = np.sum((row_sums - 1) ** 2)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, \n                -(done_cols + done_rows),\n                -(weight2_cols + weight2_rows),\n                weight3_cols + weight3_rows,\n                weight4plus_cols + weight4plus_rows,\n                col_sq_dev + row_sq_dev,\n                max_col + max_row)\n\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    try:\n        inv_matrix = gf2_inv(matrix)\n        if inv_matrix is None:\n            h_inverse = get_heuristic(np.eye(matrix.shape[0], dtype=int))\n        else:\n            h_inverse = get_heuristic(inv_matrix)\n    except:\n        h_inverse = get_heuristic(np.eye(matrix.shape[0], dtype=int))\n\n    return min(h_original, h_transpose, h_inverse)\n",
    "evaluation": {
      "fitness": 0.8714238514846177,
      "additional_data": {
        "spearman_correlation": "0.871424",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 294,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 308,
    "parent_id": 190,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.log(col_sums + 1/np.mean(col_sums))\n        log_row = np.log(row_sums + 1/np.mean(row_sums))\n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)))\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    features.append(get_features(inv_matrix))\n    features.append(get_features(inv_matrix.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7955108394320168,
      "additional_data": {
        "spearman_correlation": "0.795511",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 300,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 309,
    "parent_id": 9,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Multi-perspective logarithmic sum heuristic (original, inverse, transpose).\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return (float(np.sum(np.log(col_sums))), float(np.sum(np.log(row_sums))))\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix) % 2\n    except:\n        inv_matrix = matrix\n        \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(inv_matrix),\n        compute_metric(matrix.T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8680100893141796,
      "additional_data": {
        "spearman_correlation": "0.868010",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 303,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 310,
    "parent_id": 212,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column and row sums plus variance term, considering original, transpose, and inverses.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_var = np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        return float(np.sum(np.log(col_sums)) + np.sum(np.log(row_sums)) + col_var + row_var)\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else float('inf')\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else float('inf')\n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.8056534137134791,
      "additional_data": {
        "spearman_correlation": "0.805653",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 301,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 311,
    "parent_id": 13,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering row/column sums, inverse, and spread.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        spread = np.sum(np.abs(np.diff(m, axis=0))) + np.sum(np.abs(np.diff(m, axis=1)))\n        return (weighted_col, weighted_row, spread)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    except:\n        inv_matrix = matrix\n    \n    metrics = [\n        calculate_metrics(matrix),\n        calculate_metrics(matrix.T),\n        calculate_metrics(inv_matrix),\n        calculate_metrics(inv_matrix.T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.7240170099017037,
      "additional_data": {
        "spearman_correlation": "0.724017",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 302,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 312,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified column-focused heuristic with aggressive logarithmic scaling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with logarithmic weighting (prioritize nearly-complete columns)\n        col_completion = np.sum(np.log(col_nonzeros + 1))\n        \n        # Column distribution penalty (only for columns not already completed)\n        col_sums = np.sum(m, axis=0)\n        incomplete_cols = col_nonzeros != 1\n        col_dist = np.sum(np.abs(col_sums[incomplete_cols] - 1))\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8835222683809771,
      "additional_data": {
        "spearman_correlation": "0.883522",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 305,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 313,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with more aggressive logarithmic scaling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # More aggressive logarithmic weighting using log2\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Count of columns with exactly 1 non-zero (direct measure of progress)\n        col_singles = np.sum(col_nonzeros == 1)\n        \n        # Column distribution penalty\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1)\n        \n        return (col_completion, -col_singles, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 17)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 306,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 314,
    "parent_id": 75,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better column prioritization and squared imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Prioritize columns with sum=1 more than rows\n        cols_done = np.sum(col_sums == 1) * 2\n        rows_done = np.sum(row_sums == 1)\n        zeros_done = np.sum(col_sums == 0) + np.sum(row_sums == 0)\n        # Use squared differences to prioritize larger imbalances\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        # Summarize sums statistics more compactly\n        col_stats = (np.mean(col_sums), np.std(col_sums))\n        row_stats = (np.mean(row_sums), np.std(row_sums))\n        return (nonzeros, cols_done + rows_done, zeros_done, \n                col_imbalance + row_imbalance, *col_stats, *row_stats)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8529963515688058,
      "additional_data": {
        "spearman_correlation": "0.852996",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 304,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 315,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with better logarithmic scaling of column sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        \n        # Column completion with logarithmic weighting using actual column sums\n        col_completion = np.sum(np.log(col_sums + 1))\n        \n        # Column distribution penalty (how far from single non-zero per column)\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 307,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 316,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering columns, rows, and equivalent matrices.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log1p(col_sums))\n        log_row = np.sum(np.log1p(row_sums))\n        return min(log_col, log_row)\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverse = compute_metric(np.linalg.inv(matrix).astype(int) % 2\n    \n    return min(original, transposed, inverse)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 308,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 317,
    "parent_id": 1,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums and transposed matrix.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    base_heuristic = float(np.sum(matrix))\n    col_heuristic = float(np.sum(np.log2(col_sums + 1)))\n    transposed_heuristic = float(np.sum(matrix.T))\n    return (base_heuristic, col_heuristic, transposed_heuristic)\n",
    "evaluation": {
      "fitness": 0.766856818032109,
      "additional_data": {
        "spearman_correlation": "0.766857",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 310,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 318,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with log2 scaling and sparsity term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting (more aggressive scaling)\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution penalty\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Small sparsity term to break ties\n        sparsity = np.count_nonzero(m) / (n*n)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842652417319493,
      "additional_data": {
        "spearman_correlation": "0.884265",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 309,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 319,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        \n        # Column completion with logarithmic weighting\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_completion = np.sum(np.log(col_nonzeros + 1))\n        \n        # Row completion with logarithmic weighting\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_completion = np.sum(np.log(row_nonzeros + 1))\n        \n        # Quadratic penalty for column distribution\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Quadratic penalty for row distribution\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Diagonal dominance measure\n        diag_measure = np.sum(np.abs(m - np.diag(np.diag(m))))\n        \n        return (col_completion + row_completion, col_dist + row_dist, diag_measure)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    # Combine information from all variants\n    heuristics = [get_heuristic(v) for v in variants]\n    return tuple(np.min([h[i] for h in heuristics]) for i in range(3))\n",
    "evaluation": {
      "fitness": 0.8801471428795585,
      "additional_data": {
        "spearman_correlation": "0.880147",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 311,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 320,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        A = A.astype(int)\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] != 0:\n                    pivot = r\n                    break\n            if pivot != col:\n                aug[[pivot, col]] = aug[[col, pivot]]\n            for r in range(n):\n                if r != col and aug[r, col] != 0:\n                    aug[r] = (aug[r] ^ aug[col])\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        m_bin = (m != 0).astype(int)\n        col_sums = np.sum(m_bin, axis=0)\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_completion = np.sum(col_sums <= 2)\n        return (log_sum, -col_completion)\n\n    inv = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8741184919991442,
      "additional_data": {
        "spearman_correlation": "0.874118",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 222,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 22
    }
  },
  {
    "id": 321,
    "parent_id": 236,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column/row patterns and diagonal properties.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def analyze(m):\n        n = m.shape[0]\n        col_props = []\n        row_props = []\n        \n        for i in range(n):\n            col = m[:, i]\n            row = m[i, :]\n            col_weight = np.sum(col)\n            row_weight = np.sum(row)\n            col_props.append((col_weight, int(col[i]), np.sum(col[i+1:])))\n            row_props.append((row_weight, int(row[i]), np.sum(row[i+1:])))\n            \n        diag = np.diag(m)\n        diag_sum = np.sum(diag)\n        off_diag = np.sum(m) - diag_sum\n        \n        col_weights = sorted([p[0] for p in col_props], reverse=True)\n        row_weights = sorted([p[0] for p in row_props], reverse=True)\n        col_diag = sum(p[1] for p in col_props)\n        row_diag = sum(p[1] for p in row_props)\n        col_tri = sum(p[2] for p in col_props)\n        row_tri = sum(p[2] for p in row_props)\n        \n        return (\n            off_diag,\n            diag_sum,\n            tuple(col_weights),\n            tuple(row_weights),\n            col_diag + row_diag,\n            col_tri + row_tri\n        )\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    h_original = analyze(matrix)\n    h_inverse = analyze(inv_matrix)\n    h_transpose = analyze(matrix.T)\n    h_inverse_transpose = analyze(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.7678943740422519,
      "additional_data": {
        "spearman_correlation": "0.767894",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 312,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 322,
    "parent_id": 134,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        prod_cols = np.prod(np.maximum(col_sums, 1))\n        sorted_cols = sorted(col_sums)\n        sorted_rows = sorted(row_sums)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        var_col = np.var(col_sums)\n        cols_with_2 = np.sum(col_sums == 2)\n        rows_with_2 = np.sum(row_sums == 2)\n        unique_col_sums = len(np.unique(col_sums))\n        unique_row_sums = len(np.unique(row_sums))\n        col_diff = sum(abs(a-b) for a,b in zip(sorted_cols[:-1], sorted_cols[1:]))\n        row_diff = sum(abs(a-b) for a,b in zip(sorted_rows[:-1], sorted_rows[1:]))\n        \n        return (nonzeros, -done_cols-done_rows-zero_cols-zero_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, prod_cols, var_col, min_col,\n                cols_with_2 + rows_with_2, unique_col_sums + unique_row_sums,\n                col_diff + row_diff, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 314,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 323,
    "parent_id": 221,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column uniqueness and linear independence\n        _, pivots = np.linalg.qr(m)\n        independent_cols = len(pivots)\n        \n        # Column overlap/entanglement\n        col_overlap = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_overlap += np.sum(m[:,i] & m[:,j])\n        \n        # Triangularity measures\n        L, U = lu(m, permute_l=True)[:2]\n        lower_tri = np.sum(np.tril(L, -1))\n        upper_tri = np.sum(np.triu(U, 1))\n        \n        # Column completion (prioritize nearly done columns)\n        col_completion = sum(2-s for s in col_sums if s <= 2)\n        \n        # Row symmetry\n        row_symmetry = -np.sum(np.abs(row_sums - np.mean(row_sums)))\n        \n        # Column linear dependence\n        dep_cols = n - independent_cols\n        \n        return (nonzeros,\n                col_overlap,\n                -col_completion,\n                lower_tri + upper_tri,\n                -independent_cols,\n                dep_cols,\n                row_symmetry)\n    \n    h_original = get_metrics(matrix)\n    h_inverse = get_metrics(np.linalg.inv(matrix))\n    \n    # Also consider partial inverses\n    h_partial = []\n    for i in range(matrix.shape[0]):\n        partial = matrix.copy()\n        partial[:,i] = np.linalg.solve(matrix, np.eye(matrix.shape[0])[:,i])\n        h_partial.append(get_metrics(partial))\n    \n    return min(h_original, h_inverse, *h_partial)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 316,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 324,
    "parent_id": 100,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        weighted_sparsity = np.sum(m * np.arange(1, m.shape[0]+1)[:, np.newaxis])\n        col_diff = np.sum(np.abs(np.diff(col_sums)))\n        return (log_col, log_row, non_zero_cols, non_zero_rows, weighted_sparsity, col_diff)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7106277699053162,
      "additional_data": {
        "spearman_correlation": "0.710628",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 317,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 325,
    "parent_id": 142,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using column/row patterns and tuple return.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column metric: combination of sum of logs and distance from identity\n        col_log_sum = np.sum(np.log(col_sums + 1e-5))\n        col_diff = np.sum(np.abs(col_sums - 1))\n        col_metric = col_log_sum + col_diff\n        \n        # Row metric: same calculation for rows\n        row_log_sum = np.sum(np.log(row_sums + 1e-5))\n        row_diff = np.sum(np.abs(row_sums - 1))\n        row_metric = row_log_sum + row_diff\n        \n        return (col_metric, row_metric)\n    \n    original_metrics = calculate_metrics(matrix)\n    inverse_metrics = calculate_metrics(np.linalg.inv(matrix))\n    \n    # Return the better of original or inverse metrics (lex order)\n    return min(original_metrics, inverse_metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 319,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 326,
    "parent_id": 239,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = aug[r] ^ aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        off_diag = np.sum(m) - np.trace(m)\n        \n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        done_penalty = 2 * n - (cols_done + rows_done)\n        \n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        total_dev = col_imbalance + row_imbalance\n        \n        col_devs = np.abs(col_sums - 1)\n        row_devs = np.abs(row_sums - 1)\n        sorted_col_devs = sorted(col_devs, reverse=True)\n        sorted_row_devs = sorted(row_devs, reverse=True)\n        \n        # New metrics\n        upper_tri_penalty = 0 if np.allclose(np.tril(m, -1), 0) else 1\n        spread = np.sum([np.abs(i-j) for i in range(n) for j in range(n) if m[i,j] == 1])\n        \n        return (nonzeros, off_diag, spread, done_penalty, total_dev, upper_tri_penalty, *sorted_col_devs, *sorted_row_devs)\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        h_inv = get_heuristic(inv_matrix)\n        return min(h_orig, h_inv, h_trans)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.8520403484016351,
      "additional_data": {
        "spearman_correlation": "0.852040",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 318,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 327,
    "parent_id": 120,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.concatenate((matrix, np.eye(n, dtype=int)), axis=1)\n    for col in range(n):\n        pivot = np.where(aug[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            return None\n        pivot = pivot[0] + col\n        if pivot != col:\n            aug[[col, pivot]] = aug[[pivot, col]]\n        for r in range(n):\n            if r != col and aug[r, col]:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:].astype(int)\n\ndef heuristic(matrix):\n    matrix = matrix.astype(int)\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = np.sum(-col_sums * np.log(np.maximum(col_sums, 1e-9)))\n        row_entropy = np.sum(-row_sums * np.log(np.maximum(row_sums, 1e-9)))\n        total_entropy = col_entropy + row_entropy\n        return (nonzeros, -total_entropy)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        if inv_matrix is not None:\n            h_inverse = get_heuristic(inv_matrix)\n        else:\n            h_inverse = h_original\n    except:\n        h_inverse = h_original\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 236,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 328,
    "parent_id": 168,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_stats(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        total_ones = np.sum(m)\n        col_log_sum = np.sum(np.log(np.maximum(col_sums, 1)))\n        row_log_sum = np.sum(np.log(np.maximum(row_sums, 1)))\n        \n        # Spread metrics\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        # Interaction metrics\n        row_dists = np.sum(np.abs(m[:, None, :] - m[None, :, :]), axis=(0,1))\n        col_dists = np.sum(np.abs(m.T[:, None, :] - m.T[None, :, :]), axis=(0,1))\n        \n        # Column/row uniqueness\n        unique_rows = len(np.unique(m, axis=0))\n        unique_cols = len(np.unique(m.T, axis=0))\n        \n        return (col_log_sum + row_log_sum, \n                total_ones,\n                col_var + row_var,\n                row_dists + col_dists,\n                unique_rows + unique_cols)\n    \n    original = matrix_stats(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = matrix_stats(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20, 1e20, 1e20)\n    transpose = matrix_stats(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 320,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 329,
    "parent_id": 181,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and simplified features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = 3.0 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.5 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.0 * np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827461778922673,
      "additional_data": {
        "spearman_correlation": "0.882746",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 323,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 330,
    "parent_id": 314,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Primary metric: columns with sum=1 are most valuable\n        col_progress = np.sum(np.exp(-np.abs(col_sums - 1)))\n        \n        # Secondary metric: global matrix sparsity and structure\n        matrix_imbalance = np.linalg.norm(m - np.eye(m.shape[0], dtype=int), 'fro')\n        \n        # Tertiary metric: logarithmic penalty for large column/row sums\n        log_penalty = np.sum(np.log(1 + np.abs(col_sums - 1))) + \\\n                      np.sum(np.log(1 + np.abs(row_sums - 1)))\n        \n        # Combine metrics with strong emphasis on column progress\n        return (matrix_imbalance + log_penalty) / (1 + col_progress)\n    \n    h_original = evaluate(matrix)\n    h_inverse = evaluate(np.linalg.inv(matrix))\n    h_transpose = evaluate(matrix.T)\n    h_row_reduced = evaluate(matrix[::-1])  # Try row reversal\n    \n    return min(h_original, h_inverse, h_transpose, h_row_reduced)\n",
    "evaluation": {
      "fitness": 0.4991904100543851,
      "additional_data": {
        "spearman_correlation": "0.499190",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 324,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 331,
    "parent_id": 121,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.append(inv_mat)\n        variants.append(inv_mat.T)  # Add inverse transpose\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        h_val = np.sum(np.log(col_weights))  # Safe since invertible matrices have no zero columns\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8725265272009427,
      "additional_data": {
        "spearman_correlation": "0.872527",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 298,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 332,
    "parent_id": 79,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with logarithmic weighting and combined matrix analysis.\"\"\"\n    import numpy as np\n    import math\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Logarithmic weighting for near-complete columns/rows\n        log_col = sum(-math.log(cs) if cs > 0 else 0 for cs in col_sums)\n        log_row = sum(-math.log(rs) if rs > 0 else 0 for rs in row_sums)\n        \n        # Diagonal correctness\n        diag_correct = sum(m[i,i] for i in range(n))\n        \n        # Column/row distribution features\n        col_features = (\n            sum(col_sums == 1),  # weight-1 cols\n            sum(col_sums == 2),  # weight-2 cols\n            sum(col_sums > 2),   # weight>2 cols\n            sum(col_sums == 0)  # zero cols\n        )\n        \n        row_features = (\n            sum(row_sums == 1),\n            sum(row_sums == 2),\n            sum(row_sums > 2),\n            sum(row_sums == 0)\n        )\n        \n        # Combined metrics\n        progress_metric = diag_correct - (nonzeros - diag_correct)\n        log_metric = log_col + log_row\n        \n        return (nonzeros, progress_metric, log_metric, *col_features, *row_features)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    # Combine heuristics rather than just taking min\n    combined = tuple(min(x,y,z) for x,y,z in zip(h_original, h_inverse, h_transpose))\n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 325,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 333,
    "parent_id": 20,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Returns tuple of (minimum, average) of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    avg = (original + inverse + transpose) / 3\n    min_val = min(original, inverse, transpose)\n    return (min_val, avg)\n",
    "evaluation": {
      "fitness": 0.8712225806009647,
      "additional_data": {
        "spearman_correlation": "0.871223",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 327,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 334,
    "parent_id": 318,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Enhanced column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # More meaningful sparsity term using log2\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.88426700095711,
      "additional_data": {
        "spearman_correlation": "0.884267",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 35,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 328,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 335,
    "parent_id": 318,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering both column and row properties with block patterns.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        \n        # Column properties\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        col_sum_deviation = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row properties\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_completion = np.sum(np.log2(row_nonzeros + 1))\n        row_sum_deviation = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Block pattern detection\n        quadrant_size = max(1, n//2)\n        q1 = m[:quadrant_size, :quadrant_size]\n        q2 = m[:quadrant_size, quadrant_size:]\n        q3 = m[quadrant_size:, :quadrant_size]\n        q4 = m[quadrant_size:, quadrant_size:]\n        block_score = (np.count_nonzero(q1) + np.count_nonzero(q4) - \n                      np.count_nonzero(q2) - np.count_nonzero(q3)) / (n*n)\n        \n        # Permutation similarity\n        perm_score = np.sum(m * (1 - m)) / (n*n)  # Penalty for non-binary values\n        \n        return (col_completion + row_completion, \n                col_sum_deviation + row_sum_deviation, \n                block_score, \n                perm_score)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.880599633487224,
      "additional_data": {
        "spearman_correlation": "0.880600",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 329,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 336,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def f2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for i in range(n):\n            pivot = np.where(aug[i:, i] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + i\n            if pivot != i:\n                aug[[i, pivot]] = aug[[pivot, i]]\n            for j in range(n):\n                if j != i and aug[j, i]:\n                    aug[j] ^= aug[i]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        extra_nonzeros = nonzeros - n\n        \n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        total_imbalance = col_imbalance + row_imbalance\n        \n        n_std_cols = np.sum(col_sums == 1)\n        n_std_rows = np.sum(row_sums == 1)\n        std_penalty = (n - n_std_cols) + (n - n_std_rows)\n        \n        cols = m.T\n        exact_col_pairs = near_col_pairs = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                if diff == 0:\n                    exact_col_pairs += 1\n                elif diff == 1:\n                    near_col_pairs += 1\n        \n        rows = m\n        exact_row_pairs = near_row_pairs = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                if diff == 0:\n                    exact_row_pairs += 1\n                elif diff == 1:\n                    near_row_pairs += 1\n        \n        return (extra_nonzeros, total_imbalance, std_penalty,\n                -exact_col_pairs, -near_col_pairs,\n                -exact_row_pairs, -near_row_pairs)\n    \n    h_original = get_heuristic(matrix)\n    h_inv = get_heuristic(f2_inv(matrix.astype(int))) if f2_inv(matrix.astype(int)) is not None else h_original\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inv, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8761217124766668,
      "additional_data": {
        "spearman_correlation": "0.876122",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 261,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 270,
      "exploited_organism_fitness": 0.8833166762905816,
      "child_number": 4
    }
  },
  {
    "id": 337,
    "parent_id": 213,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    total_ones_orig = np.sum(matrix)\n    \n    try:\n        inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n        total_ones_inv = np.sum(inv_matrix)\n    except np.linalg.LinAlgError:\n        total_ones_inv = total_ones_orig\n    \n    return min(total_ones_orig - n, total_ones_inv - n)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 233,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 338,
    "parent_id": 115,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column completion metrics\n        single_cols = np.sum(col_sums == 1)\n        near_single_cols = np.sum((col_sums > 0) & (col_sums <= 2))\n        col_completion = single_cols + 0.5 * near_single_cols\n        \n        # Column interaction metrics\n        col_interactions = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                col_interactions.append(overlap)\n        avg_col_interaction = np.mean(col_interactions) if col_interactions else 0\n        \n        # Column spread metric\n        col_spread = np.sum(np.abs(np.diff(col_sums)))\n        \n        return (col_completion, -avg_col_interaction, col_spread)\n    \n    def structural_metrics(m):\n        n = m.shape[0]\n        upper = np.triu(m, k=1)\n        lower = np.tril(m, k=-1)\n        diag = np.diag(m)\n        \n        # Triangular structure metrics\n        upper_nonzero = np.count_nonzero(upper)\n        lower_nonzero = np.count_nonzero(lower)\n        tri_diff = abs(upper_nonzero - lower_nonzero)\n        \n        # Diagonal dominance\n        diag_dominance = np.sum(diag) / (np.sum(m) + 1e-10)\n        \n        # Block structure\n        block_score = 0\n        for block_size in [2, 3, n//2]:\n            if block_size >= n:\n                continue\n            for i in range(0, n-block_size+1):\n                block = m[i:i+block_size, i:i+block_size]\n                block_score += np.linalg.det(block) if block_size == 2 else np.linalg.norm(block)\n        \n        return (tri_diff, -diag_dominance, block_score)\n    \n    def get_heuristic(m):\n        try:\n            col_metrics = column_metrics(m)\n            struct_metrics = structural_metrics(m)\n            rank = np.linalg.matrix_rank(m)\n            return (*col_metrics, *struct_metrics, -rank)\n        except:\n            return (float('inf'),)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix)) if np.linalg.det(matrix) != 0 else (float('inf'),)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.000000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 331,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 339,
    "parent_id": 189,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # LU decomposition properties\n        P, L, U = lu(m)\n        u_rank = np.linalg.matrix_rank(U)\n        u_nonzeros = np.count_nonzero(U)\n        \n        # Row and column completion metrics\n        col_completion = sum(1 for s in col_sums if s == 1)\n        row_completion = sum(1 for s in row_sums if s == 1)\n        \n        # Column dependency metrics\n        unique_cols = len(set(tuple(col) for col in m.T))\n        dependent_cols = m.shape[1] - basis_cols\n        \n        # Upper triangular properties\n        upper_tri_ratio = u_nonzeros / (m.shape[0] * m.shape[1]) if (m.shape[0] * m.shape[1]) > 0 else 0\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                dependent_cols,\n                u_nonzeros,\n                -u_rank,\n                -upper_tri_ratio)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 332,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 340,
    "parent_id": 60,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Dynamic epsilon based on matrix size\n        eps = 1.0 / (2 * n)\n        safe_col = np.maximum(col_sums, eps)\n        safe_row = np.maximum(row_sums, eps)\n        \n        # Enhanced logarithmic features\n        log_col = np.log(safe_col + 1/np.max(safe_col))\n        log_row = np.log(safe_row + 1/np.max(safe_row))\n        \n        # Additional features\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_entropy = -np.sum(m * np.log(m + (m == 0)), axis=0)\n        row_entropy = -np.sum(m * np.log(m + (m == 0)), axis=1)\n        \n        return (\n            float(np.sum(log_col)),\n            float(np.sum(log_row)),\n            float(np.sum(m)),\n            float(np.sum(col_nonzeros)),\n            float(np.sum(row_nonzeros)),\n            float(np.sum(col_entropy)),\n            float(np.sum(row_entropy))\n        )\n    \n    # Consider more transformations\n    transformations = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        matrix[::-1, :],  # row reverse\n        matrix[:, ::-1],  # column reverse\n        matrix[::-1, ::-1]  # both\n    ]\n    \n    features = [get_features(t) for t in transformations]\n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7499232113560002,
      "additional_data": {
        "spearman_correlation": "0.749923",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 333,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 341,
    "parent_id": 29,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-10\n    \n    # Hierarchical column metrics\n    col_metrics = []\n    for i in range(n):\n        dependent_cols = np.sum(matrix[:,i].reshape(-1,1) * matrix, axis=0)\n        col_metrics.append(np.sum(np.log(col_sums + dependent_cols + epsilon)))\n    \n    # Hierarchical row metrics\n    row_metrics = []\n    for i in range(n):\n        dependent_rows = np.sum(matrix[i,:] * matrix.T, axis=1)\n        row_metrics.append(np.sum(np.log(row_sums + dependent_rows + epsilon)))\n    \n    # Permutation distance\n    perm_dist = np.sum(np.abs(matrix - np.eye(n)))\n    \n    return (np.mean(col_metrics), np.mean(row_metrics), perm_dist) + \n            tuple(sorted(col_metrics)) + tuple(sorted(row_metrics)))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unmatched ')' (<string>, line 25)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 335,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 342,
    "parent_id": 219,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def safe_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 0.5).astype(float)\n        except:\n            return None\n    \n    def get_metrics(m):\n        if m is None:\n            return (float('inf'), float('inf'), float('inf'), float('inf'))\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        col_var = np.var(col_sums)\n        return (log_col, log_row, total_ones, col_var)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        safe_inv(matrix),\n        safe_inv(matrix.T)\n    ]\n    \n    metrics = []\n    for variant in variants:\n        m = get_metrics(variant)\n        if m[0] == float('inf'):\n            continue\n        # Dynamic weights based on matrix properties\n        weight_col = 0.5 - 0.2 * np.tanh(m[3])  # Less weight when column variance is high\n        weight_row = 0.3\n        weight_ones = 0.2 + 0.1 * np.tanh(m[2]/matrix.size)  # More weight when matrix is sparse\n        weighted = (\n            weight_col * m[0],\n            weight_row * m[1],\n            weight_ones * m[2]\n        )\n        metrics.append(weighted)\n    \n    if not metrics:\n        return (float('inf'), float('inf'), float('inf'))\n    \n    # Return tuple of best metrics from all variants\n    best_metrics = min(metrics)\n    return best_metrics\n",
    "evaluation": {
      "fitness": 0.6656422852764499,
      "additional_data": {
        "spearman_correlation": "0.665642",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 334,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 343,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with absolute differences and row distribution.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution term\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Simplified sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842532805103959,
      "additional_data": {
        "spearman_correlation": "0.884253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 336,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 344,
    "parent_id": 126,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m != 0)\n        \n        # Adjusted weights with increased sparsity term\n        return (0.6 * (col_log + row_log) + 0.2 * (col_linear + row_linear) + 0.2 * sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8725078281419497,
      "additional_data": {
        "spearman_correlation": "0.872508",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 337,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 345,
    "parent_id": 28,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    # Compute column sums and row sums for original matrix\n    col_sums_orig = np.sum(matrix, axis=0)\n    row_sums_orig = np.sum(matrix, axis=1)\n    \n    # Compute inverse mod2\n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    except:\n        inv_matrix = matrix  # fallback if inversion fails (shouldn't happen for GL matrices)\n    \n    # Compute column sums and row sums for inverse matrix\n    col_sums_inv = np.sum(inv_matrix, axis=0)\n    row_sums_inv = np.sum(inv_matrix, axis=1)\n    \n    # Avoid log(0) by clamping to small positive value\n    eps = 1e-12\n    col_sums_orig = np.maximum(col_sums_orig, eps)\n    row_sums_orig = np.maximum(row_sums_orig, eps)\n    col_sums_inv = np.maximum(col_sums_inv, eps)\n    row_sums_inv = np.maximum(row_sums_inv, eps)\n    \n    # Calculate heuristic for each representation\n    h1 = np.sum(np.log(col_sums_orig))  # original matrix\n    h2 = np.sum(np.log(row_sums_orig))  # transpose of original\n    h3 = np.sum(np.log(col_sums_inv))   # inverse matrix\n    h4 = np.sum(np.log(row_sums_inv))   # transpose of inverse\n    \n    return min(h1, h2, h3, h4)\n",
    "evaluation": {
      "fitness": 0.7224085820979554,
      "additional_data": {
        "spearman_correlation": "0.722409",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 299,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 346,
    "parent_id": 93,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better column metrics and squared imbalance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Prioritize columns with sum=1\n        cols_done = np.sum(col_sums == 1)\n        # Use squared differences for imbalance to emphasize larger deviations\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        # Include column sum statistics more prominently\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        return (nonzeros, cols_done, col_imbalance + row_imbalance, max_col, min_col)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.852557778142363,
      "additional_data": {
        "spearman_correlation": "0.852558",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 338,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 347,
    "parent_id": 317,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums, transposed and inverse matrices.\"\"\"\n    import numpy as np\n    epsilon = 1e-10\n    col_sums = np.sum(matrix, axis=0)\n    base_heuristic = float(np.sum(matrix))\n    col_heuristic = float(np.sum(np.log2(col_sums + epsilon)))\n    transposed_heuristic = float(np.sum(matrix.T))\n    inverse_heuristic = float(np.sum(np.linalg.inv(matrix)))\n    return (base_heuristic, inverse_heuristic, col_heuristic, transposed_heuristic)\n",
    "evaluation": {
      "fitness": 0.756342116994146,
      "additional_data": {
        "spearman_correlation": "0.756342",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 339,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 348,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic combining row/column patterns, interactions and rank approximation.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with exponential weighting\n        col_completion = np.sum(np.exp(1 - col_nonzeros))\n        \n        # Row completion with exponential weighting\n        row_completion = np.sum(np.exp(1 - row_nonzeros))\n        \n        # Column interaction term (measures how columns affect each other)\n        col_interaction = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        # Rank approximation term (lower rank should be cheaper)\n        _, s, _ = np.linalg.svd(m)\n        rank_approx = np.sum(s > 1e-6)\n        \n        # Pattern clustering term (favors clustered nonzeros)\n        row_cluster = np.sum(np.diff(np.sort(row_nonzeros))**2)\n        col_cluster = np.sum(np.diff(np.sort(col_nonzeros))**2)\n        \n        return (col_completion, row_completion, col_interaction, rank_approx, row_cluster, col_cluster)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.7995119345504801,
      "additional_data": {
        "spearman_correlation": "-0.799512",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 340,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 349,
    "parent_id": 296,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with better weighting for columns with exactly 2 nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Enhanced column completion with special case for 2 nonzeros\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, \n                                      np.where(col_nonzeros == 2, 1.5, np.log(col_nonzeros))))\n        \n        # Absolute column distribution penalty\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Small row nonzeros term for tie-breaking\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_penalty = 0.02 * np.sum(row_nonzeros)\n        \n        return (col_completion, col_dist, row_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.6110229308929638,
      "additional_data": {
        "spearman_correlation": "0.611023",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 341,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 350,
    "parent_id": 110,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic features\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        \n        # Logarithmic column features\n        log_col_sum = sum(log2(cs + 1) for cs in col_sums if cs > 0)\n        log_row_sum = sum(log2(rs + 1) for rs in row_sums if rs > 0)\n        \n        # Column/row weight statistics\n        col_weight_var = np.var(col_sums)\n        row_weight_var = np.var(row_sums)\n        \n        return (\n            total_ones - n,\n            n - col1_count,\n            n - row1_count,\n            log_col_sum,\n            log_row_sum,\n            col_weight_var,\n            row_weight_var\n        )\n    \n    candidates = []\n    # Original matrix\n    candidates.append(get_features(matrix))\n    # Transpose\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse\n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    # Column permutations (sample a few)\n    for _ in range(2):\n        perm = np.random.permutation(matrix.shape[1])\n        candidates.append(get_features(matrix[:, perm]))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.7393744431832446,
      "additional_data": {
        "spearman_correlation": "0.739374",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 342,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 351,
    "parent_id": 175,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, squared deviations and almost-done tracking.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        if np.linalg.matrix_rank(matrix) < n:\n            raise ValueError(\"Matrix not invertible\")\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        log_sum = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        squared_dev = np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2)\n        max_sum = np.max(col_sums) + np.max(row_sums)\n        return (nonzeros, \n                -(done_cols + done_rows + 0.75*(almost_done_cols + almost_done_rows) + 0.25*(zero_cols + zero_rows)),\n                log_sum,\n                squared_dev,\n                max_sum)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(gf2_inv(matrix))\n        h_inverse_transpose = get_heuristic(gf2_inv(matrix).T)\n    except:\n        h_inverse = h_original\n        h_inverse_transpose = h_original\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8645680603266452,
      "additional_data": {
        "spearman_correlation": "0.864568",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 343,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 352,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        total_elements = n * n\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Smoother column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Better normalized sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1) / np.log2(total_elements + 1)\n        \n        # Small row distribution term\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1)) / n\n        \n        return (col_completion, col_dist, sparsity, row_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842575946075834,
      "additional_data": {
        "spearman_correlation": "0.884258",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 344,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 353,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better column completion and added row distribution.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Enhanced column completion with better handling of weight-1 columns\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, np.log2(col_nonzeros)))\n        \n        # Softer column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1)\n        \n        # Row distribution term to complement column metrics\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Sparsity term remains similar but accounts for both dimensions\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 345,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 354,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with balanced terms and added row distribution.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution term\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Simplified sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842532805103959,
      "additional_data": {
        "spearman_correlation": "0.884253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 346,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 355,
    "parent_id": 201,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse and four matrix variants.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        A = matrix.copy().astype(int)\n        I = np.eye(n, dtype=int)\n        # Forward elimination\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if A[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                A[[col, pivot]] = A[[pivot, col]]\n                I[[col, pivot]] = I[[pivot, col]]\n            for row in range(col+1, n):\n                if A[row, col]:\n                    A[row] = (A[row] + A[col]) % 2\n                    I[row] = (I[row] + I[col]) % 2\n        # Backward elimination\n        for col in range(n-1, -1, -1):\n            for row in range(col-1, -1, -1):\n                if A[row, col]:\n                    A[row] = (A[row] + A[col]) % 2\n                    I[row] = (I[row] + I[col]) % 2\n        return I\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        cols_almost = np.sum(col_sums == 2)\n        rows_almost = np.sum(row_sums == 2)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        return (nonzeros, cols_done + rows_done, cols_almost + rows_almost, \n                col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    inv = gf2_inv(matrix)\n    if inv is None:\n        return h_original\n    h_inverse = get_heuristic(inv)\n    h_inv_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_transpose, h_inverse, h_inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8279207712957701,
      "additional_data": {
        "spearman_correlation": "0.827921",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 321,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 356,
    "parent_id": 143,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining multiple metrics and considering variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        col_var = float(np.var(col_sums))\n        return (log_col, col_var, max_col, log_row, sum_total)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8728383689718151,
      "additional_data": {
        "spearman_correlation": "0.872838",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 347,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 357,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.sum(col_sums)\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        num_basis_columns = np.sum(col_sums == 1)\n        num_weight2_columns = np.sum(col_sums == 2)\n        good_columns = num_basis_columns + 0.5 * num_weight2_columns\n        return (nonzeros, log_sum, -good_columns)\n    \n    m1 = matrix\n    try:\n        inv_real = np.linalg.inv(m1.astype(float))\n        m2 = (np.round(inv_real) % 2).astype(int)\n    except:\n        m2 = m1\n    m3 = m1.T\n    try:\n        inv_real_t = np.linalg.inv(m3.astype(float))\n        m4 = (np.round(inv_real_t) % 2).astype(int)\n    except:\n        m4 = m3\n    \n    h_original = get_heuristic(m1)\n    h_inverse = get_heuristic(m2)\n    h_transpose = get_heuristic(m3)\n    h_inverse_transpose = get_heuristic(m4)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.7412597765418609,
      "additional_data": {
        "spearman_correlation": "0.741260",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 263,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 23
    }
  },
  {
    "id": 358,
    "parent_id": 18,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        \n        # New metrics\n        cols_with_weight_1 = np.sum(col_sums == 1)\n        rows_with_weight_1 = np.sum(row_sums == 1)\n        col_row_overlap = np.sum(m * m.T)\n        \n        main_metric = log_col + log_row + hamming\n        secondary_metric = float(cols_with_weight_1 + rows_with_weight_1)\n        tertiary_metric = float(col_row_overlap)\n        \n        return main_metric, secondary_metric, tertiary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    min_tertiary = min(original[2], transposed[2], inverted[2])\n    \n    return (min_main, min_secondary, min_tertiary)\n",
    "evaluation": {
      "fitness": 0.7217304445037985,
      "additional_data": {
        "spearman_correlation": "0.721730",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 348,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 359,
    "parent_id": 150,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    original_score = np.sum(col_sums) + 0.5 * np.sum(row_sums)\n    \n    transposed = matrix.T\n    trans_col_sums = np.sum(transposed, axis=0)\n    trans_row_sums = np.sum(transposed, axis=1)\n    transposed_score = np.sum(trans_col_sums) + 0.5 * np.sum(trans_row_sums)\n    \n    return min(original_score, transposed_score)\n",
    "evaluation": {
      "fitness": 0.7461313165891074,
      "additional_data": {
        "spearman_correlation": "0.746131",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 351,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 360,
    "parent_id": 343,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with squared differences and enhanced sparsity terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Row distribution term using squared differences\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Enhanced sparsity terms\n        col_sparsity = np.sum(np.log2(col_nonzeros + 1))\n        row_sparsity = np.sum(np.log2(row_nonzeros + 1))\n        total_nonzeros = np.count_nonzero(m)\n        \n        return (col_completion, col_dist, row_dist, col_sparsity, row_sparsity, total_nonzeros)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8832934912678442,
      "additional_data": {
        "spearman_correlation": "0.883293",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 350,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 361,
    "parent_id": 329,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and simplified features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = 2.5 * np.sum(np.log1p(col_sums))\n        log_rows = 0.3 * np.sum(np.log1p(row_sums))\n        col_imbalance = 3.2 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 0.8 * np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -correct_cols, log_cols, col_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 352,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 362,
    "parent_id": 5,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Vector heuristic based on log-transformed sorted column sums, considering inverse matrix.\"\"\"\n    import numpy as np\n    epsilon = 1e-10\n    col_sums = np.sum(matrix, axis=0)\n    log_col_sums = np.log(col_sums + epsilon)\n    inv_col_sums = np.sum(np.linalg.inv(matrix), axis=0)\n    log_inv_col_sums = np.log(np.abs(inv_col_sums) + epsilon)\n    return min(tuple(sorted(log_col_sums)), tuple(sorted(log_inv_col_sums))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 10)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 353,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 363,
    "parent_id": 54,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def col_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        non_zero = np.where(col_sums == 0, 1, col_sums)\n        log_terms = np.log2(non_zero + 1)\n        sqrt_terms = np.sqrt(col_sums)\n        weighted = np.sum(col_sums * log_terms * sqrt_terms)\n        return (weighted,) + tuple(sorted(log_terms * sqrt_terms))\n    \n    def row_heuristics(m):\n        row_sums = np.sum(m, axis=1)\n        non_zero = np.where(row_sums == 0, 1, row_sums)\n        log_terms = np.log2(non_zero + 1)\n        sqrt_terms = np.sqrt(row_sums)\n        weighted = np.sum(row_sums * log_terms * sqrt_terms)\n        return (weighted,) + tuple(sorted(log_terms * sqrt_terms))\n    \n    def get_all_heuristics(m):\n        original_col = col_heuristics(m)\n        original_row = row_heuristics(m)\n        transposed_col = col_heuristics(m.T)\n        transposed_row = row_heuristics(m.T)\n        inv = np.linalg.inv(m.astype(float)).astype(int) % 2\n        inv_col = col_heuristics(inv)\n        inv_row = row_heuristics(inv)\n        return min(original_col + original_row, \n                  transposed_col + transposed_row,\n                  inv_col + inv_row)\n    \n    return get_all_heuristics(matrix)\n",
    "evaluation": {
      "fitness": 0.6858366544235258,
      "additional_data": {
        "spearman_correlation": "0.685837",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 354,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 364,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering both row/column properties and matrix algebra features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Balanced row/column completion using sqrt\n        row_completion = np.sum(np.sqrt(row_nonzeros))\n        col_completion = np.sum(np.sqrt(col_nonzeros))\n        \n        # Distribution penalty using absolute differences\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Enhanced sparsity considering both dimensions\n        sparsity = (np.count_nonzero(m) / (n*n)\n        \n        # Matrix algebra features\n        rank = np.linalg.matrix_rank(m)\n        det = np.abs(np.linalg.det(m))\n        \n        return (\n            rank,\n            -det,  # Higher determinant matrices are often simpler\n            row_completion + col_completion,\n            row_dist + col_dist,\n            sparsity\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 20)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 355,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 365,
    "parent_id": 230,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        lower_tri = np.tril(m, -1)\n        upper_tri = np.triu(m, 1)\n        \n        # Primary metric: polynomial column sums (balanced emphasis)\n        col_poly = np.sum((col_sums + 1)**0.5)\n        \n        # Secondary metric: polynomial row sums\n        row_poly = np.sum((row_sums + 1)**0.5)\n        \n        # Tertiary metric: column uniqueness\n        _, col_counts = np.unique(m.T, axis=0, return_counts=True)\n        uniqueness = np.sum(col_counts == 1)\n        \n        # Quaternary metric: nonzeros in both triangles\n        lower_nonzeros = np.count_nonzero(lower_tri)\n        upper_nonzeros = np.count_nonzero(upper_tri)\n        tri_nonzeros = lower_nonzeros + upper_nonzeros\n        \n        return (col_poly, row_poly, uniqueness, tri_nonzeros)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_score(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 357,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 366,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced matrix structure heuristic incorporating row/column interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with exponential weighting\n        col_completion = np.sum(np.exp(col_nonzeros/n) - n\n        \n        # Row completion term\n        row_completion = np.sum(np.exp(row_nonzeros/n)) - n\n        \n        # Column interaction term (measures how columns differ from each other)\n        col_interaction = np.sum(np.exp(np.abs(np.outer(col_sums, 1/col_sums) - 1)))\n        \n        # Row interaction term\n        row_interaction = np.sum(np.exp(np.abs(np.outer(row_sums, 1/row_sums) - 1)))\n        \n        # Sparsity term using matrix rank\n        sparsity = np.linalg.matrix_rank(m)/n\n        \n        return (col_completion, row_completion, col_interaction, row_interaction, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 14)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 358,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 367,
    "parent_id": 278,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    m_orig = matrix.astype(int)\n    m_inv = gf2_inv(m_orig)\n    \n    def compute_tuple(m):\n        T = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        L1 = np.sum(np.log2(col_sums))\n        L2 = np.sum(np.log2(row_sums))\n        return (T, min(L1, L2), max(L1, L2))\n    \n    candidates = [compute_tuple(m_orig)]\n    if m_inv is not None:\n        candidates.append(compute_tuple(m_inv))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 297,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 368,
    "parent_id": 318,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on maximum column weight and total extra ones.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_max = np.max(col_nonzeros)\n        col_extra = np.sum(col_nonzeros - 1)  # Each column has at least 1\n        sparsity = np.count_nonzero(m) / (n * n)\n        return (col_max, col_extra, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8221045584253382,
      "additional_data": {
        "spearman_correlation": "0.822105",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 309,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 318,
      "exploited_organism_fitness": 0.8842652417319493,
      "child_number": 3
    }
  },
  {
    "id": 369,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with better column completion and distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        \n        # Enhanced column completion with better weighting\n        epsilon = 1e-10\n        col_completion = np.sum(np.log2(col_nonzeros + epsilon)) + 0.1 * np.sum(col_nonzeros == 1)\n        \n        # Improved column distribution penalty\n        col_dist = np.sum(np.abs(col_sums - 1)) + 0.1 * np.sum(col_sums == 1)\n        \n        # Better sparsity term considering both rows and columns\n        sparsity = (np.log2(np.count_nonzero(m) + 1) - np.log2(n)) + 0.05 * (np.log2(np.sum(row_nonzeros) + 1) - np.log2(n))\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.883621965840447,
      "additional_data": {
        "spearman_correlation": "0.883622",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 361,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 370,
    "parent_id": 23,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic incorporating inverse/transpose and weighted metrics.\"\"\"\n    import numpy as np\n    epsilon = 1e-10\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.log(col_sums + epsilon)\n        log_row = np.log(row_sums + epsilon)\n        return np.concatenate([log_col, log_row])\n    \n    original = get_metrics(matrix)\n    transposed = get_metrics(matrix.T)\n    inverted = get_metrics(np.linalg.inv(matrix))\n    \n    combined = np.concatenate([\n        0.5 * original,\n        0.3 * transposed,\n        0.2 * inverted\n    ])\n    \n    return tuple(sorted(combined))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 363,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 371,
    "parent_id": 233,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        log_col = np.sum(np.log(col_sums[col_sums > 0])) if non_zero_cols > 0 else 0\n        log_row = np.sum(np.log(row_sums[row_sums > 0])) if non_zero_rows > 0 else 0\n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        max_row = np.max(row_sums) if row_sums.size > 0 else 0\n        sparsity = np.sum(m)\n        cols_with_1 = np.sum(col_sums == 1)\n        rows_with_1 = np.sum(row_sums == 1)\n        cols_with_2 = np.sum(col_sums == 2)\n        rows_with_2 = np.sum(row_sums == 2)\n        min_col = np.min(col_sums[col_sums > 0]) if non_zero_cols > 0 else 0\n        min_row = np.min(row_sums[row_sums > 0]) if non_zero_rows > 0 else 0\n        var_col = np.var(col_sums[col_sums > 0]) if non_zero_cols > 0 else 0\n        var_row = np.var(row_sums[row_sums > 0]) if non_zero_rows > 0 else 0\n        prod_col = np.prod(col_sums[col_sums > 0]) if non_zero_cols > 0 else 1\n        return (log_col, log_row, -non_zero_cols, -non_zero_rows, max_col, max_row, sparsity, -cols_with_1, -rows_with_1, -cols_with_2, -rows_with_2, -min_col, -min_row, var_col, var_row, -prod_col)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    inverse = evaluate(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inverse_transposed = evaluate(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverse, inverse_transposed)\n",
    "evaluation": {
      "fitness": 0.7129135471645985,
      "additional_data": {
        "spearman_correlation": "0.712914",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 362,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 372,
    "parent_id": 74,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        sum_part = np.sum(col_sums)\n        log_part = np.sum(np.log2(col_sums + 1))\n        return sum_part + log_part\n    \n    variants = [\n        matrix,\n        matrix.T,\n    ]\n    \n    try:\n        inv = np.linalg.inv(matrix)\n        if np.all(inv == inv.astype(int)):\n            variants.extend([inv, inv.T])\n    except:\n        pass\n    \n    return min(compute_metric(m) for m in variants)\n",
    "evaluation": {
      "fitness": -0.029432551833675557,
      "additional_data": {
        "spearman_correlation": "-0.029433",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 366,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 373,
    "parent_id": 191,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        epsilon = 1/(np.max(col_sums)+1)\n        log_col = np.log(col_sums + epsilon)\n        log_row = np.log(row_sums + epsilon)\n        nnz = float(np.count_nonzero(m))\n        \n        # New features\n        col_pairs = np.sum(np.outer(col_sums, col_sums) * (m.T @ m))\n        row_pairs = np.sum(np.outer(row_sums, row_sums) * (m @ m.T))\n        unique_cols = len(np.unique(m, axis=1))\n        unique_rows = len(np.unique(m, axis=0))\n        \n        return (float(np.sum(log_col)), float(np.sum(log_row)), \n                float(np.sum(m)), nnz, \n                float(col_pairs), float(row_pairs),\n                unique_cols, unique_rows)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2.T\n    ]\n    \n    features = []\n    for variant in variants:\n        features.append(get_features(variant))\n    \n    # Weighted combination instead of simple min\n    weights = [0.25, 0.25, 0.25, 0.25]\n    combined = tuple(sum(w*f[i] for w, f in zip(weights, features)) for i in range(len(features[0])))\n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid decimal literal (<string>, line 29)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 364,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 374,
    "parent_id": 53,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        \n        log_col = np.sum(np.log(col_sums))\n        hamming = np.sum(m)\n        max_col = np.max(col_sums)\n        \n        main_metric = log_col * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)) + max_col\n        return (main_metric, secondary_metric)\n    \n    original_mat = matrix\n    transposed_mat = matrix.T\n    \n    mat_float = matrix.astype(float)\n    inv_float = np.linalg.inv(mat_float)\n    inverted_mat = np.round(inv_float).astype(int) % 2\n    inv_trans_mat = inverted_mat.T\n    \n    metrics = [\n        calculate_metrics(original_mat),\n        calculate_metrics(transposed_mat),\n        calculate_metrics(inverted_mat),\n        calculate_metrics(inv_trans_mat)\n    ]\n    \n    min_metric = min(metrics)\n    \n    return min_metric\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 16)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 313,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 375,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with absolute differences and simplified terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Simplified sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842652417319493,
      "additional_data": {
        "spearman_correlation": "0.884265",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 367,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 376,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row analysis with interaction terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Weighted column completion with sqrt instead of log\n        col_completion = np.sum(np.sqrt(col_nonzeros))\n        \n        # Row completion term\n        row_completion = np.sum(np.sqrt(row_nonzeros))\n        \n        # Interaction term between columns and rows\n        interaction = np.sum(np.outer(col_nonzeros, row_nonzeros) * m)\n        \n        # Diagonal dominance term\n        diag = np.sum(np.diag(m))\n        off_diag = np.sum(np.abs(m)) - diag\n        diagonal_dominance = off_diag / (diag + 1e-9)\n        \n        # Normalized sparsity term\n        total_nonzero = np.count_nonzero(m)\n        sparsity = (n**2 - total_nonzero) / n**2\n        \n        return (col_completion, row_completion, interaction, diagonal_dominance, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.879484768394147,
      "additional_data": {
        "spearman_correlation": "0.879485",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 368,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 377,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with natural log weighting\n        col_completion = np.sum(np.log(col_nonzeros + 1))\n        \n        # Column distribution using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution term\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Simplified sparsity term\n        sparsity = np.log(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8835260564554043,
      "additional_data": {
        "spearman_correlation": "0.883526",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 370,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 378,
    "parent_id": 344,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m != 0)\n        completed = np.sum(col_sums == 1) + np.sum(row_sums == 1)\n        \n        return (0.65 * (col_log + row_log) + 0.15 * (col_linear + row_linear) + 0.15 * sparsity + 0.05 * completed,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8726172694045817,
      "additional_data": {
        "spearman_correlation": "0.872617",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 369,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 379,
    "parent_id": 97,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with refined weight-one and completion terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with weight exactly 1\n        weight_one_cols = np.sum(col_sums == 1)\n        weight_one_rows = np.sum(row_sums == 1)\n        # Count completed columns/rows (weight 0)\n        completed_cols = np.sum(col_sums == 0)\n        completed_rows = np.sum(row_sums == 0)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Refined imbalance calculation\n        col_imbalance = np.sum(np.abs(col_sums - 1) * (1 + 0.5*(col_sums != 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1) * (1 + 0.5*(row_sums != 1))\n        return (nonzeros, col_imbalance + row_imbalance, -weight_one_cols, -weight_one_rows, -completed_cols, -completed_rows, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 21)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 371,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 380,
    "parent_id": 70,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)  # Count of non-zero elements\n        \n        # Adjusted weights with increased sparsity term\n        return (0.5 * (col_log + row_log) + 0.4 * (col_linear + row_linear) + 0.1 * sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8716995854526459,
      "additional_data": {
        "spearman_correlation": "0.871700",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 374,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 381,
    "parent_id": 177,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Logarithmic sums for columns and rows\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        log_sum = log_cols + log_rows\n        \n        # Row-column interaction measure\n        row_col_interaction = np.sum(m @ m.T)\n        \n        # Unique columns and rows\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        # Sum of pairwise column inner products\n        col_features_sum = 0\n        ncols = m.shape[1]\n        for i in range(ncols):\n            for j in range(i+1, ncols):\n                col_features_sum += np.sum(m[:, i] & m[:, j])\n        \n        return (nonzeros, \n                -unique_cols, \n                -unique_rows,\n                log_sum,\n                row_col_interaction,\n                col_features_sum)\n    \n    n = matrix.shape[0]\n    candidates = []\n    \n    # Original matrix\n    candidates.append(matrix)\n    \n    # Column-sorted versions of original\n    col_sums0 = np.sum(matrix, axis=0)\n    perm_asc0 = np.argsort(col_sums0)\n    perm_desc0 = np.argsort(-col_sums0)\n    candidates.append(matrix[:, perm_asc0])\n    candidates.append(matrix[:, perm_desc0])\n    \n    # Transpose and its column-sorted versions\n    trans = matrix.T\n    candidates.append(trans)\n    col_sums1 = np.sum(trans, axis=0)\n    perm_asc1 = np.argsort(col_sums1)\n    perm_desc1 = np.argsort(-col_sums1)\n    candidates.append(trans[:, perm_asc1])\n    candidates.append(trans[:, perm_desc1])\n    \n    # Evaluate all candidates and return best heuristic\n    best_h = None\n    for mat in candidates:\n        h_val = get_heuristic(mat)\n        if best_h is None or h_val < best_h:\n            best_h = h_val\n            \n    return best_h\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 330,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 382,
    "parent_id": 248,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log_sum = np.sum(np.log2(col_sums))\n        row_log_sum = np.sum(np.log2(row_sums))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (col_log_sum, row_log_sum, max_col, max_row)\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*4\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*4\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8747772933293487,
      "additional_data": {
        "spearman_correlation": "0.874777",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 349,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 383,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with diagonal consideration and correct column/row counting.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        diag_sum = np.sum(np.diag(m))\n        \n        # Count correct columns and rows (sum = 1)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        \n        # Count exact and near matches\n        cols = m.T\n        exact_col_pairs = 0\n        near_col_pairs = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                if diff == 0:\n                    exact_col_pairs += 1\n                elif diff == 1:\n                    near_col_pairs += 1\n        \n        rows = m\n        exact_row_pairs = 0\n        near_row_pairs = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                if diff == 0:\n                    exact_row_pairs += 1\n                elif diff == 1:\n                    near_row_pairs += 1\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(col_sums == 0)*2 + np.sum(col_sums == len(col_sums))*2\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + np.sum(row_sums == 0)*2 + np.sum(row_sums == len(row_sums))*2\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -correct_cols, -correct_rows, -diag_sum,\n                -exact_col_pairs, -near_col_pairs,\n                -exact_row_pairs, -near_row_pairs,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8715037567461293,
      "additional_data": {
        "spearman_correlation": "0.871504",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 373,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 384,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with better logarithmic terms and difference metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Enhanced column completion with natural log and epsilon\n        eps = 1e-6\n        col_completion = np.sum(np.log(col_nonzeros + eps))\n        \n        # Improved column distribution using absolute differences\n        col_dist = np.sum(np.abs(col_sums - 1) + eps)\n        \n        # Better sparsity term using relative nonzeros\n        sparsity = np.log(np.count_nonzero(m)/(n*n) + eps)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8818791665218506,
      "additional_data": {
        "spearman_correlation": "0.881879",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 375,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 385,
    "parent_id": 316,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(m):\n        n = m.shape[0]\n        aug = np.hstack((m, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def compute_candidate(m):\n        col_weights = tuple(sorted(m.sum(axis=0)))\n        total_ones = m.sum()\n        diag_sum = np.diag(m).sum()\n        off_diag = total_ones - diag_sum\n        return col_weights + (off_diag,)\n\n    candidates = []\n    candidates.append(compute_candidate(matrix))\n    candidates.append(compute_candidate(matrix.T))\n    inv = gf2_inv(matrix)\n    if inv is not None:\n        candidates.append(compute_candidate(inv))\n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.8445476985296635,
      "additional_data": {
        "spearman_correlation": "0.844548",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 315,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 386,
    "parent_id": 290,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1.1)  # changed from 1 to 1.1\n        log_col = np.sum(np.log1p(col_weights))  # changed from log2 to log1p\n        sum_weights = np.sum(m)\n        h_val = 0.7 * log_col + 0.3 * (sum_weights/10.0)  # weighted combination\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8723128204231708,
      "additional_data": {
        "spearman_correlation": "0.872313",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 377,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 387,
    "parent_id": 234,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import scipy.linalg\n    \n    def get_features(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Continuous column features\n        col_log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_quad_sum = np.sum(col_sums**2)\n        \n        # Continuous row features\n        row_log_sum = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_quad_sum = np.sum(row_sums**2)\n        \n        # Total ones minus identity (original idea)\n        total_ones = np.sum(m) - n\n        \n        return (total_ones, col_log_sum, row_log_sum, col_quad_sum, row_quad_sum)\n    \n    candidates = []\n    candidates.append(get_features(matrix))\n    candidates.append(get_features(matrix.T))\n    \n    # Try different inverse methods\n    for inv_func in [np.linalg.pinv, scipy.linalg.pinv, np.linalg.inv]:\n        try:\n            inv_matrix = inv_func(matrix)\n            inv_matrix = np.round(inv_matrix).astype(int) % 2\n            if inv_matrix.shape == matrix.shape:\n                candidates.append(get_features(inv_matrix))\n                candidates.append(get_features(inv_matrix.T))\n        except:\n            continue\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.7420327412816259,
      "additional_data": {
        "spearman_correlation": "0.742033",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 379,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 388,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic combining row/column interactions, rank deficiency, and singular values.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-row interaction penalty\n        interaction = np.sum(np.abs(np.outer(row_sums, col_sums) * m)\n        \n        # Rank deficiency measure (distance from full rank)\n        rank_def = n - np.linalg.matrix_rank(m)\n        \n        # Singular value based complexity\n        svd = np.linalg.svd(m, compute_uv=False)\n        sv_complexity = np.sum(np.log2(svd + 1))\n        \n        # Non-linearity measure (how far from being factorizable)\n        factor_penalty = np.sum(np.abs(m - np.outer(row_sums/n, col_sums)))\n        \n        return (rank_def, interaction, sv_complexity, factor_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 12)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 381,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 389,
    "parent_id": 106,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column interaction terms\n        col_xor = np.zeros(n)\n        for i in range(n):\n            for j in range(i+1, n):\n                xor_count = np.sum(m[:,i] != m[:,j])\n                col_xor[i] += xor_count\n                col_xor[j] += xor_count\n        \n        # Row interaction terms\n        row_xor = np.zeros(n)\n        for i in range(n):\n            for j in range(i+1, n):\n                xor_count = np.sum(m[i,:] != m[j,:])\n                row_xor[i] += xor_count\n                row_xor[j] += xor_count\n        \n        # Spread metrics\n        col_spread = np.sum([np.std(m[:,i]) for i in range(n)])\n        row_spread = np.sum([np.std(m[i,:]) for i in range(n)])\n        \n        # Pattern metrics\n        col_pattern = np.sum([np.sum(np.diff(m[:,i])**2) for i in range(n)])\n        row_pattern = np.sum([np.sum(np.diff(m[i,:])**2) for i in range(n)])\n        \n        # Combined metrics\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        imbalance = np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2)\n        interaction = np.sum(col_xor) + np.sum(row_xor)\n        spread = col_spread + row_spread\n        pattern = col_pattern + row_pattern\n        \n        return (nonzeros, interaction, spread, pattern, imbalance, log_cols + log_rows, *col_sums, *row_sums)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8731919352830925,
      "additional_data": {
        "spearman_correlation": "0.873192",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 378,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 390,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row metrics with entropy and interaction terms.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column and row completion with entropy weighting\n        col_completion = entropy(col_nonzeros + 1)\n        row_completion = entropy(row_nonzeros + 1)\n        \n        # Enhanced column/row interaction terms\n        col_interaction = np.sum(np.abs(np.dot(m.T, m) - np.eye(n)))\n        row_interaction = np.sum(np.abs(np.dot(m, m.T) - np.eye(n)))\n        \n        # Entropy-based sparsity measurement\n        sparsity = entropy(m.flatten() + 1)\n        \n        # Cross term measuring column-row alignment\n        cross_term = np.sum(np.abs(np.sum(m, axis=0) - np.sum(m, axis=1)))\n        \n        return (col_completion, row_completion, col_interaction, \n                row_interaction, sparsity, cross_term)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 382,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 14
    }
  },
  {
    "id": 391,
    "parent_id": 105,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining raw sums and logarithmic terms from both original and transposed matrices.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-15\n    log_col_sums = np.log(col_sums + epsilon)\n    log_row_sums = np.log(row_sums + epsilon)\n    \n    transposed = matrix.T\n    t_col_sums = np.sum(transposed, axis=0)\n    t_row_sums = np.sum(transposed, axis=1)\n    t_log_col_sums = np.log(t_col_sums + epsilon)\n    t_log_row_sums = np.log(t_row_sums + epsilon)\n    \n    return (np.sum(matrix),) + tuple(sorted(log_col_sums)) + tuple(sorted(log_row_sums)) + \\\n           (np.sum(transposed),) + tuple(sorted(t_log_col_sums)) + tuple(sorted(t_log_row_sums))\n",
    "evaluation": {
      "fitness": 0.7742032010392207,
      "additional_data": {
        "spearman_correlation": "0.774203",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 384,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 392,
    "parent_id": 183,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic features\n        nonzero_count = np.count_nonzero(m)\n        col_entropy = np.sum(-(col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        row_entropy = np.sum(-(row_sums/n) * np.log2(np.maximum(row_sums/n, 1e-10)))\n        \n        # Interaction term\n        interaction = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        return (\n            nonzero_count,\n            col_entropy + row_entropy,\n            interaction,\n            *sorted(col_sums, reverse=True)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 18)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 385,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 393,
    "parent_id": 316,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log1p(col_sums))\n        log_row = np.sum(np.log1p(row_sums))\n        sum_total = np.sum(m)\n        col_nonzero = np.count_nonzero(col_sums)\n        row_nonzero = np.count_nonzero(row_sums)\n        return (log_col, log_row, sum_total, col_nonzero, row_nonzero)\n    \n    original = get_metrics(matrix)\n    transposed = get_metrics(matrix.T)\n    try:\n        inverse = get_metrics(np.linalg.inv(matrix).astype(int) % 2)\n    except:\n        inverse = (float('inf'),)*5\n    \n    return min(original, transposed, inverse)\n",
    "evaluation": {
      "fitness": 0.7213368621858042,
      "additional_data": {
        "spearman_correlation": "0.721337",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 387,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 394,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with more aggressive column weighting and linear sparsity.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_sums = np.sum(m, axis=0)\n        \n        # More aggressive column completion weighting\n        col_completion = np.sum(1/(col_nonzeros + 0.1))\n        \n        # Absolute difference column distribution penalty\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        # Linear sparsity term\n        sparsity = np.count_nonzero(m)/n\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.7964443727070982,
      "additional_data": {
        "spearman_correlation": "-0.796444",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 388,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 15
    }
  },
  {
    "id": 395,
    "parent_id": 324,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def normalized_entropy(arr):\n        counts = np.bincount(arr)\n        counts = counts[counts > 0]\n        return entropy(counts) if len(counts) > 1 else 0\n    \n    def evaluate(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        \n        # Column features\n        col_sums = np.sum(m, axis=0)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        col_entropy = [normalized_entropy(m[:,i]) for i in range(n)]\n        \n        # Row features\n        row_sums = np.sum(m, axis=1)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        row_entropy = [normalized_entropy(m[i,:]) for i in range(n)]\n        \n        # Interaction features\n        col_col_corr = np.abs(np.corrcoef(m, rowvar=False)).sum()\n        row_row_corr = np.abs(np.corrcoef(m, rowvar=True)).sum()\n        \n        # Structural features\n        triu_sum = np.triu(m).sum()\n        tril_sum = np.tril(m).sum()\n        \n        # Combined metrics\n        col_metric = np.sum(np.log(col_sums + 1)) + np.sum(col_entropy)\n        row_metric = np.sum(np.log(row_sums + 1)) + np.sum(row_entropy)\n        structure_metric = (triu_sum + tril_sum) / (n * n)\n        \n        return (col_metric, row_metric, np.mean(col_nonzero), np.mean(row_nonzero),\n                col_col_corr, row_row_corr, structure_metric)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        np.linalg.inv(matrix.T.astype(float)).astype(int) % 2\n    ]\n    \n    evaluations = [evaluate(v) for v in variants]\n    combined = tuple(np.min(evaluations, axis=0))\n    \n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 386,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 396,
    "parent_id": 182,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int) % 2\n        I = np.eye(n, dtype=int)\n        aug = np.hstack([mat, I])\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix is singular in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def compute_metric(m):\n        m = m.astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        return np.sum(np.log(col_sums)) + np.sum(np.log(row_sums))\n\n    variants = [\n        matrix,\n        matrix.T,\n        gf2_inv(matrix),\n        gf2_inv(matrix).T\n    ]\n    metrics = [compute_metric(v) for v in variants]\n    sorted_metrics = sorted(metrics)\n    return (float(sorted_metrics[0]), float(sorted_metrics[1]))\n",
    "evaluation": {
      "fitness": 0.8746192847101879,
      "additional_data": {
        "spearman_correlation": "0.874619",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 326,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 397,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log1p weighting\n        col_completion = np.sum(np.log1p(col_nonzeros))\n        \n        # Column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution consideration\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1)) / n\n        \n        # Sparsity term using natural log\n        sparsity = np.log1p(np.count_nonzero(m)) - np.log(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8835260564554043,
      "additional_data": {
        "spearman_correlation": "0.883526",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 389,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 16
    }
  },
  {
    "id": 398,
    "parent_id": 285,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for row in range(col, n):\n                if aug[row, col] == 1:\n                    pivot = row\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[pivot, col]] = aug[[col, pivot]]\n            for row in range(n):\n                if row != col and aug[row, col] == 1:\n                    aug[row] = (aug[row] + aug[col]) % 2\n        return aug[:, n:].astype(int)\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_weights = np.sum(m, axis=0)\n        total_extra = np.sum(col_weights) - n\n        sum_sq = np.sum(col_weights ** 2)\n        return (total_extra, sum_sq)\n\n    matrix_int = matrix.astype(int)\n    variants = [\n        matrix_int,\n        gf2_inv(matrix_int),\n        matrix_int.T,\n        gf2_inv(matrix_int.T)\n    ]\n    valid_variants = [v for v in variants if v is not None]\n    return min(get_heuristic(v) for v in valid_variants)\n",
    "evaluation": {
      "fitness": 0.8412498378717478,
      "additional_data": {
        "spearman_correlation": "0.841250",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 277,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 285,
      "exploited_organism_fitness": 0.8835222683809771,
      "child_number": 9
    }
  },
  {
    "id": 399,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Smoother column distribution penalty using sqrt\n        col_dist = np.sum(np.sqrt(np.abs(np.sum(m, axis=0) - 1)))\n        \n        # Adjusted sparsity term\n        sparsity = 0.5 * np.log2(np.count_nonzero(m) + 1) - 0.5 * np.log2(n)\n        \n        # Small row distribution term\n        row_dist = 0.1 * np.sum(np.log2(row_nonzeros + 1))\n        \n        return (col_completion, col_dist, sparsity, row_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8841975521746918,
      "additional_data": {
        "spearman_correlation": "0.884198",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 390,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 17
    }
  },
  {
    "id": 400,
    "parent_id": 182,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with additional matrix variant and weighted combination.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        sums = np.concatenate([col_sums, row_sums])\n        sums = np.maximum(sums, 1e-10)\n        return np.sum(np.log(sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    product = compute_metric(matrix @ np.linalg.inv(matrix))\n    \n    variants = [original, transposed, inverted, inv_transposed, product]\n    weights = [1.0, 0.9, 0.9, 0.9, 1.2]  # Higher weight for product variant\n    \n    weighted = [w*v for w,v in zip(weights, variants)]\n    return (float(original), float(min(weighted)))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 391,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 401,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with natural log weighting\n        col_completion = np.sum(np.log1p(col_nonzeros))\n        \n        # Enhanced column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        \n        # Row distribution penalty\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2\n        \n        # More meaningful sparsity term using natural log\n        sparsity = np.log1p(np.count_nonzero(m)) - np.log(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 392,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 18
    }
  },
  {
    "id": 402,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix is singular\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[pivot, col]] = aug[[col, pivot]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        nonzeros = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log_sum = np.sum(np.log2(col_sums + 1))\n        row_log_sum = np.sum(np.log2(row_sums + 1))\n        unique_cols = len(set(tuple(col) for col in m.T))\n        row_weight1 = np.sum(row_sums == 1)\n        col_weight1 = np.sum(col_sums == 1)\n        return (nonzeros, col_log_sum, row_log_sum, -unique_cols, -row_weight1, -col_weight1)\n    \n    try:\n        inv = gf2_inv(matrix)\n    except ValueError:\n        inv = matrix\n    \n    variants = [\n        matrix,\n        inv,\n        matrix.T,\n        inv.T\n    ]\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 360,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 24
    }
  },
  {
    "id": 403,
    "parent_id": 68,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_spread = np.std(col_sums)\n        row_spread = np.std(row_sums)\n        row_col_corr = np.abs(np.corrcoef(m)[0,1] if m.shape[0] > 1 else 0)\n        col_row_corr = np.abs(np.corrcoef(m.T)[0,1] if m.shape[1] > 1 else 0)\n        return (log_cols + log_rows, \n                col_spread + row_spread,\n                row_col_corr + col_row_corr,\n                np.sum(np.abs(col_sums - 1)),\n                np.sum(np.abs(row_sums - 1)))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.04019541880144682,
      "additional_data": {
        "spearman_correlation": "0.040195",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 394,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 404,
    "parent_id": 26,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        return (col_log + row_log, col_linear + row_linear)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    inv_transpose = calculate_metrics(np.linalg.inv(matrix.T) % 2)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8734834094236276,
      "additional_data": {
        "spearman_correlation": "0.873483",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 395,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 7
    }
  },
  {
    "id": 405,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering both row and column properties with mixedness measure.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Enhanced completion terms using both rows and columns\n        col_completion = np.sum(np.log2(col_nonzeros + 1) + 1/(col_nonzeros + 1))\n        row_completion = np.sum(np.log2(row_nonzeros + 1) + 1/(row_nonzeros + 1))\n        \n        # Balanced distribution penalties\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Advanced sparsity measure considering both dimensions\n        sparsity = (np.log2(np.count_nonzero(m) + 1) - np.log2(n)) * 2\n        \n        # Mixedness measure - variance of distances between ones\n        ones_pos = np.argwhere(m)\n        if len(ones_pos) > 1:\n            distances = []\n            for i in range(len(ones_pos)):\n                for j in range(i+1, len(ones_pos)):\n                    distances.append(np.sum((ones_pos[i] - ones_pos[j])**2))\n            mixedness = np.log2(np.var(distances) + 1) if distances else 0\n        else:\n            mixedness = 0\n            \n        return (col_completion + row_completion, \n                col_dist + row_dist, \n                sparsity, \n                -mixedness)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8803189180362015,
      "additional_data": {
        "spearman_correlation": "0.880319",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 393,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 19
    }
  },
  {
    "id": 406,
    "parent_id": 236,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with basis vector proximity.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def column_metric(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        basis_proximity = 0\n        column_entropy = 0\n        \n        for col in range(n):\n            current_col = m[:, col]\n            weight = np.sum(current_col)\n            \n            # Basis proximity: how close to being a basis vector\n            basis_proximity += (n - weight) if weight == 1 else (weight + n)\n            \n            # Column entropy: favors columns that are nearly done\n            if weight > 1:\n                p = current_col / weight\n                entropy = -np.sum(p * np.log2(p + 1e-10))\n                column_entropy += entropy * weight\n        \n        total_ones = np.sum(col_sums)\n        col_variance = np.var(col_sums)\n        \n        return (total_ones, basis_proximity, column_entropy, col_variance)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n    \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    return min(column_metric(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8595049379480812,
      "additional_data": {
        "spearman_correlation": "0.859505",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 397,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 407,
    "parent_id": 81,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        perm_distance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        log_colsum = np.sum(np.log2(col_sums + (col_sums == 0)))\n        return (perm_distance, log_colsum)\n    \n    orig_metric = simple_metric(matrix)\n    trans_metric = simple_metric(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        inv_metric = simple_metric(inv_matrix)\n    except np.linalg.LinAlgError:\n        inv_metric = (float('inf'), float('inf'))\n    \n    return min(orig_metric, trans_metric, inv_metric)\n",
    "evaluation": {
      "fitness": 0.7337216168296673,
      "additional_data": {
        "spearman_correlation": "0.733722",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 399,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 408,
    "parent_id": 234,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import math\n    \n    def evaluate(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Continuous measures of column/row completion\n        col_progress = sum(math.log2(s) if s > 1 else 0 for s in col_sums)\n        row_progress = sum(math.log2(s) if s > 1 else 0 for s in row_sums)\n        \n        # Weighted sum that prioritizes columns with few entries\n        weighted_col_sum = sum(1/(s+0.1) for s in col_sums if s > 0)\n        \n        return (total_ones, -col_progress, -row_progress, weighted_col_sum)\n    \n    candidates = []\n    candidates.append(evaluate(matrix))\n    candidates.append(evaluate(matrix.T))\n    \n    # Consider column/row reversed versions\n    reversed_cols = matrix[:, ::-1]\n    candidates.append(evaluate(reversed_cols))\n    candidates.append(evaluate(reversed_cols.T))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.6988579607536459,
      "additional_data": {
        "spearman_correlation": "0.698858",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 401,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 409,
    "parent_id": 168,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def basis_vector_score(m):\n        n = m.shape[0]\n        basis_vecs = np.eye(n)\n        col_scores = []\n        for col in m.T:\n            min_dist = n\n            for b in basis_vecs:\n                dist = np.sum(col != b)\n                if dist < min_dist:\n                    min_dist = dist\n            col_scores.append(min_dist)\n        return sum(col_scores)\n    \n    def column_interaction_score(m):\n        score = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                overlap = np.sum(m[:,i] & m[:,j])\n                score += overlap * (overlap > 0)\n        return score\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1)))\n        basis_score = basis_vector_score(m)\n        interaction_score = column_interaction_score(m)\n        return (basis_score, interaction_score, col_log + row_log)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8305436507573463,
      "additional_data": {
        "spearman_correlation": "0.830544",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 400,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 410,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Row-focused heuristic with rank analysis and interaction terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Row completion with exponential weighting\n        row_completion = np.sum(np.exp(row_nonzeros) - np.exp(1))\n        \n        # Rank deficiency measure (distance from full rank)\n        rank_penalty = n - np.linalg.matrix_rank(m)\n        \n        # Row-column interaction term\n        interaction = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        # Non-linearity in column weights\n        col_weights = np.sum(col_nonzeros * np.log2(col_nonzeros + 1))\n        \n        return (rank_penalty, row_completion, interaction, col_weights)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8037726258085932,
      "additional_data": {
        "spearman_correlation": "0.803773",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 402,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 20
    }
  },
  {
    "id": 411,
    "parent_id": 86,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using spectral properties and pattern analysis.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Pattern analysis metrics\n        spectral_radius = np.max(np.abs(np.linalg.eigvals(m)))\n        diag_dominance = np.sum(np.abs(m.diagonal())) / (nonzeros + 1e-9)\n        cluster_metric = np.sum(np.abs(m - np.roll(m, 1, axis=0))) + np.sum(np.abs(m - np.roll(m, 1, axis=1)))\n        \n        # Column/row structure metrics\n        col_entropy = np.sum(-col_sums * np.log(col_sums + 1e-9))\n        row_entropy = np.sum(-row_sums * np.log(row_sums + 1e-9))\n        \n        # Combined heuristic as a single float\n        return float(nonzeros + spectral_radius - diag_dominance + cluster_metric + col_entropy + row_entropy)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": -0.5332004941655006,
      "additional_data": {
        "spearman_correlation": "-0.533200",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 403,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 412,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting and small epsilon\n        col_completion = np.sum(np.log2(col_nonzeros + 1e-10))\n        \n        # Column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Sparsity term without normalization\n        sparsity = np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8832332512131749,
      "additional_data": {
        "spearman_correlation": "0.883233",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 404,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 21
    }
  },
  {
    "id": 413,
    "parent_id": 379,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column sums and nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        weight_one_cols = np.sum(col_sums == 1)\n        completed_cols = np.sum(col_sums == 0)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, col_imbalance, -weight_one_cols, -completed_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.880413309569905,
      "additional_data": {
        "spearman_correlation": "0.880413",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 406,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 414,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic incorporating row/column patterns and diagonal similarity.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Enhanced column completion with exponential weighting\n        col_completion = np.sum(np.exp(1/(col_nonzeros + 0.1)))\n        \n        # Row completion term for better balance\n        row_completion = np.sum(np.exp(1/(row_nonzeros + 0.1)))\n        \n        # Column distribution using higher power\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**4)\n        \n        # Diagonal similarity measure\n        diag_sim = -np.sum(m * np.eye(n))\n        \n        # Combined sparsity measure\n        sparsity = (np.count_nonzero(m)/(n*n) - 1/n)**2\n        \n        return (col_completion + row_completion, col_dist, diag_sim, sparsity)\n    \n    # Generate all cost-equivalent variants\n    variants = [matrix]\n    try:\n        variants += [np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix.T)]\n    except:\n        pass\n        \n    # Consider row/column permutations (limited to avoid excessive computation)\n    for _ in range(2):\n        perm = np.random.permutation(matrix.shape[0])\n        variants.append(matrix[perm,:])\n        variants.append(matrix[:,perm])\n    \n    return min(get_heuristic(v) for v in variants if not np.array_equal(v, np.eye(matrix.shape[0])))\n",
    "evaluation": {
      "fitness": -0.8150240566800943,
      "additional_data": {
        "spearman_correlation": "-0.815024",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 405,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 22
    }
  },
  {
    "id": 415,
    "parent_id": 337,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        log_weights = np.sum(np.log2(np.maximum(col_sums, 1)))\n        total_ones = np.sum(m)\n        return (log_weights, total_ones - n)\n    \n    metrics_orig = compute_metrics(matrix)\n    \n    try:\n        inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n        metrics_inv = compute_metrics(inv_matrix)\n    except np.linalg.LinAlgError:\n        metrics_inv = metrics_orig\n    \n    return min(metrics_orig, metrics_inv)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 408,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 416,
    "parent_id": 186,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse, inverse transpose, and basis vector features.\"\"\"\n    import numpy as np\n\n    def gf2_inv(matrix):\n        \"\"\"Compute inverse of binary matrix over GF(2).\"\"\"\n        n = matrix.shape[0]\n        mat_int = matrix.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for i in range(n):\n            if aug[i, i] == 0:\n                for j in range(i+1, n):\n                    if aug[j, i] == 1:\n                        aug[[i, j]] = aug[[j, i]]\n                        break\n                else:\n                    raise ValueError(\"Matrix is singular.\")\n            for j in range(n):\n                if j != i and aug[j, i] == 1:\n                    aug[j] = (aug[j] + aug[i]) % 2\n        return aug[:, n:].astype(int)\n\n    def get_heuristic(m):\n        \"\"\"Compute heuristic tuple for a single matrix.\"\"\"\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        nonbasis_cols = np.sum(col_sums != 1)\n        nonbasis_rows = np.sum(row_sums != 1)\n        log_imbalance = np.sum(np.log(col_sums)) + np.sum(np.log(row_sums))\n        abs_imbalance = 0.7*np.sum(np.abs(col_sums - 1)) + 0.3*np.sum(np.abs(row_sums - 1))\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, nonbasis_cols, nonbasis_rows, log_imbalance, abs_imbalance, col_var, row_var, *sorted_cols, *sorted_rows)\n    \n    # Generate candidate matrices\n    try:\n        inv_matrix = gf2_inv(matrix)\n        candidates = [\n            matrix,\n            matrix.T,\n            inv_matrix,\n            inv_matrix.T\n        ]\n    except:\n        candidates = [matrix, matrix.T]\n    \n    # Return minimal heuristic across candidates\n    return min(get_heuristic(cand) for cand in candidates)\n",
    "evaluation": {
      "fitness": 0.8718743660193651,
      "additional_data": {
        "spearman_correlation": "0.871874",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 372,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 417,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining row/column statistics and multi-variant analysis.\"\"\"\n    import numpy as np\n    \n    def analyze_variant(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column progress metrics\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_progress = np.sum(np.sqrt(col_nonzeros))\n        col_uniformity = np.std(col_sums)\n        \n        # Row progress metrics\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_progress = np.sum(np.sqrt(row_nonzeros))\n        row_uniformity = np.std(row_sums)\n        \n        # Interaction terms\n        interaction = np.sum(m * m.T) / (n*n)\n        \n        # Combined metrics\n        completion = (col_progress + row_progress) / (2*n)\n        balance = (col_uniformity + row_uniformity) / 2\n        \n        return (completion, balance, interaction)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    variant_scores = [analyze_variant(v) for v in variants]\n    \n    # Combine information from all variants\n    combined_score = tuple(np.min(variant_scores, axis=0))\n    return combined_score\n",
    "evaluation": {
      "fitness": 0.8797918517990212,
      "additional_data": {
        "spearman_correlation": "0.879792",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 409,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 23
    }
  },
  {
    "id": 418,
    "parent_id": 180,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def base_heuristic(m):\n        row_weights = np.sum(m, axis=1)\n        log_sum = 0.0\n        for w in row_weights:\n            if w > 1:\n                log_sum += np.log2(w)\n        nonzeros = float(np.count_nonzero(m))\n        return (log_sum, nonzeros)\n    \n    transpose = matrix.T\n    inv = gf2_inv(matrix)\n    versions = [matrix, transpose]\n    if inv is not None:\n        versions.append(inv)\n        versions.append(inv.T)\n    \n    best_heuristic = None\n    for m in versions:\n        h = base_heuristic(m)\n        if best_heuristic is None or h < best_heuristic:\n            best_heuristic = h\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 359,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 419,
    "parent_id": 268,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with better metrics and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Max sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        # Product of sums\n        col_product = np.prod(col_sums)\n        row_product = np.prod(row_sums)\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                max_col + max_row,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                col_product + row_product,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8827241623770307,
      "additional_data": {
        "spearman_correlation": "0.882724",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 4,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 407,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 420,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with adjusted weighting and additional penalty term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Adjusted column completion with better weighting\n        col_completion = np.sum(np.sqrt(col_nonzeros))\n        \n        # Enhanced column distribution penalty\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        \n        # Direct non-zero count term\n        sparsity = total_nonzeros / n\n        \n        # Additional penalty for multiple high-weight columns\n        high_weight_penalty = np.sum(col_nonzeros > 1)\n        \n        return (col_completion, col_dist, sparsity, high_weight_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 410,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 24
    }
  },
  {
    "id": 421,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with modified column distribution and sparsity terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Modified column distribution using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Improved sparsity term comparing to max possible nonzeros\n        sparsity = np.log2(total_nonzeros + 1) - np.log2(n*n + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842652417319493,
      "additional_data": {
        "spearman_correlation": "0.884265",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 411,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 25
    }
  },
  {
    "id": 422,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced sparsity and column distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log1p weighting\n        col_completion = np.sum(np.log1p(col_nonzeros))\n        \n        # Enhanced column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        \n        # Row distribution penalty\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Improved sparsity term normalized by matrix size\n        sparsity = np.log1p(np.count_nonzero(m)) - np.log1p(n*n)\n        \n        return (col_completion, col_dist + row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 412,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 26
    }
  },
  {
    "id": 423,
    "parent_id": 50,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined heuristic using non-zero count and improved column sum metrics.\"\"\"\n    import numpy as np\n    \n    def count_nonzeros(m):\n        return np.count_nonzero(m)\n    \n    def column_metric(m):\n        col_sums = np.sum(m, axis=0)\n        return np.sum(np.log2(1 + col_sums))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T\n    ]\n    \n    h_nz = min(count_nonzeros(v) for v in variants)\n    h_col = min(column_metric(v) for v in variants)\n    \n    return (h_nz, h_col)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 413,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 424,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on singular values and row/column interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        \n        # Compute singular values\n        svals = np.linalg.svd(m, compute_uv=False)\n        \n        # Measure of matrix complexity using singular values\n        sv_complexity = np.sum(np.log2(svals + 1))\n        \n        # Row and column non-zero counts\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Combined row/column completion metric\n        rc_completion = np.sum(np.log2(row_nonzeros + 1)) + np.sum(np.log2(col_nonzeros + 1))\n        \n        # Interaction term: how many row-column pairs have overlapping non-zeros\n        interaction = np.log2(np.sum(m @ m.T) + 1)\n        \n        return (sv_complexity, rc_completion, interaction)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.7469795994725915,
      "additional_data": {
        "spearman_correlation": "0.746980",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 414,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 27
    }
  },
  {
    "id": 425,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved with absolute column differences and added row distribution term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Softer column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution penalty\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842532805103959,
      "additional_data": {
        "spearman_correlation": "0.884253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 416,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 28
    }
  },
  {
    "id": 426,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced weighting and difference metric.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # More aggressive column completion weighting with smaller epsilon\n        col_completion = np.sum(np.log2(col_nonzeros + 1e-6))\n        \n        # Column distribution using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Enhanced sparsity term considering both rows and columns\n        sparsity = (np.log2(np.sum(col_nonzeros) + np.log2(np.sum(row_nonzeros))) / (2 * np.log2(n))\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 18)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 417,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 29
    }
  },
  {
    "id": 427,
    "parent_id": 108,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with more column focus and almost-done terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        cols_almost = np.sum(col_sums == 2)\n        rows_almost = np.sum(row_sums == 2)\n        sorted_cols = tuple(sorted(col_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, cols_done, rows_done, cols_almost, rows_almost, col_imbalance, row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8524229019976367,
      "additional_data": {
        "spearman_correlation": "0.852423",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 418,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 428,
    "parent_id": 15,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        return sum(np.sum(m, axis=0))\n    \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(matrix.T),\n        compute_metric(np.linalg.inv(matrix)),\n        compute_metric(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.2792271273234173,
      "additional_data": {
        "spearman_correlation": "-0.279227",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 421,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 429,
    "parent_id": 360,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column state quality (higher is better)\n        col_quality = np.prod([(1 + (cs == 1) * (n-1) + (cs != 1) * (1/(col_nonzeros[i]+0.1)) \n                             for i, cs in enumerate(col_sums)])\n        \n        # Row distribution penalty\n        row_penalty = np.sum((row_sums - 1)**2 * np.log2(row_nonzeros + 1))\n        \n        # Column completion (weight columns near completion more)\n        col_completion = np.sum((col_sums == 1) * n + (col_sums != 1) * np.log2(col_nonzeros + 1))\n        \n        # Interaction term between columns\n        interaction = np.sum([np.sum(m[:,i] * m[:,j]) for i in range(n) for j in range(i+1, n)])\n        \n        # Correct columns bonus\n        correct_cols = np.sum(col_sums == 1)\n        \n        return (1/col_quality, row_penalty, -correct_cols, interaction, col_completion)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "closing parenthesis ']' does not match opening parenthesis '(' on line 13 (<string>, line 14)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 419,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 430,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with weighted terms and better normalization.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Weighted column completion with natural log\n        col_completion = 1.5 * np.sum(np.log(col_nonzeros + 1))\n        \n        # Normalized column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(col_sums - 1)) / n\n        \n        # Enhanced sparsity term using non-zero ratio\n        sparsity = np.log((total_nonzeros + 0.5) / (n**2 + 1))\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8835428112403165,
      "additional_data": {
        "spearman_correlation": "0.883543",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 420,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 30
    }
  },
  {
    "id": 431,
    "parent_id": 135,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column/row matches and diagonal elements.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count matching column pairs\n        cols = m.T\n        col_pairs = sum(np.array_equal(cols[i], cols[j]) \n                       for i in range(len(cols)) \n                       for j in range(i+1, len(cols)))\n        \n        # Count matching row pairs\n        rows = m\n        row_pairs = sum(np.array_equal(rows[i], rows[j])\n                       for i in range(len(rows))\n                       for j in range(i+1, len(rows)))\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)  # Changed to squared error\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Add diagonal consideration\n        diag = np.diag(m)\n        diag_correct = np.sum(diag == 1)\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -(col_pairs + row_pairs), -diag_correct, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8690099975262918,
      "additional_data": {
        "spearman_correlation": "0.869010",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 422,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 432,
    "parent_id": 214,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with log-weighted column sums.\"\"\"\n    import numpy as np\n    import math\n    \n    def get_heuristic(m):\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        sum_log = sum(math.log2(w) for w in col_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, sum_log, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "math domain error"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 383,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 433,
    "parent_id": 317,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums, transposed and inverse matrices.\"\"\"\n    import numpy as np\n    epsilon = 1e-10\n    col_sums = np.sum(matrix, axis=0)\n    base_heuristic = float(np.sum(matrix))\n    col_heuristic = float(np.sum(np.log2(col_sums + epsilon)))\n    transposed_heuristic = float(np.sum(matrix.T))\n    inverse_heuristic = float(np.sum(np.linalg.inv(matrix.astype(float))))\n    return (base_heuristic, col_heuristic, transposed_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7647850616803783,
      "additional_data": {
        "spearman_correlation": "0.764785",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 426,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 434,
    "parent_id": 54,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    \n    def get_row_tuple(m):\n        row_weights = np.sum(m, axis=1)\n        h_arr = [max(0, w - 1) for w in row_weights]\n        return tuple(sorted(h_arr))\n    \n    t_orig = get_row_tuple(matrix)\n    t_trans = get_row_tuple(matrix.T)\n    \n    try:\n        inv_float = np.linalg.inv(matrix.astype(float))\n        inv_rounded = np.round(inv_float).astype(int) % 2\n        t_inv = get_row_tuple(inv_rounded)\n    except np.linalg.LinAlgError:\n        t_inv = tuple([10**9] * n)\n    \n    return min(t_orig, t_trans, t_inv)\n",
    "evaluation": {
      "fitness": 0.7274101440851689,
      "additional_data": {
        "spearman_correlation": "0.727410",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 322,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 435,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced matrix heuristic incorporating row/column interactions, structural properties, and entropy measures.\"\"\"\n    import numpy as np\n    from scipy.linalg import svd\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Structural properties\n        _, s, _ = svd(m)\n        rank = np.sum(s > 1e-10)\n        frob_norm = np.linalg.norm(m - np.eye(n), 'fro')\n        \n        # Column completion with entropy weighting\n        col_entropy = -np.sum((col_nonzeros/n) * np.log2(col_nonzeros/n + 1e-10))\n        \n        # Row completion with entropy weighting\n        row_entropy = -np.sum((row_nonzeros/n) * np.log2(row_nonzeros/n + 1e-10))\n        \n        # Interaction term between rows and columns\n        interaction = np.sum(np.abs(np.outer(row_sums, col_sums) - m))\n        \n        # Distance from identity\n        identity_dist = np.sum(np.abs(m - np.eye(n)))\n        \n        # Structural complexity\n        structural = (frob_norm + (n - rank)) / n\n        \n        return (structural, col_entropy + row_entropy, interaction, identity_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.25629570226830284,
      "additional_data": {
        "spearman_correlation": "0.256296",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 424,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 31
    }
  },
  {
    "id": 436,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with more sensitive column completion and added row terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # More sensitive column completion without +1 offset\n        col_completion = np.sum(np.log2(np.maximum(col_nonzeros, 1)))\n        \n        # Column distribution penalty\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Row distribution penalty\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8827635595344315,
      "additional_data": {
        "spearman_correlation": "0.882764",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 425,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 32
    }
  },
  {
    "id": 437,
    "parent_id": 315,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic returning a single float value.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        \n        # Column completion with logarithmic weighting using actual column sums\n        col_completion = np.sum(np.log(col_sums + 1))\n        \n        # Column distribution penalty (how far from single non-zero per column)\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        return col_completion + 0.5 * col_dist  # Weighted combination\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.06891248550905411,
      "additional_data": {
        "spearman_correlation": "-0.068912",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 431,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 438,
    "parent_id": 34,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    if matrix.size == 0:\n        return (0.0, 0.0)\n    try:\n        det = np.linalg.det(matrix)\n        adj = det * np.linalg.inv(matrix)\n        adj_int = np.round(adj).astype(int)\n        inv_gf2 = adj_int % 2\n    except:\n        inv_gf2 = matrix\n    matrices = [matrix, inv_gf2, matrix.T]\n    col_metrics = []\n    row_metrics = []\n    for mat in matrices:\n        col_sums = np.sum(mat, axis=0)\n        row_sums = np.sum(mat, axis=1)\n        col_sums = np.clip(col_sums, 1, None)\n        row_sums = np.clip(row_sums, 1, None)\n        col_metrics.append(np.sum(np.log(col_sums)))\n        row_metrics.append(np.sum(np.log(row_sums)))\n    min_col = min(col_metrics)\n    min_row = min(row_metrics)\n    return (min_col, min_row)\n",
    "evaluation": {
      "fitness": 0.8678717325996724,
      "additional_data": {
        "spearman_correlation": "0.867872",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 365,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 439,
    "parent_id": 297,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = 1.9 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.1 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.9 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        return (nonzeros, incorrect_total, logs, imbalance, cols_two, max_sum)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = get_heuristic(inv_matrix)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.871621482092455,
      "additional_data": {
        "spearman_correlation": "0.871621",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 427,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 440,
    "parent_id": 262,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        sum_weights = np.sum(m)\n        \n        h_val = np.sum(1/(col_weights)) + 0.1 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": -0.7727936272745461,
      "additional_data": {
        "spearman_correlation": "-0.772794",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 5,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 429,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 441,
    "parent_id": 314,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Diagonal vs off-diagonal weights\n        diag = np.diag(m)\n        off_diag = m - np.diag(diag)\n        diag_score = np.sum(diag != 1)\n        off_diag_score = np.count_nonzero(off_diag)\n        \n        # Logarithmic column prioritization\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Permutation distance\n        perm_dist = np.sum(np.abs(m - np.eye(m.shape[0], dtype=int)))\n        \n        # Column completion metrics\n        cols_near_complete = np.sum((col_sums == 1) | (col_sums == 0))\n        rows_near_complete = np.sum((row_sums == 1) | (row_sums == 0))\n        \n        # Combined features\n        base_score = nonzeros + perm_dist\n        col_priority = log_cols * (1 + off_diag_score)\n        row_priority = log_rows * (1 + diag_score)\n        \n        return (base_score, \n                col_priority + row_priority, \n                cols_near_complete + rows_near_complete,\n                diag_score + off_diag_score)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7424049552736421,
      "additional_data": {
        "spearman_correlation": "0.742405",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 430,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 442,
    "parent_id": 70,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        n = m.shape[0]\n        metrics = []\n        for col in m.T:\n            weight = np.sum(col)\n            if weight == 0:\n                metrics.append(0)\n                continue\n            basis_dist = min(np.sum(col ^ basis) for basis in [np.eye(n, dtype=int)[:,i] for i in range(n)])\n            log_term = np.log(weight)\n            metrics.append(basis_dist + log_term)\n        return tuple(sorted(metrics))\n    \n    original = column_metrics(matrix)\n    inverse = column_metrics(np.linalg.inv(matrix) % 2)\n    transpose = column_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_xor' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 434,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 443,
    "parent_id": 141,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with row sums and better combination of variants.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return np.sum(np.log(col_sums)) + 0.5 * np.sum(np.log(row_sums))\n    \n    original = compute_metric(matrix)\n    transposed = compute_metric(matrix.T)\n    inverted = compute_metric(np.linalg.inv(matrix))\n    inv_transposed = compute_metric(np.linalg.inv(matrix).T)\n    \n    min_variant = min(transposed, inverted, inv_transposed)\n    mean_variant = (transposed + inverted + inv_transposed) / 3\n    \n    return (float(original), float(min_variant), float(mean_variant))\n",
    "evaluation": {
      "fitness": 0.7940867620312532,
      "additional_data": {
        "spearman_correlation": "0.794087",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 436,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 444,
    "parent_id": 312,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion metrics\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        col_progress = np.sum(1/(col_nonzeros + 0.1))\n        \n        # Row completion metrics\n        row_completion = np.sum(np.log2(row_nonzeros + 1))\n        row_progress = np.sum(1/(row_nonzeros + 0.1))\n        \n        # Position-based metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        # Distance from identity\n        identity_diff = np.sum(np.abs(m - np.eye(n)))\n        \n        return (col_completion + row_completion, \n                col_progress + row_progress, \n                tri_diff, \n                identity_diff)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    heuristics = [get_heuristic(v) for v in variants]\n    return min(heuristics)\n",
    "evaluation": {
      "fitness": 0.8787676608401734,
      "additional_data": {
        "spearman_correlation": "0.878768",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 435,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 445,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        n = A.shape[0]\n        A = A % 2\n        aug = np.hstack([A, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return A\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:] % 2\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_completion = np.sum(np.log2(np.maximum(1, col_nonzeros)))\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        return (col_completion, col_dist)\n\n    m_inv = gf2_inv(matrix)\n    m_T = matrix.T\n    m_T_inv = gf2_inv(m_T)\n    variants = [matrix, m_inv, m_T, m_T_inv]\n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8737229267796996,
      "additional_data": {
        "spearman_correlation": "0.873723",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 328,
      "is_reasoning": true,
      "exploitation": true,
      "exploited_organism_id": 334,
      "exploited_organism_fitness": 0.88426700095711,
      "child_number": 33
    }
  },
  {
    "id": 446,
    "parent_id": 350,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic counts\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        col0_count = np.count_nonzero(col_sums == 0)\n        row0_count = np.count_nonzero(row_sums == 0)\n        \n        # Logarithmic features with interaction terms\n        log_col = sum(log2(cs + 1) for cs in col_sums)\n        log_row = sum(log2(rs + 1) for rs in row_sums)\n        log_col_row = sum(log2(cs*rs + 1) for cs, rs in zip(col_sums, row_sums))\n        \n        # Variance and interaction metrics\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        covar = np.cov(col_sums, row_sums)[0,1]\n        \n        # Column/row overlap features\n        col_overlap = np.sum(m & np.roll(m, 1, axis=1))\n        row_overlap = np.sum(m & np.roll(m, 1, axis=0))\n        \n        # Hierarchical features\n        hierarchical = sum(log2(np.sum(m[:i+1,:]) + 1 for i in range(n))\n        \n        return (\n            total_ones - n,\n            n - col1_count - col0_count,\n            n - row1_count - row0_count,\n            log_col,\n            log_row,\n            log_col_row,\n            col_var,\n            row_var,\n            covar,\n            col_overlap,\n            row_overlap,\n            hierarchical\n        )\n    \n    candidates = []\n    # Original matrix and transpose\n    candidates.append(get_features(matrix))\n    candidates.append(get_features(matrix.T))\n    \n    # Systematic column permutations\n    col_order = np.argsort(np.sum(matrix, axis=0))\n    for i in range(min(3, matrix.shape[1])):\n        perm = list(range(matrix.shape[1]))\n        perm[0], perm[col_order[i]] = perm[col_order[i]], perm[0]\n        candidates.append(get_features(matrix[:, perm]))\n    \n    # Inverse considerations\n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n            candidates.append(get_features(inv_matrix.T))\n    except:\n        try:\n            inv_matrix = np.linalg.pinv(matrix)\n            inv_matrix = np.round(inv_matrix).astype(int) % 2\n            if inv_matrix.shape == matrix.shape:\n                candidates.append(get_features(inv_matrix))\n                candidates.append(get_features(inv_matrix.T))\n        except:\n            pass\n    \n    # Row permutations\n    row_order = np.argsort(np.sum(matrix, axis=1))\n    for i in range(min(3, matrix.shape[0])):\n        perm = list(range(matrix.shape[0]))\n        perm[0], perm[row_order[i]] = perm[row_order[i]], perm[0]\n        candidates.append(get_features(matrix[perm, :]))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 33)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 433,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 447,
    "parent_id": 92,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        unique_cols, counts = np.unique(m, axis=1, return_counts=True)\n        total_sum = np.sum(m)\n        \n        col_complexity = np.sum(np.sqrt(col_sums)) + np.sum(counts-1)\n        row_complexity = np.sum(np.sqrt(row_sums))\n        max_col = np.max(col_sums)\n        \n        main_metric = col_complexity + 0.1 * total_sum\n        secondary_metric = (row_complexity, max_col)\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary_row = min(original[1][0], transposed[1][0], inverted[1][0])\n    min_secondary_max = min(original[1][1], transposed[1][1], inverted[1][1])\n    \n    return (min_main, (min_secondary_row, min_secondary_max))\n",
    "evaluation": {
      "fitness": 0.722255552321525,
      "additional_data": {
        "spearman_correlation": "0.722256",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 438,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 448,
    "parent_id": 215,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use absolute deviations instead of squared\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # Separate column and row correct counts\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        # Count diagonal elements\n        diag_elements = np.sum(np.diag(m))\n        # Sort column sums for more information\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance + row_imbalance, -correct_cols, -correct_rows, -diag_elements, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8804415091974939,
      "additional_data": {
        "spearman_correlation": "0.880442",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 439,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 449,
    "parent_id": 159,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        col_completion = np.sum(col_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        return (nonzeros, -col_completion, log_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8824026700296522,
      "additional_data": {
        "spearman_correlation": "0.882403",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 398,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 450,
    "parent_id": 27,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        # Handle zero sums by replacing with 1 (log(1)=0)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        \n        col_metric = np.sum(np.log(col_sums))\n        row_metric = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        \n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = max(diag, anti_diag)\n        \n        return (col_metric, row_metric, -total_ones, -diag_metric)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8724072052212639,
      "additional_data": {
        "spearman_correlation": "0.872407",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 441,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 451,
    "parent_id": 134,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        near_done_cols = np.sum(col_sums == 2)\n        near_done_rows = np.sum(row_sums == 2)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        prod_cols = np.prod(np.maximum(col_sums, 1))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        var_col = np.var(col_sums)\n        var_row = np.var(row_sums)\n        return (nonzeros, -done_cols-done_rows-zero_cols-zero_rows-near_done_cols-near_done_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, prod_cols, var_col + var_row, min_col,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8778992958931168,
      "additional_data": {
        "spearman_correlation": "0.877899",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 440,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 452,
    "parent_id": 395,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        np.linalg.inv(matrix.T.astype(float)).astype(int) % 2\n    ]\n    \n    sums = [np.sum(v) for v in variants]\n    return min(sums)\n",
    "evaluation": {
      "fitness": 0.7035822039010619,
      "additional_data": {
        "spearman_correlation": "0.703582",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 444,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 453,
    "parent_id": 281,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional transformations.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        col_sums = np.maximum(col_sums, 1.0)\n        row_sums = np.maximum(row_sums, 1.0)\n        return float(0.55 * np.sum(np.log(col_sums)) + 0.35 * np.sum(np.sqrt(col_sums)) + \n                    0.3 * np.sum(np.log(row_sums)) + 0.1 * total_sum\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix.T) % 2)\n    return min(original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 11)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 443,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 454,
    "parent_id": 252,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with linear imbalance and enhanced similarity measures.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Enhanced similarity measure for columns\n        cols = m.T\n        col_sim = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                col_sim += max(0, 3 - diff)  # rewards more for closer matches\n                \n            # Reward columns that are close to basis vectors\n            if np.sum(cols[i]) == 1:\n                col_sim += 1\n        \n        # Enhanced similarity measure for rows\n        rows = m\n        row_sim = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                row_sim += max(0, 3 - diff)\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # linear instead of squared\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -(col_sim + row_sim), *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8814115279887685,
      "additional_data": {
        "spearman_correlation": "0.881412",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 442,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 455,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Count columns with exactly one non-zero (completed columns)\n        num_done = np.sum(col_nonzeros == 1)\n        \n        # Logarithmic column completion term\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Sparsity term (normalized log of total non-zeros)\n        sparsity = np.log2(total_nonzeros + 1) - np.log2(n)\n        \n        return (-num_done, col_completion, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8598844357234111,
      "additional_data": {
        "spearman_correlation": "0.859884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 356,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 34
    }
  },
  {
    "id": 456,
    "parent_id": 25,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering original, transpose and inverse as tuple.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums + 0.1)))\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    return (original_heuristic, transpose_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.7885356563354137,
      "additional_data": {
        "spearman_correlation": "0.788536",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 447,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 457,
    "parent_id": 15,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        return sum(np.sum(m, axis=0))\n    \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(matrix.T),\n        compute_metric(np.linalg.inv(matrix)),\n        compute_metric(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.2792271273234173,
      "additional_data": {
        "spearman_correlation": "-0.279227",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 449,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 458,
    "parent_id": 53,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        hamming = np.sum(m)\n        max_col = np.max(col_sums)\n        completed_cols = np.sum(col_sums == 1)\n        completed_rows = np.sum(row_sums == 1)\n        \n        main_metric = log_col * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)) + max_col - (completed_cols + completed_rows))\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    \n    return (min_main, min_secondary)\n",
    "evaluation": {
      "fitness": 0.7188110720227664,
      "additional_data": {
        "spearman_correlation": "0.718811",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 445,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 459,
    "parent_id": 67,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional row metrics and off-diagonal elements.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        diag_sum = np.sum(np.diag(m))\n        off_diag = np.sum(m) - diag_sum\n        \n        return (nonzeros, col_imbalance + row_imbalance, off_diag, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8770040968734373,
      "additional_data": {
        "spearman_correlation": "0.877004",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 446,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 460,
    "parent_id": 334,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with absolute difference for column distribution penalty.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Improved column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Sparsity term using log2 normalization\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8842652417319493,
      "additional_data": {
        "spearman_correlation": "0.884265",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 423,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 35
    }
  },
  {
    "id": 461,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column sums and done columns count.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count number of already done columns/rows\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        # Logarithmic terms for columns close to done\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        return (nonzeros, log_cols + 1.2*log_rows, -done_cols-1.1*done_rows, \n                col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8722859441865158,
      "additional_data": {
        "spearman_correlation": "0.872286",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 450,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 462,
    "parent_id": 114,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from builtins import next\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = next((r for r in range(col, n) if aug[r, col] == 1), None)\n            if pivot is None:\n                return mat.copy()\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, col_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(gf2_inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8636001767289562,
      "additional_data": {
        "spearman_correlation": "0.863600",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 453,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 463,
    "parent_id": 333,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Returns tuple of (minimum, average) of logarithms of column and row sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        sums = np.concatenate([col_sums, row_sums])\n        sums = np.maximum(sums, 1e-10)\n        return float(np.sum(np.log(sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    avg = (original + inverse + transpose) / 3\n    min_val = min(original, inverse, transpose)\n    return (min_val, avg)\n",
    "evaluation": {
      "fitness": 0.8777055512112334,
      "additional_data": {
        "spearman_correlation": "0.877706",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 452,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 464,
    "parent_id": 424,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on off-diagonal interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        svals = np.linalg.svd(m, compute_uv=False)\n        sv_complexity = np.sum(np.log2(svals + 1))\n        \n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        rc_completion = np.sum(np.log2(row_nonzeros + 1)) + np.sum(np.log2(col_nonzeros + 1))\n        \n        # Compute interaction based on off-diagonal elements only\n        prod = m @ m.T\n        off_diag_sum = np.sum(prod) - np.trace(prod)\n        interaction = np.log2(off_diag_sum + 1)\n        \n        return (sv_complexity, rc_completion, interaction)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 432,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 465,
    "parent_id": 78,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 1e-10\n        \n        # Column completion metrics\n        col_completion = np.sum(np.abs(col_sums - 1))\n        col_log_weights = np.sum(np.log(col_sums + epsilon))\n        \n        # Row completion metrics\n        row_completion = np.sum(np.abs(row_sums - 1))\n        row_log_weights = np.sum(np.log(row_sums + epsilon))\n        \n        # Interaction terms\n        col_row_interaction = np.sum(m * m.T)\n        non_zero_counts = np.sum(m > 0)\n        \n        # Structural metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        return (col_completion, row_completion, col_log_weights, \n                row_log_weights, col_row_interaction, non_zero_counts, tri_diff)\n    \n    # Calculate for original, inverse and transpose\n    inv = np.linalg.inv(matrix).astype(int) % 2\n    metrics_orig = calculate_metrics(matrix)\n    metrics_inv = calculate_metrics(inv)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    # Return lexicographically smallest tuple\n    return min(metrics_orig, metrics_inv, metrics_trans)\n",
    "evaluation": {
      "fitness": 0.7370806016454604,
      "additional_data": {
        "spearman_correlation": "0.737081",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 451,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 466,
    "parent_id": 189,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        # More nuanced column completion - sum of (1 - abs(s-1)) for columns not yet completed\n        col_completion = sum(1 for s in col_sums if s == 1)\n        col_near_completion = sum(1 - abs(s-1) for s in col_sums if s != 1)\n        \n        return (nonzeros, \n                -col_completion,\n                -col_near_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 454,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 467,
    "parent_id": 227,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    import math\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_sum_metric = sum(math.log(s + 1) for s in col_sums if s > 0)\n        \n        return (nonzeros, \n                col_sum_metric,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8812379194303396,
      "additional_data": {
        "spearman_correlation": "0.881238",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 455,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 468,
    "parent_id": 351,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic with cycle detection, block analysis, and rank metrics.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        if np.linalg.matrix_rank(matrix) < n:\n            raise ValueError(\"Matrix not invertible\")\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def analyze_matrix(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Basic metrics\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        \n        # Advanced metrics\n        rank = np.linalg.matrix_rank(m)\n        lower_tri = np.sum(np.tril(m, -1))\n        upper_tri = np.sum(np.triu(m, 1))\n        diagonal = np.sum(np.diag(m))\n        \n        # Cycle detection\n        cycles = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                if m[i,j] and m[j,i]:\n                    cycles += 1\n        \n        # Column/row spread\n        col_spread = np.mean(np.var(m, axis=0))\n        row_spread = np.mean(np.var(m, axis=1))\n        \n        # Block structure\n        block_score = 0\n        half = n//2\n        blocks = [\n            m[:half,:half], m[:half,half:],\n            m[half:,:half], m[half:,half:]\n        ]\n        for blk in blocks:\n            blk_nonzero = np.count_nonzero(blk)\n            blk_size = blk.size\n            if blk_nonzero > 0:\n                block_score += (blk_nonzero/blk_size) ** 2\n        \n        return (nonzeros,\n                -(done_cols + done_rows + 0.75*(almost_done_cols + almost_done_rows) + 0.5*(zero_cols + zero_rows)),\n                rank,\n                cycles,\n                lower_tri + upper_tri,\n                diagonal,\n                col_spread + row_spread,\n                block_score)\n    \n    h_original = analyze_matrix(matrix)\n    try:\n        h_inverse = analyze_matrix(gf2_inv(matrix))\n        h_inverse_transpose = analyze_matrix(gf2_inv(matrix).T)\n    except:\n        h_inverse = h_original\n        h_inverse_transpose = h_original\n    h_transpose = analyze_matrix(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.863604930483425,
      "additional_data": {
        "spearman_correlation": "0.863605",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 448,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 469,
    "parent_id": 76,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n\n    def calculate_heuristic_tuple(m):\n        col_sums = np.sum(m, axis=0)\n        total_log = np.sum(np.log(col_sums))\n        k = np.count_nonzero(col_sums == 1)\n        return (total_log, -float(k))\n\n    def binary_inverse(m):\n        n_inv = m.shape[0]\n        inv = np.eye(n_inv, dtype=int)\n        for col in range(n_inv):\n            pivot = -1\n            for row in range(col, n_inv):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n_inv):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n\n    candidates = []\n    candidates.append(calculate_heuristic_tuple(matrix))\n    candidates.append(calculate_heuristic_tuple(matrix.T))\n    inv_matrix = binary_inverse(matrix.copy())\n    if inv_matrix is not None:\n        candidates.append(calculate_heuristic_tuple(inv_matrix))\n        candidates.append(calculate_heuristic_tuple(inv_matrix.T))\n    best = min(candidates)\n    return best\n",
    "evaluation": {
      "fitness": 0.8711320268187056,
      "additional_data": {
        "spearman_correlation": "0.871132",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 376,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 470,
    "parent_id": 200,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def binary_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 1e-10).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        return (log_col, log_row, total_ones, -col_var, -row_var)\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        binary_inv(matrix),\n        binary_inv(matrix).T\n    ]\n    \n    metrics = []\n    for m in matrices:\n        m_metrics = get_metrics(m)\n        # Dynamic weights based on matrix properties\n        weight_factor = 1.0 / (1 + np.sum(m))\n        weights = (\n            0.5 * weight_factor,\n            0.3 * weight_factor,\n            0.1 * weight_factor,\n            0.05 * weight_factor,\n            0.05 * weight_factor\n        )\n        weighted = tuple(w * m for w, m in zip(weights, m_metrics))\n        metrics.append(weighted)\n    \n    # Return tuple of all metrics for better lex ordering\n    return tuple(item for sublist in metrics for item in sublist)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 456,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 471,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic using rank, singular values, and weighted column metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Basic metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Higher-order metrics\n        rank = np.linalg.matrix_rank(m)\n        _, s, _ = np.linalg.svd(m)\n        sv_entropy = -np.sum(s * np.log(s + 1e-10))\n        \n        # Weighted column metrics\n        col_weights = np.sum(np.abs(m - np.eye(m.shape[0])), axis=0)\n        col_priority = np.sum(col_weights * (1 + np.log(col_sums + 1e-10)))\n        \n        # Row metrics\n        row_priority = np.sum(np.abs(row_sums - 1) * (1 + np.log(row_sums + 1e-10)))\n        \n        # Return as hierarchical tuple\n        return (nonzeros, rank, sv_entropy, col_priority + row_priority, *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8160369316006477,
      "additional_data": {
        "spearman_correlation": "0.816037",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 458,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 472,
    "parent_id": 215,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use absolute deviations instead of squared\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # Count number of correct columns and rows\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        # Add log of column sums\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        # Include both sorted columns and rows\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add diagonal term\n        diag = np.sum(np.diag(m))\n        return (nonzeros, col_imbalance + row_imbalance, -correct_cols - correct_rows, \n                -diag, log_cols, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.880466619633939,
      "additional_data": {
        "spearman_correlation": "0.880467",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 461,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 473,
    "parent_id": 58,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_col = np.sum(col_sums)\n        sum_row = np.sum(row_sums)\n        var_col = np.var(col_sums)\n        return (log_col, log_row, sum_col, sum_row, var_col)\n    \n    original = get_metrics(matrix)\n    inverse = get_metrics(np.linalg.inv(matrix) % 2)\n    transpose = get_metrics(matrix.T)\n    \n    combined = tuple(np.min([original[i], inverse[i], transpose[i]]) for i in range(5))\n    return combined\n",
    "evaluation": {
      "fitness": 0.8669014500596154,
      "additional_data": {
        "spearman_correlation": "0.866901",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 462,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 474,
    "parent_id": 288,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with enhanced partial matching.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = len(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        exact_pairs = 0\n        near_pairs = 0\n        inverse_pairs = 0\n        partial_pairs = 0\n        elements = list(m.T) + list(m)\n        \n        for i in range(len(elements)):\n            for j in range(i+1, len(elements)):\n                diff = np.sum(elements[i] != elements[j])\n                if diff == 0:\n                    exact_pairs += 1\n                elif diff == 1:\n                    near_pairs += 1\n                elif diff == n:\n                    inverse_pairs += 1\n                else:\n                    partial_pairs += (n - diff)/n  # Weight by similarity\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        col_imbalance = (np.sum(np.abs(col_sums - 1)) + \n                         2*np.sum(col_sums == 0) + \n                         2*np.sum(col_sums == n))\n        row_imbalance = (np.sum(np.abs(row_sums - 1)) + \n                        2*np.sum(row_sums == 0) + \n                        2*np.sum(row_sums == n))\n        \n        return (nonzeros, col_imbalance + row_imbalance,\n                -exact_pairs, -near_pairs, -inverse_pairs, -partial_pairs,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8638016620732997,
      "additional_data": {
        "spearman_correlation": "0.863802",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 457,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 475,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic focusing on column/row structural properties and entropy.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Structural metrics\n        col_entropy = entropy(col_sums + 1)  # +1 to avoid log(0)\n        row_entropy = entropy(row_sums + 1)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Interaction terms\n        col_row_interaction = np.sum(np.abs(col_sums - row_sums))\n        diagonal_dominance = np.sum(np.diag(m))\n        \n        # Advanced metrics\n        col_nonbinary = np.sum((col_sums > 0) & (col_sums != 1))\n        row_nonbinary = np.sum((row_sums > 0) & (row_sums != 1))\n        col_clustering = np.sum(np.diff(np.sort(col_sums))**2)\n        row_clustering = np.sum(np.diff(np.sort(row_sums))**2)\n        \n        # Combined metrics\n        structural_complexity = (col_entropy + row_entropy + \n                               col_variance + row_variance + \n                               col_nonbinary + row_nonbinary)\n        \n        interaction_metrics = (col_row_interaction + \n                             diagonal_dominance + \n                             col_clustering + row_clustering)\n        \n        return (structural_complexity, interaction_metrics, \n               -np.sum(col_sums == 1), -np.sum(row_sums == 1),\n               np.sum(col_sums), np.sum(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 460,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 11
    }
  },
  {
    "id": 476,
    "parent_id": 375,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with squared differences and adjusted weights.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting (no +1)\n        col_completion = np.sum(np.log2(np.maximum(col_nonzeros, 1)))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Simplified sparsity term without log\n        sparsity = np.count_nonzero(m)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8837425741988004,
      "additional_data": {
        "spearman_correlation": "0.883743",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 463,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 477,
    "parent_id": 308,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    \n    def get_features(m):\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        total_sum = np.sum(col_weights)\n        sum_log_col = np.sum(np.log(col_weights))\n        sum_log_row = np.sum(np.log(row_weights))\n        bad_cols = n - np.count_nonzero(col_weights == 1)\n        bad_rows = n - np.count_nonzero(row_weights == 1)\n        return (sum_log_col, sum_log_row, total_sum, bad_cols, bad_rows)\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    \n    inv_matrix = np.linalg.inv(matrix.astype(float))\n    inv_matrix = np.round(inv_matrix).astype(int) % 2\n    features.append(get_features(inv_matrix))\n    features.append(get_features(inv_matrix.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 380,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 478,
    "parent_id": 27,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_metric = np.sum(np.log(col_sums))\n        row_metric = np.sum(np.log(row_sums))\n        \n        # Enhanced diagonal metrics\n        diag_metrics = []\n        for shift in range(-n+1, n):\n            diag_metrics.append(np.sum(np.diag(m, k=shift)))\n            diag_metrics.append(np.sum(np.diag(np.fliplr(m), k=shift)))\n        diag_metric = max(diag_metrics) / n\n        \n        # Block structure detection\n        block_score = 0\n        for bs in [2, 4, n//2]:\n            if bs >= n:\n                continue\n            blocks = m.reshape(n//bs, bs, n//bs, bs).swapaxes(1,2)\n            block_density = np.mean(np.sum(blocks, axis=(2,3)) > 0)\n            block_score = max(block_score, block_density)\n        \n        # Column/row correlation\n        col_corr = np.abs(np.corrcoef(m.T)).sum() - n\n        row_corr = np.abs(np.corrcoef(m)).sum() - n\n        \n        return (col_metric, row_metric, -diag_metric, -block_score, col_corr, row_corr)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix[::-1],  # row reversal\n        matrix[:, ::-1],  # column reversal\n        matrix[::-1, ::-1]  # both\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations if m is not None]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 464,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 479,
    "parent_id": 97,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row properties\n        col_props = (\n            np.sum(col_sums == 1),  # exact weight-1\n            np.sum((col_sums > 1) & (col_sums <= 3)),  # nearly reducible columns\n            np.sum(col_sums > 3),  # complex columns\n            np.sum(np.abs(col_sums - 1))  # imbalance\n        )\n        \n        row_props = (\n            np.sum(row_sums == 1),\n            np.sum((row_sums > 1) & (row_sums <= 3)),\n            np.sum(row_sums > 3),\n            np.sum(np.abs(row_sums - 1))\n        \n        # Matrix structure properties\n        cluster_metric = 0\n        for i in range(m.shape[0]):\n            for j in range(m.shape[1]):\n                if m[i,j]:\n                    # Count adjacent non-zero entries\n                    neighbors = 0\n                    if i > 0 and m[i-1,j]: neighbors += 1\n                    if i < m.shape[0]-1 and m[i+1,j]: neighbors += 1\n                    if j > 0 and m[i,j-1]: neighbors += 1\n                    if j < m.shape[1]-1 and m[i,j+1]: neighbors += 1\n                    cluster_metric += neighbors\n        \n        # Column/row interaction metrics\n        col_row_interaction = np.sum(np.outer(col_sums, row_sums) * m)\n        \n        return (nonzeros, \n                *col_props, \n                *row_props, \n                cluster_metric, \n                col_row_interaction,\n                *sorted(col_sums),\n                *sorted(row_sums))\n    \n    original = get_metrics(matrix)\n    inverse = get_metrics(np.linalg.inv(matrix))\n    transpose = get_metrics(matrix.T)\n    \n    # Return all three metrics concatenated\n    return original + inverse + transpose\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 18)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 465,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 480,
    "parent_id": 236,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse and simplified tuple.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        \"\"\"Compute inverse in GF(2) using Gaussian elimination.\"\"\"\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row,\n                *sorted_cols, *sorted_rows)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix  # Fallback for singular (shouldn't occur for GL)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8719698404143058,
      "additional_data": {
        "spearman_correlation": "0.871970",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 466,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 481,
    "parent_id": 8,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining row/column sums, sparsity, and basis proximity.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        # Measure of how close columns are to basis vectors\n        basis_proximity = np.sum(np.minimum(col_sums, 1))\n        \n        # Sparsity measure\n        sparsity = np.sum(m)\n        \n        return (log_cols + log_rows, -basis_proximity, sparsity)\n    \n    original_metrics = calculate_metrics(matrix)\n    transpose_metrics = calculate_metrics(matrix.T)\n    \n    return min(original_metrics, transpose_metrics)\n",
    "evaluation": {
      "fitness": 0.7936937319051428,
      "additional_data": {
        "spearman_correlation": "0.793694",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 472,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 482,
    "parent_id": 342,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def safe_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 0.5).astype(float)\n        except:\n            return None\n    \n    def get_metrics(m):\n        if m is None:\n            return (float('inf'), float('inf'), float('inf'), float('inf'), float('inf'))\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        return (log_col, log_row, total_ones, col_var, row_var)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        safe_inv(matrix),\n        safe_inv(matrix.T)\n    ]\n    \n    metrics = []\n    for variant in variants:\n        m = get_metrics(variant)\n        if m[0] == float('inf'):\n            continue\n        # Adjusted weights\n        weight_col = 0.4 - 0.15 * np.tanh(m[3])  # Column importance\n        weight_row = 0.4 - 0.15 * np.tanh(m[4])  # Row importance\n        weight_ones = 0.2\n        sparsity_penalty = 0.1 * (1 - (m[2]/matrix.size))  # Penalty for sparse matrices\n        \n        weighted = (\n            weight_col * m[0] + weight_row * m[1],\n            weight_ones * m[2] - sparsity_penalty\n        )\n        metrics.append(weighted)\n    \n    if not metrics:\n        return (float('inf'), float('inf'))\n    \n    best_metrics = min(metrics)\n    return best_metrics\n",
    "evaluation": {
      "fitness": 0.7015096573553876,
      "additional_data": {
        "spearman_correlation": "0.701510",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 468,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 483,
    "parent_id": 375,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Comprehensive row/column interaction heuristic with nonlinear transforms.\"\"\"\n    import numpy as np\n    \n    def sig(x): return 1/(1+np.exp(-x))\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with sigmoid weighting\n        col_completion = np.sum(sig(1/(col_nonzeros + 0.1)))\n        \n        # Row completion similarly\n        row_completion = np.sum(sig(1/(row_nonzeros + 0.1)))\n        \n        # Column distribution using variance\n        col_dist = np.var(np.sum(m, axis=0))\n        \n        # Row distribution using variance\n        row_dist = np.var(np.sum(m, axis=1))\n        \n        # Interaction term between columns and rows\n        interaction = np.sum(sig(np.abs(m @ m.T - np.eye(n))))\n        \n        # Global sparsity pattern\n        global_pattern = np.log2(np.linalg.norm(m, 'fro') + 1)\n        \n        return (col_completion, row_completion, col_dist, \n                row_dist, interaction, global_pattern)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.7999034246222898,
      "additional_data": {
        "spearman_correlation": "-0.799903",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 467,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 484,
    "parent_id": 79,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weight-1 and weight-2 column/row counting.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with exactly one or two non-zeros\n        col_weight1 = np.sum(col_sums == 1)\n        row_weight1 = np.sum(row_sums == 1)\n        col_weight2 = np.sum(col_sums == 2)\n        row_weight2 = np.sum(row_sums == 2)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, col_weight1 + row_weight1, col_weight2 + row_weight2, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8696002903470132,
      "additional_data": {
        "spearman_correlation": "0.869600",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 471,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 485,
    "parent_id": 380,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with adjusted weights and multi-value return.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)\n        \n        # Adjusted weights with stronger sparsity term\n        metric1 = 0.4 * (col_log + row_log) + 0.3 * (col_linear + row_linear) + 0.3 * sparsity\n        metric2 = sparsity  # Secondary metric for lex order\n        return (metric1, metric2)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8717095789280561,
      "additional_data": {
        "spearman_correlation": "0.871710",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 473,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 486,
    "parent_id": 428,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column/row sums with logarithmic weighting.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_metric = sum(np.log(cs + 1) if cs > 0 else 0 for cs in col_sums)\n        row_metric = sum(np.log(rs + 1) if rs > 0 else 0 for rs in row_sums)\n        return col_metric + row_metric\n    \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(matrix.T),\n        compute_metric(np.linalg.inv(matrix)),\n        compute_metric(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.25116463600193667,
      "additional_data": {
        "spearman_correlation": "-0.251165",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 474,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 487,
    "parent_id": 9,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Multi-perspective logarithmic sum heuristic with tuple returns.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_metric = float(np.sum(np.log(col_sums)))\n        row_metric = float(np.sum(np.log(row_sums)))\n        return (col_metric, row_metric)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix) % 2\n    except:\n        inv_matrix = matrix\n        \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(inv_matrix),\n        compute_metric(matrix.T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8680100893141796,
      "additional_data": {
        "spearman_correlation": "0.868010",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 480,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 488,
    "parent_id": 248,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Count solved columns/rows\n        solved_cols = np.sum(col_sums == 1)\n        solved_rows = np.sum(row_sums == 1)\n        \n        # Normalized column/row sums\n        norm_col_sums = np.maximum(col_sums, 1)\n        norm_row_sums = np.maximum(row_sums, 1)\n        \n        # Logarithmic metrics\n        col_log_sum = np.sum(np.log2(norm_col_sums))\n        row_log_sum = np.sum(np.log2(norm_row_sums))\n        \n        # Variance metrics\n        col_var = np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        \n        # Dependency metrics\n        dep_score = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                if np.any(m[:,i] & m[:,j]):\n                    dep_score += 1\n        \n        # Distance to identity\n        identity_dist = np.sum(m != np.eye(n, dtype=int))\n        \n        return (\n            col_log_sum + row_log_sum,\n            -solved_cols - solved_rows,\n            col_var + row_var,\n            dep_score,\n            identity_dist\n        )\n    \n    def binary_inverse(m):\n        try:\n            return np.linalg.inv(m).astype(int) % 2\n        except:\n            return None\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*5\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*5\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.7294020112341926,
      "additional_data": {
        "spearman_correlation": "0.729402",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 469,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 489,
    "parent_id": 164,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + 0.15 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.869585041241077,
      "additional_data": {
        "spearman_correlation": "0.869585",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 428,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 490,
    "parent_id": 110,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        col_sum_std = np.std(col_sums)\n        return (total_ones - n, n - col1_count, n - row1_count, col_sum_std)\n    \n    candidates = []\n    # Original matrix features\n    candidates.append(get_features(matrix))\n    # Transpose features (swaps row/column metrics)\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse mod2 features (if computable)\n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    return min(candidates)  # Lexicographic min\n",
    "evaluation": {
      "fitness": 0.7333062426884194,
      "additional_data": {
        "spearman_correlation": "0.733306",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 479,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 491,
    "parent_id": 441,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        diag = np.diag(m)\n        off_diag = m - np.diag(diag)\n        diag_score = np.sum(diag != 1)\n        off_diag_score = np.count_nonzero(off_diag)\n        \n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        perm_dist = np.sum(np.abs(m - np.eye(m.shape[0], dtype=int)))\n        \n        cols_near_complete = np.sum(1/(np.abs(col_sums - 1) + 0.1))\n        rows_near_complete = np.sum(1/(np.abs(row_sums - 1) + 0.1))\n        \n        base_score = nonzeros + perm_dist\n        col_priority = 1.5 * log_cols * (1 + off_diag_score)\n        row_priority = 0.5 * log_rows * (1 + diag_score)\n        \n        return (base_score, \n                col_priority + row_priority, \n                cols_near_complete + rows_near_complete,\n                diag_score + off_diag_score)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7438069483116222,
      "additional_data": {
        "spearman_correlation": "0.743807",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 478,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 492,
    "parent_id": 143,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining multiple metrics and considering variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.sum(m != 0, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        sum_nonzero = float(np.sum(col_nonzero))\n        return (log_col, log_row, sum_total, max_col, sum_nonzero)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8730737524096407,
      "additional_data": {
        "spearman_correlation": "0.873074",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 481,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 493,
    "parent_id": 419,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Max and min sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        # Product of sums\n        col_product = np.prod(col_sums)\n        row_product = np.prod(row_sums)\n        \n        # Unique columns/rows\n        unique_cols = len(np.unique(m, axis=1))\n        unique_rows = len(np.unique(m, axis=0))\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                -zero_cols-zero_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                col_variance + row_variance,\n                max_col + max_row,\n                min_col + min_row,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                col_product + row_product,\n                unique_cols + unique_rows,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8826436284081286,
      "additional_data": {
        "spearman_correlation": "0.882644",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 475,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 494,
    "parent_id": 248,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        \n        # Basic sum metrics\n        total_sum = np.sum(m)\n        col_log_sum = np.sum(np.log2(col_sums))\n        row_log_sum = np.sum(np.log2(row_sums))\n        \n        # Variance metrics\n        col_var = np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        \n        # Structural metrics\n        upper_tri = np.sum(np.triu(m, k=1))\n        lower_tri = np.sum(np.tril(m, k=-1))\n        diagonal = np.sum(np.diag(m))\n        \n        # Blockiness metric (looking for block diagonal structure)\n        block_score = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j]:\n                    block_score += abs(i-j)\n        \n        # Spread metric (how concentrated are the 1s)\n        row_spread = 0\n        for row in m:\n            ones = np.where(row)[0]\n            if len(ones) > 1:\n                row_spread += np.ptp(ones)\n        \n        col_spread = 0\n        for col in m.T:\n            ones = np.where(col)[0]\n            if len(ones) > 1:\n                col_spread += np.ptp(ones)\n        \n        return (total_sum, \n                col_log_sum + row_log_sum, \n                col_var + row_var,\n                upper_tri + lower_tri,\n                block_score,\n                row_spread + col_spread,\n                n - diagonal)\n    \n    def binary_inverse(m):\n        try:\n            return np.linalg.inv(m).astype(int) % 2\n        except:\n            return None\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*7\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*7\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 476,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 495,
    "parent_id": 18,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # New: count of columns/rows with sum=1\n        cols_near_done = np.sum(col_sums == 1)\n        rows_near_done = np.sum(row_sums == 1)\n        \n        # Modified log terms to emphasize near-complete columns/rows\n        log_col = np.sum(np.log(2 - (1/col_sums)))\n        log_row = np.sum(np.log(2 - (1/row_sums)))\n        hamming = np.sum(m)\n        \n        main_metric = (cols_near_done + rows_near_done) * log_col * log_row * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)))\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    \n    return (min_main, min_secondary)\n",
    "evaluation": {
      "fitness": -0.2709379636359768,
      "additional_data": {
        "spearman_correlation": "-0.270938",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 482,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 496,
    "parent_id": 50,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined heuristic with additional variants and weighted column sums.\"\"\"\n    import numpy as np\n    \n    def count_nonzeros(m):\n        return np.count_nonzero(m)\n    \n    def column_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        # Weight columns by their sum to prioritize heavier columns\n        weighted_cols = np.log2(col_sums) * col_sums\n        return np.sum(weighted_cols)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    h_nz = min(count_nonzeros(v) for v in variants)\n    h_col = min(column_metric(v) for v in variants)\n    \n    return (h_nz, h_col)\n",
    "evaluation": {
      "fitness": 0.8723085838336037,
      "additional_data": {
        "spearman_correlation": "0.872309",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 484,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 497,
    "parent_id": 168,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        non_zero = np.sum(m != 0)\n        diag_sum = np.sum(np.diag(m))\n        return (col_log + row_log, non_zero, diag_sum)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8582342271378728,
      "additional_data": {
        "spearman_correlation": "0.858234",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 485,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 498,
    "parent_id": 330,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column metrics\n        col_weights = np.sort(col_sums)\n        col_progress = np.sum(1/(1 + np.abs(col_weights - 1)))\n        col_log_penalty = np.sum(np.log2(1 + np.abs(col_weights - 1)))\n        \n        # Row metrics (symmetric to columns)\n        row_weights = np.sort(row_sums)\n        row_progress = np.sum(1/(1 + np.abs(row_weights - 1)))\n        row_log_penalty = np.sum(np.log2(1 + np.abs(row_weights - 1)))\n        \n        # Matrix structure metrics\n        diff = m - np.eye(n, dtype=int)\n        upper_tri = np.sum(np.abs(np.triu(diff)))\n        lower_tri = np.sum(np.abs(np.tril(diff)))\n        \n        # Return as tuple for lexicographic ordering\n        return (\n            -col_progress - row_progress,  # Primary: maximize progress\n            col_log_penalty + row_log_penalty,  # Secondary: minimize penalties\n            upper_tri + lower_tri  # Tertiary: minimize off-diagonal elements\n        )\n    \n    # Evaluate all relevant transformations\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix[::-1],  # row reversal\n        matrix[:, ::-1],  # column reversal\n        np.rot90(matrix)  # rotation\n    ]\n    \n    # Return the best found heuristic tuple\n    return min(evaluate(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.411575271795478,
      "additional_data": {
        "spearman_correlation": "0.411575",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 483,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 499,
    "parent_id": 381,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from builtins import set\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        nonzeros = np.count_nonzero(m)\n        return (nonzeros, log_cols)\n    \n    n = matrix.shape[0]\n    candidates = []\n    \n    candidates.append(matrix)\n    candidates.append(matrix.T)\n    \n    col_sums0 = np.sum(matrix, axis=0)\n    perm_asc0 = np.argsort(col_sums0)\n    perm_desc0 = np.argsort(-col_sums0)\n    candidates.append(matrix[:, perm_asc0])\n    candidates.append(matrix[:, perm_desc0])\n    \n    trans = matrix.T\n    col_sums1 = np.sum(trans, axis=0)\n    perm_asc1 = np.argsort(col_sums1)\n    perm_desc1 = np.argsort(-col_sums1)\n    candidates.append(trans[:, perm_asc1])\n    candidates.append(trans[:, perm_desc1])\n    \n    best_h = None\n    for mat in candidates:\n        h_val = get_heuristic(mat)\n        if best_h is None or h_val < best_h:\n            best_h = h_val\n            \n    return best_h\n",
    "evaluation": {
      "fitness": 0.7768131465650389,
      "additional_data": {
        "spearman_correlation": "0.776813",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 489,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 500,
    "parent_id": 292,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_cost = np.sum(np.where(col_sums > 1, np.log2(col_sums), axis=0)\n        row_cost = np.sum(np.where(row_sums > 1, np.log2(row_sums), 0))\n        return np.sum(np.abs(m)) + col_cost + row_cost\n    \n    try:\n        inv = np.linalg.inv(matrix)\n        h_inv = simple_heuristic(inv)\n    except:\n        h_inv = float('inf')\n        \n    h_original = simple_heuristic(matrix)\n    h_transpose = simple_heuristic(matrix.T)\n    \n    return min(h_original, h_inv, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 9)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 490,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 501,
    "parent_id": 320,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        A = A.astype(int)\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] != 0:\n                    pivot = r\n                    break\n            if pivot != col:\n                aug[[pivot, col]] = aug[[col, pivot]]\n            for r in range(n):\n                if r != col and aug[r, col] != 0:\n                    aug[r] = (aug[r] ^ aug[col])\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        m_bin = (m != 0).astype(int)\n        col_sums = np.sum(m_bin, axis=0)\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_weights = np.sum(np.where(col_sums == 1, 2, np.where(col_sums == 2, 1, 0)))\n        return (log_sum, -col_weights)\n\n    inv = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8730290221925565,
      "additional_data": {
        "spearman_correlation": "0.873029",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 487,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 502,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    return min(original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8718907237310928,
      "additional_data": {
        "spearman_correlation": "0.871891",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 493,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 15
    }
  },
  {
    "id": 503,
    "parent_id": 96,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Calculate column interactions\n        col_interactions = 0\n        n = m.shape[1]\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.dot(m[:,i], m[:,j])\n        \n        # Calculate row interactions\n        row_interactions = 0\n        for i in range(m.shape[0]):\n            for j in range(i+1, m.shape[0]):\n                row_interactions += np.dot(m[i,:], m[j,:])\n        \n        # Sparsity measure\n        sparsity = np.sum(m == 0) / m.size\n        \n        # Weighted feature combination\n        features = (\n            0.4 * np.sum(col_sums) + \n            0.3 * rank + \n            0.2 * (col_interactions + row_interactions) +\n            0.1 * (1 - sparsity)\n        \n        return features\n    \n    transformations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix @ matrix.T % 2,\n        matrix.T @ matrix % 2\n    ]\n    \n    best_heuristic = min(compute_features(m) for m in transformations)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 27)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 488,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 504,
    "parent_id": 136,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with enhanced overlap metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Enhanced overlap calculations\n        col_overlap_matrix = m.T @ m\n        row_overlap_matrix = m @ m.T\n        col_overlap_count = np.sum(col_overlap_matrix > 0) - n\n        row_overlap_count = np.sum(row_overlap_matrix > 0) - n\n        col_overlap_degree = np.sum(col_overlap_matrix) - n\n        row_overlap_degree = np.sum(row_overlap_matrix) - n\n        \n        # Count lonely 1s\n        lonely_cols = np.sum((col_sums == 1) & (np.sum(m @ m.T, axis=1) == 1))\n        lonely_rows = np.sum((row_sums == 1) & (np.sum(m.T @ m, axis=1) == 1))\n        \n        # Log terms\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Variance terms\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Max terms\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Sorted terms\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, -col_overlap_count-row_overlap_count, -col_overlap_degree-row_overlap_degree, \n                -lonely_cols-lonely_rows, log_cols+log_rows, col_imbalance + row_imbalance,\n                col_variance + row_variance, max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.715084153423439,
      "additional_data": {
        "spearman_correlation": "0.715084",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 486,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 505,
    "parent_id": 158,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_operations(m):\n        n = m.shape[0]\n        # Count how many columns differ from basis vectors\n        basis_count = 0\n        for col in m.T:\n            if np.sum(col) == 1:\n                basis_count += 1\n        return n - basis_count\n    \n    def row_operations(m):\n        return column_operations(m.T)\n    \n    def total_operations(m):\n        return np.sum(m != np.eye(m.shape[0]))\n    \n    original_col = column_operations(matrix)\n    original_row = row_operations(matrix)\n    original_total = total_operations(matrix)\n    \n    transposed_col = column_operations(matrix.T)\n    transposed_row = row_operations(matrix.T)\n    transposed_total = total_operations(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        inverted_col = column_operations(inv_matrix)\n        inverted_row = row_operations(inv_matrix)\n        inverted_total = total_operations(inv_matrix)\n    except:\n        inverted_col = inverted_row = inverted_total = float('inf')\n    \n    min_operations = min(\n        original_col, original_row, original_total,\n        transposed_col, transposed_row, transposed_total,\n        inverted_col, inverted_row, inverted_total\n    )\n    \n    return min_operations\n",
    "evaluation": {
      "fitness": 0.6638905730602448,
      "additional_data": {
        "spearman_correlation": "0.663891",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 492,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 506,
    "parent_id": 173,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic with structural analysis.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                raise np.linalg.LinAlgError(\"Singular matrix\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:].astype(int)\n    \n    def analyze(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        unique_cols = len({tuple(col) for col in m.T})\n        unique_rows = len({tuple(row) for row in m})\n        col_diversity = sum(len(set(col)) for col in m.T)\n        row_diversity = sum(len(set(row)) for row in m)\n        \n        col_dist = sum(min(sum(abs(col - target)) for target in np.eye(n).T) for col in m.T)\n        row_dist = sum(min(sum(abs(row - target)) for target in np.eye(n)) for row in m)\n        \n        block_score = 0\n        for k in range(2, n//2 + 1):\n            if np.array_equal(m[:k,:k], np.eye(k)) and np.array_equal(m[k:,k:], np.eye(n-k)):\n                block_score = k*(n-k)\n                break\n        \n        col_correlations = np.sum(np.corrcoef(m.T))\n        row_correlations = np.sum(np.corrcoef(m))\n        col_entropy = -np.sum(np.where(col_sums > 0, col_sums/n * np.log(col_sums/n), 0))\n        row_entropy = -np.sum(np.where(row_sums > 0, row_sums/n * np.log(row_sums/n), 0))\n        \n        base = (nonzeros, -block_score, col_dist + row_dist, \n                -unique_cols - unique_rows, col_entropy + row_entropy,\n                col_diversity + row_diversity, col_correlations + row_correlations)\n        return base + tuple(sorted(col_sums)) + tuple(sorted(row_sums))\n    \n    n = matrix.shape[0]\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except np.linalg.LinAlgError:\n        inv_matrix = matrix\n    base_matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    \n    perm1 = np.eye(n, dtype=int)[::-1]\n    perm2 = np.roll(np.eye(n, dtype=int), 1, axis=0)\n    perms = [perm1, perm2]\n    \n    variants = []\n    for p in base_matrices:\n        variants.append(analyze(p))\n        for perm in perms:\n            variants.append(analyze(perm @ p))\n            variants.append(analyze(p @ perm))\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 415,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 507,
    "parent_id": 449,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_elements = m.size\n        nonzeros = np.count_nonzero(m) / total_elements\n        col_completion = np.sum(col_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (nonzeros, -col_completion, log_cols, log_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8826419413176657,
      "additional_data": {
        "spearman_correlation": "0.882642",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 496,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 508,
    "parent_id": 273,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import math\n    \n    def compute_metric(m):\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        \n        # Column-based metrics\n        col_sums = np.sum(m, axis=0)\n        col_metric = sum(math.log2(c + 1) if c > 0 else 0 for c in col_sums)\n        \n        # Row-based metrics\n        row_sums = np.sum(m, axis=1)\n        row_metric = sum(math.log2(r + 1) if r > 0 else 0 for r in row_sums)\n        \n        # Total non-zero elements\n        total_nonzero = np.sum(m)\n        \n        return (col_metric + row_metric, total_nonzero)\n    \n    variants = [matrix]\n    try:\n        variants.append(matrix.T)\n    except:\n        pass\n    \n    valid_variants = []\n    for v in variants:\n        try:\n            v = np.array(v, dtype=float)\n            if not np.isnan(v).any():\n                valid_variants.append(v)\n        except:\n            continue\n    \n    return min(compute_metric(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.7839696108335787,
      "additional_data": {
        "spearman_correlation": "0.783970",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 495,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 509,
    "parent_id": 470,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def binary_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 1e-10).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        total_ones = np.sum(m)\n        return (log_col, total_ones)\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        binary_inv(matrix),\n        binary_inv(matrix).T\n    ]\n    \n    metrics = []\n    for m in matrices:\n        m_metrics = get_metrics(m)\n        metrics.extend(m_metrics)\n    \n    return tuple(metrics)\n",
    "evaluation": {
      "fitness": 0.7920397001290551,
      "additional_data": {
        "spearman_correlation": "0.792040",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 497,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 510,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic using log of column sums.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    logged_sums = np.log(col_sums + 1)\n    return tuple(sorted(logged_sums))\n",
    "evaluation": {
      "fitness": 0.7776224989903747,
      "additional_data": {
        "spearman_correlation": "0.777622",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 502,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 8
    }
  },
  {
    "id": 511,
    "parent_id": 503,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_features(m):\n        col_sums = np.sum(m, axis=0)\n        rank = np.linalg.matrix_rank(m)\n        log_col_sums = np.sum(np.log2(col_sums + 1))\n        \n        features = (\n            0.6 * np.sum(col_sums) + \n            0.3 * rank + \n            0.1 * log_col_sums\n        )\n        return features\n    \n    transformations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    best_heuristic = min(compute_features(m) for m in transformations)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.8699421578357812,
      "additional_data": {
        "spearman_correlation": "0.869942",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 501,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 512,
    "parent_id": 353,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better column completion and added row distribution.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Enhanced column completion with better handling of weight-1 columns\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, np.log2(col_nonzeros)))\n        \n        # Softer column distribution penalty using absolute differences\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        # Row distribution term to complement column metrics\n        row_dist = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        # Sparsity term remains similar but accounts for both dimensions\n        sparsity = np.log2(np.count_nonzero(m) + 1) - np.log2(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8837226793677702,
      "additional_data": {
        "spearman_correlation": "0.883723",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 396,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 513,
    "parent_id": 149,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        col_imbalance = 1.2 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.2 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, log_cols+log_rows,\n                col_imbalance + row_imbalance, max_col + max_row)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828073047174986,
      "additional_data": {
        "spearman_correlation": "0.882807",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 498,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 514,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    return min(original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8718907237310928,
      "additional_data": {
        "spearman_correlation": "0.871891",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 503,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 16
    }
  },
  {
    "id": 515,
    "parent_id": 292,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on nonzeros and column sums.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, col_imbalance)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8822764647853433,
      "additional_data": {
        "spearman_correlation": "0.882276",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 507,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 516,
    "parent_id": 286,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        sum_sq = col_sq + row_sq\n        \n        return (nonzeros, incorrect_total, logs, imbalance, max_sum, sum_sq)\n    \n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:\n        h_original = get_heuristic(matrix)\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_transpose)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8716504588960877,
      "additional_data": {
        "spearman_correlation": "0.871650",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 499,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 517,
    "parent_id": 159,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Enhanced column metrics\n        weighted_cols = np.sum(np.exp(-0.5*(col_sums-1)**2))\n        col_completion = sum(1 for s in col_sums if s == 1)\n        col_variance = np.var(col_sums)\n        \n        # Row metrics\n        weighted_rows = np.sum(np.exp(-0.5*(row_sums-1)**2))\n        row_completion = sum(1 for s in row_sums if s == 1)\n        \n        # Interaction metrics\n        diag_sum = np.sum(np.diag(m))\n        anti_diag_sum = np.sum(np.diag(np.fliplr(m)))\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -weighted_cols,\n                -weighted_rows,\n                col_variance,\n                -abs(diag_sum - len(m)//2),\n                -abs(anti_diag_sum - len(m)//2))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 504,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 518,
    "parent_id": 236,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and removed redundancy.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        \"\"\"Compute inverse in GF(2) using Gaussian elimination.\"\"\"\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.8 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row,\n                *sorted_cols, *sorted_rows)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8719698404143058,
      "additional_data": {
        "spearman_correlation": "0.871970",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 505,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 519,
    "parent_id": 288,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with refined column/row analysis and partial inverses.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = len(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Combined column and row matching with partial inverses\n        exact_pairs = 0\n        near_pairs = 0\n        inverse_pairs = 0\n        elements = list(m.T) + list(m)\n        \n        for i in range(len(elements)):\n            for j in range(i+1, len(elements)):\n                diff = np.sum(elements[i] != elements[j])\n                if diff == 0:\n                    exact_pairs += 1\n                elif diff == 1:\n                    near_pairs += 1\n                elif diff >= n-1:  # Relaxed inverse condition\n                    inverse_pairs += 1\n        \n        sorted_cols = sorted(col_sums)\n        sorted_rows = sorted(row_sums)\n        \n        # Refined imbalance calculation with length-dependent weights\n        col_weights = 1 + np.abs(col_sums - 1)/n\n        row_weights = 1 + np.abs(row_sums - 1)/n\n        \n        col_imbalance = (np.sum(col_weights * np.abs(col_sums - 1)) \n        row_imbalance = (np.sum(row_weights * np.abs(row_sums - 1)))\n        \n        # Additional pattern features from sorted columns/rows\n        col_pattern = sum(abs(sorted_cols[i] - sorted_cols[i-1]) for i in range(1, n))\n        row_pattern = sum(abs(sorted_rows[i] - sorted_rows[i-1]) for i in range(1, n))\n        \n        return (nonzeros, col_imbalance + row_imbalance,\n                -exact_pairs, -near_pairs, -inverse_pairs,\n                col_pattern, row_pattern,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 35)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 508,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 520,
    "parent_id": 213,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance to identity/anti-identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                        np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Overlap between columns and rows\n        col_overlap = sum(np.sum(m[:,i] & m[:,j]) \n                         for i in range(n) for j in range(i+1, n))\n        row_overlap = sum(np.sum(m[i,:] & m[j,:]) \n                         for i in range(n) for j in range(i+1, n))\n        overlap_metric = col_overlap + row_overlap\n        \n        # Logarithmic column weight penalty\n        log_col = np.sum(np.log2(col_sums + 1))  # +1 to avoid log(0)\n        \n        # Deviation from ideal number of ones (n)\n        lin_col_dev = abs(total_ones - n)\n        \n        # Combine metrics with weights\n        return 0.4 * diag_dist + 0.3 * overlap_metric + 0.2 * log_col + 0.1 * lin_col_dev\n    \n    # Compute metrics for variants\n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_metrics(inv_matrix)\n    inv_transposed = matrix_metrics(inv_matrix.T)\n    \n    # Return minimum score across all variants\n    return min(original, transposed, inverse, inv_transposed)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 509,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 521,
    "parent_id": 218,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect = (n - correct_cols) + (n - correct_rows)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = 0.2 * np.min(col_sums)\n        min_row = 0.2 * np.min(row_sums)\n        col_variance = 0.2 * np.var(col_sums)\n        row_variance = 0.2 * np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, incorrect, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                min_col + min_row, col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827976952112023,
      "additional_data": {
        "spearman_correlation": "0.882798",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 510,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 522,
    "parent_id": 78,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    \n    # Weighted column and row terms using log(1 + sum)\n    weighted_col = np.sum(col_sums * np.log(1 + col_sums))\n    weighted_row = np.sum(row_sums * np.log(1 + row_sums))\n    \n    # Enhanced interaction terms with squared sums\n    col_nonzeros = np.sum(matrix > 0, axis=0)\n    row_nonzeros = np.sum(matrix > 0, axis=1)\n    col_spread = np.sum(col_nonzeros * (col_sums ** 2))\n    row_spread = np.sum(row_nonzeros * (row_sums ** 2))\n    \n    # Additional max sum terms\n    max_col = np.max(col_sums)\n    max_row = np.max(row_sums)\n    \n    # Combined heuristic components\n    h1 = weighted_col * weighted_row\n    h2 = col_spread + row_spread\n    h3 = max_col + max_row\n    h4 = np.sum(matrix)  # Total sum as tiebreaker\n    \n    return (h1, h2, h3, h4)\n",
    "evaluation": {
      "fitness": 0.6957321728882153,
      "additional_data": {
        "spearman_correlation": "0.695732",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 512,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 523,
    "parent_id": 306,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        num_col1 = np.sum(col_sums == 1)\n        num_row1 = np.sum(row_sums == 1)\n        return (col_log + row_log, col_sq + row_sq, -(num_col1 + num_row1), total_sum)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8588223254043595,
      "additional_data": {
        "spearman_correlation": "0.858822",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 511,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 524,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use absolute deviations instead of squared\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # Weight columns by how close they are to 1\n        sorted_cols = tuple(sorted(col_sums, key=lambda x: abs(x-1)))\n        return (nonzeros, col_imbalance, row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 514,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 525,
    "parent_id": 267,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + 1e-10))\n        log_sum_row = np.sum(np.log(row_sums + 1e-10))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        rows_two = np.sum(row_sums == 2)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        t = (0.7*log_sum_col, 0.3*log_sum_row, total_ones, cols_two, rows_two, basis_cols, basis_rows, col_var, row_var)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8742526765026772,
      "additional_data": {
        "spearman_correlation": "0.874253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 513,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 526,
    "parent_id": 225,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_metric(m):\n        col_sums = np.sum(m, axis=0)\n        active_cols = col_sums[col_sums > 1]\n        if len(active_cols) == 0:\n            return 0.0\n        log_sums = np.log2(active_cols)\n        return np.sum(log_sums) + np.sum(active_cols - 1)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(simple_metric(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0389154654062815,
      "additional_data": {
        "spearman_correlation": "0.038915",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 519,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 527,
    "parent_id": 335,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering both column and row properties with block patterns.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        \n        # Column properties\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        col_sum_deviation = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        col_basis = np.sum(col_nonzeros == 1)\n        \n        # Row properties\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_completion = np.sum(np.log2(row_nonzeros + 1))\n        row_sum_deviation = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        row_basis = np.sum(row_nonzeros == 1)\n        \n        # Block pattern detection\n        quadrant_size = max(1, n//2)\n        q1 = m[:quadrant_size, :quadrant_size]\n        q2 = m[:quadrant_size, quadrant_size:]\n        q3 = m[quadrant_size:, :quadrant_size]\n        q4 = m[quadrant_size:, quadrant_size:]\n        block_score = np.log1p(np.abs(\n            np.count_nonzero(q1) + np.count_nonzero(q4) - \n            np.count_nonzero(q2) - np.count_nonzero(q3))\n        \n        # Diagonal dominance\n        diag_score = np.sum(np.diag(m)) / n\n        \n        return (col_completion + row_completion, \n                col_sum_deviation + row_sum_deviation, \n                block_score, \n                col_basis + row_basis,\n                -diag_score)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 27)"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 517,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 528,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column weight histogram: [weight1, weight2, weight3, weight>=4]\n        col_hist = [0, 0, 0, 0]\n        for s in col_sums:\n            if s == 1:\n                col_hist[0] += 1\n            elif s == 2:\n                col_hist[1] += 1\n            elif s == 3:\n                col_hist[2] += 1\n            else:\n                col_hist[3] += 1\n        \n        # Row weight histogram\n        row_hist = [0, 0, 0, 0]\n        for s in row_sums:\n            if s == 1:\n                row_hist[0] += 1\n            elif s == 2:\n                row_hist[1] += 1\n            elif s == 3:\n                row_hist[2] += 1\n            else:\n                row_hist[3] += 1\n        \n        extra_ones = nonzeros - n\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (extra_ones, col_hist[1], col_hist[2], col_hist[3],\n                row_hist[1], row_hist[2], row_hist[3],\n                log_cols, log_rows, max_col, max_row)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix).astype(int) % 2,\n        matrix.T,\n        np.linalg.inv(matrix).T.astype(int) % 2\n    ]\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.7097873412282724,
      "additional_data": {
        "spearman_correlation": "0.709787",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 437,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 529,
    "parent_id": 281,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and added max column term.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        max_col = np.max(col_sums)\n        col_sums = np.maximum(col_sums, 1.0)\n        row_sums = np.maximum(row_sums, 1.0)\n        return float(0.7 * np.sum(np.log(col_sums)) + 0.2 * np.sum(np.log(row_sums)) + 0.05 * total_sum + 0.05 * max_col\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 12)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 520,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 530,
    "parent_id": 351,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional done term.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        if np.linalg.matrix_rank(matrix) < n:\n            raise ValueError(\"Matrix not invertible\")\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        log_sum = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        squared_dev = np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2)\n        max_sum = np.max(col_sums) + np.max(row_sums)\n        return (nonzeros, \n                -(done_cols + done_rows + 0.8*(almost_done_cols + almost_done_rows) + 0.3*(zero_cols + zero_rows)),\n                -0.5*(done_cols + done_rows),\n                log_sum,\n                squared_dev,\n                max_sum)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(gf2_inv(matrix))\n        h_inverse_transpose = get_heuristic(gf2_inv(matrix).T)\n    except:\n        h_inverse = h_original\n        h_inverse_transpose = h_original\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8643696031883432,
      "additional_data": {
        "spearman_correlation": "0.864370",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 518,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 531,
    "parent_id": 369,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with refined column completion and distribution terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        \n        # Refined column completion with stronger weighting for near-complete columns\n        epsilon = 1e-10\n        col_completion = np.sum(np.log2(col_nonzeros + epsilon)) + 0.15 * np.sum(col_nonzeros == 1)\n        \n        # Enhanced column distribution penalty using squared differences\n        col_dist = np.sum((col_sums - 1)**2) + 0.15 * np.sum(col_sums == 1)\n        \n        # Balanced sparsity term considering both rows and columns\n        sparsity = (np.log2(np.count_nonzero(m) + 1) - np.log2(n) + 0.1 * (np.log2(np.sum(row_nonzeros) + 1 - np.log2(n))\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 20)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 522,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 532,
    "parent_id": 82,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional matrix forms and nearly-perfect columns.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        perfect_cols = np.sum(col_sums == 1)\n        perfect_rows = np.sum(row_sums == 1)\n        near_perfect_cols = np.sum(col_sums == 2)\n        near_perfect_rows = np.sum(row_sums == 2)\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        identical_pairs = sum([np.array_equal(m[:,i], m[:,j]) for i in range(m.shape[1]) for j in range(i)])\n        return (nonzeros, -perfect_cols-perfect_rows, -near_perfect_cols-near_perfect_rows, log_col_sums+log_row_sums, -identical_pairs, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inv_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8819609374305877,
      "additional_data": {
        "spearman_correlation": "0.881961",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 523,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 533,
    "parent_id": 298,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved row-column interaction heuristic with better zero handling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Improved interaction term using element-wise multiplication\n        interaction = np.sum(m * np.outer(row_nonzeros, col_nonzeros))\n        \n        # Better handling of zeros in log terms\n        row_term = np.sum(np.log(row_nonzeros + (row_nonzeros == 0)))\n        col_term = np.sum(np.log(col_nonzeros + (col_nonzeros == 0)))\n        \n        # More sophisticated balance term considering variance\n        row_var = np.var(row_nonzeros)\n        col_var = np.var(col_nonzeros)\n        sparsity = np.count_nonzero(m) / (n*n)\n        balance = (sparsity + row_var/n) * row_term + (1-sparsity + col_var/n) * col_term\n        \n        return (interaction, balance)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.378614547943708,
      "additional_data": {
        "spearman_correlation": "0.378615",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 525,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 534,
    "parent_id": 182,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Distance from diagonal metric\n        diag_dist = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j] == 1:\n                    diag_dist += abs(i-j)\n        \n        # Column progress metric\n        col_progress = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        \n        # Row swap estimation\n        row_swap_cost = 0\n        for i in range(n):\n            if np.sum(m[i,:]) != 1 or np.sum(m[:,i]) != 1:\n                row_swap_cost += 1\n        \n        return diag_dist + col_progress + row_swap_cost\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix),\n        np.linalg.inv(matrix).T\n    ]\n    \n    metrics = [compute_metric(v) for v in variants]\n    min_metric = min(metrics)\n    \n    # Return tuple with original and best variant\n    return (float(compute_metric(matrix)), float(min_metric))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 526,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 535,
    "parent_id": 466,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        col_completion = sum(1 for s in col_sums if s == 1)\n        col_near_completion = sum(1 - abs(s-1) for s in col_sums if s != 1)\n        return (nonzeros, -col_completion, -col_near_completion)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n        return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n    except:\n        return float('inf')\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.000000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 527,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 536,
    "parent_id": 306,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic sum metrics\n        total_sum = np.sum(col_sums)\n        col_nonzero = np.count_nonzero(col_sums)\n        row_nonzero = np.count_nonzero(row_sums)\n        \n        # Logarithmic metrics\n        col_log = np.sum(np.log(np.maximum(col_sums, 1)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1)))\n        \n        # Quadratic metrics\n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        \n        # Unit column/row counts\n        num_col1 = np.sum(col_sums == 1)\n        num_row1 = np.sum(row_sums == 1)\n        \n        # Entropy measures\n        col_entropy = entropy(col_sums + 1e-10)\n        row_entropy = entropy(row_sums + 1e-10)\n        \n        # Rank and linear dependence\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column/row uniqueness\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        return (\n            -rank,\n            col_log + row_log,\n            col_sq + row_sq,\n            -(num_col1 + num_row1),\n            col_entropy + row_entropy,\n            -(unique_cols + unique_rows),\n            -total_sum,\n            col_nonzero + row_nonzero\n        )\n    \n    original = calculate_metrics(matrix)\n    \n    # Consider inverse if exists\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20,) * 8\n    \n    # Consider transpose\n    transpose = calculate_metrics(matrix.T)\n    \n    # Consider row permutations\n    permuted_rows = calculate_metrics(matrix[np.random.permutation(matrix.shape[0])])\n    \n    # Consider column permutations\n    permuted_cols = calculate_metrics(matrix[:, np.random.permutation(matrix.shape[1])])\n    \n    return min(original, inverse, transpose, permuted_rows, permuted_cols)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 524,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 537,
    "parent_id": 238,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        diag_sum = np.sum(np.diag(m))\n        \n        # Improved column completion metric\n        col_completion = sum(np.exp(1-s) for s in col_sums if s > 0)\n        row_completion = sum(np.exp(1-s) for s in row_sums if s > 0)\n        \n        return (nonzeros, \n                col_completion,\n                row_completion,\n                -basis_cols,\n                -diag_sum)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8577342826578719,
      "additional_data": {
        "spearman_correlation": "0.857734",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 528,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 538,
    "parent_id": 412,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with adjusted log base and squared differences.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with natural log weighting\n        col_completion = np.sum(np.log(col_nonzeros + 1e-10))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        \n        # Weighted sparsity term\n        sparsity = 0.5 * np.log(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 14)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 531,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 539,
    "parent_id": 219,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        return (log_col, log_row, total_ones)\n    \n    metrics_orig = calculate_metrics(matrix)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n        metrics_inv = calculate_metrics(inv_matrix)\n        metrics_inv_trans = calculate_metrics(inv_matrix.T)\n    except:\n        metrics_inv = metrics_orig\n        metrics_inv_trans = metrics_trans\n    \n    combined = [\n        0.45 * metrics_orig[0] + 0.15 * metrics_orig[1] + 0.15 * metrics_orig[2],\n        0.45 * metrics_trans[0] + 0.15 * metrics_trans[1] + 0.15 * metrics_trans[2],\n        0.45 * metrics_inv[0] + 0.15 * metrics_inv[1] + 0.15 * metrics_inv[2],\n        0.45 * metrics_inv_trans[0] + 0.15 * metrics_inv_trans[1] + 0.15 * metrics_inv_trans[2]\n    ]\n    \n    combined_sorted = sorted(combined)\n    return tuple(combined_sorted)\n",
    "evaluation": {
      "fitness": 0.7487898903340278,
      "additional_data": {
        "spearman_correlation": "0.748790",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 500,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 540,
    "parent_id": 162,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with squared deviations and removed redundant term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.5 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Weight columns more\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.5 * np.sum((col_sums - 1) ** 2)  # Squared deviations\n        row_imbalance = 1.5 * np.sum((row_sums - 1) ** 2)  # Squared deviations\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = done_cols\n        correct_rows = done_rows\n        return (nonzeros, -correct_cols - correct_rows,  # Removed redundant positive term\n                log_cols + log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828205891891349,
      "additional_data": {
        "spearman_correlation": "0.882821",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 459,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 12
    }
  },
  {
    "id": 541,
    "parent_id": 44,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved composite heuristic with weighted combination of features.\"\"\"\n    import numpy as np\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 0.1) + 0.1))\n        row_log = np.sum(np.log(np.maximum(row_sums, 0.1) + 0.1))\n        interaction = np.sum(col_sums * row_sums)\n        inter_log = np.log(interaction + 0.1) if interaction > 0 else 0\n        total_sum = np.sum(m)\n        return (col_log, row_log, inter_log, total_sum)\n    \n    features = []\n    for m in [matrix, matrix.T, np.linalg.inv(matrix.astype(float)).astype(int) % 2]:\n        features.append(get_features(m))\n    \n    # Weighted combination of features (weights optimized for correlation)\n    scores = []\n    for f in features:\n        score = 0.4*f[0] + 0.4*f[1] + 0.1*f[2] + 0.1*f[3]\n        scores.append(score)\n    \n    return min(scores)\n",
    "evaluation": {
      "fitness": 0.7229169161297491,
      "additional_data": {
        "spearman_correlation": "0.722917",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 532,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 542,
    "parent_id": 522,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import svd\n    \n    # Singular value decomposition based metrics\n    U, s, Vh = svd(matrix)\n    rank = np.sum(s > 1e-10)\n    entropy = -np.sum((s/s.sum()) * np.log(s/s.sum() + 1e-10))\n    \n    # Sparsity and spread metrics\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    col_nonzeros = np.sum(matrix > 0, axis=0)\n    row_nonzeros = np.sum(matrix > 0, axis=1)\n    \n    # Structural complexity metrics\n    col_skew = np.mean((col_sums - np.mean(col_sums))**3)\n    row_skew = np.mean((row_sums - np.mean(row_sums))**3)\n    interaction = np.sum(matrix * matrix.T)\n    \n    # Combined heuristic\n    h = (rank * entropy + \n         np.sum(col_nonzeros * row_nonzeros) + \n         np.abs(col_skew) + np.abs(row_skew) + \n         interaction)\n    \n    return h\n",
    "evaluation": {
      "fitness": 0.7218500252285708,
      "additional_data": {
        "spearman_correlation": "0.721850",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 533,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 543,
    "parent_id": 493,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        \n        # New: count matching almost-done columns\n        matching_almost_cols = 0\n        for i in range(m.shape[1]):\n            if col_sums[i] == 2:\n                for j in range(i+1, m.shape[1]):\n                    if col_sums[j] == 2 and np.array_equal(m[:,i], m[:,j]):\n                        matching_almost_cols += 1\n                        break\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Max and min sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        \n        # New: max difference between column sums\n        max_col_diff = np.max(col_sums) - np.min(col_sums)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        # Product of sums\n        col_product = np.prod(col_sums)\n        row_product = np.prod(row_sums)\n        \n        # Unique columns/rows\n        unique_cols = len(np.unique(m, axis=1))\n        unique_rows = len(np.unique(m, axis=0))\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                -matching_almost_cols,\n                -zero_cols-zero_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                col_variance + row_variance,\n                max_col + max_row,\n                min_col + min_row,\n                max_col_diff,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                col_product + row_product,\n                unique_cols + unique_rows,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8827034918946831,
      "additional_data": {
        "spearman_correlation": "0.882703",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 529,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 544,
    "parent_id": 458,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        \n        log_col = np.sum(np.log(col_sums))\n        hamming = np.sum(m)\n        max_col = np.max(col_sums)\n        completed_cols = np.sum(col_sums == 1)\n        completed_rows = np.sum(row_sums == 1)\n        \n        main_metric = log_col * hamming\n        secondary_metric = float(np.sum(np.log(row_sums + col_sums)) + max_col - (completed_cols + completed_rows))\n        return main_metric, secondary_metric\n    \n    # Compute all candidate matrices\n    candidates = [\n        matrix,\n        matrix.T,\n        (inv := np.linalg.inv(matrix.astype(float)).astype(int) % 2),\n        inv.T\n    ]\n    \n    # Calculate metrics for all candidates\n    metrics = [calculate_metrics(cand) for cand in candidates]\n    main_metrics = [m[0] for m in metrics]\n    secondary_metrics = [m[1] for m in metrics]\n    \n    return (min(main_metrics), min(secondary_metrics))\n",
    "evaluation": {
      "fitness": 0.7207537776878462,
      "additional_data": {
        "spearman_correlation": "0.720754",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 477,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 545,
    "parent_id": 484,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weighted column emphasis and squared imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with exactly one or two non-zeros\n        col_weight1 = np.sum(col_sums == 1)\n        row_weight1 = np.sum(row_sums == 1)\n        col_weight2 = np.sum(col_sums == 2)\n        row_weight2 = np.sum(row_sums == 2)\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Column-focused imbalance with squared terms\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        max_col = np.max(col_sums)\n        return (nonzeros, col_imbalance + 0.5*row_imbalance, max_col, \n                col_weight1 + 0.5*row_weight1, col_weight2 + 0.5*row_weight2, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8694739964479599,
      "additional_data": {
        "spearman_correlation": "0.869474",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 536,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 546,
    "parent_id": 221,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column pattern analysis\n        unique_cols = len(set(tuple(col) for col in m.T))\n        col_pairs = sum(1 for i in range(n) for j in range(i+1, n) \n                       if np.array_equal(m[:,i], m[:,j]))\n        \n        # Column completion metrics\n        col_completion = sum(1/s if s > 0 else 0 for s in col_sums)\n        col_variance = np.var(col_sums)\n        \n        # Linear algebra properties\n        _, _, u = lu(m)\n        u_rank = np.sum(np.abs(np.diag(u)) > 1e-10)\n        \n        # Column dependencies\n        col_deps = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                if np.array_equal(m[:,i] & m[:,j], m[:,i]):\n                    col_deps += 1\n        \n        return (nonzeros,\n                -col_completion,\n                -rank,\n                -unique_cols,\n                col_variance,\n                -col_pairs,\n                -u_rank,\n                -col_deps)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix).astype(int))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T.astype(int))\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 534,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 547,
    "parent_id": 250,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_cost(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Improved diagonal distance considering partial matches\n        diag_dist = min(np.sum(m * (1 - np.eye(n, dtype=int))),\n                        np.sum(m * (1 - np.fliplr(np.eye(n, dtype=int)))))\n        \n        # Smoother logarithmic column weight penalty\n        log_col = np.sum(np.log(np.maximum(col_sums, 1)))  # Using natural log\n        \n        # Adjusted weights based on component importance\n        return 0.6 * diag_dist + 0.25 * log_col + 0.15 * (total_ones - n)\n    \n    # Compute cost for all variants\n    original = matrix_cost(matrix)\n    transposed = matrix_cost(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_cost(inv_matrix)\n    inv_transposed = matrix_cost(inv_matrix.T)\n    \n    # Return the minimum cost across all variants\n    return min(original, transposed, inverse, inv_transposed)\n",
    "evaluation": {
      "fitness": 0.6937688182725963,
      "additional_data": {
        "spearman_correlation": "0.693769",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 538,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 548,
    "parent_id": 27,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Modified log metrics with small constant\n        col_metric = np.sum(np.log(col_sums + 0.1))\n        row_metric = np.sum(np.log(row_sums + 0.1))\n        \n        # Enhanced diagonal metrics\n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = (diag + anti_diag) / (2 * m.shape[0])\n        \n        # Add total ones metric\n        total_ones = np.sum(m)\n        \n        return (col_metric, row_metric, -diag_metric, total_ones)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8721783759829099,
      "additional_data": {
        "spearman_correlation": "0.872178",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 539,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 549,
    "parent_id": 170,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on key metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        done_cols = np.sum(col_sums == 1)\n        return (nonzeros, log_col_sums, -done_cols)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n    except:\n        h_inverse = (float('inf'),)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8811498042381746,
      "additional_data": {
        "spearman_correlation": "0.881150",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 541,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 550,
    "parent_id": 119,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    matrix = matrix.astype(int)\n    \n    def is_permutation(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        return np.all(row_sums == 1) and np.all(col_sums == 1)\n    \n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0) + 1\n        row_sums = np.sum(m, axis=1) + 1\n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums - 1)\n        row_linear = np.sum(row_sums - 1)\n        return (col_log + row_log, col_linear + row_linear)\n    \n    orig = matrix\n    inv = gf2_inv(orig)\n    trans = orig.T\n    inv_trans = inv.T\n    candidates = [orig, inv, trans, inv_trans]\n    \n    for cand in candidates:\n        if is_permutation(cand):\n            return (0.0, 0.0)\n    \n    metrics = [calculate_metrics(cand) for cand in candidates]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8731288073029102,
      "additional_data": {
        "spearman_correlation": "0.873129",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 537,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 551,
    "parent_id": 1,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both total sum and column weights.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n    return (float(np.sum(matrix)), log_sum)\n",
    "evaluation": {
      "fitness": 0.7668892445337393,
      "additional_data": {
        "spearman_correlation": "0.766889",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 544,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 552,
    "parent_id": 29,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix_inv = np.linalg.inv(matrix) % 2\n    col_prod = np.prod(np.sum(matrix, axis=0) + 1)\n    row_prod = np.prod(np.sum(matrix, axis=1) + 1)\n    inv_col_prod = np.prod(np.sum(matrix_inv, axis=0) + 1)\n    inv_row_prod = np.prod(np.sum(matrix_inv, axis=1) + 1)\n    log_col = np.log(col_prod * inv_col_prod + 1e-10)\n    log_row = np.log(row_prod * inv_row_prod + 1e-10)\n    cross_term = np.sum(matrix * matrix_inv.T)\n    return (log_col + log_row, cross_term)\n",
    "evaluation": {
      "fitness": 0.8628939914686177,
      "additional_data": {
        "spearman_correlation": "0.862894",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 543,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 553,
    "parent_id": 111,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    \n    def log_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        return float(np.sum(np.log(col_sums)))\n    \n    def ones_heuristic(m):\n        total_ones = np.sum(m)\n        return total_ones - n\n    \n    candidates = []\n    \n    # Original matrix\n    log_orig = log_heuristic(matrix)\n    ones_orig = ones_heuristic(matrix)\n    candidates.append((log_orig, ones_orig))\n    \n    # Inverse matrix\n    inv_real = np.linalg.inv(matrix)\n    inv_int = np.round(inv_real).astype(int)\n    inv_gf2 = inv_int % 2\n    log_inv = log_heuristic(inv_gf2)\n    ones_inv = ones_heuristic(inv_gf2)\n    candidates.append((log_inv, ones_inv))\n    \n    # Transpose matrix\n    trans = matrix.T\n    log_trans = log_heuristic(trans)\n    ones_trans = ones_heuristic(trans)\n    candidates.append((log_trans, ones_trans))\n    \n    return min(candidates, key=lambda x: (x[0], x[1]))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 545,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 554,
    "parent_id": 146,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering multiple matrix properties.\"\"\"\n    import numpy as np\n    \n    def matrix_properties(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (total_ones, weighted_col, weighted_row, col_variance + row_variance)\n    \n    original_props = matrix_properties(matrix)\n    transposed_props = matrix_properties(matrix.T)\n    try:\n        inverse_props = matrix_properties(np.linalg.inv(matrix).astype(int) % 2)\n        return min(original_props, transposed_props, inverse_props)\n    except:\n        return min(original_props, transposed_props)\n",
    "evaluation": {
      "fitness": 0.7210320382671255,
      "additional_data": {
        "spearman_correlation": "0.721032",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 546,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 555,
    "parent_id": 82,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(matrix):\n        inv_float = np.linalg.inv(matrix)\n        inv_rounded = np.round(inv_float).astype(int)\n        inv_gf2 = inv_rounded % 2\n        return inv_gf2\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        perfect_cols = np.sum(col_sums == 1)\n        perfect_rows = np.sum(row_sums == 1)\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sum_sq_cols = np.sum(col_sums**2)\n        sum_sq_rows = np.sum(row_sums**2)\n        return (nonzeros, -perfect_cols, -perfect_rows, log_col_sums, log_row_sums, sum_sq_cols, sum_sq_rows)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        inv = gf2_inv(matrix)\n        h_inv = get_heuristic(inv)\n    except np.linalg.LinAlgError:\n        h_inv = (float('inf'),) * 7\n    h_trans = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": 0.739524461695631,
      "additional_data": {
        "spearman_correlation": "0.739524",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 470,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 556,
    "parent_id": 312,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Row interaction heuristic with dependency scoring.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_sums = np.sum(m, axis=1)\n        \n        # Base row complexity (logarithmic to prioritize nearly-complete rows)\n        row_complexity = np.sum(np.log(row_nonzeros + 1))\n        \n        # Row interaction score (measures dependencies between rows)\n        interaction = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.dot(m[i], m[j])\n                interaction += overlap / (row_nonzeros[i] * row_nonzeros[j])\n        \n        # Row completion bonus (prioritize matrices closer to identity)\n        completion = np.sum(np.abs(row_sums - 1))\n        \n        return (row_complexity, interaction, completion)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8830853269751068,
      "additional_data": {
        "spearman_correlation": "0.883085",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 550,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 557,
    "parent_id": 358,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Weight columns slightly more than rows\n        log_col = 1.1 * np.sum(np.log(col_sums))\n        log_row = 0.9 * np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        \n        # Penalty for non-zero diagonal\n        diag_penalty = np.sum(np.diag(m))\n        \n        cols_with_weight_1 = np.sum(col_sums == 1)\n        rows_with_weight_1 = np.sum(row_sums == 1)\n        min_col_sum = np.min(col_sums)\n        \n        col_row_overlap = np.sum(m * m.T)\n        \n        main_metric = log_col + log_row + hamming + diag_penalty\n        secondary_metric = float(cols_with_weight_1 + rows_with_weight_1 + min_col_sum)\n        tertiary_metric = float(col_row_overlap)\n        \n        return main_metric, secondary_metric, tertiary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    min_tertiary = min(original[2], transposed[2], inverted[2])\n    \n    return (min_main, min_secondary, min_tertiary)\n",
    "evaluation": {
      "fitness": 0.6955742891774658,
      "additional_data": {
        "spearman_correlation": "0.695574",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 551,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 558,
    "parent_id": 284,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = aug[r] ^ aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        col_devs = np.abs(col_sums - 1)\n        row_devs = np.abs(row_sums - 1)\n        total_dev = np.sum(col_devs) + np.sum(row_devs)\n        col_log_sum = np.sum(np.log(col_sums))\n        row_log_sum = np.sum(np.log(row_sums))\n        gram_col = np.dot(m.T, m)\n        col_overlaps = np.sum(gram_col) - np.sum(np.diag(gram_col))\n        gram_row = np.dot(m, m.T)\n        row_overlaps = np.sum(gram_row) - np.sum(np.diag(gram_row))\n        sorted_col_devs = sorted(col_devs, reverse=True)\n        sorted_row_devs = sorted(row_devs, reverse=True)\n        features = [nonzeros, total_dev, col_log_sum, row_log_sum, col_overlaps, row_overlaps]\n        features.extend(sorted_col_devs)\n        features.extend(sorted_row_devs)\n        return tuple(features)\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        h_inv = get_heuristic(inv_matrix)\n        return min(h_orig, h_inv, h_trans)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.8686533533467901,
      "additional_data": {
        "spearman_correlation": "0.868653",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 494,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 559,
    "parent_id": 41,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.sparse.csgraph import connected_components\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        simple_sum = np.sum(m)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Connectivity metric\n        _, comps = connected_components(m, directed=False)\n        connectivity = (n - comps) / n\n        \n        # Distance to nearest permutation\n        perm_dist = np.sum(np.sort(col_sums)[::-1] - np.arange(n))\n        \n        # Pairwise column correlations\n        corr = np.corrcoef(m.T)\n        np.fill_diagonal(corr, 0)\n        col_corr = np.sum(np.abs(corr))\n        \n        # Adaptive weights\n        density = simple_sum / (n*n)\n        w1 = 0.4 - 0.2*density\n        w2 = 0.3 + 0.1*density\n        w3 = 0.2 - 0.1*density\n        w4 = 0.05 + 0.05*density\n        w5 = 0.05 + 0.05*density\n        \n        return (w1*simple_sum + w2*log_col + w3*log_row + \n                w4*connectivity + w5*perm_dist + 0.1*col_corr)\n    \n    # Consider all isomorphic variants\n    variants = [\n        matrix,\n        matrix.T,\n        np.fliplr(matrix),\n        np.flipud(matrix),\n        np.rot90(matrix, 1),\n        np.rot90(matrix, 2),\n        np.rot90(matrix, 3)\n    ]\n    \n    # Add matrix inverse if invertible\n    try:\n        inv_matrix = np.linalg.inv(matrix).round().astype(int) % 2\n        variants.append(inv_matrix)\n    except:\n        pass\n    \n    return min(evaluate(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 552,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 560,
    "parent_id": 147,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering multiple matrix transformations and patterns.\"\"\"\n    import numpy as np\n    \n    def compute_score(m):\n        # Normalize matrix to avoid numerical issues\n        m = m.astype(float)\n        m[np.abs(m) < 1e-10] = 0\n        \n        # Calculate both row and column metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Avoid log(0) and division by zero\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Combine multiple metrics\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        element_sum = np.sum(m)\n        nonzero_count = np.sum(m != 0)\n        \n        # Weighted combination of metrics\n        return 0.4 * log_col + 0.4 * log_row + 0.1 * element_sum + 0.1 * nonzero_count\n    \n    # Consider original, inverse, transpose, and inverse transpose\n    transformations = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    # Return the minimum score across all transformations\n    return min(compute_score(t) for t in transformations)\n",
    "evaluation": {
      "fitness": -0.044811747862624006,
      "additional_data": {
        "spearman_correlation": "-0.044812",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 553,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 561,
    "parent_id": 221,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Weighted column completion score\n        col_completion = sum(np.exp(2-s) for s in col_sums if s >= 1)\n        \n        # Column dependency score\n        _, U = np.linalg.qr(m)\n        diag = np.abs(np.diag(U))\n        col_dependency = -np.sum(diag > 1e-8)  # Effective rank\n        \n        # Column clustering score\n        unique_cols = len(set(tuple(col) for col in m.T))\n        \n        return (col_completion,\n                col_dependency,\n                -unique_cols,\n                nonzeros)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 554,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 562,
    "parent_id": 223,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        col_pairs = [(i,j) for i in range(m.shape[1]) for j in range(i+1, m.shape[1])]\n        row_pairs = [(i,j) for i in range(m.shape[0]) for j in range(i+1, m.shape[0])]\n        avg_col_dist = np.mean([hamming(m[:,i], m[:,j]) for i,j in col_pairs]) if col_pairs else 0\n        avg_row_dist = np.mean([hamming(m[i,:], m[j,:]) for i,j in row_pairs]) if row_pairs else 0\n        \n        diag_dom = np.sum(np.abs(np.diag(m))) / (np.sum(np.abs(m)) + 1e-8)\n        rank_approx = np.linalg.matrix_rank(m.astype(float))\n        \n        return [\n            -np.sum(col_sums),\n            -np.sum(row_sums),\n            -unique_cols,\n            -unique_rows,\n            -avg_col_dist,\n            -avg_row_dist,\n            -diag_dom,\n            -rank_approx\n        ]\n    \n    features = get_features(matrix)\n    trans_features = get_features(matrix.T)\n    inv_features = get_features(np.linalg.inv(matrix.astype(float)) if np.linalg.det(matrix) != 0 else [0]*8)\n    \n    return tuple(np.minimum.reduce([features, trans_features, inv_features]))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 555,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 563,
    "parent_id": 146,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering inverse and refined column weights.\"\"\"\n    import numpy as np\n    \n    def matrix_properties(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # More refined column weighting emphasizing near-complete columns\n        weighted_col = np.sum(np.where(col_sums > 0, np.log2(col_sums) + 1/(col_sums+0.1), 0))\n        weighted_row = np.sum(np.where(row_sums > 0, np.log2(row_sums) + 1/(row_sums+0.1), 0))\n        \n        # Diagonal dominance measure\n        diag_dom = np.sum(np.abs(np.diag(m) - 1))\n        \n        return (total_ones, weighted_col, weighted_row, diag_dom)\n    \n    original_props = matrix_properties(matrix)\n    transposed_props = matrix_properties(matrix.T)\n    inverse_props = matrix_properties(np.linalg.inv(matrix) % 2)\n    inverse_transposed_props = matrix_properties(np.linalg.inv(matrix.T) % 2)\n    \n    return min(original_props, transposed_props, inverse_props, inverse_transposed_props)\n",
    "evaluation": {
      "fitness": 0.8699963182159798,
      "additional_data": {
        "spearman_correlation": "0.869996",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 556,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 564,
    "parent_id": 113,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural log and max sum terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_std = np.std(col_sums)\n        row_std = np.std(row_sums)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                col_std + row_std, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827938168792194,
      "additional_data": {
        "spearman_correlation": "0.882794",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 557,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 565,
    "parent_id": 364,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    matrix = matrix.astype(int)\n    \n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = col\n            while pivot < n and aug[pivot, col] == 0:\n                pivot += 1\n            if pivot == n:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def is_permutation(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        return np.all(row_sums == 1) and np.all(col_sums == 1)\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        if is_permutation(m):\n            return (0.0, 0.0, 0.0, 0.0, 0.0)\n        row_nonzeros = np.sum(m, axis=1)\n        col_nonzeros = np.sum(m, axis=0)\n        row_completion = np.sum(np.sqrt(row_nonzeros))\n        col_completion = np.sum(np.sqrt(col_nonzeros))\n        row_dist = np.sum(np.abs(row_nonzeros - 1))\n        col_dist = np.sum(np.abs(col_nonzeros - 1))\n        sparsity = np.count_nonzero(m) / (n * n)\n        return (row_completion, col_completion, row_dist, col_dist, sparsity)\n    \n    variants = [matrix, matrix.T]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        variants.append(inv_matrix)\n        variants.append(inv_matrix.T)\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.872132072285007,
      "additional_data": {
        "spearman_correlation": "0.872132",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 491,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 566,
    "parent_id": 320,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        A = A.astype(int)\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] != 0:\n                    pivot = r\n                    break\n            if pivot != col:\n                aug[[pivot, col]] = aug[[col, pivot]]\n            for r in range(n):\n                if r != col and aug[r, col] != 0:\n                    aug[r] = (aug[r] ^ aug[col])\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        m_bin = (m != 0).astype(int)\n        col_sums = np.sum(m_bin, axis=0)\n        n = m.shape[0]\n        total_ones = np.sum(col_sums)\n        lb = total_ones - n\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        count_weight1 = np.sum(col_sums == 1)\n        count_weight2 = np.sum(col_sums == 2)\n        return (lb, log_sum, -count_weight1, -count_weight2)\n\n    inv = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8713723670142689,
      "additional_data": {
        "spearman_correlation": "0.871372",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 535,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 567,
    "parent_id": 489,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + 0.05 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8689446406075221,
      "additional_data": {
        "spearman_correlation": "0.868945",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 516,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 568,
    "parent_id": 539,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_nonzero = np.maximum(col_nonzero, 1)\n        row_nonzero = np.maximum(row_nonzero, 1)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        log_col_nz = np.sum(np.log(col_nonzero))\n        log_row_nz = np.sum(np.log(row_nonzero))\n        \n        total_ones = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        return (log_col * log_col_nz, log_row * log_row_nz, \n                total_ones * (1 + col_var) * (1 + row_var))\n    \n    metrics_orig = calculate_metrics(matrix)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = (inv_matrix % 2).astype(int)\n        metrics_inv = calculate_metrics(inv_matrix)\n        metrics_inv_trans = calculate_metrics(inv_matrix.T)\n    except:\n        metrics_inv = metrics_orig\n        metrics_inv_trans = metrics_trans\n    \n    variants = [\n        (0.5, 0.3, 0.2, metrics_orig),\n        (0.3, 0.5, 0.2, metrics_trans),\n        (0.4, 0.3, 0.3, metrics_inv),\n        (0.3, 0.4, 0.3, metrics_inv_trans)\n    ]\n    \n    combined = []\n    for w1, w2, w3, (m1, m2, m3) in variants:\n        score = (w1 * m1 + w2 * m2 + w3 * m3) / (w1 + w2 + w3)\n        combined.append(score)\n    \n    combined_sorted = sorted(combined)\n    return tuple(combined_sorted)\n",
    "evaluation": {
      "fitness": 0.7178442082568868,
      "additional_data": {
        "spearman_correlation": "0.717844",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 559,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 569,
    "parent_id": 228,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        diag_sum = np.sum(np.diag(m))\n        \n        # Count unique columns and rows\n        cols = [tuple(col) for col in m.T]\n        rows = [tuple(row) for row in m]\n        unique_cols = len(set(cols))\n        unique_rows = len(set(rows))\n                \n        col_completion = sum(np.log2(s) if s > 0 else 0 for s in col_sums)\n        row_completion = sum(np.log2(s) if s > 0 else 0 for s in row_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                -unique_rows,\n                -diag_sum)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 561,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 570,
    "parent_id": 484,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Full weight distribution for columns and rows\n        col_weights = [np.sum(col_sums == w) for w in range(n+1)]\n        row_weights = [np.sum(row_sums == w) for w in range(n+1)]\n        \n        # Distance metrics\n        col_dist = np.sum((col_sums - 1)**2)  # L2 distance\n        row_dist = np.sum((row_sums - 1)**2)\n        \n        # Diagonal information\n        diag = np.diag(m)\n        diag_sum = np.sum(diag)\n        diag_nonzero = np.count_nonzero(diag)\n        \n        # Off-diagonal information\n        off_diag = m - np.diag(diag)\n        off_diag_sum = np.sum(off_diag)\n        off_diag_nonzero = np.count_nonzero(off_diag)\n        \n        return (nonzeros, col_dist + row_dist, off_diag_nonzero, diag_nonzero, \n                *col_weights, *row_weights, diag_sum, off_diag_sum)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    # Combine all three rather than taking min\n    combined = tuple(x + y + z for x, y, z in zip(h_original, h_inverse, h_transpose))\n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 560,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 571,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def normalize(m):\n        return m / np.max(np.abs(m)) if np.max(np.abs(m)) != 0 else m\n    \n    def get_heuristic(m):\n        m = normalize(m)\n        col_sums = np.sum(np.abs(m), axis=0)\n        row_sums = np.sum(np.abs(m), axis=1)\n        col_entropy = entropy(col_sums + 1e-10)  # Add small value to avoid log(0)\n        row_entropy = entropy(row_sums + 1e-10)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum((col_sums - 1) ** 2)\n        row_imbalance = np.sum((row_sums - 1) ** 2)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, col_imbalance + row_imbalance, col_entropy + row_entropy, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    # Return all three heuristics to be compared lexicographically\n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8484717025093049,
      "additional_data": {
        "spearman_correlation": "0.848472",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 563,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 572,
    "parent_id": 2,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Sum of logarithms of column sums, considering inverse and transpose.\"\"\"\n    import numpy as np\n    \n    def compute_h(mat):\n        col_sums = np.sum(mat, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    h_original = compute_h(matrix)\n    h_transpose = compute_h(matrix.T)\n    try:\n        h_inverse = compute_h(np.linalg.inv(matrix))\n    except np.linalg.LinAlgError:\n        h_inverse = float('inf')\n    \n    return min(h_original, h_transpose, h_inverse)\n",
    "evaluation": {
      "fitness": -0.16898660351655273,
      "additional_data": {
        "spearman_correlation": "-0.168987",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 564,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 573,
    "parent_id": 303,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with near-completion metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # New near-completion metrics\n        near_cols = np.sum((col_sums > 0.5) & (col_sums < 1.5))\n        near_rows = np.sum((row_sums > 0.5) & (row_sums < 1.5))\n        \n        # Column/row interaction metrics\n        col_overlaps = np.sum(m.T @ m) - np.sum(col_sums)\n        row_overlaps = np.sum(m @ m.T) - np.sum(row_sums)\n        \n        # Rank-based metrics\n        rank = np.linalg.matrix_rank(m)\n        nullity = n - rank\n        \n        # Distance to basis vectors\n        col_dist = np.sum(np.minimum(col_sums, np.abs(col_sums - 1)))\n        row_dist = np.sum(np.minimum(row_sums, np.abs(row_sums - 1)))\n        \n        # Column/row clustering\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, -done_cols-done_rows, -near_cols-near_rows, nullity, \n                col_overlaps + row_overlaps, col_dist + row_dist, rank, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8583024728518179,
      "additional_data": {
        "spearman_correlation": "0.858302",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 562,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 574,
    "parent_id": 390,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row metrics with entropy and interaction terms.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column and row completion with entropy weighting\n        col_completion = entropy(col_nonzeros + 1)\n        row_completion = entropy(row_nonzeros + 1)\n        \n        # Enhanced column/row interaction terms\n        col_interaction = np.sum(np.abs(np.dot(m.T, m) - np.eye(n)))\n        row_interaction = np.sum(np.abs(np.dot(m, m.T) - np.eye(n)))\n        \n        # Entropy-based sparsity measurement\n        sparsity = entropy(m.flatten() + 1)\n        \n        # Cross term measuring column-row alignment\n        cross_term = np.sum(np.abs(np.sum(m, axis=0) - np.sum(m, axis=1)))\n        \n        # Combine all components into a single float\n        return (col_completion + row_completion + col_interaction + \n                row_interaction + sparsity + cross_term)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.12703171088950885,
      "additional_data": {
        "spearman_correlation": "0.127032",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 566,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 575,
    "parent_id": 110,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        col2_count = np.count_nonzero(col_sums == 2)\n        row2_count = np.count_nonzero(row_sums == 2)\n        return (total_ones - n, n - col1_count, n - row1_count, n - col2_count, n - row2_count)\n    \n    candidates = []\n    # Original matrix features\n    candidates.append(get_features(matrix))\n    # Transpose features (swaps row/column metrics)\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse mod2 features (if computable)\n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    return min(candidates)  # Lexicographic min\n",
    "evaluation": {
      "fitness": 0.7397574977975586,
      "additional_data": {
        "spearman_correlation": "0.739757",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 565,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 576,
    "parent_id": 297,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (nonzeros, incorrect_total, log_cols, log_rows, col_imbalance, row_imbalance, max_col, max_row)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = get_heuristic(inv_matrix)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8713906836456581,
      "additional_data": {
        "spearman_correlation": "0.871391",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 548,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 577,
    "parent_id": 509,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def binary_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 1e-10).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        return (log_col, log_row, total_ones)\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        binary_inv(matrix),\n        binary_inv(matrix).T\n    ]\n    \n    metrics = []\n    for m in matrices:\n        m_metrics = get_metrics(m)\n        metrics.extend(m_metrics)\n    \n    return tuple(metrics)\n",
    "evaluation": {
      "fitness": 0.7932053297365754,
      "additional_data": {
        "spearman_correlation": "0.793205",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 569,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 578,
    "parent_id": 210,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based metrics\n        col_log = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_dist = np.sum([min(np.sum(np.abs(col - basis)) for basis in np.eye(n)) for col in m.T])\n        \n        # Row-based metrics\n        row_log = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_dist = np.sum([min(np.sum(np.abs(row - basis)) for basis in np.eye(n)) for row in m])\n        \n        # Structural metrics\n        nonzeros = np.count_nonzero(m)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Combined metrics\n        log_terms = 1.5 * col_log + 0.8 * row_log\n        dist_terms = 0.7 * col_dist + 0.4 * row_dist\n        max_terms = 0.9 * max_col + 0.5 * max_row\n        \n        return (nonzeros, log_terms, dist_terms, max_terms)\n    \n    # Generate all permutation variants (row/column permutations)\n    variants = [matrix]\n    for _ in range(3):  # Limited number of permutations for efficiency\n        variants.append(matrix[:, np.random.permutation(matrix.shape[1])])\n        variants.append(matrix[np.random.permutation(matrix.shape[0]), :])\n    \n    # Add inverse/transpose variants\n    variants += [np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix).T]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8818502746220233,
      "additional_data": {
        "spearman_correlation": "0.881850",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 568,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 579,
    "parent_id": 44,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column dependency hierarchy and minimal spanning set.\"\"\"\n    import numpy as np\n    \n    def get_column_dependencies(m):\n        n = m.shape[0]\n        basis = []\n        dependencies = []\n        for col in m.T:\n            vec = col.copy()\n            rank_before = len(basis)\n            if len(basis) > 0:\n                vec = vec.copy()\n                for b in reversed(basis):\n                    if np.dot(vec, b) % 2:\n                        vec = (vec + b) % 2\n            if np.any(vec):\n                basis.append(vec)\n                dependencies.append(rank_before)\n            else:\n                dependencies.append(len(basis))\n        return dependencies\n    \n    def compute_hierarchy_cost(deps):\n        cost = 0\n        level_counts = {}\n        for d in deps:\n            level = d\n            cost += level\n            level_counts[level] = level_counts.get(level, 0) + 1\n        for level, count in level_counts.items():\n            if level > 0:\n                cost += np.log(count + 1)\n        return cost\n    \n    def matrix_cost(m):\n        deps = get_column_dependencies(m)\n        return compute_hierarchy_cost(deps)\n    \n    original_cost = matrix_cost(matrix)\n    transposed_cost = matrix_cost(matrix.T)\n    inverse_cost = matrix_cost(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_cost = min(original_cost, transposed_cost, inverse_cost)\n    total_sum = np.sum(matrix)\n    \n    return (min_cost, -total_sum)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'reversed' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 570,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 580,
    "parent_id": 265,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns and rows\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        unique_rows = 1\n        rows = [tuple(row) for row in m]\n        for i in range(1, len(rows)):\n            if rows[i] not in rows[:i]:\n                unique_rows += 1\n                \n        col_completion = sum(col_sums)\n        row_completion = sum(row_sums)\n        log_col_sums = sum(np.log2(np.maximum(col_sums, 1)))\n        \n        return (nonzeros, \n                col_completion,\n                row_completion,\n                log_col_sums,\n                -basis_cols,\n                -unique_cols,\n                -unique_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8805876519998003,
      "additional_data": {
        "spearman_correlation": "0.880588",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 567,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 581,
    "parent_id": 35,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.trace(m)\n        total_nonzero = np.count_nonzero(m)\n        off_diag_nonzero = total_nonzero - diag_sum\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        h1 = float(np.sum(np.log(col_sums)))\n        h2 = float(np.sum(np.log(row_sums)))\n        h3 = float(total_nonzero)\n        h4 = float(diag_sum)\n        h5 = float(off_diag_nonzero)\n        return (h1, h2, h3, h4, h5)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8680702386029537,
      "additional_data": {
        "spearman_correlation": "0.868070",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 571,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 582,
    "parent_id": 118,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        identity = np.eye(n, dtype=int)\n        aug = np.hstack((mat, identity))\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                raise ValueError(\"Singular matrix\")\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log2(col_sums[col_sums > 1])) \n        row_log = np.sum(np.log2(row_sums[row_sums > 1]))\n        return (total_ones - n, col_log + row_log)\n\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    try:\n        inv_matrix = gf2_inv(matrix)\n        h_inverse = get_heuristic(inv_matrix)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8724104368850486,
      "additional_data": {
        "spearman_correlation": "0.872410",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 530,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 583,
    "parent_id": 161,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import inv, matrix_power\n    \n    def matrix_entropy(m):\n        m = m.astype(float)\n        total = np.sum(m)\n        if total == 0:\n            return 0\n        prob = m / total\n        prob = prob[prob > 0]\n        return -np.sum(prob * np.log2(prob))\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        entropy = matrix_entropy(m)\n        return (weighted_col + weighted_row) / 2 + entropy\n    \n    original = calculate_heuristic(matrix)\n    transposed = calculate_heuristic(matrix.T)\n    try:\n        inverse = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse = float('inf')\n    try:\n        product = calculate_heuristic((matrix @ matrix.T) % 2)\n    except:\n        product = float('inf')\n    \n    min_h = min(original, transposed, inverse, product)\n    max_h = max(original, transposed, inverse, product)\n    mean_h = np.mean([h for h in [original, transposed, inverse, product] if h != float('inf')])\n    \n    return (min_h, mean_h, max_h, matrix_entropy(matrix))\n",
    "evaluation": {
      "fitness": 0.40929248770415577,
      "additional_data": {
        "spearman_correlation": "0.409292",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 572,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 584,
    "parent_id": 3,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved vector heuristic using log column sums and considering inverses.\"\"\"\n    import numpy as np\n    \n    def compute_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        log_sums = np.log2(np.maximum(col_sums, 1))  # log2 of sums, min 1 to avoid log(0)\n        return tuple(sorted(log_sums))\n    \n    h1 = compute_heuristic(matrix)\n    h2 = compute_heuristic(matrix.T)  # transpose\n    h3 = compute_heuristic(np.linalg.inv(matrix))  # inverse\n    \n    return min(h1, h2, h3)\n",
    "evaluation": {
      "fitness": 0.0251492518531978,
      "additional_data": {
        "spearman_correlation": "0.025149",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 577,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 585,
    "parent_id": 418,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def base_heuristic(m):\n        row_weights = np.sum(m, axis=1)\n        log_sum = 0.0\n        for w in row_weights:\n            if w > 1:\n                log_sum += np.log2(w)\n        nonzeros = float(np.count_nonzero(m))\n        return (log_sum, nonzeros)\n    \n    transpose = matrix.T\n    inv = gf2_inv(matrix)\n    versions = [matrix, transpose]\n    if inv is not None:\n        versions.append(inv)\n        versions.append(inv.T)\n    \n    best_heuristic = None\n    for m in versions:\n        h = base_heuristic(m)\n        if best_heuristic is None or h < best_heuristic:\n            best_heuristic = h\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 574,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 586,
    "parent_id": 473,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag = np.diag(m)\n        off_diag = np.sum(m) - np.sum(diag)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_col = np.sum(col_sums)\n        sum_row = np.sum(row_sums)\n        var_col = np.var(col_sums)\n        diag_dominance = np.sum(diag)/np.sum(m)\n        rank = np.linalg.matrix_rank(m)\n        det = np.abs(np.linalg.det(m))\n        return (log_col, log_row, sum_col, sum_row, var_col, \n                diag_dominance, off_diag, rank, det)\n    \n    original = get_metrics(matrix)\n    inverse = get_metrics(np.linalg.inv(matrix) % 2)\n    transpose = get_metrics(matrix.T)\n    square = get_metrics(np.dot(matrix, matrix) % 2)\n    \n    weights = [1.0, 0.8, 0.9, 0.8, 0.7, 1.2, 0.9, 0.6, 0.5]\n    combined = tuple(min(original[i], inverse[i], transpose[i], square[i]) * weights[i] \n                for i in range(9))\n    return combined\n",
    "evaluation": {
      "fitness": 0.5723858218878346,
      "additional_data": {
        "spearman_correlation": "0.572386",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 573,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 587,
    "parent_id": 167,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using logarithms of sums to prioritize near-1 columns/rows.\"\"\"\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    \n    log_col = tuple(np.log2(np.maximum(col_sums, 1)))\n    log_row = tuple(np.log2(np.maximum(row_sums, 1)))\n    log_trans_col = tuple(np.log2(np.maximum(trans_col_sums, 1)))\n    log_trans_row = tuple(np.log2(np.maximum(trans_row_sums, 1)))\n    \n    option1 = log_col + log_row\n    option2 = log_trans_col + log_trans_row\n    return min(option1, option2)\n",
    "evaluation": {
      "fitness": 0.5050660960030456,
      "additional_data": {
        "spearman_correlation": "0.505066",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 579,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 588,
    "parent_id": 210,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.8 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.2 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827672020947716,
      "additional_data": {
        "spearman_correlation": "0.882767",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 578,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 589,
    "parent_id": 345,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    \n    def get_heuristic_tuple(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        eps = 1e-12\n        col_sums = np.maximum(col_sums, eps)\n        row_sums = np.maximum(row_sums, eps)\n        col_heuristic = np.sort(np.log(col_sums))\n        row_heuristic = np.sort(np.log(row_sums))\n        return tuple(col_heuristic), tuple(row_heuristic)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    except:\n        inv_matrix = matrix\n        \n    h1_col, h1_row = get_heuristic_tuple(matrix)\n    h2_col, h2_row = get_heuristic_tuple(matrix.T)\n    h3_col, h3_row = get_heuristic_tuple(inv_matrix)\n    h4_col, h4_row = get_heuristic_tuple(inv_matrix.T)\n    \n    return min((h1_col, h1_row), (h2_col, h2_row), (h3_col, h3_row), (h4_col, h4_row))\n",
    "evaluation": {
      "fitness": 0.7077712396546979,
      "additional_data": {
        "spearman_correlation": "0.707771",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 580,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 590,
    "parent_id": 482,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_features(m):\n        if m is None:\n            return None\n        \n        # Basic features\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Interaction features\n        col_interactions = np.sum(np.abs(np.diff(m, axis=0)))\n        row_interactions = np.sum(np.abs(np.diff(m, axis=1)))\n        \n        # Rank and norm features\n        rank = np.linalg.matrix_rank(m)\n        frob_norm = np.linalg.norm(m, 'fro')\n        spec_norm = np.linalg.norm(m, 2)\n        \n        # Entropy measures\n        col_entropy = -np.sum(col_sums * np.log(col_sums + 1e-10))\n        row_entropy = -np.sum(row_sums * np.log(row_sums + 1e-10))\n        \n        # Decomposition features\n        u, s, vh = np.linalg.svd(m)\n        sv_entropy = -np.sum(s * np.log(s + 1e-10))\n        \n        return {\n            'col_sums': col_sums,\n            'row_sums': row_sums,\n            'total_ones': total_ones,\n            'col_inter': col_interactions,\n            'row_inter': row_interactions,\n            'rank': rank,\n            'frob_norm': frob_norm,\n            'spec_norm': spec_norm,\n            'col_entropy': col_entropy,\n            'row_entropy': row_entropy,\n            'sv_entropy': sv_entropy\n        }\n    \n    def evaluate_features(feats):\n        if feats is None:\n            return (float('inf'), float('inf'), float('inf'))\n        \n        # Primary heuristic components\n        complexity = (feats['col_entropy'] + feats['row_entropy']) / 2\n        structure = feats['sv_entropy'] / feats['rank'] if feats['rank'] > 0 else float('inf')\n        density = feats['total_ones'] / (matrix.size + 1e-10)\n        \n        # Secondary components\n        interaction = (feats['col_inter'] + feats['row_inter']) / (2 * matrix.size)\n        norm_ratio = feats['frob_norm'] / (feats['spec_norm'] + 1e-10)\n        \n        return (\n            complexity + structure,\n            -density,\n            interaction * norm_ratio\n        )\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.pinv(matrix) > 0.5,\n        np.linalg.pinv(matrix.T) > 0.5\n    ]\n    \n    metrics = []\n    for variant in variants:\n        feats = matrix_features(variant)\n        if feats is None:\n            continue\n        metrics.append(evaluate_features(feats))\n    \n    if not metrics:\n        return (float('inf'), float('inf'), float('inf'))\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.7008837146111208,
      "additional_data": {
        "spearman_correlation": "-0.700884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 575,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 591,
    "parent_id": 247,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column distribution metrics\n        col_entropy = -np.sum([(s/nonzeros)*np.log2(s/nonzeros) \n                             for s in col_sums if s > 0])\n        col_variance = np.var(col_sums)\n        \n        # Row distribution metrics\n        row_entropy = -np.sum([(s/nonzeros)*np.log2(s/nonzeros) \n                             for s in row_sums if s > 0])\n        \n        # Matrix structure metrics\n        _, L, U = lu(m)\n        l_nnz = np.count_nonzero(L)\n        u_nnz = np.count_nonzero(U)\n        \n        # Singular value based metric\n        svd_rank = np.linalg.matrix_rank(m)\n        sv_entropy = -np.sum([(s/svd_rank)*np.log2(s/svd_rank) \n                            for s in np.linalg.svd(m)[1] if s > 0])\n        \n        # Combined weighted score\n        score = (0.4 * nonzeros + \n                0.3 * (col_entropy + row_entropy) +\n                0.2 * (l_nnz + u_nnz) +\n                0.1 * sv_entropy)\n        \n        return score\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8511919124362022,
      "additional_data": {
        "spearman_correlation": "0.851192",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 581,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 592,
    "parent_id": 323,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_metrics(m):\n        n = m.shape[0]\n        m_binary = (m % 2).astype(int)  # Ensure binary values\n        col_sums = np.sum(m_binary, axis=0)\n        row_sums = np.sum(m_binary, axis=1)\n        nonzeros = np.count_nonzero(m_binary)\n        basis_cols = np.linalg.matrix_rank(m_binary)\n        \n        # Column uniqueness and linear independence\n        _, pivots = np.linalg.qr(m_binary)\n        independent_cols = len(pivots)\n        \n        # Column overlap/entanglement\n        col_overlap = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_overlap += np.sum(m_binary[:,i] & m_binary[:,j])\n        \n        # Triangularity measures\n        try:\n            L, U = lu(m_binary, permute_l=True)[:2]\n            lower_tri = np.sum(np.tril(L, -1))\n            upper_tri = np.sum(np.triu(U, 1))\n            tri_measure = lower_tri + upper_tri\n        except:\n            tri_measure = n*n  # Large penalty if LU fails\n            \n        # Column completion (prioritize nearly done columns)\n        col_completion = sum(2-s for s in col_sums if s <= 2)\n        \n        # Row symmetry\n        row_symmetry = -np.sum(np.abs(row_sums - np.mean(row_sums)))\n        \n        # Column linear dependence\n        dep_cols = n - independent_cols\n        \n        return (nonzeros,\n                col_overlap,\n                -col_completion,\n                tri_measure,\n                -independent_cols,\n                dep_cols,\n                row_symmetry)\n    \n    try:\n        h_original = get_metrics(matrix)\n        h_inverse = get_metrics(np.linalg.inv(matrix) % 2)\n        h_transpose = get_metrics(matrix.T % 2)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_metrics(matrix)\n",
    "evaluation": {
      "fitness": 0.7728950366438295,
      "additional_data": {
        "spearman_correlation": "0.772895",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 584,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 593,
    "parent_id": 85,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using average of variants and including row sums.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 8)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 587,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 594,
    "parent_id": 265,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_log_completion = sum(np.log2(np.maximum(col_sums, 1)))\n        \n        return (nonzeros, \n                -col_log_completion,\n                -basis_cols,\n                -unique_cols*2)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8583732607001645,
      "additional_data": {
        "spearman_correlation": "0.858373",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 585,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 595,
    "parent_id": 200,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def safe_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 0.5).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        \n        col_entropy = np.sum(entropy(col_sums))\n        row_entropy = np.sum(entropy(row_sums))\n        \n        col_interactions = np.sum(np.log(np.sum(m * m.T, axis=0)))\n        row_interactions = np.sum(np.log(np.sum(m * m.T, axis=1)))\n        \n        return (\n            log_col, log_row, total_ones,\n            col_entropy, row_entropy,\n            col_interactions, row_interactions,\n            np.min(col_sums), np.max(col_sums),\n            np.min(row_sums), np.max(row_sums)\n        )\n    \n    m_orig = matrix\n    m_trans = matrix.T\n    m_inv = safe_inv(matrix)\n    m_inv_trans = m_inv.T\n    \n    metrics = [\n        calculate_metrics(m_orig),\n        calculate_metrics(m_trans),\n        calculate_metrics(m_inv),\n        calculate_metrics(m_inv_trans)\n    ]\n    \n    # Return tuple of min/max metrics across all variants\n    min_log_col = min(m[0] for m in metrics)\n    max_log_col = max(m[0] for m in metrics)\n    min_total_ones = min(m[2] for m in metrics)\n    min_col_entropy = min(m[3] for m in metrics)\n    max_col_interactions = max(m[5] for m in metrics)\n    \n    return (\n        min_log_col,\n        max_log_col,\n        min_total_ones,\n        min_col_entropy,\n        max_col_interactions\n    )\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 586,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 596,
    "parent_id": 7,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column and row sums of matrix and its variants.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        return (float(np.sum(col_sums)), float(np.sum(row_sums)))\n    \n    metrics = [\n        calculate_metrics(matrix),\n        calculate_metrics(np.linalg.inv(matrix)),\n        calculate_metrics(matrix.T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.2758886734673673,
      "additional_data": {
        "spearman_correlation": "-0.275889",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 588,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 597,
    "parent_id": 410,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with balanced components.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Row completion with polynomial weighting\n        row_completion = np.sum(row_nonzeros ** 2)\n        \n        # Rank deficiency measure\n        rank_penalty = n - np.linalg.matrix_rank(m)\n        \n        # Simplified interaction term\n        interaction = np.sum(np.abs(m)) - n\n        \n        # Column weights with natural log\n        col_weights = np.sum(col_nonzeros * np.log(col_nonzeros + 1))\n        \n        return (rank_penalty, row_completion, interaction, col_weights)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.844025662355025,
      "additional_data": {
        "spearman_correlation": "0.844026",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 590,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 598,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Use absolute deviations instead of squared\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # Sort column sums for consistent ordering\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8825352905882856,
      "additional_data": {
        "spearman_correlation": "0.882535",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 591,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 599,
    "parent_id": 578,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based metrics\n        col_log = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_dist_l1 = np.sum([min(np.sum(np.abs(col - basis)) for basis in np.eye(n)) for col in m.T])\n        col_dist_l2 = np.sum([min(np.sqrt(np.sum((col - basis)**2)) for basis in np.eye(n)) for col in m.T])\n        \n        # Row-based metrics\n        row_log = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_dist_l1 = np.sum([min(np.sum(np.abs(row - basis)) for basis in np.eye(n)) for row in m])\n        row_dist_l2 = np.sum([min(np.sqrt(np.sum((row - basis)**2)) for basis in np.eye(n)) for row in m])\n        \n        # Structural metrics\n        nonzeros = np.count_nonzero(m)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Combined metrics with optimized weights\n        log_terms = 1.6 * col_log + 0.9 * row_log\n        dist_terms = 0.8 * col_dist_l1 + 0.5 * row_dist_l1 + 0.6 * col_dist_l2 + 0.3 * row_dist_l2\n        max_terms = 1.0 * max_col + 0.6 * max_row\n        \n        return (nonzeros, log_terms, dist_terms, max_terms)\n    \n    # Systematic permutation variants\n    n = matrix.shape[0]\n    variants = [matrix]\n    if n > 1:\n        # Add cyclic permutations\n        perm1 = np.arange(n)\n        perm1[-1], perm1[-2] = perm1[-2], perm1[-1]\n        variants.append(matrix[perm1, :])\n        variants.append(matrix[:, perm1])\n    \n    # Add inverse/transpose variants\n    variants += [np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix).T]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8809411127149417,
      "additional_data": {
        "spearman_correlation": "0.880941",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 589,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 600,
    "parent_id": 338,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        total_ones = np.sum(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column completion priority\n        col_priority = np.sum(1/(col_sums + 0.1))  # Favors columns with few 1s\n        \n        # Row imbalance\n        row_imbalance = np.sum(np.abs(row_sums - np.mean(row_sums)))\n        \n        return (total_ones, -rank, col_priority, row_imbalance)\n    \n    h_original = simple_heuristic(matrix)\n    h_inverse = simple_heuristic(np.linalg.inv(matrix)) if np.linalg.det(matrix) != 0 else (float('inf'),)\n    h_transpose = simple_heuristic(matrix.T)\n    \n    # Combine metrics rather than just taking min\n    combined = tuple(np.minimum.reduce([h_original, h_inverse, h_transpose]))\n    return combined\n",
    "evaluation": {
      "fitness": -0.4825766031796825,
      "additional_data": {
        "spearman_correlation": "-0.482577",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 592,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 601,
    "parent_id": 134,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on most discriminative features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, \n                -(done_cols + done_rows), \n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                max_col + max_row,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827838302711529,
      "additional_data": {
        "spearman_correlation": "0.882784",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 549,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 602,
    "parent_id": 140,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        col_metrics = np.sum(np.log(col_sums + 1)) + np.sum(col_nonzero)\n        row_metrics = np.sum(np.log(row_sums + 1)) + np.sum(row_nonzero)\n        total_entries = np.sum(m)\n        \n        return (col_metrics, row_metrics, total_entries)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    combined = tuple(min(x, y, z) for x, y, z in zip(original, inverse, transpose))\n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 593,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 603,
    "parent_id": 534,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance from diagonal metric using numpy.abs\n        diag_dist = np.sum(np.abs(np.arange(n)[:, None] - np.arange(n)) * m)\n        \n        # Column progress metric with clipping to avoid log(0)\n        col_progress = np.sum(np.log(np.clip(col_sums, 1, None)))\n        \n        return diag_dist + col_progress\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix).astype(int),\n        np.linalg.inv(matrix).T.astype(int)\n    ]\n    \n    metrics = [compute_metric(v) for v in variants if np.all(np.isfinite(v))]\n    min_metric = min(metrics) if metrics else compute_metric(matrix)\n    \n    return (float(compute_metric(matrix)), float(min_metric))\n",
    "evaluation": {
      "fitness": 0.6031446487036075,
      "additional_data": {
        "spearman_correlation": "0.603145",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 594,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 604,
    "parent_id": 268,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        aug = np.hstack([matrix, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        weight2_cols = np.sum(col_sums == 2)\n        weight2_rows = np.sum(row_sums == 2)\n        log_cols = np.sum(np.log2(col_sums))\n        log_rows = np.sum(np.log2(row_sums))\n        col_imbalance = np.sum((col_sums - 1) ** 2)\n        row_imbalance = np.sum((row_sums - 1) ** 2)\n        col_range = np.max(col_sums) - np.min(col_sums)\n        row_range = np.max(row_sums) - np.min(row_sums)\n        return (nonzeros,\n                -done_cols - done_rows,\n                -(weight2_cols + weight2_rows),\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                col_range + row_range)\n    \n    inv = gf2_inv(matrix)\n    if inv is None:\n        candidates = [matrix, matrix.T]\n    else:\n        candidates = [matrix, inv, matrix.T, inv.T]\n    \n    feature_tuples = [get_features(cand) for cand in candidates]\n    return min(feature_tuples)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 521,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 605,
    "parent_id": 61,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        # Column statistics with logarithmic weighting\n        col_sums = np.sum(m, axis=0)\n        log_col_weights = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Row statistics\n        row_sums = np.sum(m, axis=1)\n        row_weight = np.sum(row_sums * (row_sums > 1))\n        \n        # Matrix properties\n        rank = np.linalg.matrix_rank(m)\n        density = np.count_nonzero(m) / m.size\n        rank_ratio = rank / m.shape[0]\n        \n        # Interaction terms\n        col_row_interaction = np.sum(col_sums * row_sums)\n        \n        # Weighted combination\n        return (0.4 * log_col_weights + \n                0.3 * row_weight + \n                0.2 * (1 - rank_ratio) + \n                0.1 * (1 - density) + \n                0.05 * col_row_interaction)\n    \n    original = evaluate(matrix)\n    inverse = evaluate(np.linalg.inv(matrix))\n    transpose = evaluate(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": -0.26843753518398544,
      "additional_data": {
        "spearman_correlation": "-0.268438",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 595,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 606,
    "parent_id": 121,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.append(inv_mat)\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        h_col = np.sum(np.log(col_weights))\n        \n        row_weights = np.sum(m, axis=1)\n        row_weights = np.maximum(row_weights, 1)\n        h_row = np.sum(np.log(row_weights))\n        \n        h_val = min(h_col, h_row)\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8725265272009427,
      "additional_data": {
        "spearman_correlation": "0.872527",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 598,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 607,
    "parent_id": 375,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with squared differences for stronger penalty.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Simplified sparsity term\n        sparsity = np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.88426700095711,
      "additional_data": {
        "spearman_correlation": "0.884267",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 599,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 608,
    "parent_id": 39,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    # Convert to binary matrix\n    A = (matrix.astype(int) % 2)\n    n = A.shape[0]\n    \n    # Helper function for GF(2) inverse\n    def gf2_inv(mat):\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return None\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    # Compute representations\n    rep0 = A\n    rep1 = gf2_inv(A)\n    if rep1 is None:\n        rep1 = A\n    rep2 = A.T\n    rep3 = rep1.T\n    \n    # Calculate heuristics for each representation\n    h_vals = []\n    for rep in [rep0, rep1, rep2, rep3]:\n        col_sums = np.sum(rep, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        h_vals.append(float(np.sum(np.log(col_sums))))\n    \n    return tuple(sorted(h_vals))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 515,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 609,
    "parent_id": 277,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = -np.sum(col_sums * np.log2(np.maximum(col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log2(np.maximum(row_sums, 1)))\n        return (np.sum(m), col_entropy + row_entropy, *sorted(col_sums, reverse=True))\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    best_heuristic = None\n    for variant in variants:\n        current = compute_metrics(variant)\n        if best_heuristic is None or current < best_heuristic:\n            best_heuristic = current\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.8730835274496052,
      "additional_data": {
        "spearman_correlation": "0.873084",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 601,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 610,
    "parent_id": 475,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic focusing on column/row structural properties and entropy.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Structural metrics\n        col_entropy = entropy(col_sums + 1)  # +1 to avoid log(0)\n        row_entropy = entropy(row_sums + 1)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Interaction terms\n        col_row_interaction = np.sum(np.abs(col_sums - row_sums))\n        diagonal_dominance = np.sum(np.diag(m))\n        \n        # Advanced metrics\n        col_nonbinary = np.sum((col_sums > 0) & (col_sums != 1))\n        row_nonbinary = np.sum((row_sums > 0) & (row_sums != 1))\n        col_clustering = np.sum(np.diff(np.sort(col_sums))**2)\n        row_clustering = np.sum(np.diff(np.sort(row_sums))**2)\n        \n        # Combined metrics\n        structural_complexity = (col_entropy + row_entropy + \n                               col_variance + row_variance + \n                               col_nonbinary + row_nonbinary)\n        \n        interaction_metrics = (col_row_interaction + \n                             diagonal_dominance + \n                             col_clustering + row_clustering)\n        \n        return (structural_complexity, interaction_metrics, \n               -np.sum(col_sums == 1), -np.sum(row_sums == 1),\n               np.sum(col_sums), np.sum(row_sums))\n    \n    variants = [\n        get_heuristic(matrix),\n        get_heuristic(np.linalg.inv(matrix)),\n        get_heuristic(matrix.T),\n        get_heuristic(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 600,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 611,
    "parent_id": 458,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        hamming = np.sum(m)\n        log_col = np.sum(np.log2(col_sums))\n        max_col = np.max(col_sums)\n        main_metric = log_col * hamming\n        return (main_metric, max_col)\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    ]\n    \n    candidates = [calculate_metrics(m) for m in matrices]\n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 542,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 612,
    "parent_id": 528,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column weight histogram: [weight1, weight2, weight3, weight4, weight>=5]\n        col_hist = [0, 0, 0, 0, 0]\n        for s in col_sums:\n            if s == 1:\n                col_hist[0] += 1\n            elif s == 2:\n                col_hist[1] += 1\n            elif s == 3:\n                col_hist[2] += 1\n            elif s == 4:\n                col_hist[3] += 1\n            else:  # s>=5\n                col_hist[4] += 1\n        \n        # Row weight histogram: [weight1, weight2, weight3, weight4, weight>=5]\n        row_hist = [0, 0, 0, 0, 0]\n        for s in row_sums:\n            if s == 1:\n                row_hist[0] += 1\n            elif s == 2:\n                row_hist[1] += 1\n            elif s == 3:\n                row_hist[2] += 1\n            elif s == 4:\n                row_hist[3] += 1\n            else:  # s>=5\n                row_hist[4] += 1\n        \n        extra_ones = nonzeros - n\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_weight_sq = np.sum(col_sums * col_sums)\n        row_weight_sq = np.sum(row_sums * row_sums)\n        \n        return (extra_ones, \n                -col_hist[0], col_hist[1], col_hist[2], col_hist[3], col_hist[4],\n                -row_hist[0], row_hist[1], row_hist[2], row_hist[3], row_hist[4],\n                log_cols, log_rows, \n                max_col, max_row,\n                col_weight_sq, row_weight_sq)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix).astype(int) % 2,\n        matrix.T,\n        np.linalg.inv(matrix).T.astype(int) % 2\n    ]\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.7108875378365371,
      "additional_data": {
        "spearman_correlation": "0.710888",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 547,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 613,
    "parent_id": 450,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        \n        # Column pair interactions\n        col_pairs = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                and_sum = np.sum(m[:,i] & m[:,j])\n                xor_sum = np.sum(m[:,i] ^ m[:,j])\n                col_pairs += min(and_sum, xor_sum)\n        \n        # Row pair interactions\n        row_pairs = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                and_sum = np.sum(m[i,:] & m[j,:])\n                xor_sum = np.sum(m[i,:] ^ m[j,:])\n                row_pairs += min(and_sum, xor_sum)\n        \n        # Column completion metrics\n        col_completion = np.sum(np.abs(col_sums - 1))\n        \n        # Block patterns (2x2 submatrices)\n        block_score = 0\n        for i in range(n-1):\n            for j in range(n-1):\n                block = m[i:i+2, j:j+2]\n                if np.sum(block) in {1, 3}:\n                    block_score += 1\n        \n        return (col_pairs, row_pairs, -col_completion, -block_score)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 603,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 614,
    "parent_id": 11,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering matrix variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_heuristic = np.sum(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_heuristic = np.sum(np.log(row_sums))\n        \n        return (float(col_heuristic), float(row_heuristic))\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inverse = calculate_heuristic(np.linalg.inv(matrix.astype(float)) if np.linalg.det(matrix) != 0 else (float('inf'), float('inf'))\n    \n    return min(original, transpose, inverse)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 606,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 615,
    "parent_id": 214,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic combining multiple matrix properties.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        # Basic properties\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column and row metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Rank consideration\n        rank = np.linalg.matrix_rank(m)\n        \n        # Distance from permutation matrix\n        perm_distance = np.sum(np.abs(m - np.eye(n)))\n        \n        # Hamming weights\n        col_hamming = np.sum(col_sums != 1)\n        row_hamming = np.sum(row_sums != 1)\n        \n        # Sorted column sums for tie-breaking\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, rank, col_imbalance + row_imbalance, \n                perm_distance, col_hamming + row_hamming, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8275951863510804,
      "additional_data": {
        "spearman_correlation": "0.827595",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 604,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 616,
    "parent_id": 203,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    eps = 1e-10\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + eps))\n        log_sum_row = np.sum(np.log(row_sums + eps))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        diag_ones = np.sum(np.diag(m))\n        t = (log_sum_col, log_sum_row, total_ones, -basis_cols, -basis_rows, -diag_ones)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8734495015576936,
      "additional_data": {
        "spearman_correlation": "0.873450",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 605,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 617,
    "parent_id": 246,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Focus on column completion and log sums\n        col_log = sum(log2(max(s, 1)) for s in col_sums)\n        col_complete = sum(s <= 1 for s in col_sums)\n        \n        # Simple row metrics\n        row_log = sum(log2(max(s, 1)) for s in row_sums)\n        row_complete = sum(s <= 1 for s in row_sums)\n        \n        # Weighted combination favoring column completion\n        return (0.4 * col_log + \n                0.4 * row_log - \n                0.1 * col_complete - \n                0.1 * row_complete)\n    \n    h_original = evaluate(matrix)\n    h_transpose = evaluate(matrix.T)\n    \n    return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8010052483232938,
      "additional_data": {
        "spearman_correlation": "0.801005",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 608,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 618,
    "parent_id": 143,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    \n    # Convert to binary integer matrix mod2\n    def to_binary(m):\n        m_int = np.rint(m).astype(int) % 2\n        return m_int\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_sum = np.sum(m)\n        extra_ones = total_sum - n\n        return (extra_ones, log_col, log_row)\n    \n    # Convert the original matrix to binary\n    matrix_bin = to_binary(matrix)\n    \n    # Compute the variants: original, inverse, transpose, inverse of transpose\n    try:\n        inv_matrix = np.linalg.inv(matrix_bin.astype(float))\n    except np.linalg.LinAlgError:\n        inv_matrix = np.eye(n)\n    inv_matrix_bin = to_binary(inv_matrix)\n    \n    trans_matrix = matrix_bin.T\n    \n    try:\n        inv_trans_matrix = np.linalg.inv(trans_matrix.astype(float))\n    except np.linalg.LinAlgError:\n        inv_trans_matrix = np.eye(n)\n    inv_trans_matrix_bin = to_binary(inv_trans_matrix)\n    \n    variants = [\n        matrix_bin,\n        inv_matrix_bin,\n        trans_matrix,\n        inv_trans_matrix_bin\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 506,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 619,
    "parent_id": 417,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def column_distance(m):\n        n = m.shape[0]\n        basis = np.eye(n)\n        distances = []\n        for col in m.T:\n            min_dist = min(np.sum(np.abs(col - basis_col)) for basis_col in basis.T)\n            distances.append(min_dist)\n        return np.array(distances)\n    \n    def analyze_variant(m):\n        n = m.shape[0]\n        col_dists = column_distance(m)\n        weighted_cols = np.sum(np.exp(-col_dists))\n        \n        _, _, u = lu(m)\n        rank = np.linalg.matrix_rank(u)\n        rank_factor = (n - rank) / n\n        \n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_complexity = np.sum(1 / (1 + np.exp(-(col_nonzeros - 1))))\n        \n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_complexity = np.sum(1 / (1 + np.exp(-(row_nonzeros - 1))))\n        \n        return (weighted_cols, rank_factor, col_complexity, row_complexity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    # Consider all column permutations for the original matrix\n    n = matrix.shape[1]\n    if n <= 4:  # Only permute for small matrices\n        from itertools import permutations\n        for perm in permutations(range(n)):\n            variants.append(matrix[:, list(perm)])\n    \n    variant_scores = [analyze_variant(v) for v in variants]\n    combined_score = tuple(np.min(variant_scores, axis=0))\n    return combined_score\n",
    "evaluation": {
      "fitness": -0.7892460146330693,
      "additional_data": {
        "spearman_correlation": "-0.789246",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 607,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 620,
    "parent_id": 349,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with optimized weights.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Optimized column completion weights\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, \n                                      np.where(col_nonzeros == 2, 1.2, np.log1p(col_nonzeros))))\n        \n        # Absolute column distribution penalty\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1)\n        \n        # Adjusted row nonzeros term\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_penalty = 0.05 * np.sum(row_nonzeros)\n        \n        # Small sparsity term\n        sparsity = 0.01 * np.sum(m)\n        \n        return (col_completion, col_dist, row_penalty, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 610,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 621,
    "parent_id": 32,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Improved spread metric considering all pairwise differences\n        row_diff = np.sum(np.abs(np.diff(m, axis=0, n=m.shape[0]-1)))\n        col_diff = np.sum(np.abs(np.diff(m, axis=1, n=m.shape[1]-1)))\n        spread = row_diff + col_diff\n        \n        # Additional metric for basis vector closeness\n        basis_closeness = np.sum(np.minimum(col_sums, 1))\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread, -basis_closeness)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8724236680139758,
      "additional_data": {
        "spearman_correlation": "0.872424",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 3,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 609,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 622,
    "parent_id": 519,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums and inverse/transpose.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = len(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column and row imbalance metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Consider sorted columns for pattern matching\n        sorted_cols = sorted(col_sums)\n        col_pattern = sum(abs(sorted_cols[i] - sorted_cols[i-1]) for i in range(1, n))\n        \n        return (nonzeros, col_imbalance + row_imbalance, col_pattern)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 614,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 623,
    "parent_id": 29,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_weights = np.sum(matrix, axis=0)\n    row_weights = np.sum(matrix, axis=1)\n    col_correlations = np.sum(matrix.T @ matrix, axis=1)\n    row_correlations = np.sum(matrix @ matrix.T, axis=1)\n    \n    col_metrics = np.log(col_weights + 1) * np.log(col_correlations + 1)\n    row_metrics = np.log(row_weights + 1) * np.log(row_correlations + 1)\n    \n    inv_matrix = np.linalg.inv(matrix) % 2\n    inv_col_weights = np.sum(inv_matrix, axis=0)\n    inv_row_weights = np.sum(inv_matrix, axis=1)\n    \n    combined_col = tuple(sorted(col_metrics)) + tuple(sorted(inv_col_weights))\n    combined_row = tuple(sorted(row_metrics)) + tuple(sorted(inv_row_weights))\n    \n    return combined_col + combined_row\n",
    "evaluation": {
      "fitness": 0.7116524912911076,
      "additional_data": {
        "spearman_correlation": "0.711652",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 612,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 624,
    "parent_id": 558,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = aug[r] ^ aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = int(np.sum(col_sums))\n        col_devs = np.abs(col_sums - 1)\n        row_devs = np.abs(row_sums - 1)\n        total_dev = np.sum(col_devs) + np.sum(row_devs)\n        col_log_sum = np.sum(np.log(col_sums))\n        row_log_sum = np.sum(np.log(row_sums))\n        gram_col = np.dot(m.T, m)\n        col_overlaps = np.sum(gram_col) - np.sum(np.diag(gram_col))\n        gram_row = np.dot(m, m.T)\n        row_overlaps = np.sum(gram_row) - np.sum(np.diag(gram_row))\n        sorted_col_devs = sorted(col_devs, reverse=True)\n        sorted_row_devs = sorted(row_devs, reverse=True)\n        col_row_dot = np.dot(col_devs, row_devs)\n        max_col_row_dev = max(col_devs * row_devs)\n        features = [nonzeros, total_dev, col_log_sum, row_log_sum, col_overlaps, row_overlaps, col_row_dot, max_col_row_dev]\n        features.extend(sorted_col_devs)\n        features.extend(sorted_row_devs)\n        return tuple(features)\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        h_inv = get_heuristic(inv_matrix)\n        return min(h_orig, h_inv, h_trans)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.8688193634166623,
      "additional_data": {
        "spearman_correlation": "0.868819",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 611,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 625,
    "parent_id": 207,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def col_based_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        non_zero_cols = np.count_nonzero(col_sums)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        return (non_zero_cols, -log_cols)\n    \n    def row_based_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        non_zero_rows = np.count_nonzero(row_sums)\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        return (non_zero_rows, log_rows)\n    \n    original_col = col_based_heuristic(matrix)\n    inverse_col = col_based_heuristic(np.linalg.inv(matrix) % 2)\n    transpose_col = col_based_heuristic(matrix.T)\n    \n    original_row = row_based_heuristic(matrix)\n    inverse_row = row_based_heuristic(np.linalg.inv(matrix) % 2)\n    transpose_row = row_based_heuristic(matrix.T)\n    \n    best_col = min(original_col, inverse_col, transpose_col)\n    best_row = min(original_row, inverse_row, transpose_row)\n    \n    return best_col + best_row\n",
    "evaluation": {
      "fitness": -0.7621624548565373,
      "additional_data": {
        "spearman_correlation": "-0.762162",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 615,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 626,
    "parent_id": 525,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + 1e-10))\n        log_sum_row = np.sum(np.log(row_sums + 1e-10))\n        total_ones = np.sum(col_sums)\n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        rows_two = np.sum(row_sums == 2)\n        cols_three = np.sum(col_sums == 3)\n        rows_three = np.sum(row_sums == 3)\n        t = (0.8*log_sum_col, 0.2*log_sum_row, total_ones, cols_two, rows_two, cols_three, rows_three, basis_cols, basis_rows)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8741713890827777,
      "additional_data": {
        "spearman_correlation": "0.874171",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 613,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 627,
    "parent_id": 419,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified column-focused heuristic.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        total_weight = np.sum(col_sums)\n        incomplete_cols = np.sum(col_sums != 1)\n        \n        # Column interaction measure (sum of dot products between columns)\n        interaction = np.sum((m.T @ m) - np.diag(col_sums))\n        \n        return (total_weight, incomplete_cols, interaction)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": -0.22287485285523725,
      "additional_data": {
        "spearman_correlation": "-0.222875",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 616,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 628,
    "parent_id": 218,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.sum([np.any(col == np.eye(n)[i] for i, col in enumerate(m.T)])\n        basis_rows = np.sum([np.any(row == np.eye(n)[i] for i, row in enumerate(m)])\n        \n        # Column/row quality metrics\n        col_quality = np.sum([1/(np.sum(col != np.eye(n)[:,i]) + 0.1) for i, col in enumerate(m.T)])\n        row_quality = np.sum([1/(np.sum(row != np.eye(n)[i]) + 0.1) for i, row in enumerate(m)])\n        \n        # Dependency metrics\n        col_deps = np.sum([np.sum(np.logical_and(col1, col2)) for col1 in m.T for col2 in m.T if not np.array_equal(col1, col2)])\n        row_deps = np.sum([np.sum(np.logical_and(row1, row2)) for row1 in m for row2 in m if not np.array_equal(row1, row2)])\n        \n        # Structural metrics\n        col_entropy = np.sum([-p*np.log2(p+1e-10) for col in m.T for p in [np.mean(col)]])\n        row_entropy = np.sum([-p*np.log2(p+1e-10) for row in m for p in [np.mean(row)]])\n        \n        # Distance metrics\n        col_dist = np.sum([np.sum(np.abs(col - np.eye(n)[:,i])) for i, col in enumerate(m.T)])\n        row_dist = np.sum([np.sum(np.abs(row - np.eye(n)[i])) for i, row in enumerate(m)])\n        \n        return (nonzeros, \n                -basis_cols - basis_rows,\n                col_quality + row_quality,\n                col_deps + row_deps,\n                col_entropy + row_entropy,\n                col_dist + row_dist,\n                *sorted(col_sums),\n                *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "closing parenthesis ']' does not match opening parenthesis '(' (<string>, line 12)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 617,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 629,
    "parent_id": 444,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        \n        # Primary metric: column completion (emphasized more)\n        col_completion = np.sum(np.log2(col_weights + 1)) * 2\n        \n        # Secondary metric: row completion\n        row_completion = np.sum(np.log2(row_weights + 1))\n        \n        # Matrix rank metric\n        rank = np.linalg.matrix_rank(m)\n        \n        # Spread metric (variance of non-zero positions)\n        row_spread = np.var(np.where(m != 0)[0])\n        col_spread = np.var(np.where(m != 0)[1])\n        spread_metric = (row_spread + col_spread) / 2\n        \n        return (col_completion + row_completion, \n                rank, \n                spread_metric)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    heuristics = [get_heuristic(v) for v in variants]\n    return min(heuristics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 619,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 630,
    "parent_id": 128,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_features(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row statistics\n        col_stats = (np.mean(col_sums), np.std(col_sums), np.max(col_sums), np.min(col_sums))\n        row_stats = (np.mean(row_sums), np.std(row_sums), np.max(row_sums), np.min(row_sums))\n        \n        # Pairwise column/row interactions\n        col_hamming = np.sum([np.sum(m[:,i] != m[:,j]) for i in range(n) for j in range(i+1, n)])\n        row_hamming = np.sum([np.sum(m[i,:] != m[j,:]) for i in range(n) for j in range(i+1, n)])\n        \n        # Linear algebra features\n        rank = np.linalg.matrix_rank(m)\n        det = abs(np.linalg.det(m)) if n == m.shape[1] else 1\n        _, s, _ = np.linalg.svd(m)\n        sv_entropy = -np.sum(s * np.log(s + 1e-10))\n        \n        # Weighted combination of features\n        base_cost = nonzeros / (n*n)\n        col_cost = np.sum(np.log(col_sums + 1)) / n\n        row_cost = np.sum(np.log(row_sums + 1)) / n\n        interaction_cost = (col_hamming + row_hamming) / (n*n*(n-1))\n        rank_cost = (n - rank) / n\n        \n        # Combined score with learned weights\n        score = (10 * base_cost + \n                 5 * col_cost + \n                 5 * row_cost + \n                 3 * interaction_cost + \n                 8 * rank_cost + \n                 2 * sv_entropy)\n        \n        return score\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(matrix_features(v) for v in variants if np.all(np.isfinite(v)))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 621,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 631,
    "parent_id": 549,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with row sums and weighted log terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        log_col_sums = 0.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = 0.3 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        done_cols = np.sum(col_sums == 1)\n        return (nonzeros, log_col_sums + log_row_sums, -done_cols)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    except:\n        h_inverse = (float('inf'), float('inf'), float('inf'))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8705172160939733,
      "additional_data": {
        "spearman_correlation": "0.870517",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 624,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 632,
    "parent_id": 511,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def is_permutation(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        return np.all(row_sums == 1) and np.all(col_sums == 1)\n\n    def gf2_rank(m):\n        mat = m.copy().astype(int)\n        n_rows, n_cols = mat.shape\n        rank = 0\n        pivot_row = 0\n        for col in range(n_cols):\n            if pivot_row >= n_rows:\n                break\n            pivot = pivot_row\n            while pivot < n_rows and mat[pivot, col] == 0:\n                pivot += 1\n            if pivot == n_rows:\n                continue\n            if pivot != pivot_row:\n                mat[[pivot, pivot_row]] = mat[[pivot_row, pivot]]\n            for r in range(pivot_row + 1, n_rows):\n                if mat[r, col] == 1:\n                    mat[r] = (mat[r] + mat[pivot_row]) % 2\n            pivot_row += 1\n            rank += 1\n        return rank\n\n    def inverse_mod2(m):\n        n = m.shape[0]\n        aug = np.hstack((m, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = col\n            while pivot < n and aug[pivot, col] == 0:\n                pivot += 1\n            if pivot == n:\n                raise np.linalg.LinAlgError(\"Singular matrix\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    rank_orig = gf2_rank(matrix)\n    transformations = [matrix, matrix.T]\n    if rank_orig == n:\n        try:\n            inv = inverse_mod2(matrix)\n            transformations.append(inv)\n            transformations.append(inv.T)\n        except:\n            pass\n\n    best_heuristic = float('inf')\n    for m in transformations:\n        if is_permutation(m):\n            return 0.0\n        r = gf2_rank(m)\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        log_col_sums = np.sum(np.log2(col_sums + 1))\n        max_col = np.max(col_sums)\n        num_col_weight1 = np.sum(col_sums == 1)\n        h_val = 0.4 * total_ones + 0.2 * (n - r) + 0.1 * log_col_sums + 0.1 * max_col + 0.2 * (n - num_col_weight1)\n        if h_val < best_heuristic:\n            best_heuristic = h_val\n\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.8619185460995276,
      "additional_data": {
        "spearman_correlation": "0.861919",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 540,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 633,
    "parent_id": 530,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering matrix structure and multiple transformations.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        if np.linalg.matrix_rank(matrix) < n:\n            raise ValueError(\"Matrix not invertible\")\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # More sophisticated metrics\n        col_entropy = -np.sum(col_sums * np.log(np.where(col_sums > 0, col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log(np.where(row_sums > 0, row_sums, 1)))\n        \n        # Block structure detection\n        block_score = 0\n        n = m.shape[0]\n        for i in range(n):\n            for j in range(n):\n                if m[i,j] == 1:\n                    block_score += np.sum(m[i:i+2,j:j+2]) if i < n-1 and j < n-1 else 0\n        \n        # Diagonal dominance\n        diag_dominance = np.sum(np.diag(m)) - (np.sum(m) - np.sum(np.diag(m)))\n        \n        return (nonzeros,\n                -rank,\n                col_entropy + row_entropy,\n                -block_score,\n                diag_dominance,\n                np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2))\n    \n    def get_min_heuristic(m):\n        metrics = matrix_metrics(m)\n        try:\n            inv_metrics = matrix_metrics(gf2_inv(m))\n            inv_trans_metrics = matrix_metrics(gf2_inv(m).T)\n            return min(metrics, inv_metrics, inv_trans_metrics, matrix_metrics(m.T))\n        except:\n            return min(metrics, matrix_metrics(m.T))\n    \n    return get_min_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8723591509204766,
      "additional_data": {
        "spearman_correlation": "0.872359",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 622,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 634,
    "parent_id": 297,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        log_cols = 2.0 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (nonzeros, incorrect_total, logs, imbalance, max_col, max_row)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = get_heuristic(inv_matrix)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8716490668756194,
      "additional_data": {
        "spearman_correlation": "0.871649",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 625,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 635,
    "parent_id": 511,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column features\n        col_nonzero = np.count_nonzero(col_sums)\n        col_mean = np.mean(col_sums)\n        col_var = np.var(col_sums)\n        col_log = np.sum(np.log2(col_sums + 1))\n        \n        # Row features\n        row_nonzero = np.count_nonzero(row_sums)\n        row_mean = np.mean(row_sums)\n        row_var = np.var(row_sums)\n        \n        # Interaction features\n        col_row_ratio = col_mean / (row_mean + 1e-6)\n        \n        features = (\n            0.4 * np.sum(col_sums) +\n            0.3 * rank +\n            0.1 * col_var +\n            0.1 * row_var +\n            0.05 * col_log +\n            0.05 * col_row_ratio\n        )\n        return features\n    \n    transformations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    best_heuristic = min(compute_features(m) for m in transformations)\n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.8257967783754804,
      "additional_data": {
        "spearman_correlation": "0.825797",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 626,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 636,
    "parent_id": 205,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        cols_two = np.sum(col_sums == 2)\n        rows_two = np.sum(row_sums == 2)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (nonzeros, \n                -done_cols, -done_rows,\n                -cols_two, -rows_two,\n                log_cols, log_rows,\n                col_imbalance, row_imbalance,\n                max_col, max_row)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix) if inv_matrix is not None else h_original\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T) if inv_matrix is not None else h_transpose\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 27)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 576,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 637,
    "parent_id": 346,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weighted imbalance and additional row metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        # Weight column imbalance more heavily (2:1 ratio)\n        col_imbalance = 2 * np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        # Add product of column sums to favor sparse columns\n        col_product = np.prod(col_sums + 1)  # +1 to avoid 0\n        return (nonzeros, cols_done + rows_done, col_imbalance + row_imbalance, max_col, min_col, col_product)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8519992047125419,
      "additional_data": {
        "spearman_correlation": "0.851999",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 629,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 638,
    "parent_id": 492,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic using matrix rank, linear dependencies, and weighted metrics.\"\"\"\n    import numpy as np\n    \n    def matrix_rank(m):\n        return np.linalg.matrix_rank(m)\n    \n    def linear_dependencies(m):\n        _, pivots = np.linalg.qr(m)\n        return m.shape[1] - len(pivots)\n    \n    def block_structure_score(m):\n        n = m.shape[0]\n        if n <= 1:\n            return 0\n        block_score = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                if np.array_equal(m[i] & m[j], np.zeros(n)):\n                    block_score += 1\n        return block_score\n    \n    def calculate_heuristics(m):\n        rank = matrix_rank(m)\n        deps = linear_dependencies(m)\n        blocks = block_structure_score(m)\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        \n        # Weight metrics based on matrix properties\n        weight = 1 + (rank / m.shape[0])\n        complexity = (log_col + log_row) * weight\n        structure = (blocks - deps) / m.shape[0]\n        \n        return (complexity, sum_total, max_col, -structure)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 627,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 639,
    "parent_id": 194,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column features\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        col_pairs = sum((col_sums[i] + col_sums[j] - 2*np.sum(m[:,i] & m[:,j])) \n                       for i in range(n) for j in range(i+1, n))\n        col_hamming = sum(np.sum(m[:,i] ^ m[:,j]) for i in range(n) for j in range(i+1, n))\n        \n        # Row features\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        row_pairs = sum((row_sums[i] + row_sums[j] - 2*np.sum(m[i,:] & m[j,:])) \n                   for i in range(n) for j in range(i+1, n))\n        row_hamming = sum(np.sum(m[i,:] ^ m[j,:]) for i in range(n) for j in range(i+1, n))\n        \n        # Combined features\n        diagonal = np.sum(np.diag(m))\n        off_diagonal = nonzeros - diagonal\n        rank = np.linalg.matrix_rank(m)\n        triangularity = (np.sum(np.triu(m)) - np.sum(np.tril(m)))\n        \n        # Tuple ordered by importance\n        return (nonzeros, \n                -rank,\n                col_pairs + row_pairs,\n                col_hamming + row_hamming,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                off_diagonal,\n                triangularity,\n                *sorted(col_sums, reverse=True),\n                *sorted(row_sums, reverse=True))\n    \n    # Generate all equivalent matrices (inverse, transpose, permutations)\n    variants = [matrix, np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix).T]\n    for _ in range(3):  # Try a few random column permutations\n        perm = np.random.permutation(matrix.shape[1])\n        variants.append(matrix[:, perm])\n        variants.append(np.linalg.inv(matrix)[:, perm])\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 628,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 640,
    "parent_id": 80,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with absolute deviations and row information.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # L1 norm instead of L2\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance, row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823310788347797,
      "additional_data": {
        "spearman_correlation": "0.882331",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 631,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 641,
    "parent_id": 32,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Weighted spread - higher rows/columns get more weight\n        rows, cols = m.shape\n        row_weights = np.arange(rows, 0, -1)\n        col_weights = np.arange(cols, 0, -1)\n        row_diff = np.sum(np.abs(np.diff(m, axis=0)) * row_weights[:-1, np.newaxis])\n        col_diff = np.sum(np.abs(np.diff(m, axis=1)) * col_weights[np.newaxis, :-1])\n        spread = row_diff + col_diff\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8725020206785339,
      "additional_data": {
        "spearman_correlation": "0.872502",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 630,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 642,
    "parent_id": 124,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with adjusted diagonal weight and non-zero count.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.sum(np.diag(m))\n        non_zero = np.count_nonzero(m)\n        col_sums = np.maximum(col_sums, 1e-5)\n        row_sums = np.maximum(row_sums, 1e-5)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)\n        \n        return (0.5 * (col_log + row_log) + 0.4 * (col_linear + row_linear) + \n                0.05 * sparsity - 0.05 * diag_sum + 0.01 * non_zero)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8694474537334935,
      "additional_data": {
        "spearman_correlation": "0.869447",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 632,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 643,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with natural logs and squared imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827944247801224,
      "additional_data": {
        "spearman_correlation": "0.882794",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 634,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 644,
    "parent_id": 493,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Max and min sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Sorted sums differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.sum(np.diff(sorted_cols))\n        row_diffs = np.sum(np.diff(sorted_rows))\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        \n        # Count matching columns/rows\n        unique_cols, col_counts = np.unique(m, axis=1, return_counts=True)\n        unique_rows, row_counts = np.unique(m, axis=0, return_counts=True)\n        matching_cols = np.sum(col_counts - 1)\n        matching_rows = np.sum(row_counts - 1)\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                max_col + max_row,\n                col_diffs + row_diffs,\n                col_interactions,\n                matching_cols + matching_rows,\n                np.sum(sorted_cols[-2:]),\n                np.sum(sorted_rows[-2:]))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return (h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7840305123744392,
      "additional_data": {
        "spearman_correlation": "0.784031",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 633,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 645,
    "parent_id": 357,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        log_col_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sum = np.sum(np.log2(np.maximum(row_sums, 1)))\n        num_basis_cols = np.sum(col_sums == 1)\n        num_weight2_cols = np.sum(col_sums == 2)\n        num_basis_rows = np.sum(row_sums == 1)\n        num_weight2_rows = np.sum(row_sums == 2)\n        good_cols = num_basis_cols + 0.5 * num_weight2_cols\n        good_rows = num_basis_rows + 0.5 * num_weight2_rows\n        return (nonzeros, log_col_sum + log_row_sum, -good_cols, -good_rows)\n    \n    m1 = matrix\n    try:\n        inv_real = np.linalg.inv(m1.astype(float))\n        m2 = (np.round(inv_real) % 2).astype(int)\n    except:\n        m2 = m1\n    m3 = m1.T\n    try:\n        inv_real_t = np.linalg.inv(m3.astype(float))\n        m4 = (np.round(inv_real_t) % 2).astype(int)\n    except:\n        m4 = m3\n    \n    h_original = get_heuristic(m1)\n    h_inverse = get_heuristic(m2)\n    h_transpose = get_heuristic(m3)\n    h_inverse_transpose = get_heuristic(m4)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.742180510379895,
      "additional_data": {
        "spearman_correlation": "0.742181",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 635,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 646,
    "parent_id": 636,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, -done_cols, log_cols, col_imbalance)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix) if inv_matrix is not None else h_original\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T) if inv_matrix is not None else h_transpose\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8712984044714928,
      "additional_data": {
        "spearman_correlation": "0.871298",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 637,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 647,
    "parent_id": 201,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row interaction terms\n        col_interactions = np.sum(m.T @ m) - n\n        row_interactions = np.sum(m @ m.T) - n\n        \n        # Block pattern detection\n        block_score = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j]:\n                    neighbors = 0\n                    if i > 0: neighbors += m[i-1,j]\n                    if i < n-1: neighbors += m[i+1,j]\n                    if j > 0: neighbors += m[i,j-1]\n                    if j < n-1: neighbors += m[i,j+1]\n                    block_score += neighbors\n        \n        # Higher-order statistics\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Distance from permutation matrices\n        perm_distance = min(np.sum(np.abs(m - p)) for p in itertools.permutations(np.eye(n)))\n        \n        return (nonzeros, \n                col_interactions + row_interactions,\n                block_score,\n                col_variance + row_variance,\n                perm_distance,\n                *sorted(col_sums),\n                *sorted(row_sums))\n    \n    # Consider all matrix variants that are equivalent under synthesis\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix[::-1],  # row reversed\n        matrix[:, ::-1],  # column reversed\n        np.rot90(matrix)  # rotated\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'itertools' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 636,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 648,
    "parent_id": 131,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional log terms and diagonal consideration.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        log_cols2 = np.sum(np.log(np.maximum(col_sums + 1, 1)))\n        log_rows2 = np.sum(np.log(np.maximum(row_sums + 1, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        diag_sum = np.sum(np.diag(m))\n        log_product = log_cols * log_rows\n        log_product2 = log_cols2 * log_rows2\n        correct_total = correct_cols + correct_rows\n        return (nonzeros, -correct_total, log_product, log_product2,\n                col_imbalance + row_imbalance, max_col + max_row, diag_sum,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.881760037829341,
      "additional_data": {
        "spearman_correlation": "0.881760",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 638,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 649,
    "parent_id": 343,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with squared differences and overlap term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with refined log weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 0.1))\n        \n        # Column distribution using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        \n        # Row distribution term with squared differences\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2\n        \n        # Overlap term - counts shared row positions between columns\n        overlap = np.sum((m.T @ m) * (1 - np.eye(n)))\n        \n        return (col_completion, col_dist, row_dist, overlap)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 639,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 650,
    "parent_id": 516,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n_outer = matrix.shape[0]\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.sum(m)\n        extra_ones = nonzeros - n\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        almost_cols = np.sum(col_sums == 2)\n        almost_rows = np.sum(row_sums == 2)\n        almost_total = almost_cols + almost_rows\n        \n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        sum_sq = col_sq + row_sq\n        \n        return (extra_ones, incorrect_total, almost_total, logs, imbalance, max_sum, sum_sq)\n    \n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:\n        h_original = get_heuristic(matrix)\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_transpose)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.857998319708034,
      "additional_data": {
        "spearman_correlation": "0.857998",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 602,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 651,
    "parent_id": 495,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def distance_from_identity(m):\n        identity = np.eye(m.shape[0], dtype=int)\n        diff = np.abs(m - identity)\n        col_dist = np.sum(diff, axis=0)\n        row_dist = np.sum(diff, axis=1)\n        \n        col_priority = np.sum(np.where(col_dist == 1, 0.5, col_dist))\n        row_priority = np.sum(np.where(row_dist == 1, 0.5, row_dist))\n        \n        return col_priority + row_priority\n    \n    def column_row_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(col_sums != 1)\n        row_nonzero = np.count_nonzero(row_sums != 1)\n        return col_nonzero + row_nonzero\n    \n    def calculate_metrics(m):\n        dist_id = distance_from_identity(m)\n        cr_metrics = column_row_metrics(m)\n        return dist_id + cr_metrics\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    return min(original, transposed, inverted)\n",
    "evaluation": {
      "fitness": 0.4047768514848313,
      "additional_data": {
        "spearman_correlation": "0.404777",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 642,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 652,
    "parent_id": 92,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_dependency_metrics(m):\n        n = m.shape[0]\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        \n        # Column interaction metrics\n        interaction = np.zeros(n)\n        for i in range(n):\n            for j in range(i+1, n):\n                interaction[i] += np.sum(m[:,i] & m[:,j])\n                interaction[j] += np.sum(m[:,i] & m[:,j])\n        \n        # Triangularity measure\n        upper = np.triu(m, k=1)\n        lower = np.tril(m, k=-1)\n        triangularity = min(np.sum(upper), np.sum(lower))\n        \n        # Column completion priority\n        completion = np.sum(np.exp(-np.abs(col_weights - 1)))\n        \n        main_metric = np.sum(col_weights) + np.sum(interaction) - completion\n        secondary_metric = (triangularity, np.max(col_weights), np.sum(row_weights))\n        return main_metric, secondary_metric\n    \n    original = column_dependency_metrics(matrix)\n    transposed = column_dependency_metrics(matrix.T)\n    inverted = column_dependency_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_triangularity = min(original[1][0], transposed[1][0], inverted[1][0])\n    min_max_col = min(original[1][1], transposed[1][1], inverted[1][1])\n    min_row_sum = min(original[1][2], transposed[1][2], inverted[1][2])\n    \n    return (min_main, (min_triangularity, min_max_col, min_row_sum))\n",
    "evaluation": {
      "fitness": 0.6939699486241347,
      "additional_data": {
        "spearman_correlation": "0.693970",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 640,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 653,
    "parent_id": 102,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic weighting and entropy measures.\"\"\"\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Logarithmic column weighting\n        log_col_weights = sum(log2(c + 1) for c in col_sums)\n        \n        # Column entropy measure\n        col_entropy = 0\n        for col in m.T:\n            p = np.mean(col)\n            if 0 < p < 1:\n                col_entropy += -p*log2(p) - (1-p)*log2(1-p)\n        \n        # Matrix norm measures\n        frob_norm = np.linalg.norm(m, 'fro')\n        spec_norm = np.linalg.norm(m, 2)\n        \n        # Column/row interaction\n        col_row_interaction = np.sum(np.abs(m @ m.T - np.eye(m.shape[0])))\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, log_col_weights, col_entropy, \n                frob_norm, spec_norm, col_row_interaction, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 643,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 654,
    "parent_id": 20,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Minimum of logarithms of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8658840755208309,
      "additional_data": {
        "spearman_correlation": "0.865884",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 646,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 655,
    "parent_id": 390,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row metrics with entropy and interaction terms.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column and row completion with entropy weighting\n        col_completion = entropy(col_nonzeros + 1)\n        row_completion = entropy(row_nonzeros + 1)\n        \n        # Enhanced column/row interaction terms\n        col_interaction = np.sum(np.abs(np.dot(m.T, m) - np.eye(n)))\n        row_interaction = np.sum(np.abs(np.dot(m, m.T) - np.eye(n)))\n        \n        # Entropy-based sparsity measurement\n        sparsity = entropy(m.flatten() + 1)\n        \n        # Cross term measuring column-row alignment\n        cross_term = np.sum(np.abs(np.sum(m, axis=0) - np.sum(m, axis=1)))\n        \n        return sum((col_completion, row_completion, col_interaction, \n                row_interaction, sparsity, cross_term))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.12703171088950885,
      "additional_data": {
        "spearman_correlation": "0.127032",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 648,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 656,
    "parent_id": 439,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Primary metrics\n        total_ones = np.sum(col_sums)\n        col_entropy = np.sum(col_sums * np.log2(np.maximum(col_sums, 1)))\n        row_entropy = np.sum(row_sums * np.log2(np.maximum(row_sums, 1)))\n        \n        # Secondary metrics\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        bandedness = np.sum(np.abs(m - np.roll(m, 1, axis=0)))\n        \n        # Combined metrics with optimized weights\n        h1 = 0.45 * total_ones + 0.35 * (col_entropy + row_entropy)\n        h2 = 0.15 * (col_variance + row_variance) + 0.05 * bandedness\n        \n        # Pattern detection\n        diag_ones = np.sum(np.diag(m))\n        anti_diag_ones = np.sum(np.diag(np.fliplr(m)))\n        pattern_score = 0.2 * (diag_ones + anti_diag_ones)\n        \n        return (h1 + h2 - pattern_score, total_ones, col_entropy, row_entropy)\n\n    # Consider all matrix transformations\n    transformations = [matrix]\n    if matrix.shape[0] == matrix.shape[1]:\n        transformations.append(matrix.T)\n        inv = gf2_inv(matrix)\n        if inv is not None:\n            transformations.append(inv)\n            transformations.append(inv.T)\n    \n    # Get all possible heuristics\n    heuristics = [get_heuristic(t) for t in transformations]\n    \n    # Return the minimal heuristic\n    return min(heuristics)\n",
    "evaluation": {
      "fitness": 0.8320035686355388,
      "additional_data": {
        "spearman_correlation": "0.832004",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 645,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 657,
    "parent_id": 180,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        upper_tri = np.sum(np.triu(m) != 0)\n        lower_tri = np.sum(np.tril(m) != 0)\n        tri_metric = min(upper_tri, lower_tri)\n        \n        return (nonzeros, \n                tri_metric,\n                np.sum(np.abs(col_sums - 1)),\n                -np.linalg.matrix_rank(m))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8718307043033074,
      "additional_data": {
        "spearman_correlation": "0.871831",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 650,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 658,
    "parent_id": 218,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        rank = np.linalg.matrix_rank(m)\n        off_diagonal = np.sum(m - np.diag(np.diag(m)))\n        col_nonzeros = np.sum(m != 0, axis=0)\n        row_nonzeros = np.sum(m != 0, axis=1)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Pairwise column interactions\n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        # Pairwise row interactions\n        row_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                row_interactions += np.sum(m[i,:] & m[j,:])\n        \n        # Column completion metrics\n        col_completion = np.sum((col_sums == 1) & (col_nonzeros == 1))\n        row_completion = np.sum((row_sums == 1) & (row_nonzeros == 1))\n        \n        # Distance metrics\n        col_distance = np.sum(np.abs(col_sums - 1))\n        row_distance = np.sum(np.abs(row_sums - 1))\n        \n        return (rank, \n                off_diagonal, \n                col_interactions + row_interactions,\n                n - col_completion,\n                n - row_completion,\n                col_distance + row_distance,\n                *sorted(col_nonzeros),\n                *sorted(row_nonzeros))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 647,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 659,
    "parent_id": 108,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with more granular almost-done terms and better inverse/transpose handling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        cols_almost = (np.sum(col_sums == 2), np.sum(col_sums == 3))\n        rows_almost = (np.sum(row_sums == 2), np.sum(row_sums == 3))\n        cols_empty = np.sum(col_sums == 0)\n        rows_empty = np.sum(row_sums == 0)\n        sorted_cols = tuple(sorted(col_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, cols_done, rows_done, *cols_almost, *rows_almost, cols_empty, rows_empty, col_imbalance, row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min((h_original, h_inverse, h_transpose), key=lambda x: (x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], x[9]))\n",
    "evaluation": {
      "fitness": 0.8525184490497885,
      "additional_data": {
        "spearman_correlation": "0.852518",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 649,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 660,
    "parent_id": 297,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.sum(col_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        \n        # Advanced column metrics\n        col_difficulty = np.sum(np.where(col_sums > 1, col_sums * np.log2(col_sums), axis=0)\n        row_difficulty = np.sum(np.where(row_sums > 1, row_sums * np.log2(row_sums), axis=0)\n        \n        # Interaction metrics\n        interaction = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                interaction += np.sum(m[:,i] & m[:,j]) * 0.5\n        \n        # Column/row completion progress\n        col_progress = np.sum(1.0 / np.maximum(col_sums, 1))\n        row_progress = np.sum(1.0 / np.maximum(row_sums, 1))\n        \n        # Weighted combination\n        h = (\n            1.5 * nonzeros,\n            -0.8 * (correct_cols + correct_rows),\n            1.2 * col_difficulty,\n            0.9 * row_difficulty,\n            0.7 * interaction,\n            -0.5 * (col_progress + row_progress)\n        )\n        return h\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = get_heuristic(inv_matrix)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 32)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 644,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 661,
    "parent_id": 104,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if not aug[pivot, col]:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    bin_matrix = (matrix != 0).astype(int)\n    inv_matrix = gf2_inv(bin_matrix)\n    \n    col_orig = np.sum(bin_matrix, axis=0)\n    row_orig = np.sum(bin_matrix, axis=1)\n    h_col_orig = np.sum(np.log(col_orig + 1e-5))\n    h_row_orig = np.sum(np.log(row_orig + 1e-5))\n    \n    col_inv = np.sum(inv_matrix, axis=0)\n    row_inv = np.sum(inv_matrix, axis=1)\n    h_col_inv = np.sum(np.log(col_inv + 1e-5))\n    h_row_inv = np.sum(np.log(row_inv + 1e-5))\n    \n    min_col = min(h_col_orig, h_col_inv, h_row_orig)\n    min_row = min(h_row_orig, h_row_inv, h_col_orig)\n    \n    return (min_col, min_row)\n",
    "evaluation": {
      "fitness": 0.8684647239129762,
      "additional_data": {
        "spearman_correlation": "0.868465",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 583,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 662,
    "parent_id": 30,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and additional matrix sum term.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-8)\n        row_sums = np.maximum(row_sums, 1e-8)\n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        total_sum = np.sum(m)\n        return float(0.65 * log_cols + 0.25 * log_rows + 0.1 * total_sum)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    return min(original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8732729117660106,
      "additional_data": {
        "spearman_correlation": "0.873273",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 652,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 663,
    "parent_id": 167,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Quantum-aware heuristic with logarithmic scaling and inverse consideration.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        sparse_col_boost = np.sum(col_sums == 1)\n        return (log_cols, -sparse_col_boost, np.sum(col_sums), np.sum(row_sums))\n    \n    inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    options = [\n        evaluate(matrix),\n        evaluate(matrix.T),\n        evaluate(inv_matrix),\n        evaluate(inv_matrix.T)\n    ]\n    return min(options)\n",
    "evaluation": {
      "fitness": 0.7218349483596981,
      "additional_data": {
        "spearman_correlation": "0.721835",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 654,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 664,
    "parent_id": 346,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.sparse.csgraph import connected_components\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Graph-based metrics\n        graph = m @ m.T\n        _, component_counts = connected_components(graph, directed=False)\n        graph_complexity = np.sum(graph) - n  # Subtract diagonal\n        \n        # Block structure analysis\n        permuted = m[np.lexsort(-m.T), :][:, np.lexsort(-m)]\n        block_score = np.sum(np.triu(permuted, 1) + np.sum(np.tril(permuted, -1))\n        \n        # Weighted metrics\n        weights = np.arange(n, 0, -1)\n        weighted_cols = np.sum(m * weights.reshape(-1, 1), axis=0)\n        weighted_rows = np.sum(m * weights.reshape(1, -1), axis=1)\n        \n        # Combined metrics\n        return (\n            nonzeros,\n            graph_complexity,\n            component_counts,\n            block_score,\n            np.sum(np.abs(col_sums - 1)),\n            np.sum(np.abs(weighted_cols - np.median(weighted_cols))),\n            np.sum(np.abs(weighted_rows - np.median(weighted_rows)))\n        )\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 653,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 665,
    "parent_id": 176,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with basis vector counting and separated column/row metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        \n        rank = np.linalg.matrix_rank(m)\n        total_ones = np.sum(m)\n        \n        return (log_cols + 0.8*log_rows,  # Weight columns slightly more\n                -rank,\n                -(basis_cols + basis_rows), # Prefer matrices with more basis vectors\n                total_ones)\n    \n    metrics = calculate_metrics(matrix)\n    trans_metrics = calculate_metrics(matrix.T)\n    \n    return min(metrics, trans_metrics)\n",
    "evaluation": {
      "fitness": 0.7952140392511251,
      "additional_data": {
        "spearman_correlation": "0.795214",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 655,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 666,
    "parent_id": 368,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column weights and row consideration.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_max = np.max(col_nonzeros)\n        col_extra = np.sum(np.log2(np.maximum(col_nonzeros, 1)))\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_extra = np.sum(np.log2(np.maximum(row_nonzeros, 1)))\n        return (col_max, col_extra, row_extra)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8212937154360652,
      "additional_data": {
        "spearman_correlation": "0.821294",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 658,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 667,
    "parent_id": 363,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def col_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        non_zero = np.where(col_sums == 0, 1, col_sums)\n        log_terms = np.log2(non_zero + 0.5)\n        sqrt_terms = np.sqrt(col_sums)\n        weighted = np.sum(col_sums * log_terms * sqrt_terms)\n        return (weighted,) + tuple(sorted(log_terms * sqrt_terms))\n    \n    def row_heuristics(m):\n        row_sums = np.sum(m, axis=1)\n        non_zero = np.where(row_sums == 0, 1, row_sums)\n        log_terms = np.log2(non_zero + 0.5)\n        sqrt_terms = np.sqrt(row_sums)\n        weighted = np.sum(row_sums * log_terms * sqrt_terms)\n        return (weighted,) + tuple(sorted(log_terms * sqrt_terms))\n    \n    def get_all_heuristics(m):\n        original_col = col_heuristics(m)\n        original_row = row_heuristics(m)\n        transposed_col = col_heuristics(m.T)\n        transposed_row = row_heuristics(m.T)\n        inv = np.linalg.inv(m.astype(float)).astype(int) % 2\n        inv_col = col_heuristics(inv)\n        inv_row = row_heuristics(inv)\n        inv_transposed_col = col_heuristics(inv.T)\n        inv_transposed_row = row_heuristics(inv.T)\n        return min(original_col + original_row, \n                  transposed_col + transposed_row,\n                  inv_col + inv_row,\n                  inv_transposed_col + inv_transposed_row)\n    \n    return get_all_heuristics(matrix)\n",
    "evaluation": {
      "fitness": 0.6860328114911997,
      "additional_data": {
        "spearman_correlation": "0.686033",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 657,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 668,
    "parent_id": 528,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column weight histogram: [weight1, weight2, weight3, weight>=4]\n        col_hist = [0, 0, 0, 0]\n        for s in col_sums:\n            if s == 1:\n                col_hist[0] += 1\n            elif s == 2:\n                col_hist[1] += 1\n            elif s == 3:\n                col_hist[2] += 1\n            else:\n                col_hist[3] += 1\n        \n        # Row weight histogram\n        row_hist = [0, 0, 0, 0]\n        for s in row_sums:\n            if s == 1:\n                row_hist[0] += 1\n            elif s == 2:\n                row_hist[1] += 1\n            elif s == 3:\n                row_hist[2] += 1\n            else:\n                row_hist[3] += 1\n        \n        # New metric: sum of pairwise column overlaps\n        col_overlaps = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_overlaps += np.dot(m[:,i], m[:,j]) % 2\n        \n        extra_ones = nonzeros - n\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (extra_ones, col_hist[1], col_hist[2], col_hist[3],\n                row_hist[1], row_hist[2], row_hist[3],\n                log_cols, log_rows, max_col, max_row, col_overlaps)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix).astype(int) % 2,\n        matrix.T,\n        np.linalg.inv(matrix).T.astype(int) % 2\n    ]\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.7142960430145068,
      "additional_data": {
        "spearman_correlation": "0.714296",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 656,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 669,
    "parent_id": 367,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    m = matrix.astype(int)\n    m_inv = gf2_inv(m)\n    m_trans = m.T\n    \n    def compute_metrics(mat):\n        if mat is None:\n            return (float('inf'), float('inf'), float('inf'), float('inf'))\n        T = np.sum(mat)\n        col_sums = np.sum(mat, axis=0)\n        row_sums = np.sum(mat, axis=1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        entropy = -np.sum(mat * np.log2(np.maximum(mat, 1)) + (1-mat) * np.log2(np.maximum(1-mat, 1)))\n        return (T, log_cols, log_rows, entropy)\n    \n    candidates = [\n        compute_metrics(m),\n        compute_metrics(m_inv),\n        compute_metrics(m_trans)\n    ]\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 660,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 670,
    "parent_id": 8,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    n = matrix.shape[0]\n    h1 = calculate_heuristic(matrix)\n    h2 = calculate_heuristic(matrix.T)\n    h3 = h4 = float('inf')\n    if n <= 20:\n        inv = gf2_inv(matrix)\n        if inv is not None:\n            h3 = calculate_heuristic(inv)\n            h4 = calculate_heuristic(inv.T)\n    return min(h1, h2, h3, h4)\n",
    "evaluation": {
      "fitness": 0.8725265272009427,
      "additional_data": {
        "spearman_correlation": "0.872527",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 620,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 671,
    "parent_id": 225,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_distance(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        \n        # Simplified column dependencies\n        col_deps = np.zeros(n)\n        for i in range(n):\n            if col_sums[i] == 1:\n                continue\n            for j in range(n):\n                if m[j,i] == 1:\n                    col_deps[i] += col_sums[j]\n        \n        # Simplified cost calculation\n        col_costs = np.zeros(n)\n        for i in range(n):\n            if col_sums[i] == 1:\n                continue\n            col_costs[i] = col_sums[i] + 0.5 * col_deps[i] / n\n        \n        total_cost = np.sum(col_costs * (2 - 1/col_sums))\n        return total_cost / n\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(column_distance(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.16463124232111173,
      "additional_data": {
        "spearman_correlation": "0.164631",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 662,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 672,
    "parent_id": 633,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering matrix structure and multiple transformations.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        if np.linalg.matrix_rank(matrix) < n:\n            raise ValueError(\"Matrix not invertible\")\n        aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix not invertible in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Enhanced entropy calculation\n        col_entropy = -np.sum(np.where(col_sums > 0, col_sums * np.log2(col_sums + 1e-10), 0))\n        row_entropy = -np.sum(np.where(row_sums > 0, row_sums * np.log2(row_sums + 1e-10), 0))\n        \n        # Extended block structure detection\n        block_score = 0\n        n = m.shape[0]\n        for i in range(n-2):\n            for j in range(n-2):\n                if m[i,j] == 1:\n                    block_score += np.sum(m[i:i+3,j:j+3])\n        \n        # Diagonal dominance\n        diag_dominance = np.sum(np.diag(m)) - (np.sum(m) - np.sum(np.diag(m)))\n        \n        # Triangularity metric\n        upper_tri = np.triu(m, k=1)\n        lower_tri = np.tril(m, k=-1)\n        triangularity = max(np.sum(upper_tri), np.sum(lower_tri))\n        \n        return (nonzeros,\n                -rank,\n                col_entropy + row_entropy,\n                -block_score,\n                diag_dominance,\n                np.sum((col_sums - 1)**2) + np.sum((row_sums - 1)**2),\n                -triangularity)\n    \n    def get_min_heuristic(m):\n        metrics = matrix_metrics(m)\n        try:\n            inv_metrics = matrix_metrics(gf2_inv(m))\n            inv_trans_metrics = matrix_metrics(gf2_inv(m).T)\n            return min(metrics, inv_metrics, inv_trans_metrics, matrix_metrics(m.T))\n        except:\n            return min(metrics, matrix_metrics(m.T))\n    \n    return get_min_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8721708637524457,
      "additional_data": {
        "spearman_correlation": "0.872171",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 659,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 673,
    "parent_id": 643,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with log2 and diagonal term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        diag_correct = np.sum(np.diag(m) == 1)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, -diag_correct, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8820208173789824,
      "additional_data": {
        "spearman_correlation": "0.882021",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 661,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 674,
    "parent_id": 19,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Lexicographic heuristic combining sum of elements and log of column sums for original, inverse, and transpose.\"\"\"\n    import numpy as np\n    \n    def element_sum(m):\n        return float(np.sum(m))\n    \n    def log_col_sum(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T\n    ]\n    \n    results = []\n    for variant in variants:\n        results.append((element_sum(variant), log_col_sum(variant)))\n    \n    return min(results)\n",
    "evaluation": {
      "fitness": 0.8666347480499503,
      "additional_data": {
        "spearman_correlation": "0.866635",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 665,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 675,
    "parent_id": 533,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional near-completion reward term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        interaction = np.sum(m * np.outer(row_nonzeros, col_nonzeros))\n        \n        row_term = np.sum(np.log(row_nonzeros + (row_nonzeros == 0)))\n        col_term = np.sum(np.log(col_nonzeros + (col_nonzeros == 0)))\n        \n        row_var = np.var(row_nonzeros)\n        col_var = np.var(col_nonzeros)\n        sparsity = np.count_nonzero(m) / (n*n)\n        balance = (sparsity + row_var/n) * row_term + (1-sparsity + col_var/n) * col_term\n        \n        # New term: reward columns/rows close to completion\n        near_completion = np.sum(np.exp(-np.abs(col_nonzeros - 1))) + np.sum(np.exp(-np.abs(row_nonzeros - 1)))\n        \n        return (interaction, balance, -near_completion)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.37862856641033443,
      "additional_data": {
        "spearman_correlation": "0.378629",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 664,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 676,
    "parent_id": 216,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums and total sum.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        total_sum = np.sum(m)\n        return (float(total_sum), float(np.sum(col_sums * (col_sums - 1))))\n    \n    try:\n        inv = np.linalg.inv(matrix)\n    except:\n        inv = matrix\n        \n    h_matrix = calculate_heuristic(matrix)\n    h_inv = calculate_heuristic(inv)\n    h_trans = calculate_heuristic(matrix.T)\n    \n    return tuple(np.mean([h_matrix, h_inv, h_trans], axis=0))\n",
    "evaluation": {
      "fitness": 0.7298483952378034,
      "additional_data": {
        "spearman_correlation": "0.729848",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 666,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 677,
    "parent_id": 431,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.sum(m)\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        basis_rows = np.count_nonzero(row_sums == 1)\n        basis_cols = np.count_nonzero(col_sums == 1)\n        return (nonzeros, row_imbalance + col_imbalance, -(basis_rows + basis_cols))\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    try:\n        inv = gf2_inv(matrix)\n        h_inv = get_heuristic(inv)\n    except:\n        h_inv = h_orig\n    return min(h_orig, h_trans, h_inv)\n",
    "evaluation": {
      "fitness": 0.8662394486479444,
      "additional_data": {
        "spearman_correlation": "0.866239",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 582,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 678,
    "parent_id": 118,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Distance from nearest permutation matrix\n        perm_dist = np.sum(np.minimum(m, 1-m))\n        \n        # Column-based metrics\n        col_metric = np.sum(np.log2(np.maximum(col_sums, 1)) + np.sum(col_sums > 1)\n        \n        # Row-based metrics\n        row_metric = np.sum(np.log2(np.maximum(row_sums, 1)) + np.sum(row_sums > 1)\n        \n        return (perm_dist, col_metric + row_metric, *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 14)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 667,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 679,
    "parent_id": 557,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        \n        # Metrics for each column\n        log_sums = np.log(col_sums)\n        distances = np.abs(col_sums - 1)\n        is_basis = [1 if np.sum(col) == 1 else 0 for col in m.T]\n        \n        # Column-wise metrics\n        sum_log = np.sum(log_sums)\n        sum_dist = np.sum(distances)\n        sum_basis = np.sum(is_basis)\n        min_log = np.min(log_sums)\n        min_dist = np.min(distances)\n        \n        return sum_log, sum_dist, sum_basis, min_log, min_dist\n    \n    def row_metrics(m):\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Metrics for each row\n        log_sums = np.log(row_sums)\n        distances = np.abs(row_sums - 1)\n        \n        # Row-wise metrics\n        sum_log = np.sum(log_sums)\n        sum_dist = np.sum(distances)\n        min_log = np.min(log_sums)\n        min_dist = np.min(distances)\n        \n        return sum_log, sum_dist, min_log, min_dist\n    \n    # Calculate metrics for original, transposed and inverted versions\n    col_orig = column_metrics(matrix)\n    row_orig = row_metrics(matrix)\n    \n    col_trans = column_metrics(matrix.T)\n    row_trans = row_metrics(matrix.T)\n    \n    inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n    col_inv = column_metrics(inv_matrix)\n    row_inv = row_metrics(inv_matrix)\n    \n    # Combine all metrics with preference for column metrics\n    metrics = [\n        (col_orig[0] + 0.8*row_orig[0], col_orig[1] + 0.8*row_orig[1], \n         col_orig[2], col_orig[3] + row_orig[2], col_orig[4] + row_orig[3]),\n        (col_trans[0] + 0.8*row_trans[0], col_trans[1] + 0.8*row_trans[1], \n         col_trans[2], col_trans[3] + row_trans[2], col_trans[4] + row_trans[3]),\n        (col_inv[0] + 0.8*row_inv[0], col_inv[1] + 0.8*row_inv[1], \n         col_inv[2], col_inv[3] + row_inv[2], col_inv[4] + row_inv[3])\n    ]\n    \n    # Return the minimum metrics lexicographically\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.7236903394237033,
      "additional_data": {
        "spearman_correlation": "0.723690",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 663,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 680,
    "parent_id": 19,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Minimum heuristic across variants combined with total sum as secondary metric.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_heuristic = np.sum(np.log(col_sums))\n        row_heuristic = np.sum(np.log(row_sums))\n        total_sum = np.sum(m)\n        return min(col_heuristic, row_heuristic), total_sum\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    heuristics = [calculate_heuristic(v) for v in variants]\n    return min(heuristics)\n",
    "evaluation": {
      "fitness": 0.8722799714275807,
      "additional_data": {
        "spearman_correlation": "0.872280",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 668,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 681,
    "parent_id": 598,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        mat = (matrix % 2).astype(int)\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = np.where(mat[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix is singular mod2\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                mat[[col, pivot]] = mat[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for r in range(n):\n                if r != col and mat[r, col] == 1:\n                    mat[r] = (mat[r] + mat[col]) % 2\n                    inv[r] = (inv[r] + inv[col]) % 2\n        return inv\n\n    def get_heuristic(m):\n        m = m.astype(int)  # Ensure integer type\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum((col_sums - 1) ** 2)\n        row_imbalance = np.sum((row_sums - 1) ** 2)\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance + row_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    try:\n        inv_mat = gf2_inv(matrix)\n        h_inverse = get_heuristic(inv_mat)\n        h_inverse_transpose = get_heuristic(inv_mat.T)\n        return min(h_original, h_transpose, h_inverse, h_inverse_transpose)\n    except ValueError:\n        return min(h_original, h_transpose)\n\n",
    "evaluation": {
      "fitness": 0.8268133087918398,
      "additional_data": {
        "spearman_correlation": "0.826813",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 618,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 682,
    "parent_id": 80,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def get_heuristic(m):\n        # Convert to F\u2082 (0-1 integers)\n        m_int = m.astype(int)\n        m_f2 = m_int % 2\n        col_sums = np.sum(m_f2, axis=0)\n        nonzeros = np.count_nonzero(m_f2)\n        # Use absolute deviations (L1 norm)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        sorted_cols = tuple(sorted(col_sums))\n        return (nonzeros, col_imbalance, *sorted_cols)\n\n    h_original = get_heuristic(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n    except np.linalg.LinAlgError:\n        inv_real = matrix  # Fallback (shouldn't occur for GL matrices)\n    h_inverse = get_heuristic(inv_real)\n    h_transpose = get_heuristic(matrix.T)\n    h_inv_trans = get_heuristic(inv_real.T)\n\n    return min(h_original, h_inverse, h_transpose, h_inv_trans)\n",
    "evaluation": {
      "fitness": 0.7227965716454011,
      "additional_data": {
        "spearman_correlation": "0.722797",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 558,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 683,
    "parent_id": 324,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        non_zero_cols = np.sum(col_sums > 0)\n        non_zero_rows = np.sum(row_sums > 0)\n        weighted_sparsity = np.sum(m * np.sqrt(np.arange(1, m.shape[0]+1)[:, np.newaxis]))\n        blockiness = 0\n        for i in range(m.shape[0]-1):\n            for j in range(m.shape[1]-1):\n                blockiness += m[i,j] * m[i+1,j] * m[i,j+1] * m[i+1,j+1]\n        return (log_col, log_row, non_zero_cols, non_zero_rows, weighted_sparsity, blockiness)\n    \n    original = evaluate(matrix)\n    transposed = evaluate(matrix.T)\n    \n    return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.7999549542076485,
      "additional_data": {
        "spearman_correlation": "0.799955",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 670,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 684,
    "parent_id": 213,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance to identity/anti-identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                        np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Overlap between columns and rows\n        col_overlap = sum(np.sum(m[:,i] & m[:,j]) \n                         for i in range(n) for j in range(i+1, n))\n        row_overlap = sum(np.sum(m[i,:] & m[j,:]) \n                         for i in range(n) for j in range(i+1, n))\n        overlap_metric = col_overlap + row_overlap\n        \n        # Logarithmic column weight penalty\n        log_col = np.sum(np.log2(col_sums))  # Safe since invertible matrices have no zero columns\n        \n        # Deviation from ideal number of ones (n)\n        lin_col_dev = total_ones - n\n        \n        return (diag_dist, overlap_metric, log_col, lin_col_dev)\n    \n    # Compute metrics for variants\n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_metrics(inv_matrix)\n    inv_transposed = matrix_metrics(inv_matrix.T)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    \n    # Select best (min) for each metric across variants\n    best_diag_dist = min(m[0] for m in metrics)\n    best_overlap = min(m[1] for m in metrics)\n    best_log_col = min(m[2] for m in metrics)\n    best_lin_col_dev = min(m[3] for m in metrics)\n    \n    return best_diag_dist + best_overlap + best_log_col + best_lin_col_dev\n",
    "evaluation": {
      "fitness": 0.7023260456549075,
      "additional_data": {
        "spearman_correlation": "0.702326",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 672,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 685,
    "parent_id": 80,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using absolute deviations for column imbalance.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # L1 norm\n        return (nonzeros, col_imbalance, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8817377970298539,
      "additional_data": {
        "spearman_correlation": "0.881738",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 676,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 686,
    "parent_id": 282,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering basis vector proximity and operation distances.\"\"\"\n    import numpy as np\n    \n    def basis_proximity(m):\n        row_dists = np.sum((m - np.eye(m.shape[0], dtype=int))**2, axis=1)\n        col_dists = np.sum((m - np.eye(m.shape[0], dtype=int))**2, axis=0)\n        return np.sum(row_dists) + np.sum(col_dists)\n    \n    def operation_distance(m):\n        row_ops = np.sum(m != 0, axis=1) - 1\n        col_ops = np.sum(m != 0, axis=0) - 1\n        return np.sum(np.maximum(row_ops, 0)) + np.sum(np.maximum(col_ops, 0))\n    \n    def get_heuristic(m):\n        basis_score = basis_proximity(m)\n        ops_score = operation_distance(m)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(np.sum(m, axis=0)))\n        return (basis_score, ops_score, nonzeros, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.4824888163429044,
      "additional_data": {
        "spearman_correlation": "0.482489",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 673,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 687,
    "parent_id": 456,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined row and column sum logarithms with multiplicative combination, considering original, transpose and inverse.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        col_term = np.prod(np.log(col_sums + 0.1))\n        row_term = np.prod(np.log(row_sums + 0.1))\n        return float(col_term * row_term)\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    return (original_heuristic, transpose_heuristic, inverse_heuristic)\n",
    "evaluation": {
      "fitness": 0.8186468438181175,
      "additional_data": {
        "spearman_correlation": "0.818647",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 679,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 688,
    "parent_id": 472,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column completion metrics\n        col_completion = np.sum(np.exp(-np.abs(col_sums - 1)))\n        nearly_complete_cols = np.sum((col_sums > 0) & (col_sums <= 2))\n        \n        # Row metrics\n        row_nonzeros = np.count_nonzero(row_sums)\n        row_completion = np.sum(np.exp(-np.abs(row_sums - 1)))\n        \n        # Interaction between rows and columns\n        col_row_overlap = np.sum(m * (1 - np.eye(m.shape[0])))\n        \n        # Spread metrics\n        col_spread = np.sum(np.abs(np.diff(np.sort(col_sums))))\n        row_spread = np.sum(np.abs(np.diff(np.sort(row_sums))))\n        \n        # Diagonal and inverse diagonal\n        diag = np.sum(np.diag(m))\n        inv_diag = np.sum(np.diag(np.fliplr(m)))\n        \n        return (nonzeros, \n                -col_completion, \n                -nearly_complete_cols,\n                -row_completion,\n                col_row_overlap,\n                col_spread + row_spread,\n                -diag - inv_diag,\n                row_nonzeros)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inv_trans = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inv_trans)\n",
    "evaluation": {
      "fitness": 0.8821831888885207,
      "additional_data": {
        "spearman_correlation": "0.882183",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 675,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 689,
    "parent_id": 365,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        lower_tri = np.tril(m, -1)\n        upper_tri = np.triu(m, 1)\n        \n        # Primary metric: polynomial column sums (balanced emphasis)\n        col_poly = np.sum((col_sums + 1)**0.5)\n        \n        # Secondary metric: polynomial row sums\n        row_poly = np.sum((row_sums + 1)**0.5)\n        \n        # Tertiary metric: column uniqueness\n        _, col_counts = np.unique(m.T, axis=0, return_counts=True)\n        uniqueness = np.sum(col_counts == 1)\n        \n        # Quaternary metric: nonzeros in both triangles\n        lower_nonzeros = np.count_nonzero(lower_tri)\n        upper_nonzeros = np.count_nonzero(upper_tri)\n        tri_nonzeros = lower_nonzeros + upper_nonzeros\n        \n        # Combine all components into a single weighted score\n        return col_poly * 0.5 + row_poly * 0.3 + uniqueness * 0.1 + tri_nonzeros * 0.1\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_score(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.1418976567885478,
      "additional_data": {
        "spearman_correlation": "0.141898",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 677,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 690,
    "parent_id": 466,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Column-based metrics\n        col_metrics = []\n        for s in col_sums:\n            if s == 0:\n                col_metrics.append(0)\n            elif s == 1:\n                col_metrics.append(0)\n            else:\n                col_metrics.append(log2(s) + 1)\n        \n        # Row-based metrics\n        row_metrics = []\n        for s in row_sums:\n            if s == 0:\n                row_metrics.append(0)\n            elif s == 1:\n                row_metrics.append(0)\n            else:\n                row_metrics.append(log2(s) + 1)\n                \n        # Matrix-wide metrics\n        rank = np.linalg.matrix_rank(m)\n        unique_cols = len(set(tuple(col) for col in m.T))\n        \n        return (\n            sum(col_metrics) + sum(row_metrics),\n            total_ones,\n            -rank,\n            -unique_cols\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    best_score = None\n    for variant in variants:\n        try:\n            current_score = evaluate(variant)\n            if best_score is None or current_score < best_score:\n                best_score = current_score\n        except:\n            continue\n            \n    return best_score if best_score is not None else evaluate(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 678,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 691,
    "parent_id": 243,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        aug = (aug % 2).astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def matrix_metrics(m):\n        if m.size == 0:\n            return (0,)\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column-wise metrics\n        col_weights = tuple(sorted(col_sums, reverse=True))\n        col_completion = tuple(sorted((col_sums == 1).astype(int), reverse=True))\n        \n        # Row-wise metrics\n        row_weights = tuple(sorted(row_sums, reverse=True))\n        row_completion = tuple(sorted((row_sums == 1).astype(int), reverse=True))\n        \n        # Interaction metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        col_interactions = np.sum(np.log2(np.maximum(np.sum(m & m[:, np.newaxis], axis=(0,1)), 1)))\n        \n        # Basis vector distance metrics\n        basis_dist = np.sum(np.min(np.sum(np.abs(m - np.eye(m.shape[0], dtype=int)[:, np.newaxis]), axis=2), axis=1))\n        \n        return (nonzeros, rank, upper_tri_nonzeros, col_interactions, basis_dist, \n                *col_weights, *row_weights, *col_completion, *row_completion)\n    \n    inv_matrix = gf2_inv(matrix)\n    variants = [\n        matrix_metrics(matrix),\n        matrix_metrics(matrix.T),\n        matrix_metrics(inv_matrix) if inv_matrix is not None else (float('inf'),),\n        matrix_metrics(inv_matrix.T) if inv_matrix is not None else (float('inf'),)\n    ]\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 674,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 692,
    "parent_id": 77,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        n = m.shape[0]\n        metrics = []\n        for col in m.T:\n            weight = np.sum(col)\n            if weight == 0:\n                metrics.append(0)\n                continue\n            # Distance from nearest basis vector\n            dist = min(n - weight, weight - 1) if weight > 0 else n\n            # Combined metric with logarithmic scaling\n            metric = weight * np.log(weight + 1) + dist\n            metrics.append(metric)\n        return tuple(sorted(metrics))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(column_metrics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8570326047506459,
      "additional_data": {
        "spearman_correlation": "0.857033",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 680,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 693,
    "parent_id": 138,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def enhanced_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Weight columns/rows closer to 1 more heavily\n        col_priority = np.sum(np.log(col_sums + (col_sums == 0)))\n        row_priority = np.sum(np.log(row_sums + (row_sums == 0)))\n        \n        # Combine with weights favoring columns slightly more than rows\n        return float(total_ones), float(0.6 * col_priority + 0.4 * row_priority)\n    \n    # Calculate for original matrix\n    h_orig = enhanced_heuristic(matrix)\n    \n    try:\n        # Calculate for inverse matrix\n        det = np.linalg.det(matrix)\n        adj = np.round(det * np.linalg.inv(matrix)).astype(int)\n        inv_matrix = adj % 2\n        h_inv = enhanced_heuristic(inv_matrix)\n    except:\n        h_inv = (float('inf'), float('inf'))\n    \n    # Calculate for transpose\n    h_trans = enhanced_heuristic(matrix.T)\n    \n    # Return the minimum lex order\n    return min(h_orig, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": 0.8707166440490499,
      "additional_data": {
        "spearman_correlation": "0.870717",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 681,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 694,
    "parent_id": 662,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-8)\n        row_sums = np.maximum(row_sums, 1e-8)\n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        rank = np.linalg.matrix_rank(m)\n        \n        col_deps = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_deps += np.sum(m[:,i] & m[:,j])\n        col_deps = col_deps / (m.shape[1]*(m.shape[1]-1)/2 + 1e-8)\n        \n        spread = np.var(col_sums)\n        \n        return (rank, log_cols + log_rows, col_deps, spread)\n    \n    variants = [\n        calculate_heuristic(matrix),\n        calculate_heuristic(np.linalg.inv(matrix) % 2),\n        calculate_heuristic(matrix.T),\n        calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    ]\n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 682,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 695,
    "parent_id": 337,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (total_ones - n, log_cols, log_rows)\n    \n    original = evaluate(matrix)\n    \n    try:\n        inv = evaluate(np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2)\n    except:\n        inv = original\n    \n    try:\n        trans = evaluate(matrix.T)\n    except:\n        trans = original\n    \n    return min(original, inv, trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 686,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 696,
    "parent_id": 522,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_counts = np.sum(m > 0, axis=0)\n        row_counts = np.sum(m > 0, axis=1)\n        \n        # Distance to permutation metrics\n        col_dist = np.sum(np.abs(col_sums - 1))\n        row_dist = np.sum(np.abs(row_sums - 1))\n        col_var = np.sum((col_sums - 1)**2)\n        row_var = np.sum((row_sums - 1)**2)\n        col_entropy = -np.sum(col_sums * np.log(col_sums + 1e-10))\n        row_entropy = -np.sum(row_sums * np.log(row_sums + 1e-10))\n        \n        return (col_dist + row_dist, \n                col_var + row_var, \n                col_entropy + row_entropy,\n                np.sum(m))\n    \n    # Consider original, inverse and transpose forms\n    original = compute_metrics(matrix)\n    transposed = compute_metrics(matrix.T)\n    try:\n        inverted = compute_metrics(np.linalg.inv(matrix).astype(int) % 2)\n    except:\n        inverted = (float('inf'),)*4\n    \n    # Return the best found metrics\n    return min(original, transposed, inverted)\n",
    "evaluation": {
      "fitness": 0.7014652520746528,
      "additional_data": {
        "spearman_correlation": "0.701465",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 683,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 697,
    "parent_id": 294,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced log weighting and distance metric.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Enhanced log weighting with epsilon and log1p\n        eps = 1e-6\n        col_completion = np.sum(np.log1p(col_nonzeros + eps))\n        \n        # Weighted distance from 1 (smaller weights for closer columns)\n        col_dist = np.sum(np.abs(col_nonzeros - 1) * (1 - 0.1/(np.abs(col_nonzeros - 1) + eps))\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 687,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 698,
    "parent_id": 440,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_features = (float('inf'), float('inf'))\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        diag_sum = np.sum(np.diag(m))\n        \n        # Column features\n        col_entropy = entropy(np.maximum(col_weights, 1e-10))\n        col_inv_sum = np.sum(1/(np.maximum(col_weights, 1)))\n        \n        # Row features\n        row_entropy = entropy(np.maximum(row_weights, 1e-10))\n        \n        # Combined features\n        h1 = col_entropy + row_entropy\n        h2 = col_inv_sum + (m.shape[0] - diag_sum)\n        \n        current_features = (h1, h2)\n        if current_features < min_features:\n            min_features = current_features\n            \n    return min_features\n",
    "evaluation": {
      "fitness": 0.6749768186411581,
      "additional_data": {
        "spearman_correlation": "0.674977",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 684,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 699,
    "parent_id": 181,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and simplified features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        log_cols = 2.5 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 3.2 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.8 * np.sum(np.abs(row_sums - 1))\n        diagonal = 0.5 * np.sum(np.diag(m) == 0)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, diagonal)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8817735891776439,
      "additional_data": {
        "spearman_correlation": "0.881774",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 688,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 700,
    "parent_id": 640,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Measure column/row dependencies\n        col_rank = np.linalg.matrix_rank(m)\n        row_rank = np.linalg.matrix_rank(m.T)\n        \n        # Measure block structure\n        block_score = 0\n        for k in range(1, n//2 + 1):\n            for i in range(n - k + 1):\n                for j in range(n - k + 1):\n                    block = m[i:i+k, j:j+k]\n                    if np.all(block == 0) or np.all(block == 1):\n                        block_score += k\n        \n        # Measure hierarchical structure\n        def recursive_decomp(mat, depth=0):\n            if mat.size == 1:\n                return mat[0,0] * (1/(depth+1))\n            h, w = mat.shape\n            submatrices = [\n                mat[:h//2, :w//2], mat[:h//2, w//2:],\n                mat[h//2:, :w//2], mat[h//2:, w//2:]\n            ]\n            current = np.sum(mat) * (1/(depth+1))\n            return current + sum(recursive_decomp(m, depth+1) for m in submatrices)\n        \n        hierarchy_score = recursive_decomp(m)\n        \n        return (nonzeros, -col_rank, -row_rank, block_score, hierarchy_score, *col_sums, *row_sums)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.29791996695485706,
      "additional_data": {
        "spearman_correlation": "0.297920",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 685,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 701,
    "parent_id": 276,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s <= 1)\n        \n        # LU decomposition metric\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        return (nonzeros,\n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                -upper_tri_nonzeros)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 692,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 702,
    "parent_id": 498,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Enhanced column metrics\n        col_weights = np.sort(col_sums)\n        col_progress = np.sum(1/(1 + np.minimum(np.abs(col_weights - 1), np.abs(col_weights))))\n        col_log_penalty = np.sum(np.log2(1 + np.maximum(np.abs(col_weights - 1), np.abs(col_weights))))\n        \n        # Enhanced row metrics\n        row_weights = np.sort(row_sums)\n        row_progress = np.sum(1/(1 + np.minimum(np.abs(row_weights - 1), np.abs(row_weights))))\n        row_log_penalty = np.sum(np.log2(1 + np.maximum(np.abs(row_weights - 1), np.abs(row_weights))))\n        \n        # Matrix structure metrics\n        diff = m - np.eye(n, dtype=int)\n        upper_tri = np.sum(np.abs(np.triu(diff)))\n        lower_tri = np.sum(np.abs(np.tril(diff)))\n        \n        return (\n            -col_progress - row_progress,\n            col_log_penalty + row_log_penalty,\n            upper_tri + lower_tri\n        )\n    \n    # Evaluate transformations (removed rotation as less useful)\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix[::-1],\n        matrix[:, ::-1]\n    ]\n    \n    return min(evaluate(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.24495247544500107,
      "additional_data": {
        "spearman_correlation": "0.244952",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 689,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 703,
    "parent_id": 185,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_based_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        nonzero_columns = np.count_nonzero(col_sums)\n        completed_cols = np.sum(col_sums == 1)\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        col_sparsity = np.sum(col_sums == 0)\n        \n        # Column pattern features\n        col_nonzero_pattern = tuple(sorted(col_sums))\n        col_interactions = np.sum(m * m.T)  # Measures column-row interactions\n        \n        return (log_cols, col_imbalance, -completed_cols, nonzero_columns, \n                max_col, min_col, col_sparsity, col_interactions, *col_nonzero_pattern)\n    \n    h_original = column_based_heuristic(matrix)\n    h_inverse = column_based_heuristic(np.linalg.inv(matrix))\n    h_transpose = column_based_heuristic(matrix.T)\n    h_inverse_transpose = column_based_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.3252843088437945,
      "additional_data": {
        "spearman_correlation": "0.325284",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 690,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 704,
    "parent_id": 28,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def get_permuted_matrices(m):\n        n = m.shape[0]\n        perms = []\n        for p in permutations(range(n)):\n            perm_mat = m[np.array(p), :]\n            perms.append(perm_mat)\n        return perms\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Handle zero sums to avoid log(0)\n        col_sums = np.maximum(col_sums, 1e-12)\n        row_sums = np.maximum(row_sums, 1e-12)\n        \n        # Multiple metrics\n        log_cols = np.sum(np.log2(col_sums))\n        log_rows = np.sum(np.log2(row_sums))\n        nonzero_count = np.count_nonzero(m)\n        max_col = np.max(col_sums)\n        almost_done_cols = np.sum(col_sums == 1)\n        \n        return (log_cols, log_rows, nonzero_count, -almost_done_cols, max_col)\n    \n    matrices_to_consider = [matrix, matrix.T, np.linalg.inv(matrix).astype(int) % 2]\n    matrices_to_consider += get_permuted_matrices(matrix)\n    matrices_to_consider += get_permuted_matrices(matrix.T)\n    \n    best_heuristic = None\n    for m in matrices_to_consider:\n        current = calculate_heuristic(m)\n        if best_heuristic is None or current < best_heuristic:\n            best_heuristic = current\n    \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.7203413815935358,
      "additional_data": {
        "spearman_correlation": "0.720341",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 691,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 705,
    "parent_id": 33,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic with structural matrix properties.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sum_col = np.sum(col_sums)\n        sum_row = np.sum(row_sums)\n        \n        # Additional metrics\n        rank = np.linalg.matrix_rank(m)\n        basis_proximity = np.sum(np.minimum(col_sums, np.sum(m, axis=0) - 1)\n        pairwise_col = np.sum(np.dot(m.T, m) - np.diag(np.diag(np.dot(m.T, m))))\n        \n        return (log_col, log_row, sum_col, sum_row, -rank, basis_proximity, pairwise_col)\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    inverse = matrix_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    inv_transposed = matrix_metrics(np.linalg.inv(matrix.T.astype(float)).astype(int) % 2)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    min_log_col = min(m[0] for m in metrics)\n    min_sum_col = min(m[2] for m in metrics)\n    max_log_row = max(m[1] for m in metrics)\n    max_rank = max(-m[4] for m in metrics)\n    min_basis = min(m[5] for m in metrics)\n    min_pairwise = min(m[6] for m in metrics)\n    \n    return (min_log_col, min_sum_col, max_log_row, max_rank, min_basis, min_pairwise)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 16)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 695,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 706,
    "parent_id": 408,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import math\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Exponential weighting for nearly complete columns\n        col_weights = sum(math.exp(-(s-1)) if s > 0 else 0 for s in col_sums)\n        \n        # Interaction measure between rows and columns\n        interaction = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j]:\n                    interaction += (row_sums[i] - 1) * (col_sums[j] - 1)\n        \n        # Column completion priority\n        col_priority = sum(1/(1 + math.exp(-5*(s-1.5))) for s in col_sums if s > 0)\n        \n        return (col_weights, interaction, col_priority)\n    \n    candidates = []\n    base_candidates = [matrix, matrix.T, matrix[:, ::-1], matrix[::-1, :], \n                      matrix.T[:, ::-1], matrix.T[::-1, :]]\n    \n    for m in base_candidates:\n        candidates.append(evaluate(m))\n        candidates.append(evaluate(m[::-1, ::-1]))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": -0.8035703732734302,
      "additional_data": {
        "spearman_correlation": "-0.803570",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 693,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 707,
    "parent_id": 221,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(np.exp(1-s) for s in col_sums)\n        row_symmetry = -np.var(row_sums)\n        col_sum_norm = np.sum(col_sums)\n        diagonal = np.sum(np.abs(np.diag(m) - 1))\n        \n        return (nonzeros, \n                -col_completion,\n                row_symmetry,\n                -basis_cols,\n                -unique_cols,\n                diagonal,\n                col_sum_norm)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.880682566750631,
      "additional_data": {
        "spearman_correlation": "0.880683",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 696,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 708,
    "parent_id": 70,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)  # Count of non-zero elements\n        \n        # Adjusted weights with increased sparsity term\n        return (0.55 * (col_log + row_log) + 0.35 * (col_linear + row_linear) + 0.1 * sparsity,\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 697,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 709,
    "parent_id": 594,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        col_log_completion = sum(np.log2(np.maximum(col_sums, 1)))\n        row_log_completion = sum(np.log2(np.maximum(row_sums, 1)))\n        \n        return (nonzeros, \n                -col_log_completion,\n                -row_log_completion)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8537767148111265,
      "additional_data": {
        "spearman_correlation": "0.853777",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 699,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 710,
    "parent_id": 391,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def matrix_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.log(np.maximum(col_sums, 1))\n        log_row = np.log(np.maximum(row_sums, 1))\n        \n        # LU decomposition features\n        _, u = lu(m)\n        u_rank = np.sum(np.abs(np.diag(u)) > 1e-10)\n        \n        # Distance from permutation matrix\n        perm_dist = np.sum(np.abs(m - np.eye(m.shape[0])))\n        \n        # Column independence measure\n        col_norms = np.linalg.norm(m, axis=0)\n        col_dependence = np.prod(col_norms) / (np.sum(col_norms) + 1e-15)\n        \n        return (np.sum(m), u_rank, perm_dist, col_dependence) + tuple(sorted(log_col)) + tuple(sorted(log_row))\n    \n    original_features = matrix_features(matrix)\n    transposed_features = matrix_features(matrix.T)\n    inverted_features = matrix_features(np.linalg.inv(matrix))\n    \n    return original_features + transposed_features + inverted_features\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 698,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 711,
    "parent_id": 332,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums and nonzeros.\"\"\"\n    import numpy as np\n    import math\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        \n        # Logarithmic weighting for columns\n        log_col = sum(-math.log(cs) if cs > 0 else 0 for cs in col_sums)\n        \n        # Column features\n        col_features = (\n            sum(col_sums == 1),  # weight-1 cols\n            sum(col_sums == 2),  # weight-2 cols\n            sum(col_sums > 2),   # weight>2 cols\n        )\n        \n        return (nonzeros, log_col, *col_features)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    # Combine heuristics using element-wise min\n    combined = []\n    for i in range(len(h_original)):\n        combined.append(min(h_original[i], h_transpose[i]))\n    \n    return tuple(combined)\n",
    "evaluation": {
      "fitness": 0.7188297453108746,
      "additional_data": {
        "spearman_correlation": "0.718830",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 701,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 712,
    "parent_id": 549,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with row-wise metrics added.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = np.sum(np.log2(np.maximum(row_sums, 1)))\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        return (nonzeros, min(log_col_sums, log_row_sums), -max(done_cols, done_rows))\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n    except:\n        h_inverse = (float('inf'),)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824180021467966,
      "additional_data": {
        "spearman_correlation": "0.882418",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 703,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 713,
    "parent_id": 397,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column reduction complexity and linear dependencies.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        if np.array_equal(m, np.eye(n)):\n            return (0, 0, 0)\n            \n        # Calculate column weights with diminishing returns\n        col_weights = np.sum(m, axis=0)\n        weighted_cols = np.sum(np.sqrt(col_weights))\n        \n        # Measure linear dependencies between columns\n        rank = np.linalg.matrix_rank(m)\n        dependency_penalty = (n - rank) * 0.5\n        \n        # Column reduction potential\n        reduction_potential = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                reduction_potential += np.sum(m[:,i] & m[:,j])\n        \n        return (weighted_cols, dependency_penalty, reduction_potential)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 706,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 714,
    "parent_id": 515,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF2 inverse and log-sum of column weights.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        \"\"\"Compute inverse of binary matrix over GF2 using Gaussian elimination.\"\"\"\n        n = mat.shape[0]\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        aug = aug % 2\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                raise np.linalg.LinAlgError(\"Singular matrix\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:] % 2\n\n    def get_heuristic(m):\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        log_sum = np.sum(np.log2(col_sums))\n        return (nonzeros, log_sum)\n\n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(gf2_inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8676859578421587,
      "additional_data": {
        "spearman_correlation": "0.867686",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 597,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 715,
    "parent_id": 358,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        \n        cols_with_weight_1 = np.sum(col_sums == 1)\n        rows_with_weight_1 = np.sum(row_sums == 1)\n        col_row_overlap = np.sum(m * m.T)\n        diagonal_ones = np.sum(np.diag(m))\n        max_col_weight = np.max(col_sums)\n        max_row_weight = np.max(row_sums)\n        full_columns = np.sum(col_sums == m.shape[0])\n        full_rows = np.sum(row_sums == m.shape[1])\n        \n        main_metric = log_col + log_row + hamming\n        secondary_metric = float(cols_with_weight_1 + rows_with_weight_1 + diagonal_ones)\n        tertiary_metric = float(col_row_overlap + max_col_weight + max_row_weight + full_columns + full_rows)\n        \n        return main_metric, secondary_metric, tertiary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary = min(original[1], transposed[1], inverted[1])\n    min_tertiary = min(original[2], transposed[2], inverted[2])\n    \n    return (min_main, min_secondary, min_tertiary)\n",
    "evaluation": {
      "fitness": 0.7214460027285777,
      "additional_data": {
        "spearman_correlation": "0.721446",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 702,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 716,
    "parent_id": 470,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def binary_inv(m):\n        try:\n            inv = np.linalg.inv(m) % 2\n            return (np.abs(inv) > 1e-10).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def get_col_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)  # Avoid log(0)\n        return np.sum(np.log(col_sums))\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        binary_inv(matrix),\n        binary_inv(matrix).T\n    ]\n    \n    min_metric = float('inf')\n    for m in matrices:\n        current_metric = get_col_metric(m)\n        if current_metric < min_metric:\n            min_metric = current_metric\n    \n    return min_metric\n",
    "evaluation": {
      "fitness": 0.8730953145669448,
      "additional_data": {
        "spearman_correlation": "0.873095",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 707,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 717,
    "parent_id": 305,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                raise Exception(\"Singular matrix\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    def get_permuted(mat, perm):\n        return mat[np.ix_(perm, perm)]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    perms = list(permutations(range(n))) if n <= 4 else [tuple(range(n))]\n    \n    tuples = []\n    for m in matrices:\n        for perm in perms:\n            pm = get_permuted(m, perm)\n            col_sums = np.sum(pm, axis=0)\n            row_sums = np.sum(pm, axis=1)\n            log_sum_col = np.sum(np.log(col_sums + 1e-10))\n            log_sum_row = np.sum(np.log(row_sums + 1e-10))\n            total_ones = np.sum(col_sums)\n            basis_cols = np.sum(col_sums == 1)\n            basis_rows = np.sum(row_sums == 1)\n            cols_with_two = np.sum(col_sums == 2)\n            rows_with_two = np.sum(row_sums == 2)\n            rank = np.linalg.matrix_rank(pm)\n            basis_diff = np.abs(basis_cols - basis_rows)\n            col_var = np.var(col_sums)\n            row_var = np.var(row_sums)\n            t = (log_sum_col + log_sum_row, \n                 total_ones, \n                 -basis_cols - basis_rows,\n                 -cols_with_two - rows_with_two,\n                 -rank,\n                 basis_diff,\n                 col_var + row_var)\n            tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8747233244701361,
      "additional_data": {
        "spearman_correlation": "0.874723",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 669,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 718,
    "parent_id": 133,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with better column metrics.\"\"\"\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_heuristic(m):\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        basis = np.eye(n, dtype=int)\n        \n        # Improved column distance metric\n        col_metrics = []\n        for i in range(n):\n            min_dist = n\n            for j in range(n):\n                dist = np.sum(m[:,i] != basis[:,j])\n                if dist < min_dist:\n                    min_dist = dist\n                    if min_dist == 0:\n                        break\n            col_metrics.append(min_dist)\n        total_col_dist = sum(col_metrics)\n        \n        # Column sum imbalance with logarithmic weighting\n        col_sums = np.sum(m, axis=0)\n        col_imbalance = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Column dependency metric\n        rank = np.linalg.matrix_rank(m)\n        rank_penalty = n - rank\n        \n        return (total_col_dist, col_imbalance, rank_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        np.linalg.inv(matrix).T,\n        matrix.T.dot(np.linalg.inv(matrix))\n    ]\n    \n    valid_variants = []\n    for v in variants:\n        try:\n            v_bin = (v % 2).astype(int)\n            if not np.isnan(v_bin).any():\n                valid_variants.append(v_bin)\n        except:\n            continue\n    \n    return min(get_heuristic(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.4829936804540366,
      "additional_data": {
        "spearman_correlation": "0.482994",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 708,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 719,
    "parent_id": 276,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s <= 2)\n        col_variance = np.var(col_sums)\n        col_basis_proximity = sum(min(np.sum(np.abs(col - basis)) for basis in np.eye(m.shape[0])) for col in m.T)\n        \n        # Row metrics\n        row_variance = np.var(row_sums)\n        row_basis_proximity = sum(min(np.sum(np.abs(row - basis)) for basis in np.eye(m.shape[1])) for row in m)\n        \n        # Dependency metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        return (nonzeros,\n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                col_variance,\n                row_variance,\n                -upper_tri_nonzeros,\n                col_basis_proximity,\n                row_basis_proximity)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 710,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 720,
    "parent_id": 643,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with log2 and absolute imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        diag_sum = np.sum(np.diag(m))\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, -done_cols-done_rows, -correct_cols-correct_rows, log_cols+log_rows, col_imbalance + row_imbalance, diag_sum, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8817929983527687,
      "additional_data": {
        "spearman_correlation": "0.881793",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 709,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 721,
    "parent_id": 162,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    I = np.eye(n, dtype=int)\n    full = np.hstack((matrix, I))\n    for i in range(n):\n        pivot = -1\n        for r in range(i, n):\n            if full[r, i] == 1:\n                pivot = r\n                break\n        if pivot == -1:\n            raise ValueError(\"Singular matrix\")\n        full[[i, pivot]] = full[[pivot, i]]\n        for r in range(n):\n            if r != i and full[r, i] == 1:\n                full[r] = (full[r] + full[i]) % 2\n    inv = full[:, n:]\n    return inv\n\ndef heuristic(matrix):\n    matrix_int = (matrix % 2).astype(int)\n    inv_matrix = gf2_inv(matrix_int)\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.5 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.5 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, -(done_cols+done_rows), log_cols+log_rows, col_imbalance+row_imbalance, max_col+max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix_int)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix_int.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'gf2_inv' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 641,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 13
    }
  },
  {
    "id": 722,
    "parent_id": 15,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        log_col = np.log(np.maximum(col_sums, 1))\n        return (np.sum(col_sums), np.sum(log_col))\n    \n    metrics = [\n        compute_metric(matrix),\n        compute_metric(matrix.T),\n        compute_metric(np.linalg.inv(matrix)),\n        compute_metric(np.linalg.inv(matrix).T)\n    ]\n    \n    return min(metrics)\n",
    "evaluation": {
      "fitness": -0.2761761230539226,
      "additional_data": {
        "spearman_correlation": "-0.276176",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 716,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 723,
    "parent_id": 430,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved version with refined weights and additional row terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Enhanced column completion with log(weight + epsilon)\n        col_completion = 1.8 * np.sum(np.log(col_nonzeros + 0.5))\n        \n        # Column and row distribution penalties\n        col_dist = 0.7 * np.sum(np.abs(col_sums - 1)) / n\n        row_dist = 0.7 * np.sum(np.abs(row_sums - 1)) / n\n        \n        # Balanced sparsity term considering both dimensions\n        sparsity = 0.5 * (np.log((np.sum(col_nonzeros) + 0.5) + np.log((np.sum(row_nonzeros) + 0.5)))\n        \n        return (col_completion, col_dist + row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 22)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 714,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 724,
    "parent_id": 565,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def is_permutation(m):\n        return np.all(np.sum(m, axis=1) == 1) and np.all(np.sum(m, axis=0) == 1)\n    \n    def get_heuristic(m):\n        if is_permutation(m):\n            return (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n        \n        row_nonzeros = np.sum(m, axis=1)\n        col_nonzeros = np.sum(m, axis=0)\n        \n        # Basic metrics\n        row_entropy = -np.sum(row_nonzeros * np.log(row_nonzeros + 1e-10))\n        col_entropy = -np.sum(col_nonzeros * np.log(col_nonzeros + 1e-10))\n        total_ones = np.sum(m)\n        \n        # Linear algebra metrics\n        try:\n            _, _, u = lu(m)\n            rank = np.sum(np.abs(np.diag(u)) > 1e-10)\n        except:\n            rank = n\n            \n        row_corr = np.linalg.matrix_rank(m)\n        col_corr = np.linalg.matrix_rank(m.T)\n        \n        # Spread metrics\n        row_spread = np.sum(np.abs(np.diff(m, axis=1)))\n        col_spread = np.sum(np.abs(np.diff(m, axis=0)))\n        \n        return (row_entropy, col_entropy, total_ones, rank, row_corr, col_corr, row_spread + col_spread)\n    \n    # First check basic variants\n    basic_heuristic = get_heuristic(matrix)\n    transposed_heuristic = get_heuristic(matrix.T)\n    \n    if min(basic_heuristic, transposed_heuristic)[2] > n * 0.8:  # Only compute inverse if matrix is dense\n        try:\n            inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n            inv_heuristic = get_heuristic(inv_matrix)\n            inv_transposed_heuristic = get_heuristic(inv_matrix.T)\n            return min(basic_heuristic, transposed_heuristic, inv_heuristic, inv_transposed_heuristic)\n        except:\n            pass\n            \n    return min(basic_heuristic, transposed_heuristic)\n",
    "evaluation": {
      "fitness": -0.663893759794722,
      "additional_data": {
        "spearman_correlation": "-0.663894",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 713,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 725,
    "parent_id": 515,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with row/column squared imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        return (nonzeros, col_imbalance + row_imbalance)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8705574995070468,
      "additional_data": {
        "spearman_correlation": "0.870557",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 717,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 726,
    "parent_id": 634,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(col_sums)\n        \n        # Basic metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Interaction metrics\n        interaction = np.sum(m @ m.T) - n  # Measures row overlaps\n        col_interaction = np.sum(m.T @ m) - n  # Measures column overlaps\n        \n        # Spread metrics\n        row_spread = np.sum([np.ptp(np.where(row)[0]) if np.any(row) else 0 for row in m])\n        col_spread = np.sum([np.ptp(np.where(col)[0]) if np.any(col) else 0 for col in m.T])\n        \n        # Combined weighted score\n        score = (\n            0.4 * total_ones + \n            0.3 * (col_imbalance + row_imbalance) + \n            0.2 * (interaction + col_interaction) + \n            0.1 * (row_spread + col_spread)\n        )\n        \n        return score\n    \n    # Consider all 4 orientations\n    orientations = [matrix]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        orientations.append(inv_matrix)\n    \n    min_h = float('inf')\n    for mat in orientations:\n        current_h = get_heuristic(mat)\n        if current_h < min_h:\n            min_h = current_h\n        current_h = get_heuristic(mat.T)\n        if current_h < min_h:\n            min_h = current_h\n    \n    return min_h\n",
    "evaluation": {
      "fitness": 0.827287751117452,
      "additional_data": {
        "spearman_correlation": "0.827288",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 715,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 727,
    "parent_id": 186,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and diagonal consideration.\"\"\"\n    import numpy as np\n\n    def gf2_inv(matrix):\n        \"\"\"Compute inverse of binary matrix over GF(2).\"\"\"\n        n = matrix.shape[0]\n        mat_int = matrix.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for i in range(n):\n            if aug[i, i] == 0:\n                for j in range(i+1, n):\n                    if aug[j, i] == 1:\n                        aug[[i, j]] = aug[[j, i]]\n                        break\n                else:\n                    raise ValueError(\"Matrix is singular.\")\n            for j in range(n):\n                if j != i and aug[j, i] == 1:\n                    aug[j] = (aug[j] + aug[i]) % 2\n        return aug[:, n:].astype(int)\n\n    def get_heuristic(m):\n        \"\"\"Compute heuristic tuple for a single matrix with adjusted weights.\"\"\"\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        diag_sum = np.sum(np.diag(m))\n        \n        # Adjusted logarithmic imbalance with better handling of near-1 values\n        log_imbalance = 0.6*np.sum(np.log(col_sums + 0.05)) + 0.4*np.sum(np.log(row_sums + 0.05))\n        \n        # Weighted absolute imbalance with adjusted weights\n        abs_imbalance = 0.65*np.sum(np.abs(col_sums - 1)) + 0.35*np.sum(np.abs(row_sums - 1))\n        \n        # Variance terms with diagonal consideration\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        # Sorted distributions with diagonal bonus\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, log_imbalance, abs_imbalance, col_var, row_var, diag_sum, *sorted_cols, *sorted_rows)\n    \n    # Generate candidate matrices\n    try:\n        inv_matrix = gf2_inv(matrix)\n        candidates = [\n            matrix,\n            matrix.T,\n            inv_matrix,\n            inv_matrix.T\n        ]\n    except:\n        candidates = [matrix, matrix.T]\n    \n    # Return minimal heuristic across candidates\n    return min(get_heuristic(cand) for cand in candidates)\n",
    "evaluation": {
      "fitness": 0.8715959492705614,
      "additional_data": {
        "spearman_correlation": "0.871596",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 711,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 728,
    "parent_id": 104,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted column/row sum weighting.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(0.7 * np.sum(np.log(col_sums)) + 0.3 * np.sum(np.log(row_sums)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    h_inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.3590128947728273,
      "additional_data": {
        "spearman_correlation": "0.359013",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 719,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 729,
    "parent_id": 641,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums + 1e-10))\n        log_rows = np.sum(np.log(row_sums + 1e-10))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Improved spread metric with exponential weights and squared differences\n        rows, cols = m.shape\n        row_weights = np.exp(np.arange(rows, 0, -1)/rows)\n        col_weights = np.exp(np.arange(cols, 0, -1)/cols)\n        row_diff = np.sum(np.square(np.diff(m, axis=0)) * row_weights[:-1, np.newaxis])\n        col_diff = np.sum(np.square(np.diff(m, axis=1)) * col_weights[np.newaxis, :-1])\n        spread = row_diff + col_diff\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants if np.linalg.det(m) != 0]\n    return min(all_metrics) if all_metrics else calculate_metrics(matrix)\n",
    "evaluation": {
      "fitness": 0.8725586169401797,
      "additional_data": {
        "spearman_correlation": "0.872559",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 718,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 730,
    "parent_id": 665,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and term balancing.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        basis_cols = np.sum(col_sums == 1)\n        basis_rows = np.sum(row_sums == 1)\n        \n        rank = np.linalg.matrix_rank(m)\n        total_ones = np.sum(m)\n        n = m.shape[0]\n        \n        return (log_cols + 0.9*log_rows,  # Slightly adjusted weights\n                rank/n,                    # Scaled rank term\n                (basis_cols + basis_rows)/n, # Scaled basis term\n                total_ones/(n**2))         # Normalized ones count\n    \n    metrics = calculate_metrics(matrix)\n    trans_metrics = calculate_metrics(matrix.T)\n    \n    return min(metrics, trans_metrics)\n",
    "evaluation": {
      "fitness": 0.7941317736951685,
      "additional_data": {
        "spearman_correlation": "0.794132",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 721,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 731,
    "parent_id": 388,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based heuristic with logarithmic weighting\n        col_heuristic = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Row-based heuristic\n        row_heuristic = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Interaction between columns and rows\n        interaction = np.sum(m * np.outer(row_sums, col_sums))\n        \n        return col_heuristic + row_heuristic + interaction\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.06741902134153088,
      "additional_data": {
        "spearman_correlation": "-0.067419",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 725,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 732,
    "parent_id": 578,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column completion levels (distance to basis vectors)\n        completion = []\n        for col in m.T:\n            dists = [np.sum(np.abs(col - basis)) for basis in np.eye(n)]\n            min_dist = min(dists)\n            completion.append(min_dist)\n        completion_score = np.sum(completion)\n        \n        # Column interaction potential\n        interaction = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                interaction += np.sum(m[:,i] & m[:,j])\n        \n        # Row dependency metric\n        row_deps = 0\n        for i in range(n):\n            for j in range(n):\n                if i != j and np.any(m[i] & m[j]):\n                    row_deps += 1\n        \n        # Structural metrics\n        nonzeros = np.count_nonzero(m)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (completion_score, interaction, nonzeros, row_deps, max_col + max_row)\n    \n    # Generate systematic permutation variants\n    variants = [matrix, matrix.T, np.linalg.inv(matrix), np.linalg.inv(matrix).T]\n    \n    # Add column permutations of first/last columns (often most important)\n    for i in [0, -1]:\n        perm = np.arange(n)\n        perm[i], perm[0] = perm[0], perm[i]\n        variants.append(matrix[:, perm])\n        variants.append(matrix[perm, :])\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'n' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 720,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 733,
    "parent_id": 598,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Enhanced column metrics\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_product = np.prod(col_sums)\n        col_imbalance = np.sum(np.abs(col_sums - 1) + np.abs(np.log2(np.maximum(col_sums, 1))))\n        \n        # Enhanced row metrics\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_product = np.prod(row_sums)\n        row_imbalance = np.sum(np.abs(row_sums - 1) + np.abs(np.log2(np.maximum(row_sums, 1))))\n        \n        # Combined metrics\n        total_imbalance = col_imbalance + row_imbalance\n        log_combined = log_cols + log_rows\n        product_combined = col_product * row_product\n        \n        # Sorted features for better lex ordering\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, total_imbalance, log_combined, product_combined, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8826240575285841,
      "additional_data": {
        "spearman_correlation": "0.882624",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 723,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 734,
    "parent_id": 115,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on matrix structure and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Interaction metrics\n        interaction = np.sum(m @ m.T)\n        col_interaction = np.sum(m.T @ m)\n        \n        # Rank metric\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column entropy\n        col_entropy = -np.sum(col_sums * np.log(col_sums + 1e-10))\n        \n        return (nonzeros, \n                -interaction, \n                -col_interaction, \n                n - rank, \n                col_entropy, \n                -done_cols - done_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 724,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 735,
    "parent_id": 641,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Normalized column and row metrics\n        norm_cols = np.sum(col_sums) / n\n        norm_rows = np.sum(row_sums) / n\n        \n        # Prioritize columns/rows with single 1s\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        # Structural patterns: count diagonal and anti-diagonal elements\n        diag = np.sum(np.diag(m))\n        anti_diag = np.sum(np.diag(np.fliplr(m)))\n        \n        # Weighted difference metrics\n        row_diff = np.sum(np.abs(np.diff(m, axis=0)) * np.arange(n-1, 0, -1)[:, np.newaxis])\n        col_diff = np.sum(np.abs(np.diff(m, axis=1)) * np.arange(n-1, 0, -1)[np.newaxis, :])\n        \n        # Combine metrics with dynamic weights\n        metrics = (\n            -single_cols - single_rows,  # Prioritize single 1s\n            norm_cols + norm_rows,      # Sum of normalized sums\n            -(diag + anti_diag),        # Structural patterns\n            row_diff + col_diff         # Weighted differences\n        )\n        return metrics\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8418910093387203,
      "additional_data": {
        "spearman_correlation": "0.841891",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 728,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 736,
    "parent_id": 443,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def compute_features(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Features for columns\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        col_near_id = np.sum(col_sums * (col_sums <= 1.5))\n        \n        # Features for rows\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        row_near_id = np.sum(row_sums * (row_sums <= 1.5))\n        \n        # Count of identity-like columns\n        id_cols = np.sum([np.allclose(m[:,i], np.eye(n)[:,i]) for i in range(n)])\n        \n        return (col_log + row_log, col_near_id + row_near_id, -id_cols)\n    \n    def get_best_permutation_features(m):\n        n = m.shape[0]\n        best_features = compute_features(m)\n        if n <= 4:  # Only try permutations for small matrices\n            for perm in permutations(range(n)):\n                permuted = m[:, list(perm)]\n                current_features = compute_features(permuted)\n                if current_features < best_features:\n                    best_features = current_features\n        return best_features\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix),\n        np.linalg.inv(matrix).T\n    ]\n    \n    all_features = []\n    for variant in variants:\n        all_features.append(get_best_permutation_features(variant))\n    \n    # Combine features from all variants\n    combined = tuple(\n        min(feat[i] for feat in all_features) \n        for i in range(len(all_features[0]))\n    )\n    \n    return combined\n",
    "evaluation": {
      "fitness": -0.2831581033832999,
      "additional_data": {
        "spearman_correlation": "-0.283158",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 730,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 737,
    "parent_id": 76,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    total_ones = np.sum(matrix)\n    h_original = (total_ones - n) / 2.0\n\n    def binary_inverse(m):\n        n_inv = m.shape[0]\n        inv = np.eye(n_inv, dtype=int)\n        for col in range(n_inv):\n            pivot = -1\n            for row in range(col, n_inv):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n_inv):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n\n    inv_matrix = binary_inverse(matrix.copy())\n    if inv_matrix is not None:\n        total_inv = np.sum(inv_matrix)\n        h_inv = (total_inv - n) / 2.0\n    else:\n        h_inv = float('inf')\n\n    return min(h_original, h_inv)\n",
    "evaluation": {
      "fitness": 0.8636001767289562,
      "additional_data": {
        "spearman_correlation": "0.863600",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 623,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 738,
    "parent_id": 390,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row metrics with entropy and interaction terms.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column and row completion with entropy weighting\n        col_completion = entropy(col_nonzeros + 1)\n        row_completion = entropy(row_nonzeros + 1)\n        \n        # Enhanced column/row interaction terms\n        col_interaction = np.sum(np.abs(np.dot(m.T, m) - np.eye(n)))\n        row_interaction = np.sum(np.abs(np.dot(m, m.T) - np.eye(n)))\n        \n        # Entropy-based sparsity measurement\n        sparsity = entropy(m.flatten() + 1)\n        \n        # Cross term measuring column-row alignment\n        cross_term = np.sum(np.abs(np.sum(m, axis=0) - np.sum(m, axis=1)))\n        \n        # Combine components into single float\n        return (col_completion + row_completion + col_interaction + \n                row_interaction + sparsity + cross_term)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.12703171088950885,
      "additional_data": {
        "spearman_correlation": "0.127032",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 731,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 739,
    "parent_id": 52,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Enhanced column metrics\n        basis_distances = []\n        for col in m.T:\n            if np.sum(col) == 0:\n                basis_distances.append(n)\n            else:\n                basis_distances.append(min(np.sum(col != basis) for basis in np.eye(n))\n        min_basis_dist = min(basis_distances)\n        avg_basis_dist = np.mean(basis_distances)\n        \n        # Column interaction metrics\n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        # Spread metric\n        spread = np.sum(np.abs(col_sums - np.mean(col_sums)))\n        \n        # Enhanced log metrics\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        \n        # Weighted combination of metrics\n        return (log_cols + log_rows,\n                min_basis_dist,\n                avg_basis_dist,\n                col_interactions,\n                spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 16)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 732,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 740,
    "parent_id": 543,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    A = matrix.copy().astype(int)\n    I = np.eye(n, dtype=int)\n    \n    for col in range(n):\n        pivot = np.where(A[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            return None\n        pivot = pivot[0] + col\n        \n        if pivot != col:\n            A[[col, pivot]] = A[[pivot, col]]\n            I[[col, pivot]] = I[[pivot, col]]\n            \n        for r in range(n):\n            if r != col and A[r, col]:\n                A[r] = (A[r] + A[col]) % 2\n                I[r] = (I[r] + I[col]) % 2\n    return I\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    \n    def compute_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(m)\n        \n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        \n        bad_cols = n - done_cols - almost_done_cols\n        bad_rows = n - done_rows - almost_done_rows\n        \n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        col_interactions = np.sum(col_sums**2)\n        row_interactions = np.sum(row_sums**2)\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        \n        max_col_diff = max_col - min_col\n        max_row_diff = max_row - min_row\n        \n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        \n        return (nonzeros - n,\n                n - done_cols,\n                n - done_rows,\n                bad_cols,\n                bad_rows,\n                log_cols + log_rows,\n                col_interactions + row_interactions,\n                max_col,\n                max_row,\n                min_col,\n                min_row,\n                max_col_diff,\n                max_row_diff,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_orig = compute_heuristic(matrix)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_inv = compute_heuristic(inv_matrix) if inv_matrix is not None else h_orig\n    \n    h_trans = compute_heuristic(matrix.T)\n    \n    return min(h_orig, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 651,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 741,
    "parent_id": 737,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    total_ones = np.sum(matrix)\n    h_original = (total_ones - n) / 2.0\n    \n    def binary_inverse(m):\n        n_inv = m.shape[0]\n        inv = np.eye(n_inv, dtype=int)\n        for col in range(n_inv):\n            pivot = -1\n            for row in range(col, n_inv):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n_inv):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    inv_matrix = binary_inverse(matrix.copy())\n    if inv_matrix is not None:\n        total_inv = np.sum(inv_matrix)\n        h_inv = (total_inv - n) / 2.0\n    else:\n        h_inv = float('inf')\n    \n    trans_matrix = matrix.T.copy()\n    total_trans = np.sum(trans_matrix)\n    h_trans = (total_trans - n) / 2.0\n    \n    inv_trans_matrix = binary_inverse(trans_matrix.copy())\n    if inv_trans_matrix is not None:\n        total_inv_trans = np.sum(inv_trans_matrix)\n        h_inv_trans = (total_inv_trans - n) / 2.0\n    else:\n        h_inv_trans = float('inf')\n    \n    column_weights = np.sum(matrix, axis=0)\n    log_col_weights = np.sum(np.log2(column_weights + 1))\n    \n    min_h = min(h_original, h_inv, h_trans, h_inv_trans)\n    return (min_h, log_col_weights)\n",
    "evaluation": {
      "fitness": 0.864792765705575,
      "additional_data": {
        "spearman_correlation": "0.864793",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 733,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 742,
    "parent_id": 54,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Weight columns/rows by their uniqueness\n        _, col_counts = np.unique(m, axis=0, return_counts=True)\n        _, row_counts = np.unique(m, axis=1, return_counts=True)\n        col_weights = 1 / (1 + col_counts)\n        row_weights = 1 / (1 + row_counts)\n        \n        # Distance to identity\n        identity_dist = np.sum(m != np.eye(n))\n        \n        # Column-row interactions\n        interactions = np.sum(np.abs(m @ m.T - np.eye(n)))\n        \n        # Combine terms\n        col_term = np.sum(col_sums * col_weights)\n        row_term = np.sum(row_sums * row_weights)\n        return (identity_dist, interactions, col_term + row_term)\n    \n    original = matrix_score(matrix)\n    transposed = matrix_score(matrix.T)\n    return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.4213031411403616,
      "additional_data": {
        "spearman_correlation": "0.421303",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 736,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 743,
    "parent_id": 270,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with diagonal correctness and weighted matches.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count diagonal correctness\n        diagonal_correct = np.sum(np.diag(m) == len(m))\n        off_diagonal_zeros = np.sum(m) - np.sum(np.diag(m))\n        \n        # Weight exact matches more heavily\n        cols = m.T\n        exact_col_pairs = 0\n        near_col_pairs = 0\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                diff = np.sum(cols[i] != cols[j])\n                if diff == 0:\n                    exact_col_pairs += 2  # increased weight\n                elif diff == 1:\n                    near_col_pairs += 1\n        \n        rows = m\n        exact_row_pairs = 0\n        near_row_pairs = 0\n        for i in range(len(rows)):\n            for j in range(i+1, len(rows)):\n                diff = np.sum(rows[i] != rows[j])\n                if diff == 0:\n                    exact_row_pairs += 2  # increased weight\n                elif diff == 1:\n                    near_row_pairs += 1\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(col_sums == 0) + np.sum(col_sums == len(col_sums))\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + np.sum(row_sums == 0) + np.sum(row_sums == len(row_sums))\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -exact_col_pairs, -near_col_pairs,\n                -exact_row_pairs, -near_row_pairs,\n                diagonal_correct, off_diagonal_zeros,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8824112847561064,
      "additional_data": {
        "spearman_correlation": "0.882411",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 734,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 744,
    "parent_id": 179,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and log2.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))  # log2 and adjusted weight\n        log_rows = 1.2 * np.sum(np.log2(np.maximum(row_sums, 1)))  # log2 and adjusted weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))  # Adjusted weight\n        row_imbalance = 1.7 * np.sum(np.abs(row_sums - 1))  # Adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        rank = np.linalg.matrix_rank(m)\n        return (nonzeros, -done_cols-done_rows, \n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, rank, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8828087364758499,
      "additional_data": {
        "spearman_correlation": "0.882809",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 735,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 745,
    "parent_id": 627,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with better tuple ordering.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_weight = np.sum(col_sums)\n        incomplete_cols = np.sum(col_sums != 1)\n        incomplete_rows = np.sum(row_sums != 1)\n        \n        return (incomplete_cols, incomplete_rows, total_weight)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.3657923321815144,
      "additional_data": {
        "spearman_correlation": "0.365792",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 738,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 746,
    "parent_id": 199,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for k in range(n):\n            # Find pivot in column k\n            pivot = -1\n            for r in range(k, n):\n                if aug[r, k] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                for c in range(k+1, n):\n                    for r in range(k, n):\n                        if aug[r, c] == 1:\n                            # Swap columns k and c\n                            aug[:, [k, c]] = aug[:, [c, k]]\n                            pivot = r\n                            break\n                    if pivot != -1:\n                        break\n                if pivot == -1:\n                    return None  # Not invertible (shouldn't happen for GL)\n            if pivot != k:\n                # Swap pivot row with k\n                aug[[k, pivot]] = aug[[pivot, k]]\n            for i in range(n):\n                if i != k and aug[i, k] == 1:\n                    aug[i, :] = (aug[i, :] + aug[k, :]) % 2\n        return aug[:, n:]\n\n    def gaussian_elimination_cost(mat):\n        n = mat.shape[0]\n        mat = mat.copy().astype(int)\n        cost = 0\n        # Forward elimination\n        for k in range(n):\n            # Find pivot in column k from row k to end\n            pivot_row = -1\n            for r in range(k, n):\n                if mat[r, k] == 1:\n                    pivot_row = r\n                    break\n            if pivot_row == -1:\n                # Find pivot in other columns\n                for c in range(k+1, n):\n                    for r in range(k, n):\n                        if mat[r, c] == 1:\n                            # Swap columns k and c\n                            mat[:, [k, c]] = mat[:, [c, k]]\n                            pivot_row = r\n                            break\n                    if pivot_row != -1:\n                        break\n                if pivot_row == -1:\n                    continue  # Skip if no pivot found\n            if pivot_row != k:\n                # Swap rows\n                mat[[k, pivot_row]] = mat[[pivot_row, k]]\n            # Eliminate\n            for i in range(k+1, n):\n                if mat[i, k] == 1:\n                    mat[i, :] = (mat[i, :] + mat[k, :]) % 2\n                    cost += 1\n        # Backward elimination\n        for k in range(n-1, -1, -1):\n            for i in range(k):\n                if mat[i, k] == 1:\n                    mat[i, :] = (mat[i, :] + mat[k, :]) % 2\n                    cost += 1\n        return cost\n\n    n = matrix.shape[0]\n    options = [matrix.astype(int)]\n    # Compute inverse if possible\n    try:\n        inv = gf2_inv(matrix.astype(int))\n        if inv is not None:\n            options.append(inv)\n    except:\n        pass\n    # Always include transpose\n    options.append(matrix.T.astype(int))\n\n    best_tuple = (float('inf'), float('inf'))\n    for opt in options:\n        total_ones = np.sum(opt)\n        lower_bound = total_ones - n\n        if lower_bound < 0:\n            lower_bound = 0\n        upper_bound = gaussian_elimination_cost(opt)\n        current_tuple = (lower_bound, upper_bound)\n        if current_tuple < best_tuple:\n            best_tuple = current_tuple\n    return best_tuple\n",
    "evaluation": {
      "fitness": 0.8666585820599265,
      "additional_data": {
        "spearman_correlation": "0.866659",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 596,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 747,
    "parent_id": 266,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic using matrix norms, column proximity, and weighted features.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column features\n        sorted_cols = tuple(sorted(col_sums))\n        col_proximity = np.sum(np.exp(-np.abs(col_sums - 1)))\n        log_col_sums = np.sum(np.log2(col_sums + 1))\n        \n        # Row features\n        row_proximity = np.sum(np.exp(-np.abs(row_sums - 1)))\n        \n        # Matrix structure features\n        frobenius = np.linalg.norm(m, 'fro')\n        diag_dominance = np.sum(np.abs(np.diag(m))) / (np.sum(np.abs(m)) + 1e-9)\n        \n        # Weighted combination prioritizing column patterns\n        return (nonzeros, \n                -col_proximity, \n                log_col_sums, \n                frobenius, \n                -diag_dominance,\n                *sorted_cols)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 739,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 748,
    "parent_id": 48,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                raise ValueError(\"Singular matrix\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        return float(0.65 * np.sum(np.log(col_sums)) + 0.35 * np.sum(np.log(row_sums)))\n    \n    inv = gf2_inv(matrix)\n    h_orig = calculate_heuristic(matrix)\n    h_inv = calculate_heuristic(inv)\n    h_trans = calculate_heuristic(matrix.T)\n    h_inv_trans = calculate_heuristic(inv.T)\n    \n    return min(h_orig, h_inv, h_trans, h_inv_trans)\n",
    "evaluation": {
      "fitness": 0.874372684835882,
      "additional_data": {
        "spearman_correlation": "0.874373",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 671,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 749,
    "parent_id": 713,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column reduction complexity and linear dependencies.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        if np.array_equal(m, np.eye(n)):\n            return (0, 0, 0)\n            \n        # Convert to binary if not already\n        binary_m = (m != 0).astype(int)\n        \n        # Calculate column weights with diminishing returns\n        col_weights = np.sum(binary_m, axis=0)\n        weighted_cols = np.sum(np.sqrt(col_weights))\n        \n        # Measure linear dependencies between columns\n        rank = np.linalg.matrix_rank(binary_m)\n        dependency_penalty = (n - rank) * 0.5\n        \n        # Column reduction potential\n        reduction_potential = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                reduction_potential += np.sum(binary_m[:,i] & binary_m[:,j])\n        \n        return (weighted_cols, dependency_penalty, reduction_potential)\n    \n    variants = [\n        matrix,\n        matrix.T,\n    ]\n    \n    # Only add inverses if they are binary\n    try:\n        inv = np.linalg.inv(matrix)\n        if np.all(inv == inv.astype(int)):\n            variants.append(inv)\n        inv_t = np.linalg.inv(matrix.T)\n        if np.all(inv_t == inv_t.astype(int)):\n            variants.append(inv_t)\n    except:\n        pass\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8794783444165833,
      "additional_data": {
        "spearman_correlation": "0.879478",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 741,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 750,
    "parent_id": 516,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Enhanced column/row features\n        col_entropy = np.sum(-(col_sums/n) * np.log2(np.where(col_sums > 0, col_sums/n, 1)))\n        row_entropy = np.sum(-(row_sums/n) * np.log2(np.where(row_sums > 0, row_sums/n, 1)))\n        \n        # Block structure detection\n        block_score = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j]:\n                    neighbors = 0\n                    if i > 0 and m[i-1,j]: neighbors += 1\n                    if i < n-1 and m[i+1,j]: neighbors += 1\n                    if j > 0 and m[i,j-1]: neighbors += 1\n                    if j < n-1 and m[i,j+1]: neighbors += 1\n                    block_score += neighbors\n        \n        # Diagonal dominance\n        diag = np.sum(np.diag(m))\n        anti_diag = np.sum(np.diag(np.fliplr(m)))\n        diag_score = max(diag, anti_diag)\n        \n        # Pattern features\n        pattern_score = 0\n        for i in range(n-1):\n            for j in range(n-1):\n                if m[i,j] and m[i+1,j] and m[i,j+1] and m[i+1,j+1]:\n                    pattern_score += 1\n        \n        # Combined features\n        entropy = col_entropy + row_entropy\n        structure = block_score + pattern_score\n        balance = abs(np.sum(col_sums) - np.sum(row_sums))\n        \n        return (entropy, structure, diag_score, balance, np.sum(col_sums), np.sum(row_sums))\n    \n    # Consider all matrix variants\n    variants = [matrix]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        variants.append(inv_matrix)\n    variants.append(matrix.T)\n    if inv_matrix is not None:\n        variants.append(inv_matrix.T)\n    \n    # Also consider row/column permutations\n    for _ in range(2):\n        perm = np.random.permutation(n)\n        variants.append(matrix[perm,:])\n        variants.append(matrix[:,perm])\n        if inv_matrix is not None:\n            variants.append(inv_matrix[perm,:])\n            variants.append(inv_matrix[:,perm])\n    \n    # Return the minimum heuristic across all variants\n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 740,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 751,
    "parent_id": 117,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Measure how close to permutation matrix\n        perm_distance = np.sum((m > 0).astype(int) * (1 - m)**2)\n        \n        # Combined row and column imbalance\n        col_imbalance = np.sum((col_sums - 1) ** 2)\n        row_imbalance = np.sum((row_sums - 1) ** 2)\n        combined_imbalance = col_imbalance + row_imbalance\n        \n        # Consider sorted patterns of both rows and columns\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, combined_imbalance, perm_distance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inv_trans = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inv_trans)\n",
    "evaluation": {
      "fitness": 0.8698482968109547,
      "additional_data": {
        "spearman_correlation": "0.869848",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 742,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 6
    }
  },
  {
    "id": 752,
    "parent_id": 431,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with absolute imbalance and enhanced diagonal measure.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count matching column pairs\n        cols = m.T\n        col_pairs = sum(np.array_equal(cols[i], cols[j]) \n                       for i in range(len(cols)) \n                       for j in range(i+1, len(cols)))\n        \n        # Count matching row pairs\n        rows = m\n        row_pairs = sum(np.array_equal(rows[i], rows[j])\n                       for i in range(len(rows))\n                       for j in range(i+1, len(rows)))\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # Changed to absolute error\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Enhanced diagonal measure\n        diag = np.diag(m)\n        diag_score = np.sum(np.abs(diag - np.eye(len(diag), dtype=int)))\n        \n        return (nonzeros, col_imbalance + row_imbalance, \n                -(col_pairs + row_pairs), -diag_score, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8763467826686662,
      "additional_data": {
        "spearman_correlation": "0.876347",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 743,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 753,
    "parent_id": 321,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column/row patterns and diagonal properties.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def analyze(m):\n        n = m.shape[0]\n        col_props = []\n        row_props = []\n        col_ones = 0\n        row_ones = 0\n        \n        for i in range(n):\n            col = m[:, i]\n            row = m[i, :]\n            col_weight = np.sum(col)\n            row_weight = np.sum(row)\n            col_props.append((col_weight, int(col[i]), np.sum(col[i+1:])))\n            row_props.append((row_weight, int(row[i]), np.sum(row[i+1:])))\n            if col_weight == 1:\n                col_ones += 1\n            if row_weight == 1:\n                row_ones += 1\n            \n        diag = np.diag(m)\n        diag_sum = np.sum(diag)\n        off_diag = np.sum(m) - diag_sum\n        \n        col_weights = sorted([p[0] for p in col_props], reverse=True)\n        row_weights = sorted([p[0] for p in row_props], reverse=True)\n        col_diag = sum(p[1] for p in col_props)\n        row_diag = sum(p[1] for p in row_props)\n        col_tri = sum(p[2] for p in col_props)\n        row_tri = sum(p[2] for p in row_props)\n        \n        return (\n            off_diag,\n            diag_sum,\n            tuple(col_weights),\n            tuple(row_weights),\n            col_diag + row_diag,\n            col_tri + row_tri,\n            -(col_ones + row_ones)\n        )\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    h_original = analyze(matrix)\n    h_inverse = analyze(inv_matrix)\n    h_transpose = analyze(matrix.T)\n    h_inverse_transpose = analyze(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.7678943740422519,
      "additional_data": {
        "spearman_correlation": "0.767894",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 744,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 754,
    "parent_id": 425,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved with squared differences and column interaction term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Row distribution penalty using squared differences\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # Improved sparsity term\n        sparsity = np.sum(np.log2(row_nonzeros + 1)) - n\n        \n        # Column interaction term\n        interaction = np.sum((m.T @ m) * (1 - np.eye(n)))\n        \n        return (col_completion, col_dist, row_dist, sparsity, interaction)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8825661508034418,
      "additional_data": {
        "spearman_correlation": "0.882566",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 747,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 755,
    "parent_id": 702,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Enhanced column metrics with exponential weighting\n        col_weights = np.sort(col_sums)\n        col_progress = np.sum(np.exp(-np.minimum(np.abs(col_weights - 1), np.abs(col_weights))))\n        col_log_penalty = np.sum(np.log2(1 + np.maximum(np.abs(col_weights - 1), np.abs(col_weights))))\n        \n        # Enhanced row metrics with exponential weighting\n        row_weights = np.sort(row_sums)\n        row_progress = np.sum(np.exp(-np.minimum(np.abs(row_weights - 1), np.abs(row_weights))))\n        row_log_penalty = np.sum(np.log2(1 + np.maximum(np.abs(row_weights - 1), np.abs(row_weights))))\n        \n        # Matrix structure metrics with diagonal emphasis\n        diff = m - np.eye(n, dtype=int)\n        upper_tri = np.sum(np.abs(np.triu(diff)))\n        lower_tri = np.sum(np.abs(np.tril(diff)))\n        diag_penalty = np.sum(np.abs(np.diag(diff)))\n        \n        return (\n            -col_progress - row_progress,\n            col_log_penalty + row_log_penalty,\n            upper_tri + lower_tri + diag_penalty\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix[::-1],\n        matrix[:, ::-1]\n    ]\n    \n    return min(evaluate(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.2235649586501918,
      "additional_data": {
        "spearman_correlation": "0.223565",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 748,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 756,
    "parent_id": 568,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def binary_entropy(m):\n        p = np.mean(m)\n        if p == 0 or p == 1:\n            return 0\n        return -p * np.log2(p) - (1-p) * np.log2(1-p)\n    \n    def matrix_features(m):\n        m = m.astype(float)\n        n = m.shape[0]\n        \n        # Basic statistics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Advanced features\n        rank = np.linalg.matrix_rank(m)\n        _, lu = scipy.linalg.lu_factor(m)\n        lu_fill = np.count_nonzero(lu) / (n*n)\n        \n        # Interaction terms\n        col_col = np.sum(np.outer(col_sums, col_sums) * (1 - np.eye(n)))\n        row_row = np.sum(np.outer(row_sums, row_sums) * (1 - np.eye(n))\n        \n        # Entropy measures\n        col_entropy = entropy(col_sums + 1e-10)\n        row_entropy = entropy(row_sums + 1e-10)\n        bit_entropy = binary_entropy(m)\n        \n        # Normalized features\n        features = np.array([\n            total_ones / (n*n),\n            rank / n,\n            lu_fill,\n            col_entropy / np.log(n+1),\n            row_entropy / np.log(n+1),\n            bit_entropy,\n            col_col / (n*n*n),\n            row_row / (n*n*n)\n        ])\n        \n        return features\n    \n    def get_variants(m):\n        variants = []\n        \n        # Original and transpose\n        variants.append(matrix_features(m))\n        variants.append(matrix_features(m.T))\n        \n        # Powers of matrix\n        for p in [2,3]:\n            try:\n                power = np.linalg.matrix_power(m, p) % 2\n                variants.append(matrix_features(power))\n                variants.append(matrix_features(power.T))\n            except:\n                pass\n                \n        # Inverse if exists\n        try:\n            inv = np.linalg.inv(m) % 2\n            variants.append(matrix_features(inv))\n            variants.append(matrix_features(inv.T))\n        except:\n            pass\n            \n        return np.array(variants)\n    \n    variants = get_variants(matrix)\n    if len(variants) == 0:\n        return (0,)\n        \n    # Use both mean and min of features across variants\n    mean_features = np.mean(variants, axis=0)\n    min_features = np.min(variants, axis=0)\n    \n    # Combine most important features into tuple\n    return tuple(sorted([\n        mean_features[0] + mean_features[1],  # ones + rank\n        min_features[2] + min_features[6],    # lu fill + col interactions\n        mean_features[3] + mean_features[4],  # column/row entropy\n        min_features[5] + min_features[7]     # bit entropy + row interactions\n    ]))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 28)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 746,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 757,
    "parent_id": 491,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based features\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        cols_near_complete = np.sum(1/(np.abs(col_sums - 1) + 0.1))\n        col_nonzeros = np.count_nonzero(col_sums)\n        \n        # Row-based features (less important)\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Diagonal features\n        diag = np.diag(m)\n        diag_score = np.sum(diag != 1)\n        \n        # Off-diagonal features\n        off_diag = m - np.diag(diag)\n        off_diag_score = np.count_nonzero(off_diag)\n        \n        # Combined metrics\n        col_complexity = log_cols * (1 + off_diag_score/n)\n        diag_complexity = diag_score * (1 + log_rows/n)\n        \n        return (col_complexity, \n                diag_complexity,\n                cols_near_complete,\n                col_nonzeros)\n    \n    # Generate all equivalent matrices\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        matrix @ np.linalg.inv(matrix.T),\n        np.linalg.inv(matrix) @ matrix.T\n    ]\n    \n    # Return minimum heuristic across all variants\n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.07400425348577329,
      "additional_data": {
        "spearman_correlation": "-0.074004",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 749,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 758,
    "parent_id": 621,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Enhanced spread metric using pairwise distances\n        row_dist = np.sum([np.sum(np.abs(m[i] - m[j])) for i in range(m.shape[0]) for j in range(i+1, m.shape[0])])\n        col_dist = np.sum([np.sum(np.abs(m[:,i] - m[:,j])) for i in range(m.shape[1]) for j in range(i+1, m.shape[1])])\n        spread = row_dist + col_dist\n        \n        # Enhanced basis closeness considering both rows and columns\n        basis_closeness = np.sum(np.minimum(col_sums, 1)) + np.sum(np.minimum(row_sums, 1))\n        \n        # Small penalty for matrix size\n        size_penalty = m.shape[0] * 0.01\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread, -basis_closeness, size_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8734587205472963,
      "additional_data": {
        "spearman_correlation": "0.873459",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 750,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 759,
    "parent_id": 559,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        simple_sum = np.sum(m)\n        excess_ones = simple_sum - n\n        return (log_col, log_row, excess_ones)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.fliplr(matrix),\n        np.flipud(matrix),\n        np.rot90(matrix, 1),\n        np.rot90(matrix, 2),\n        np.rot90(matrix, 3)\n    ]\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).round().astype(int) % 2\n        variants.append(inv_matrix)\n    except:\n        pass\n    \n    best_heuristic = None\n    for v in variants:\n        candidate = evaluate(v)\n        if best_heuristic is None or candidate < best_heuristic:\n            best_heuristic = candidate\n    \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.7415117306059166,
      "additional_data": {
        "spearman_correlation": "0.741512",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 705,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 760,
    "parent_id": 646,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0] + col\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Enhanced column metrics\n        done_cols = np.sum(col_sums == 1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        \n        # Enhanced row metrics\n        done_rows = np.sum(row_sums == 1)\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        \n        # Interaction metrics\n        row_col_interaction = np.sum(np.log2(np.maximum(col_sums * row_sums, 1)))\n        clustering_metric = np.sum(np.log2(np.maximum(np.sum(m * m.T, axis=1), 1)))\n        \n        return (nonzeros, \n                -done_cols, \n                -done_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                row_col_interaction,\n                clustering_metric)\n    \n    inv_matrix = gf2_inv(matrix)\n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix) if inv_matrix is not None else h_original\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T) if inv_matrix is not None else h_transpose\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8711477478507197,
      "additional_data": {
        "spearman_correlation": "0.871148",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 751,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 761,
    "parent_id": 142,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with weighted diagonal and adjusted log scaling.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        m = m.astype(float)\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        diag = np.diag(m) + 1e-5\n        return float(0.4*np.sum(np.log(col_sums)) + 0.4*np.sum(np.log(row_sums)) + 0.2*np.sum(np.log(diag)))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    h_inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.44520671653192184,
      "additional_data": {
        "spearman_correlation": "0.445207",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 753,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 762,
    "parent_id": 480,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and terms.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        \"\"\"Compute inverse in GF(2) using Gaussian elimination.\"\"\"\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.2 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 3.0 * np.sum((col_sums - 1)**2)\n        row_imbalance = 2.0 * np.sum((row_sums - 1)**2)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, log_cols + log_rows, \n                col_imbalance + row_imbalance,\n                *sorted_cols, *sorted_rows)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8720314557799225,
      "additional_data": {
        "spearman_correlation": "0.872031",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 752,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 763,
    "parent_id": 509,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def binary_inv(m):\n        try:\n            inv = np.linalg.inv(m)\n            return (np.abs(inv) > 1e-10).astype(float)\n        except:\n            return np.eye(m.shape[0])\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        diag_ones = np.sum(np.diag(m))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        dist_identity = np.sum(np.abs(m - np.eye(m.shape[0])))\n        return (log_col, log_row, total_ones, diag_ones, max_col, max_row, dist_identity)\n    \n    matrices = [\n        matrix,\n        matrix.T,\n        binary_inv(matrix),\n        binary_inv(matrix).T,\n        matrix @ matrix,\n        matrix @ matrix.T,\n        matrix.T @ matrix\n    ]\n    \n    metrics = []\n    for m in matrices:\n        m_metrics = get_metrics(m)\n        metrics.extend(m_metrics)\n    \n    return tuple(metrics)\n",
    "evaluation": {
      "fitness": 0.7907072935751703,
      "additional_data": {
        "spearman_correlation": "0.790707",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 755,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 764,
    "parent_id": 552,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix % 2\n    matrix_inv = np.linalg.inv(matrix) % 2\n    \n    # Consider all 4 variants (original, inverse, transposes)\n    variants = [matrix, matrix_inv, matrix.T, matrix_inv.T]\n    \n    # For each variant, compute multiple features\n    features = []\n    for m in variants:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic sum features\n        total_sum = np.sum(col_sums)\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        \n        # Linear independence features\n        rank = np.linalg.matrix_rank(m)\n        u, s, vh = np.linalg.svd(m)\n        cond_num = s[0] / s[-1] if s[-1] > 0 else float('inf')\n        \n        # Triangularity features\n        upper_tri = np.triu(m).sum()\n        lower_tri = np.tril(m).sum()\n        \n        # Distinctness features\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        features.extend([\n            total_sum,\n            max_col,\n            min_col,\n            rank,\n            cond_num,\n            upper_tri,\n            lower_tri,\n            unique_cols,\n            unique_rows,\n            np.prod(col_sums + 1),\n            np.prod(row_sums + 1)\n        ])\n    \n    # Take log of products to normalize scale\n    log_features = [np.log(f + 1e-10) if f > 0 else 0 for f in features]\n    \n    # Return as tuple to help avoid local minima\n    return tuple(log_features)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 754,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 765,
    "parent_id": 709,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        epsilon = 1e-6\n        \n        col_log_completion = sum(np.log2(col_sums + epsilon))\n        row_log_completion = sum(np.log2(row_sums + epsilon))\n        total_sum = np.sum(col_sums)\n        \n        return (nonzeros, \n                -col_log_completion,\n                -row_log_completion,\n                total_sum)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 757,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 766,
    "parent_id": 288,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.hstack((matrix.astype(int), np.eye(n, dtype=int)))\n    for col in range(n):\n        pivot = np.where(aug[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            return None\n        pivot = pivot[0] + col\n        if pivot != col:\n            aug[[pivot, col]] = aug[[col, pivot]]\n        for r in range(n):\n            if r != col and aug[r, col] == 1:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:]\n\ndef heuristic(matrix):\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(m)\n        \n        num_std_rows = np.sum(row_sums == 1)\n        num_std_cols = np.sum(col_sums == 1)\n        total_std = num_std_rows + num_std_cols\n        \n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        col_imbalance += 2 * np.sum(col_sums == 0)\n        col_imbalance += 2 * np.sum(col_sums == n)\n        \n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        row_imbalance += 2 * np.sum(row_sums == 0)\n        row_imbalance += 2 * np.sum(row_sums == n)\n        \n        total_imbalance = col_imbalance + row_imbalance\n        return (nonzeros, -total_std, total_imbalance)\n    \n    m_int = matrix.astype(int)\n    h_orig = get_heuristic(m_int)\n    h_trans = get_heuristic(m_int.T)\n    \n    inv = gf2_inv(m_int)\n    if inv is not None:\n        h_inv = get_heuristic(inv)\n        return min(h_orig, h_trans, h_inv)\n    return min(h_orig, h_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 694,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 767,
    "parent_id": 597,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on distance to identity.\"\"\"\n    import numpy as np\n    \n    def basis_distance(m):\n        n = m.shape[0]\n        row_dist = np.sum(np.count_nonzero(m, axis=1) - 1) ** 2\n        col_dist = np.sum(np.count_nonzero(m, axis=0) - 1) ** 2\n        return row_dist + col_dist\n    \n    def spread_penalty(m):\n        n = m.shape[0]\n        row_spread = np.sum(1 / (np.count_nonzero(m, axis=1) + 0.1))\n        col_spread = np.sum(1 / (np.count_nonzero(m, axis=0) + 0.1))\n        return row_spread + col_spread\n    \n    def rank_deficiency(m):\n        return m.shape[0] - np.linalg.matrix_rank(m)\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        if np.array_equal(m, np.eye(n)):\n            return (0, 0, 0)\n        \n        basis_dist = basis_distance(m)\n        spread = spread_penalty(m)\n        rank_def = rank_deficiency(m)\n        \n        return (rank_def, basis_dist, spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.846398142907084,
      "additional_data": {
        "spearman_correlation": "0.846398",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 756,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 768,
    "parent_id": 527,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with corrected GF(2) inverse and tuple components.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat_int = mat.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col]:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        col_sum_deviation = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        col_basis = np.sum(col_nonzeros == 1)\n        \n        row_nonzeros = np.count_nonzero(m, axis=1)\n        row_completion = np.sum(np.log2(row_nonzeros + 1))\n        row_sum_deviation = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        row_basis = np.sum(row_nonzeros == 1)\n        \n        quadrant_size = max(1, n//2)\n        q1 = m[:quadrant_size, :quadrant_size]\n        q2 = m[:quadrant_size, quadrant_size:]\n        q3 = m[quadrant_size:, :quadrant_size]\n        q4 = m[quadrant_size:, quadrant_size:]\n        block_score = np.log1p(np.abs(\n            np.count_nonzero(q1) + np.count_nonzero(q4) - \n            np.count_nonzero(q2) - np.count_nonzero(q3)))\n        \n        diag_score = np.sum(np.diag(m)) / n\n        \n        return (col_completion + row_completion, \n                col_sum_deviation + row_sum_deviation, \n                block_score, \n                -(col_basis + row_basis), \n                -diag_score)\n    \n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:\n        variants = [matrix, matrix.T]\n    else:\n        variants = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8713720802516506,
      "additional_data": {
        "spearman_correlation": "0.871372",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 704,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 769,
    "parent_id": 99,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with column interactions and rank consideration.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Count done columns/rows\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        \n        # Logarithmic terms\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Column/row interactions\n        unique_cols = len(set(tuple(col) for col in m.T))\n        unique_rows = len(set(tuple(row) for row in m))\n        \n        # Subset relationships\n        col_subset = sum(any(np.all((m[:,i] & m[:,j]) == m[:,i]) \n                           for j in range(m.shape[1]) if j != i) \n                       for i in range(m.shape[1]))\n        row_subset = sum(any(np.all((m[i,:] & m[j,:]) == m[i,:]) \n                           for j in range(m.shape[0]) if j != i) \n                       for i in range(m.shape[0]))\n        \n        # Maximum sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        # Sort sums\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, rank, -done_cols-done_rows, log_cols+log_rows, \n                -unique_cols-unique_rows, col_subset+row_subset, \n                max_col+max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 758,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 10
    }
  },
  {
    "id": 770,
    "parent_id": 311,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def analyze(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Weight columns/rows by how close they are to completion\n        col_weights = np.sum(np.where(col_sums == 1, 0, np.minimum(col_sums, n - col_sums)))\n        row_weights = np.sum(np.where(row_sums == 1, 0, np.minimum(row_sums, n - row_sums)))\n        \n        # Analyze column interactions\n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                col_interactions += min(overlap, n - overlap)\n        \n        # Matrix rank analysis\n        rank = np.linalg.matrix_rank(m)\n        rank_metric = abs(rank - n/2)\n        \n        return (col_weights, row_weights, col_interactions, rank_metric)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    except:\n        inv_matrix = matrix\n    \n    variants = [\n        analyze(matrix),\n        analyze(matrix.T),\n        analyze(inv_matrix),\n        analyze(inv_matrix.T)\n    ]\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 759,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 771,
    "parent_id": 440,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        sum_weights = np.sum(m)\n        \n        h_val = np.sum(np.log2(col_weights)) + 0.05 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8734657940557856,
      "additional_data": {
        "spearman_correlation": "0.873466",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 760,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 772,
    "parent_id": 527,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        # Column-based metrics\n        col_cost = np.sum(np.log2(col_nonzero + 1)) + np.sum(np.abs(col_sums - 1))\n        \n        # Row-based metrics\n        row_cost = np.sum(np.log2(row_nonzero + 1)) + np.sum(np.abs(row_sums - 1))\n        \n        # Combined metric\n        return min(col_cost, row_cost)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(compute_metric(v) for v in variants if np.linalg.det(v) != 0)\n",
    "evaluation": {
      "fitness": 0.7934915496829648,
      "additional_data": {
        "spearman_correlation": "0.793492",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 763,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 773,
    "parent_id": 232,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column interactions and simplified metrics.\"\"\"\n    import numpy as np\n    \n    def matrix_complexity(m):\n        n = m.shape[0]\n        if n == 0:\n            return (0,)\n        \n        # Core column metrics\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(col_sums)\n        \n        # Off-diagonal elements\n        upper = np.triu(m, k=1)\n        lower = np.tril(m, k=-1)\n        off_diag_nnz = np.count_nonzero(upper) + np.count_nonzero(lower)\n        \n        # Column dependencies\n        col_deps = []\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                col_deps.append(overlap)\n        \n        max_col_dep = max(col_deps) if col_deps else 0\n        \n        return (np.count_nonzero(m),\n                -col_nonzeros,\n                off_diag_nnz,\n                max_col_dep)\n    \n    h_original = matrix_complexity(matrix)\n    h_inverse = (float('inf'),)\n    try:\n        inv = np.linalg.inv(matrix)\n        if np.allclose(matrix @ inv, np.eye(matrix.shape[0])):\n            h_inverse = matrix_complexity(inv)\n    except:\n        pass\n    h_transpose = matrix_complexity(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.726433527538402,
      "additional_data": {
        "spearman_correlation": "0.726434",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 762,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 774,
    "parent_id": 592,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_metrics(m):\n        n = m.shape[0]\n        m_binary = (m % 2).astype(int)  # Ensure binary values\n        col_sums = np.sum(m_binary, axis=0)\n        row_sums = np.sum(m_binary, axis=1)\n        nonzeros = np.count_nonzero(m_binary)\n        excess_ones = nonzeros - n\n        \n        col_penalty = np.sum(np.maximum(col_sums - 1, 0))\n        row_penalty = np.sum(np.maximum(row_sums - 1, 0))\n        \n        # Efficient column overlap calculation\n        gram = m_binary.T @ m_binary\n        col_overlap = (gram.sum() - gram.trace()) // 2\n        \n        # Triangularity measures\n        try:\n            L, U = lu(m_binary, permute_l=True)[:2]\n            lower_tri = np.sum(np.tril(L, -1))\n            upper_tri = np.sum(np.triu(U, 1))\n            tri_measure = lower_tri + upper_tri\n        except:\n            tri_measure = n * n  # Large penalty if LU fails\n            \n        # Count good columns and rows (weight 1)\n        col_good = np.sum(col_sums == 1)\n        row_good = np.sum(row_sums == 1)\n        \n        return (excess_ones,\n                col_penalty,\n                row_penalty,\n                col_overlap,\n                tri_measure,\n                -col_good,\n                -row_good)\n    \n    try:\n        h_original = get_metrics(matrix)\n        h_inverse = get_metrics(np.linalg.inv(matrix) % 2)\n        h_transpose = get_metrics(matrix.T % 2)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_metrics(matrix)\n",
    "evaluation": {
      "fitness": 0.7669756248574532,
      "additional_data": {
        "spearman_correlation": "0.766976",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 729,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 775,
    "parent_id": 67,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on row/column dependencies and basis vector counts.\"\"\"\n    import numpy as np\n    \n    def compute_dependency_metrics(m):\n        # Count rows and columns that are already basis vectors\n        basis_rows = np.sum(np.sum(m, axis=1) == 1)\n        basis_cols = np.sum(np.sum(m, axis=0) == 1)\n        \n        # Compute row and column dependency matrices\n        row_deps = m @ m.T\n        col_deps = m.T @ m\n        np.fill_diagonal(row_deps, 0)\n        np.fill_diagonal(col_deps, 0)\n        \n        # Get dependency complexity metrics\n        row_dep_complexity = np.sum(row_deps)\n        col_dep_complexity = np.sum(col_deps)\n        \n        # Original metrics\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        row_imbalance = np.sum(np.abs(np.sum(m, axis=1) - 1))\n        \n        return (m.shape[0] - basis_rows, \n                m.shape[1] - basis_cols,\n                row_dep_complexity + col_dep_complexity,\n                nonzeros,\n                col_imbalance + row_imbalance)\n    \n    # Precompute alternative matrices\n    matrices = [matrix]\n    try:\n        matrices.append(np.linalg.inv(matrix))\n    except:\n        pass\n    matrices.append(matrix.T)\n    \n    # Return minimum heuristic across all variants\n    return min(compute_dependency_metrics(m) for m in matrices)\n",
    "evaluation": {
      "fitness": 0.26530764033517046,
      "additional_data": {
        "spearman_correlation": "0.265308",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 764,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 776,
    "parent_id": 496,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined heuristic with additional variants and weighted column sums.\"\"\"\n    import numpy as np\n    \n    def count_nonzeros(m):\n        return np.count_nonzero(m)\n    \n    def column_row_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        # Modified weighting with epsilon and different exponents\n        weighted_cols = (np.log2(col_sums + 0.1) * (col_sums ** 1.1)\n        weighted_rows = (np.log2(row_sums + 0.1) * (row_sums ** 1.1)\n        return np.sum(weighted_cols) + np.sum(weighted_rows)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    h_nz = min(count_nonzeros(v) for v in variants)\n    h_col_row = min(column_row_metric(v) for v in variants)\n    \n    return (h_nz, h_col_row)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 765,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 777,
    "parent_id": 368,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        for col in range(n):\n            pivot_row = None\n            for r in range(col, n):\n                if aug[r, col]:\n                    pivot_row = r\n                    break\n            if pivot_row is None:\n                return mat\n            aug[[col, pivot_row]] = aug[[pivot_row, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    m_inv = gf2_inv(matrix)\n    variants = [matrix, m_inv, matrix.T, m_inv.T]\n\n    def get_heuristic(m):\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_max = np.max(col_nonzeros)\n        log_sum = np.sum(np.log2(col_nonzeros))\n        return (col_max, log_sum)\n\n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8006013240221369,
      "additional_data": {
        "spearman_correlation": "0.800601",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 700,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 778,
    "parent_id": 18,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        hamming = np.sum(m)\n        \n        main_metric = 0.4 * log_col + 0.4 * log_row + 0.2 * hamming\n        secondary_metric_col = float(np.sum(np.log(col_sums)))\n        secondary_metric_row = float(np.sum(np.log(row_sums)))\n        return main_metric, secondary_metric_col, secondary_metric_row\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    \n    try:\n        inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n        metrics = [original, transposed, inverted]\n    except:\n        metrics = [original, transposed]\n    \n    min_main = min(m[0] for m in metrics)\n    min_sec_col = min(m[1] for m in metrics)\n    min_sec_row = min(m[2] for m in metrics)\n    \n    return (min_main, min_sec_col, min_sec_row)\n",
    "evaluation": {
      "fitness": 0.7219976465356667,
      "additional_data": {
        "spearman_correlation": "0.721998",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 766,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 779,
    "parent_id": 534,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        # Augment with identity matrix\n        aug = np.hstack([matrix, np.eye(n, dtype=int)])\n        # Forward elimination\n        for col in range(n):\n            # Find pivot\n            pivot = col\n            while pivot < n and aug[pivot, col] == 0:\n                pivot += 1\n            if pivot == n:\n                return None  # Shouldn't happen for GL matrix\n            # Swap rows if needed\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            # Eliminate below\n            for row in range(col+1, n):\n                if aug[row, col]:\n                    aug[row] = (aug[row] + aug[col]) % 2\n        # Back substitution\n        for col in range(n-1, -1, -1):\n            for row in range(col-1, -1, -1):\n                if aug[row, col]:\n                    aug[row] = (aug[row] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def compute_metric(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Distance from diagonal\n        diag_dist = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j] == 1:\n                    diag_dist += np.abs(i-j)\n        \n        # Column progress\n        col_progress = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        \n        # Row swap estimation\n        row_swap_cost = 0\n        for i in range(n):\n            if np.sum(m[i,:]) != 1 or np.sum(m[:,i]) != 1:\n                row_swap_cost += 1\n        \n        return diag_dist + col_progress + row_swap_cost\n\n    # Generate matrix variants\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:  # Fallback if inversion fails\n        variants = [matrix, matrix.T]\n    else:\n        variants = [\n            matrix,\n            matrix.T,\n            inv_matrix,\n            inv_matrix.T\n        ]\n    \n    # Compute metrics\n    metrics = [compute_metric(v) for v in variants]\n    min_metric = min(metrics)\n    \n    return (float(compute_metric(matrix)), float(min_metric))\n",
    "evaluation": {
      "fitness": 0.6213764521530541,
      "additional_data": {
        "spearman_correlation": "0.621376",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 737,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 780,
    "parent_id": 613,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        \n        # Column pair interactions\n        col_pairs = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                and_sum = np.sum(m[:,i] & m[:,j])\n                xor_sum = np.sum(m[:,i] ^ m[:,j])\n                col_pairs += min(and_sum, xor_sum)\n        \n        # Row pair interactions\n        row_pairs = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                and_sum = np.sum(m[i,:] & m[j,:])\n                xor_sum = np.sum(m[i,:] ^ m[j,:])\n                row_pairs += min(and_sum, xor_sum)\n        \n        # Column completion metrics\n        col_completion = np.sum(np.abs(col_sums - 1))\n        \n        # Block patterns (2x2 submatrices)\n        block_score = 0\n        for i in range(n-1):\n            for j in range(n-1):\n                block = m[i:i+2, j:j+2]\n                if np.sum(block) in {1, 3}:\n                    block_score += 1\n        \n        return (col_pairs, row_pairs, -col_completion, -block_score)\n    \n    matrix = matrix.astype(int)\n    variations = [\n        matrix,\n        np.linalg.inv(matrix).astype(int) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T).astype(int) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.684917929988691,
      "additional_data": {
        "spearman_correlation": "0.684918",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 769,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 781,
    "parent_id": 563,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import null_space\n    \n    def evaluate_variant(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Enhanced column weighting considering pairwise interactions\n        col_pairs = np.sum([np.sum(m[:,i] & m[:,j]) for i in range(n) for j in range(i+1, n)])\n        weighted_col = np.sum(np.where(col_sums > 0, np.log2(col_sums + 1) + 1/(col_sums**2 + 1), 0)) + 0.5 * col_pairs\n        \n        # Block diagonal measure\n        block_score = 0\n        for i in range(1, n):\n            submatrix = m[:i, i:]\n            block_score += np.sum(submatrix) + np.sum(m[i:, :i])\n        \n        # Rank and null space information\n        rank = np.linalg.matrix_rank(m)\n        null_dim = n - rank\n        null_measure = null_dim * np.log2(null_dim + 1) if null_dim > 0 else 0\n        \n        # Dynamic feature selection\n        features = []\n        features.append(total_ones)\n        features.append(weighted_col)\n        if block_score < total_ones/2:\n            features.append(block_score)\n        if null_measure > 0:\n            features.append(-null_measure)\n        \n        return tuple(features)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix) % 2,\n        np.linalg.inv(matrix.T) % 2,\n        np.eye(matrix.shape[0], dtype=int)  # Identity reference\n    ]\n    \n    scores = [evaluate_variant(v) for v in variants]\n    return min(scores, key=lambda x: (len(x), sum(abs(f) for f in x)))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 768,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 782,
    "parent_id": 694,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_heuristic(m):\n        # Convert to binary to ensure integer operations\n        m = m % 2\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(col_sums)\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (total_ones, max_col, max_row)\n    \n    variants = [\n        simple_heuristic(matrix),\n        simple_heuristic(np.linalg.inv(matrix) % 2),\n        simple_heuristic(matrix.T),\n        simple_heuristic(np.linalg.inv(matrix).T % 2)\n    ]\n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.8343369630231838,
      "additional_data": {
        "spearman_correlation": "0.834337",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 772,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 783,
    "parent_id": 582,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        identity = np.eye(n, dtype=int)\n        aug = np.hstack((mat, identity))\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                raise ValueError(\"Singular matrix\")\n            aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log2(col_sums[col_sums > 1])) \n        row_log = np.sum(np.log2(row_sums[row_sums > 1]))\n        return (total_ones - n, col_log, row_log)\n\n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    try:\n        inv_matrix = gf2_inv(matrix)\n        h_inverse = get_heuristic(inv_matrix)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8691568535482572,
      "additional_data": {
        "spearman_correlation": "0.869157",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 770,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 784,
    "parent_id": 542,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        log_cols = np.sum(np.log(col_sums + 1))\n        near_one = np.sum(np.abs(col_sums - 1) < 0.5)\n        col_variation = np.std(col_sums) / (np.mean(col_sums) + 1e-10)\n        row_sums = np.sum(m, axis=1)\n        row_variation = np.std(row_sums) / (np.mean(row_sums) + 1e-10)\n        return (log_cols, -near_one, col_variation, row_variation)\n    \n    original_metrics = calculate_metrics(matrix)\n    transposed_metrics = calculate_metrics(matrix.T)\n    \n    return min(original_metrics, transposed_metrics)\n",
    "evaluation": {
      "fitness": 0.7838468434842475,
      "additional_data": {
        "spearman_correlation": "0.783847",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 773,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 785,
    "parent_id": 185,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Structural metrics\n        col_overlaps = np.sum(m.T @ m) - n  # Measures column interactions\n        row_overlaps = np.sum(m @ m.T) - n  # Measures row interactions\n        diagonal_match = np.sum(np.diag(m))  # Count of correct diagonal elements\n        off_diagonal = np.sum(m) - diagonal_match  # Off-diagonal elements\n        \n        # Column/row specific metrics\n        col_completion = np.sum(col_sums == 1)\n        row_completion = np.sum(row_sums == 1)\n        col_log = np.sum(np.log2(np.maximum(col_sums, 1)))\n        row_log = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Distance metrics\n        col_dist = np.sum(np.abs(col_sums - 1))\n        row_dist = np.sum(np.abs(row_sums - 1))\n        \n        # Interaction metrics\n        col_interactions = np.sum(np.tril(m.T @ m, -1))\n        row_interactions = np.sum(np.tril(m @ m.T, -1))\n        \n        return (off_diagonal, -col_completion-row_completion, \n                col_overlaps + row_overlaps, \n                col_dist + row_dist,\n                col_log + row_log,\n                col_interactions + row_interactions,\n                diagonal_match,\n                *sorted(col_sums),\n                *sorted(row_sums))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.05424221969981,
      "additional_data": {
        "spearman_correlation": "-0.054242",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 771,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 786,
    "parent_id": 375,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"New heuristic incorporating row metrics, linear weights, and diagonalness.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Linear column completion (weight columns by their sum)\n        col_completion = np.sum(col_sums)\n        \n        # Row completion (weight rows by their sum)\n        row_completion = np.sum(row_sums)\n        \n        # Diagonalness measure (how close to diagonal)\n        diag = np.sum(m * np.eye(n))\n        anti_diag = np.sum(m * np.eye(n)[::-1])\n        diagonalness = max(diag, anti_diag)\n        \n        # Column distribution penalty (absolute deviation from 1)\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        return (col_completion + row_completion, -diagonalness, col_dist)\n    \n    # Generate all equivalent matrices more efficiently\n    m_inv = np.linalg.inv(matrix)\n    variants = [\n        matrix,\n        m_inv,\n        matrix.T,\n        m_inv.T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.28705048318178045,
      "additional_data": {
        "spearman_correlation": "-0.287050",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 776,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 787,
    "parent_id": 200,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import pinv\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        \n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        return (log_col, log_row, total_ones, single_cols, single_rows, -col_variance, -row_variance)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n    except:\n        inv_matrix = pinv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        inv_matrix,\n        inv_matrix.T\n    ]\n    \n    all_metrics = []\n    for variant in variants:\n        metrics = calculate_metrics(variant)\n        weighted = (\n            0.35 * metrics[0] + 0.15 * metrics[1] + 0.1 * metrics[2] +\n            0.15 * metrics[3] + 0.15 * metrics[4] + 0.05 * metrics[5] + 0.05 * metrics[6]\n        )\n        all_metrics.append(weighted)\n    \n    return tuple(sorted(all_metrics, reverse=True))\n",
    "evaluation": {
      "fitness": 0.7608241654321297,
      "additional_data": {
        "spearman_correlation": "0.760824",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 775,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 788,
    "parent_id": 114,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_rank(mat):\n        rank = 0\n        n = mat.shape[0]\n        for col in range(n):\n            pivot = -1\n            for row in range(rank, n):\n                if mat[row, col] == 1:\n                    pivot = row\n                    break\n            if pivot == -1:\n                continue\n            if pivot != rank:\n                mat[[rank, pivot]] = mat[[pivot, rank]]\n            for row in range(rank + 1, n):\n                if mat[row, col] == 1:\n                    mat[row] ^= mat[rank]\n            rank += 1\n        return rank\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = gf2_rank(m.copy())\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        return (nonzeros, rank, col_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7461313165891074,
      "additional_data": {
        "spearman_correlation": "0.746131",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 777,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 789,
    "parent_id": 609,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I)))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        \n        col_entropy = -np.sum(col_sums * np.log2(np.maximum(col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log2(np.maximum(row_sums, 1)))\n        \n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        \n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        \n        return (total_sum, \n                col_entropy + row_entropy, \n                -(single_cols + single_rows),\n                max_col + max_row,\n                col_var + row_var,\n                *sorted(col_sums, reverse=True),\n                *sorted(row_sums, reverse=True))\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    best_heuristic = None\n    for variant in variants:\n        current = compute_metrics(variant)\n        if best_heuristic is None or current < best_heuristic:\n            best_heuristic = current\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unmatched ')' (<string>, line 9)"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 774,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 790,
    "parent_id": 447,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        unique_cols, counts = np.unique(m, axis=1, return_counts=True)\n        total_sum = np.sum(m)\n        \n        col_complexity = np.sum(np.log2(col_sums + 1)) + np.sum(counts-1)\n        row_complexity = np.sum(np.sqrt(row_sums))\n        max_col = np.max(col_sums)\n        \n        main_metric = col_complexity + 0.05 * total_sum\n        secondary_metric = (row_complexity, max_col)\n        return main_metric, secondary_metric\n    \n    original = calculate_metrics(matrix)\n    transposed = calculate_metrics(matrix.T)\n    inverted = calculate_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_main = min(original[0], transposed[0], inverted[0])\n    min_secondary_row = min(original[1][0], transposed[1][0], inverted[1][0])\n    min_secondary_max = min(original[1][1], transposed[1][1], inverted[1][1])\n    \n    return (min_main, (min_secondary_row, min_secondary_max))\n",
    "evaluation": {
      "fitness": 0.7235585310411782,
      "additional_data": {
        "spearman_correlation": "0.723559",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 779,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 791,
    "parent_id": 581,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.trace(m)\n        total_nonzero = np.count_nonzero(m)\n        off_diag_nonzero = total_nonzero - diag_sum\n        \n        # Count how many columns are basis vectors\n        basis_cols = sum(np.any(m[:,i].reshape(-1,1) == np.eye(n), axis=0)\n        \n        # Measure of column \"closeness\" to basis vectors\n        col_basis_dist = np.sum(np.min(np.abs(m[:,:,None] - np.eye(n)[None,:,:]), axis=1))\n        \n        # Rank of the matrix\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column/row spread (entropy-like measure)\n        col_spread = -np.sum((col_sums/np.sum(col_sums)) * np.log(col_sums/np.sum(col_sums) + 1e-10))\n        row_spread = -np.sum((row_sums/np.sum(row_sums)) * np.log(row_sums/np.sum(row_sums) + 1e-10))\n        \n        # Additional structural measures\n        upper_tri = np.triu(m, k=1).sum()\n        lower_tri = np.tril(m, k=-1).sum()\n        \n        return (float(basis_cols), \n                float(-col_basis_dist), \n                float(rank),\n                float(col_spread),\n                float(row_spread),\n                float(total_nonzero),\n                float(diag_sum),\n                float(off_diag_nonzero),\n                float(upper_tri),\n                float(lower_tri))\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 13)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 778,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 792,
    "parent_id": 463,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Returns tuple of (minimum, weighted_avg) of log2 of column sums across original, inverse, and transpose matrices.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return float(np.sum(np.log2(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    weighted_avg = 0.5*original + 0.3*inverse + 0.2*transpose\n    min_val = min(original, inverse, transpose)\n    return (min_val, weighted_avg)\n",
    "evaluation": {
      "fitness": 0.8713663145504523,
      "additional_data": {
        "spearman_correlation": "0.871366",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 784,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 793,
    "parent_id": 581,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_sum = np.trace(m)\n        total_nonzero = np.count_nonzero(m)\n        off_diag_nonzero = total_nonzero - diag_sum\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        h1 = float(np.sum(np.log(col_sums)))\n        h2 = float(np.sum(np.log(row_sums)))\n        h3 = float(total_nonzero)\n        h4 = float(diag_sum)\n        h5 = float(off_diag_nonzero)\n        h6 = float(np.sum(np.abs(col_sums - 1)))\n        return (h1, h2, h3, h4, h5, h6)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8680702386029537,
      "additional_data": {
        "spearman_correlation": "0.868070",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 782,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 794,
    "parent_id": 471,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column/row priorities and nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        col_weights = np.sum(np.abs(m - np.eye(m.shape[0])), axis=0)\n        col_priority = np.sum(col_weights * (1 + np.log(col_sums + 1e-10)))\n        row_priority = np.sum(np.abs(row_sums - 1) * (1 + np.log(row_sums + 1e-10)))\n        \n        return (nonzeros, col_priority + row_priority, *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8504588885731174,
      "additional_data": {
        "spearman_correlation": "0.850459",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 783,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 795,
    "parent_id": 772,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        # Column-based metrics\n        col_weight_cost = np.sum(np.abs(col_sums - 1))\n        col_sparsity_cost = np.sum(np.log2(col_nonzero + 1))\n        col_basis_cost = np.sum((col_sums == 1) & (col_nonzero == 1))\n        \n        # Row-based metrics\n        row_weight_cost = np.sum(np.abs(row_sums - 1))\n        row_sparsity_cost = np.sum(np.log2(row_nonzero + 1))\n        row_basis_cost = np.sum((row_sums == 1) & (row_nonzero == 1))\n        \n        # Spread metric (clustering of 1s)\n        diff_matrix = np.abs(m[:, None] - m)\n        spread_cost = np.sum(diff_matrix) / (m.size * 2)\n        \n        col_metric = col_weight_cost + col_sparsity_cost - col_basis_cost + spread_cost\n        row_metric = row_weight_cost + row_sparsity_cost - row_basis_cost + spread_cost\n        \n        return (col_metric, row_metric)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    valid_variants = [v for v in variants if np.linalg.det(v) != 0]\n    if not valid_variants:\n        return float('inf')\n    \n    metrics = [compute_metrics(v) for v in valid_variants]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.83610064543993,
      "additional_data": {
        "spearman_correlation": "0.836101",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 781,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 796,
    "parent_id": 185,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with structural matrix properties.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        \n        # Structural properties\n        rank = np.linalg.matrix_rank(m)\n        unique_cols = len({tuple(col) for col in m.T})\n        unique_rows = len({tuple(row) for row in m})\n        \n        # Spread metrics\n        col_entropy = np.sum(-(col_sums/np.sum(col_sums)) * np.log2(np.sum(col_sums)+1)\n        row_entropy = np.sum(-(row_sums/np.sum(row_sums)) * np.log2(np.sum(row_sums)+1)\n        \n        # Diagonal dominance\n        diag_dom = np.sum(np.abs(np.diag(m) - 1)) + np.sum(np.abs(m - np.diag(np.diag(m))))\n        \n        # Overlap metrics\n        col_overlap = sum(np.dot(m[:,i], m[:,j]) for i in range(m.shape[1]) for j in range(i+1, m.shape[1]))\n        row_overlap = sum(np.dot(m[i,:], m[j,:]) for i in range(m.shape[0]) for j in range(i+1, m.shape[0]))\n        \n        return (rank, nonzeros, -correct_cols-correct_rows, \n                col_entropy + row_entropy, diag_dom, \n                col_overlap + row_overlap, unique_cols + unique_rows,\n                *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 780,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 797,
    "parent_id": 507,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        total_elements = m.size\n        nonzeros = np.count_nonzero(m) / total_elements\n        col_completion = np.sum(col_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        diagonal = np.sum(np.diag(m) == 1) / m.shape[0]\n        return (nonzeros, -col_completion, log_cols, -diagonal)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8816668079347858,
      "additional_data": {
        "spearman_correlation": "0.881667",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 786,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 798,
    "parent_id": 378,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = np.array(matrix)\n    \n    def calculate_metrics(m):\n        m = np.array(m, dtype=int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        log_sum = col_log + row_log\n        H = np.sum(m)\n        completed_cols = np.sum(col_sums == 1)\n        completed_rows = np.sum(row_sums == 1)\n        completed = completed_cols + completed_rows\n        return (log_sum, H, -completed)\n    \n    # Compute candidates: original, inverse, transpose, inverse-transpose\n    candidates = []\n    candidates.append(calculate_metrics(matrix))\n    \n    inv_float = np.linalg.inv(matrix)\n    inv_matrix = (np.round(inv_float) % 2).astype(int)\n    candidates.append(calculate_metrics(inv_matrix))\n    \n    candidates.append(calculate_metrics(matrix.T))\n    \n    inv_trans_matrix = inv_matrix.T\n    candidates.append(calculate_metrics(inv_trans_matrix))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 722,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 799,
    "parent_id": 545,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with exponential weighting and higher-order imbalances.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Exponential weighting for columns/rows near completion\n        col_weight = np.sum(np.exp(-np.abs(col_sums - 1)))\n        row_weight = np.sum(np.exp(-np.abs(row_sums - 1)))\n        \n        # Higher-order imbalances (4th power)\n        col_imbalance = np.sum((col_sums - 1)**4)\n        row_imbalance = np.sum((row_sums - 1)**4)\n        \n        # Spread metric (variance of nonzero positions)\n        nonzero_pos = np.argwhere(m)\n        if len(nonzero_pos) > 1:\n            spread = np.var(nonzero_pos, axis=0).sum()\n        else:\n            spread = 0\n            \n        # Column clustering (prefer columns with adjacent nonzeros)\n        col_cluster = 0\n        for col in m.T:\n            runs = np.diff(np.where(col)[0])\n            col_cluster += np.sum(runs == 1)\n            \n        return (nonzeros, \n                -col_weight - 0.3*row_weight,  # negative since we want to maximize weight\n                col_imbalance + 0.3*row_imbalance,\n                -spread,  # negative since lower spread is better\n                col_cluster)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inv_trans = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inv_trans)\n",
    "evaluation": {
      "fitness": 0.8822968262060935,
      "additional_data": {
        "spearman_correlation": "0.882297",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 785,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 800,
    "parent_id": 257,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        log_col_sums = sum(log2(s + 1) for s in col_sums)\n        col_completion = sum(1/(s + 1) for s in col_sums)\n        \n        # Row metrics\n        unique_rows = len({tuple(row) for row in m})\n        log_row_sums = sum(log2(s + 1) for s in row_sums)\n        row_completion = sum(1/(s + 1) for s in row_sums)\n        \n        # Combine all metrics into a single float\n        return (nonzeros * 0.5 + \n                -log_col_sums * 0.2 + \n                -col_completion * 0.1 + \n                -basis_cols * 0.1 + \n                -unique_cols * 0.05 + \n                -log_row_sums * 0.02 + \n                -row_completion * 0.02 + \n                -unique_rows * 0.01)\n    \n    # Consider all isomorphic variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T,\n        matrix[:, ::-1],\n        matrix[::-1, :],\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.13523350862354108,
      "additional_data": {
        "spearman_correlation": "0.135234",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 787,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 801,
    "parent_id": 208,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column sums with element-wise minimum across variants.\"\"\"\n    import numpy as np\n    def get_col_sums(m):\n        return np.sum(m, axis=0)\n    \n    col_sums = get_col_sums(matrix)\n    col_sums_inv = get_col_sums(np.linalg.inv(matrix) % 2)\n    col_sums_trans = get_col_sums(matrix.T)\n    \n    min_col_sums = np.minimum.reduce([col_sums, col_sums_inv, col_sums_trans])\n    min_col_sums = np.maximum(min_col_sums, 1)\n    \n    return float(np.sum(np.log(min_col_sums)))\n",
    "evaluation": {
      "fitness": 0.7616516427474967,
      "additional_data": {
        "spearman_correlation": "0.761652",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 792,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 802,
    "parent_id": 631,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and better inverse handling.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m) + 0.2 * np.sum(row_sums)\n        log_col_sums = 0.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = 0.2 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        done_cols = np.sum(col_sums == 1)\n        return (nonzeros, log_col_sums + log_row_sums, -done_cols)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    except:\n        h_inverse = h_original\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8702342169540326,
      "additional_data": {
        "spearman_correlation": "0.870234",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 791,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 803,
    "parent_id": 729,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-5)  # Adjusted epsilon\n        row_sums = np.maximum(row_sums, 1e-5)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        rows, cols = m.shape\n        # Adaptive weights based on matrix density\n        density = np.sum(m) / (rows * cols)\n        row_weights = np.exp(np.arange(rows, 0, -1)/(rows * (0.5 + density)))\n        col_weights = np.exp(np.arange(cols, 0, -1)/(cols * (0.5 + density)))\n        row_diff = np.sum(np.square(np.diff(m, axis=0)) * row_weights[:-1, np.newaxis])\n        col_diff = np.sum(np.square(np.diff(m, axis=1)) * col_weights[np.newaxis, :-1])\n        spread = row_diff + col_diff\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants if np.linalg.det(m) != 0]\n    return min(all_metrics) if all_metrics else calculate_metrics(matrix)\n",
    "evaluation": {
      "fitness": 0.872471956607848,
      "additional_data": {
        "spearman_correlation": "0.872472",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 788,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 804,
    "parent_id": 367,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack([mat, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    m_orig = matrix.astype(int)\n    m_inv = gf2_inv(m_orig)\n    \n    def compute_tuple(m):\n        T = float(np.sum(m))\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        L1 = np.sum(np.log2(col_sums))\n        L2 = np.sum(np.log2(row_sums))\n        num_row1 = np.sum(row_sums == 1)\n        num_col1 = np.sum(col_sums == 1)\n        total_ones1 = num_row1 + num_col1\n        return (T, min(L1, L2), max(L1, L2), -float(total_ones1))\n    \n    candidates = []\n    candidates.append(compute_tuple(m_orig))\n    if m_inv is not None:\n        candidates.append(compute_tuple(m_inv))\n    candidates.append(compute_tuple(m_orig.T))\n    if m_inv is not None:\n        candidates.append(compute_tuple(m_inv.T))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 726,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 805,
    "parent_id": 587,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    \n    def score(sums):\n        weights = np.where(sums == 1, 0, 1/(0.1 + np.abs(sums - 1)))\n        return np.sum(weights * sums)\n    \n    original_score = score(col_sums) + score(row_sums)\n    transposed_score = score(trans_col_sums) + score(trans_row_sums)\n    return min(original_score, transposed_score)\n",
    "evaluation": {
      "fitness": 0.6147447834732588,
      "additional_data": {
        "spearman_correlation": "0.614745",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 793,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 806,
    "parent_id": 13,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering column sums, row sums, and matrix transpose.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (weighted_col + weighted_row) / 2\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transposed_heuristic = calculate_heuristic(matrix.T)\n    inverse_heuristic = calculate_heuristic(np.linalg.inv(matrix.astype(float)).real\n    min_heuristic = min(original_heuristic, transposed_heuristic, inverse_heuristic)\n    \n    return (min_heuristic, original_heuristic)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 795,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 807,
    "parent_id": 522,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    \n    # Weighted column and row terms using log(1 + sum)\n    weighted_col = np.sum(col_sums * np.log(1.5 + col_sums))\n    weighted_row = np.sum(row_sums * np.log(1.5 + row_sums))\n    \n    # Enhanced interaction terms with squared sums\n    col_nonzeros = np.sum(matrix > 0, axis=0)\n    row_nonzeros = np.sum(matrix > 0, axis=1)\n    col_spread = np.sum(col_nonzeros * (col_sums ** 1.5))\n    row_spread = np.sum(row_nonzeros * (row_sums ** 1.5))\n    \n    # Additional max sum terms\n    max_col = np.max(col_sums)\n    max_row = np.max(row_sums)\n    \n    # Combined heuristic components\n    h1 = weighted_col * weighted_row\n    h2 = col_spread + row_spread\n    h3 = max_col + max_row\n    \n    return (h1, h2, h3)\n",
    "evaluation": {
      "fitness": 0.6957912923484465,
      "additional_data": {
        "spearman_correlation": "0.695791",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 790,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 808,
    "parent_id": 488,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        solved_cols = np.sum(col_sums == 1)\n        solved_rows = np.sum(row_sums == 1)\n        \n        norm_col_sums = np.maximum(col_sums, 1)\n        norm_row_sums = np.maximum(row_sums, 1)\n        \n        col_log_sum = np.sum(np.log2(norm_col_sums))\n        row_log_sum = np.sum(np.log2(norm_row_sums))\n        \n        # Improved distance to identity considering permutations\n        identity_dist = min(\n            np.sum(m != np.eye(n, dtype=int)),\n            np.sum(m != np.eye(n, dtype=int)[::-1])  # Check reversed identity too\n        )\n        \n        # Column/row interaction features\n        col_interactions = 0\n        row_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n                row_interactions += np.sum(m[i,:] & m[j,:])\n        \n        # Hamming distances between columns\n        col_hamming = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_hamming += np.sum(m[:,i] != m[:,j])\n        \n        return (\n            col_log_sum + row_log_sum,\n            -solved_cols - solved_rows,\n            identity_dist,\n            col_interactions + row_interactions,\n            -col_hamming\n        )\n    \n    def binary_inverse(m):\n        try:\n            return np.linalg.inv(m).astype(int) % 2\n        except:\n            return None\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*5\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*5\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.7245899821911083,
      "additional_data": {
        "spearman_correlation": "0.724590",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 794,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 809,
    "parent_id": 615,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced column-focused heuristic with dependency analysis.\"\"\"\n    import numpy as np\n    \n    def column_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion metrics\n        completion = np.sum(np.abs(col_sums - 1))\n        near_completion = np.sum(np.exp(-np.abs(col_sums - 1)))\n        \n        # Column interaction metrics\n        col_deps = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_deps += np.sum(m[:,i] & m[:,j])\n        \n        # Column uniqueness metrics\n        _, counts = np.unique(m, axis=1, return_counts=True)\n        uniqueness = -np.sum(counts * (counts - 1))  # Penalize duplicate columns\n        \n        # Column ordering metrics\n        sorted_cols = tuple(sorted(col_nonzeros))\n        col_rank = np.linalg.matrix_rank(m)\n        \n        # Combined metrics\n        return (completion, col_deps, uniqueness, near_completion, col_rank, *sorted_cols)\n    \n    h_original = column_metrics(matrix)\n    h_inverse = column_metrics(np.linalg.inv(matrix) % 2)\n    h_transpose = column_metrics(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 797,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 810,
    "parent_id": 379,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with refined weight-one and completion terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Count columns/rows with weight exactly 1\n        weight_one_cols = np.sum(col_sums == 1)\n        weight_one_rows = np.sum(row_sums == 1)\n        # Refined imbalance calculation\n        col_imbalance = np.sum(np.abs(col_sums - 1) * (1 + 0.25*(col_sums != 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1) * (1 + 0.25*(row_sums != 1)))\n        return (nonzeros, col_imbalance + row_imbalance, -weight_one_cols, -weight_one_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8810892862433733,
      "additional_data": {
        "spearman_correlation": "0.881089",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 801,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 811,
    "parent_id": 787,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import pinv\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        \n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        return (log_col, log_row, total_ones, single_cols, single_rows)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n    except:\n        inv_matrix = pinv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        inv_matrix,\n        inv_matrix.T\n    ]\n    \n    all_metrics = []\n    for variant in variants:\n        metrics = calculate_metrics(variant)\n        weighted = (\n            0.5 * metrics[0] + 0.2 * metrics[1] + \n            0.15 * metrics[2] + 0.075 * metrics[3] + 0.075 * metrics[4]\n        )\n        all_metrics.append(weighted)\n    \n    return tuple(sorted(all_metrics, reverse=True))\n",
    "evaluation": {
      "fitness": 0.7681975042183048,
      "additional_data": {
        "spearman_correlation": "0.768198",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 799,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 812,
    "parent_id": 386,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        \n        # Features based on columns\n        col_features = np.sort(col_weights)\n        col_log = np.sum(np.log1p(col_features))\n        col_entropy = -np.sum((col_features/np.sum(col_features)) * np.log1p(col_features/np.sum(col_features)))\n        \n        # Features based on rows\n        row_features = np.sort(row_weights)\n        row_log = np.sum(np.log1p(row_features))\n        row_entropy = -np.sum((row_features/np.sum(row_features)) * np.log1p(row_features/np.sum(row_features)))\n        \n        # Interaction features\n        interaction = np.sum(m * (m.T))\n        \n        # Combined heuristic\n        h_val = (0.4 * col_log + 0.3 * row_log + \n                 0.1 * col_entropy + 0.1 * row_entropy + \n                 0.1 * interaction/m.size)\n        \n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8724072185493088,
      "additional_data": {
        "spearman_correlation": "0.872407",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 798,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 813,
    "parent_id": 123,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Returns tuple of (sum_log_cols, sum_log_rows) for better lex comparison.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return (float(np.sum(np.log(col_sums))), float(np.sum(np.log(row_sums))))\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'), float('inf'))\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'), float('inf'))\n    \n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.8741442613874844,
      "additional_data": {
        "spearman_correlation": "0.874144",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 800,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 814,
    "parent_id": 139,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n_inv, dtype=int)))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    variants = [matrix, matrix.T]\n    if n <= 20:\n        try:\n            inv = gf2_inv(matrix)\n            if inv is not None:\n                variants.append(inv)\n                variants.append(inv.T)\n        except:\n            pass\n    \n    best_tuple = None\n    for m in variants:\n        total_ones = np.sum(m)\n        col_weights = np.sum(m, axis=0)\n        ones = np.count_nonzero(col_weights == 1)\n        non_basis_columns = n - ones\n        mask = col_weights >= 2\n        weights = col_weights[mask]\n        sum_log = np.sum(np.log2(weights)) if weights.size > 0 else 0.0\n        current_tuple = (total_ones, non_basis_columns, sum_log)\n        if best_tuple is None or current_tuple < best_tuple:\n            best_tuple = current_tuple\n    \n    return best_tuple\n",
    "evaluation": {
      "fitness": 0.8712984044714928,
      "additional_data": {
        "spearman_correlation": "0.871298",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 712,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 815,
    "parent_id": 676,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic incorporating row sums, Hamming weights, and interactions.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        hamming_weights = np.sum(m != 0, axis=0)\n        row_hamming = np.sum(m != 0, axis=1)\n        interaction = np.sum(col_sums * row_sums)\n        return (float(total_sum), float(np.sum(col_sums * (col_sums - 1))), \n                float(np.sum(row_sums * (row_sums - 1))), \n                float(np.sum(hamming_weights)), float(np.sum(row_hamming)),\n                float(interaction))\n    \n    try:\n        inv = np.linalg.inv(matrix)\n    except:\n        inv = matrix\n        \n    h_matrix = calculate_heuristic(matrix)\n    h_inv = calculate_heuristic(inv)\n    h_trans = calculate_heuristic(matrix.T)\n    \n    return tuple(np.mean([h_matrix, h_inv, h_trans], axis=0))\n",
    "evaluation": {
      "fitness": 0.729287653164686,
      "additional_data": {
        "spearman_correlation": "0.729288",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 803,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 816,
    "parent_id": 605,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        # Simple column sum metric\n        col_sums = np.sum(m, axis=0)\n        col_cost = np.sum(col_sums)\n        \n        # Simple row sum metric\n        row_sums = np.sum(m, axis=1)\n        row_cost = np.sum(row_sums)\n        \n        # Rank penalty\n        rank = np.linalg.matrix_rank(m)\n        rank_penalty = (m.shape[0] - rank) * 0.5\n        \n        return col_cost + row_cost - rank_penalty\n    \n    original = evaluate(matrix)\n    inverse = evaluate(np.linalg.inv(matrix))\n    transpose = evaluate(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": -0.2770778154783479,
      "additional_data": {
        "spearman_correlation": "-0.277078",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 806,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 817,
    "parent_id": 440,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.sum(m, axis=1)\n        row_weights = np.maximum(row_weights, 1)\n        sum_weights = np.sum(m)\n        \n        h_val = np.sum(1/col_weights) + np.sum(1/row_weights) + 0.05 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": -0.8085228503428311,
      "additional_data": {
        "spearman_correlation": "-0.808523",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 796,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 818,
    "parent_id": 201,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with column relationships and proximity to basis vectors.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count columns/rows with sum exactly 1\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        \n        # Count columns with sum <= 2 (almost done)\n        cols_almost = np.sum(col_sums <= 2)\n        rows_almost = np.sum(row_sums <= 2)\n        \n        # Measure column overlaps (how many rows share ones)\n        overlap = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap += np.sum(m[:,i] & m[:,j])\n        \n        # Measure distance to basis vectors\n        basis_dist = 0\n        for c in range(n):\n            basis_dist += min(np.sum(m[:,c] != np.eye(n)[:,i]) for i in range(n))\n        \n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Use squared differences for imbalance\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        return (nonzeros, cols_done + rows_done, cols_almost + rows_almost, \n                overlap, basis_dist, col_imbalance + row_imbalance, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix).astype(int))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7144012465518125,
      "additional_data": {
        "spearman_correlation": "0.714401",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 802,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 819,
    "parent_id": 347,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    epsilon = 1e-10\n    n = matrix.shape[0]\n    \n    # Base metrics\n    total_sum = float(np.sum(matrix))\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    \n    # Column completion metrics\n    col_completion = np.sum(1/(col_sums + epsilon))\n    col_log = float(np.sum(np.log2(col_sums + epsilon)))\n    \n    # Row completion metrics\n    row_completion = np.sum(1/(row_sums + epsilon))\n    row_log = float(np.sum(np.log2(row_sums + epsilon)))\n    \n    # Best permutation metrics (consider column permutations)\n    best_perm_metric = float('inf')\n    if n <= 4:  # Only check permutations for small matrices\n        for perm in permutations(range(n)):\n            perm_matrix = matrix[:, list(perm)]\n            perm_sum = float(np.sum(perm_matrix))\n            if perm_sum < best_perm_metric:\n                best_perm_metric = perm_sum\n    \n    # Combine metrics\n    if n <= 4:\n        return (total_sum, best_perm_metric, col_completion, row_completion, col_log, row_log)\n    else:\n        return (total_sum, col_completion, row_completion, col_log, row_log)\n",
    "evaluation": {
      "fitness": 0.7043057333454604,
      "additional_data": {
        "spearman_correlation": "0.704306",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 804,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 820,
    "parent_id": 211,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        col_completion = sum(2 - s for s in col_sums if s <= 2)\n        row_completion = sum(2 - s for s in row_sums if s <= 2)\n        \n        # LU decomposition metrics\n        _, _, u = lu(m)\n        lu_rank = np.sum(np.abs(np.diag(u)) > 1e-10)\n        \n        return (nonzeros, \n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                -lu_rank)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8792971906449311,
      "additional_data": {
        "spearman_correlation": "0.879297",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 807,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 25
    }
  },
  {
    "id": 821,
    "parent_id": 621,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Improved spread metric using full pairwise differences\n        row_diff = np.sum(np.abs(m[:, None, :] - m[None, :, :]))\n        col_diff = np.sum(np.abs(m[:, :, None] - m[:, None, :]))\n        spread = row_diff + col_diff\n        \n        # Enhanced basis closeness for both rows and columns\n        basis_closeness = np.sum(np.minimum(col_sums, 1)) + np.sum(np.minimum(row_sums, 1))\n        \n        # Diagonal closeness metric\n        diag_closeness = np.sum(m * np.eye(m.shape[0]))\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread, -basis_closeness, -diag_closeness)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8726492600799851,
      "additional_data": {
        "spearman_correlation": "0.872649",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 809,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 822,
    "parent_id": 457,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return log_cols * log_rows\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix),\n        np.linalg.inv(matrix).T\n    ]\n    \n    metrics = [compute_metric(v) for v in variants]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.038947918189533685,
      "additional_data": {
        "spearman_correlation": "0.038948",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 813,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 823,
    "parent_id": 702,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Enhanced column metrics\n        col_weights = np.sort(col_sums)\n        col_progress = np.sum((col_weights - 1)**2)\n        col_penalty = np.sum(np.sqrt(1 + np.abs(col_weights - 1)))\n        \n        # Enhanced row metrics\n        row_weights = np.sort(row_sums)\n        row_progress = np.sum((row_weights - 1)**2)\n        row_penalty = np.sum(np.sqrt(1 + np.abs(row_weights - 1)))\n        \n        # Weighted triangular difference\n        diff = m - np.eye(n, dtype=int)\n        weights = np.abs(np.arange(n)[:, None] - np.arange(n)) + 1\n        weighted_diff = np.sum(np.abs(diff) / weights)\n        \n        return (\n            col_progress + row_progress,\n            col_penalty + row_penalty,\n            weighted_diff\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        matrix[::-1],\n        matrix[:, ::-1]\n    ]\n    \n    return min(evaluate(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.23625844297937748,
      "additional_data": {
        "spearman_correlation": "0.236258",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 810,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 824,
    "parent_id": 452,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        np.linalg.inv(matrix.T.astype(float)).astype(int) % 2\n    ]\n    \n    def score(m):\n        col_sums = np.sum(m, axis=0)\n        log_scores = np.sum(np.log2(col_sums + 1))\n        return np.sum(m) + log_scores\n    \n    scores = [score(v) for v in variants]\n    return min(scores)\n",
    "evaluation": {
      "fitness": 0.7098050641981047,
      "additional_data": {
        "spearman_correlation": "0.709805",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 814,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 825,
    "parent_id": 356,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining multiple metrics and considering variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        min_col = float(np.min(col_sums))\n        col_var = float(np.var(col_sums))\n        row_var = float(np.var(row_sums))\n        return (log_col, col_var, row_var, max_col, min_col, log_row, sum_total)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8703960331570572,
      "additional_data": {
        "spearman_correlation": "0.870396",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 811,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 826,
    "parent_id": 311,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with refined metrics and averaging.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log1p(col_sums))\n        weighted_row = np.sum(np.log1p(row_sums))\n        spread = np.sum(np.abs(np.diff(m, axis=0))) + np.sum(np.abs(np.diff(m, axis=1)))\n        nonzero = np.count_nonzero(m)\n        return (weighted_col + weighted_row + spread + nonzero)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    except:\n        inv_matrix = matrix\n    \n    metrics = [\n        calculate_metrics(matrix),\n        calculate_metrics(matrix.T),\n        calculate_metrics(inv_matrix),\n        calculate_metrics(inv_matrix.T)\n    ]\n    \n    return np.mean(metrics)\n",
    "evaluation": {
      "fitness": 0.581278003625701,
      "additional_data": {
        "spearman_correlation": "0.581278",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 815,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 827,
    "parent_id": 125,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        log_sum = float(np.sum(np.log(col_sums)))\n        total_sum = float(np.sum(col_sums))\n        return (log_sum, total_sum)\n    \n    h_col_orig = calculate_heuristics(matrix)\n    h_row_orig = calculate_heuristics(matrix.T)\n    inv_matrix = np.linalg.inv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    h_col_inv = calculate_heuristics(inv_matrix)\n    h_row_inv = calculate_heuristics(inv_matrix.T)\n    \n    return max(h_col_orig, h_row_orig, h_col_inv, h_row_inv)\n",
    "evaluation": {
      "fitness": 0.7747293172397294,
      "additional_data": {
        "spearman_correlation": "0.774729",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 820,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 828,
    "parent_id": 543,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with additional metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # New: column clustering score (lower is better)\n        col_cluster_score = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_cluster_score += np.sum(m[:,i] == m[:,j])\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        zero_cols = np.sum(col_sums == 0)\n        zero_rows = np.sum(row_sums == 0)\n        \n        # New: count matching almost-done columns\n        matching_almost_cols = 0\n        for i in range(m.shape[1]):\n            if col_sums[i] == 2:\n                for j in range(i+1, m.shape[1]):\n                    if col_sums[j] == 2 and np.array_equal(m[:,i], m[:,j]):\n                        matching_almost_cols += 1\n                        break\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Max and min sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        \n        # New: max difference between column sums\n        max_col_diff = np.max(col_sums) - np.min(col_sums)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        # Product of sums\n        col_product = np.prod(col_sums)\n        row_product = np.prod(row_sums)\n        \n        # Unique columns/rows\n        unique_cols = len(np.unique(m, axis=1))\n        unique_rows = len(np.unique(m, axis=0))\n        \n        return (nonzeros, \n                -col_cluster_score,\n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                -matching_almost_cols,\n                -zero_cols-zero_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                col_variance + row_variance,\n                max_col + max_row,\n                min_col + min_row,\n                max_col_diff,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                col_product + row_product,\n                unique_cols + unique_rows,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8711559210338984,
      "additional_data": {
        "spearman_correlation": "0.871156",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 808,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 829,
    "parent_id": 250,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_cost(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based metrics\n        col_penalty = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_target = np.sum(np.minimum(col_sums, np.ones(n)))\n        \n        # Row-based metrics\n        row_penalty = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_target = np.sum(np.minimum(row_sums, np.ones(n)))\n        \n        # Pattern matching\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                       np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Interaction terms\n        interaction = np.sum(m & m.T)  # Count symmetric entries\n        \n        # Combine metrics with dynamic weights\n        return (0.3 * (col_penalty + row_penalty) + \n                0.2 * (n - (col_target + row_target)/2) + \n                0.3 * diag_dist + \n                0.2 * interaction)\n    \n    # Compute all variants\n    variants = [\n        matrix_cost(matrix),\n        matrix_cost(matrix.T),\n        matrix_cost(np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2),\n        matrix_cost(np.round(np.linalg.inv(matrix.T.astype(float))).astype(int) % 2)\n    ]\n    \n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.6916859174053062,
      "additional_data": {
        "spearman_correlation": "0.691686",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 821,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 830,
    "parent_id": 548,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Tuned log metrics with smaller constant\n        col_metric = np.sum(np.log(col_sums + 0.01))\n        row_metric = np.sum(np.log(row_sums + 0.01))\n        \n        # More precise diagonal metrics\n        diag = np.sum(m * np.eye(m.shape[0]))\n        anti_diag = np.sum(m * np.eye(m.shape[0])[::-1])\n        diag_metric = diag + anti_diag\n        \n        # Add total ones metric\n        total_ones = np.sum(m)\n        \n        return (col_metric, row_metric, -diag_metric, total_ones)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix[::-1]  # row-reversed\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8724793996219157,
      "additional_data": {
        "spearman_correlation": "0.872479",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 819,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 831,
    "parent_id": 467,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    import math\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns\n        unique_cols = len({tuple(col) for col in m.T})\n        \n        # LU decomposition metrics\n        p, l, u = lu(m)\n        lu_nonzeros = np.count_nonzero(l) + np.count_nonzero(u)\n        \n        # Column metrics\n        col_sum_metric = sum(math.log(s + 1) for s in col_sums if s > 0)\n        col_pair_deps = sum(1 for i in range(m.shape[1]) \n                          for j in range(i+1, m.shape[1]) \n                          if np.array_equal(m[:,i], m[:,j]))\n        \n        # Row metrics\n        row_sum_metric = sum(math.log(s + 1) for s in row_sums if s > 0)\n        \n        return (nonzeros,\n                lu_nonzeros,\n                col_sum_metric,\n                row_sum_metric,\n                -basis_cols,\n                -unique_cols,\n                col_pair_deps)\n    \n    # Generate all permutations to consider\n    matrices = [matrix]\n    try:\n        matrices.append(np.linalg.inv(matrix))\n    except:\n        pass\n    matrices.append(matrix.T)\n    try:\n        matrices.append(np.linalg.inv(matrix).T)\n    except:\n        pass\n    \n    # Consider row permutations\n    if matrix.shape[0] <= 4:  # Only for small matrices\n        for perm in itertools.permutations(range(matrix.shape[0])):\n            matrices.append(matrix[list(perm), :])\n    \n    return min(get_heuristic(m) for m in matrices)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'itertools' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 817,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 832,
    "parent_id": 621,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        # Improved spread metric considering all pairwise differences\n        row_diff = np.sum(np.abs(m[:, None, :] - m[None, :, :]))\n        col_diff = np.sum(np.abs(m.T[:, None, :] - m.T[None, :, :]))\n        spread = row_diff + col_diff\n        \n        # Basis closeness for both columns and rows\n        col_basis = np.sum(np.minimum(col_sums, 1))\n        row_basis = np.sum(np.minimum(row_sums, 1))\n        basis_closeness = col_basis + row_basis\n        \n        return (log_cols + log_rows, abs_cols + abs_rows, -spread, -basis_closeness)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.8734587205472963,
      "additional_data": {
        "spearman_correlation": "0.873459",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 822,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 833,
    "parent_id": 38,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        col_metric = np.sum(np.log(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1e-10)\n        row_metric = np.sum(np.log(row_sums))\n        \n        total_sum = np.sum(m)\n        \n        return 0.5 * col_metric + 0.5 * row_metric + total_sum\n    \n    original = compute_metric(matrix)\n    try:\n        inv = compute_metric(np.linalg.inv(matrix))\n    except:\n        inv = float('inf')\n    trans = compute_metric(matrix.T)\n    \n    return (original + inv + trans) / 3\n",
    "evaluation": {
      "fitness": 0.08980827367083362,
      "additional_data": {
        "spearman_correlation": "0.089808",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 824,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 834,
    "parent_id": 348,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_weights = np.sum(m, axis=0)\n        \n        # Logarithmic penalty for non-zero columns\n        log_penalty = np.sum(np.log1p(col_nonzeros))\n        \n        # Weighted column sum penalty\n        weight_penalty = np.sum(np.log1p(col_weights))\n        \n        # Column difference penalty (measures distance from identity)\n        diff_penalty = np.sum(np.abs(m - np.eye(n)))\n        \n        return (log_penalty, weight_penalty, diff_penalty)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(column_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 826,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 835,
    "parent_id": 747,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic combining multiple features into a single float.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column features\n        col_proximity = np.sum(np.exp(-np.abs(col_sums - 1)))\n        log_col_sums = np.sum(np.log2(col_sums + 1))\n        \n        # Row features\n        row_proximity = np.sum(np.exp(-np.abs(row_sums - 1)))\n        \n        # Matrix structure features\n        frobenius = np.linalg.norm(m, 'fro')\n        diag_dominance = np.sum(np.abs(np.diag(m))) / (np.sum(np.abs(m)) + 1e-9)\n        \n        # Weighted combination of features\n        return (nonzeros * 0.5 + \n                (1 - col_proximity) * 0.3 + \n                log_col_sums * 0.2 + \n                frobenius * 0.1 - \n                diag_dominance * 0.1)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.15819040369924353,
      "additional_data": {
        "spearman_correlation": "0.158190",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 825,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 836,
    "parent_id": 586,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def get_metrics(m):\n        # Convert to integer 0/1 matrix\n        m = (np.round(m) % 2).astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(col_sums)\n        n = m.shape[0]\n        \n        # Check for permutation matrix\n        if total_ones == n and np.all(col_sums == 1) and np.all(row_sums == 1):\n            return (0.0, 0.0, 0.0, 0.0)\n        \n        # Compute features\n        col_sums = np.maximum(col_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        var_col = np.var(col_sums)\n        diag_sum = np.sum(np.diag(m))\n        off_diag = total_ones - diag_sum\n        return (log_col, total_ones, var_col, off_diag)\n    \n    # Define transformations\n    m1 = matrix\n    m2 = (np.round(np.linalg.inv(matrix)) % 2).astype(int)\n    m3 = matrix.T\n    m4 = (np.round(np.linalg.inv(matrix).T) % 2).astype(int)\n    matrices = [m1, m2, m3, m4]\n    \n    # Compute metrics for all transformations\n    all_metrics = [get_metrics(m) for m in matrices]\n    \n    # Find minimum for each feature across transformations\n    min_log_col = min(metrics[0] for metrics in all_metrics)\n    min_total_ones = min(metrics[1] for metrics in all_metrics)\n    min_var_col = min(metrics[2] for metrics in all_metrics)\n    min_off_diag = min(metrics[3] for metrics in all_metrics)\n    \n    # Apply weights\n    weights = [1.0, 0.9, 0.7, 0.9]\n    combined = (\n        min_log_col * weights[0],\n        min_total_ones * weights[1],\n        min_var_col * weights[2],\n        min_off_diag * weights[3]\n    )\n    return combined\n",
    "evaluation": {
      "fitness": 0.7335523433224204,
      "additional_data": {
        "spearman_correlation": "0.733552",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 727,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 837,
    "parent_id": 475,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic focusing on column/row structural properties and entropy.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Structural metrics\n        col_entropy = entropy(col_sums + 1)  # +1 to avoid log(0)\n        row_entropy = entropy(row_sums + 1)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        # Interaction terms\n        col_row_interaction = np.sum(np.abs(col_sums - row_sums))\n        diagonal_dominance = np.sum(np.diag(m))\n        \n        # Advanced metrics\n        col_nonbinary = np.sum((col_sums > 0) & (col_sums != 1))\n        row_nonbinary = np.sum((row_sums > 0) & (row_sums != 1))\n        col_clustering = np.sum(np.diff(np.sort(col_sums))**2)\n        row_clustering = np.sum(np.diff(np.sort(row_sums))**2)\n        \n        # Combined metrics\n        structural_complexity = (col_entropy + row_entropy + \n                               col_variance + row_variance + \n                               col_nonbinary + row_nonbinary)\n        \n        interaction_metrics = (col_row_interaction + \n                             diagonal_dominance + \n                             col_clustering + row_clustering)\n        \n        return (structural_complexity, interaction_metrics, \n               -np.sum(col_sums == 1), -np.sum(row_sums == 1),\n               np.sum(col_sums), np.sum(row_sums))\n    \n    variants = [\n        get_heuristic(matrix),\n        get_heuristic(np.linalg.inv(matrix)),\n        get_heuristic(matrix.T),\n        get_heuristic(np.linalg.inv(matrix).T)\n    ]\n    \n    # Find the minimum tuple lexicographically\n    min_h = variants[0]\n    for h in variants[1:]:\n        if h < min_h:\n            min_h = h\n    return min_h\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 823,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 838,
    "parent_id": 45,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        \n        # Adjusted weights favoring logarithmic metric more\n        return (0.75 * (col_log + row_log) + 0.25 * (col_linear + row_linear),)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8716887195229283,
      "additional_data": {
        "spearman_correlation": "0.871689",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 828,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 839,
    "parent_id": 440,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.sum(m, axis=1)\n        row_weights = np.maximum(row_weights, 1)\n        sum_weights = np.sum(m)\n        \n        h_val = np.sum(1/(col_weights)) + 0.5 * sum_weights + 0.1 * np.sum(1/(row_weights))\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.6720152406082724,
      "additional_data": {
        "spearman_correlation": "0.672015",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 827,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 840,
    "parent_id": 450,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.where(col_sums == 0, 1, col_sums)\n        row_sums = np.where(row_sums == 0, 1, row_sums)\n        \n        col_metric = np.sum(np.log(col_sums))\n        row_metric = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        \n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = max(diag, anti_diag)\n        \n        # Additional metric: sum of min column pairs\n        n = m.shape[0]\n        col_pairs = sum(min(col_sums[i], col_sums[j]) for i in range(n) for j in range(i+1, n))\n        \n        return (col_metric, row_metric, -total_ones, -diag_metric, -col_pairs)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8724073716494755,
      "additional_data": {
        "spearman_correlation": "0.872407",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 829,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 841,
    "parent_id": 789,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(m)\n        col_entropy = -np.sum(col_sums * np.log2(np.maximum(col_sums, 1)))\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        return (total_sum, col_entropy, -(single_cols + single_rows))\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    best_heuristic = None\n    for variant in variants:\n        current = compute_metrics(variant)\n        if best_heuristic is None or current < best_heuristic:\n            best_heuristic = current\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.87117527717882,
      "additional_data": {
        "spearman_correlation": "0.871175",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 831,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 842,
    "parent_id": 158,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(col_sums)\n        row_nonzero = np.count_nonzero(row_sums)\n        return np.sum(col_sums) + np.sum(row_sums), col_nonzero + row_nonzero\n    \n    original = simple_metric(matrix)\n    transposed = simple_metric(matrix.T)\n    inverted = simple_metric(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    min_sum = min(original[0], transposed[0], inverted[0])\n    min_nonzero = min(original[1], transposed[1], inverted[1])\n    \n    return (min_sum, min_nonzero)\n",
    "evaluation": {
      "fitness": 0.7165091997327048,
      "additional_data": {
        "spearman_correlation": "0.716509",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 835,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 843,
    "parent_id": 662,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and additional matrix sum term.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-8)\n        row_sums = np.maximum(row_sums, 1e-8)\n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        total_sum = np.sum(m)\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        return float(0.7 * log_cols + 0.2 * log_rows + 0.08 * total_sum + 0.01 * col_var + 0.01 * row_var)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    return min(original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8735029200623395,
      "additional_data": {
        "spearman_correlation": "0.873503",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 832,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 844,
    "parent_id": 653,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic weighting and entropy measures.\"\"\"\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Logarithmic column weighting\n        log_col_weights = sum(log2(c + 1) for c in col_sums)\n        \n        # Column entropy measure\n        col_entropy = 0\n        for col in m.T:\n            p = np.mean(col)\n            if 0 < p < 1:\n                col_entropy += -p*log2(p) - (1-p)*log2(1-p)\n        \n        # Matrix norm measures\n        frob_norm = np.linalg.norm(m, 'fro')\n        spec_norm = np.linalg.norm(m, 2)\n        \n        # Column/row interaction\n        col_row_interaction = np.sum(np.abs(m @ m.T - np.eye(m.shape[0])))\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, log_col_weights, col_entropy, \n                frob_norm, spec_norm, col_row_interaction, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    # Compare tuples lexicographically\n    return min([h_original, h_inverse, h_transpose, h_inverse_transpose], key=lambda x: x)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 833,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 845,
    "parent_id": 265,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column statistics\n        col_variance = np.var(col_sums)\n        col_max = np.max(col_sums)\n        col_min = np.min(col_sums)\n        \n        # Row statistics\n        row_variance = np.var(row_sums)\n        row_max = np.max(row_sums)\n        row_min = np.min(row_sums)\n        \n        # Column overlaps\n        col_overlaps = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_overlaps += np.sum(m[:,i] & m[:,j])\n                \n        # Row overlaps\n        row_overlaps = 0\n        for i in range(m.shape[0]):\n            for j in range(i+1, m.shape[0]):\n                row_overlaps += np.sum(m[i,:] & m[j,:])\n        \n        # LU decomposition properties\n        _, L, U = lu(m)\n        L_nonzeros = np.count_nonzero(L)\n        U_nonzeros = np.count_nonzero(U)\n        \n        # Distance to basis vectors\n        basis_dist = 0\n        for col in m.T:\n            basis_dist += min(np.sum(col != basis) for basis in np.eye(m.shape[0]))\n            \n        return (nonzeros,\n                -basis_cols,\n                col_max,\n                row_max,\n                col_variance,\n                row_variance,\n                col_overlaps,\n                row_overlaps,\n                L_nonzeros,\n                U_nonzeros,\n                basis_dist)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 830,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 846,
    "parent_id": 463,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Returns tuple combining multiple matrix properties with weighted importance.\"\"\"\n    import numpy as np\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        unique_cols = len(np.unique(m, axis=1))\n        unique_rows = len(np.unique(m, axis=0))\n        rank = np.linalg.matrix_rank(m)\n        \n        # Weighted features\n        weighted_col = np.sum(col_sums * (col_sums > 1))\n        weighted_row = np.sum(row_sums * (row_sums > 1))\n        interaction = np.sum(col_sums * row_sums[:, np.newaxis])\n        \n        return np.array([\n            np.sum(col_sums),\n            np.sum(row_sums),\n            weighted_col,\n            weighted_row,\n            interaction,\n            unique_cols,\n            unique_rows,\n            rank\n        ])\n    \n    features_original = get_features(matrix)\n    features_inverse = get_features(np.linalg.inv(matrix) % 2)\n    features_transpose = get_features(matrix.T)\n    \n    # Combine features with different weights\n    combined = (features_original * 0.5 + features_inverse * 0.3 + features_transpose * 0.2)\n    \n    # Return two most significant components\n    return (float(combined[2]), float(combined[4]))\n",
    "evaluation": {
      "fitness": 0.8365721987100162,
      "additional_data": {
        "spearman_correlation": "0.836572",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 834,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 847,
    "parent_id": 80,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with row sums and absolute deviations.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # L1 norm\n        row_imbalance = np.sum(np.abs(row_sums - 1))  # L1 norm\n        return (nonzeros, col_imbalance, row_imbalance)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8820925350010066,
      "additional_data": {
        "spearman_correlation": "0.882093",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 838,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 848,
    "parent_id": 161,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import inv, matrix_power\n    \n    def matrix_entropy(m):\n        m = m.astype(float)\n        total = np.sum(m)\n        if total == 0:\n            return 0\n        prob = m / total\n        prob = prob[prob > 0]\n        return -np.sum(prob * np.log2(prob))\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        entropy = matrix_entropy(m)\n        return (weighted_col + weighted_row) / 2 + entropy\n    \n    original = calculate_heuristic(matrix)\n    transposed = calculate_heuristic(matrix.T)\n    try:\n        inverse = calculate_heuristic(inv(matrix.astype(float)).astype(int) % 2)\n    except:\n        inverse = original\n    try:\n        product = calculate_heuristic((matrix @ matrix.T) % 2)\n    except:\n        product = original\n    \n    min_h = min(original, transposed, inverse, product)\n    max_h = max(original, transposed, inverse, product)\n    mean_h = np.mean([original, transposed, inverse, product])\n    \n    return (min_h, mean_h, max_h, matrix_entropy(matrix), np.sum(matrix))\n",
    "evaluation": {
      "fitness": 0.40929248770415577,
      "additional_data": {
        "spearman_correlation": "0.409292",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 837,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 849,
    "parent_id": 304,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect = (n - correct_cols) + (n - correct_rows)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        col_imbalance = 2.4 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.2 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        col_variance = 0.6 * np.var(col_sums)\n        row_variance = 0.4 * np.var(row_sums)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, incorrect, log_cols + log_rows, \n                col_imbalance + row_imbalance, max_col + max_row, \n                col_variance + row_variance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827606797637496,
      "additional_data": {
        "spearman_correlation": "0.882761",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 836,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 850,
    "parent_id": 216,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        max_row = np.max(row_sums)\n        min_row = np.min(row_sums)\n        rank = np.linalg.matrix_rank(m)\n        total_ones = np.sum(m)\n        nonzero_cols = np.count_nonzero(col_sums)\n        nonzero_rows = np.count_nonzero(row_sums)\n        \n        return (float(rank), float(total_ones), float(max_col), float(min_col), \n                float(max_row), float(min_row), float(nonzero_cols), float(nonzero_rows))\n    \n    try:\n        inv = np.linalg.inv(matrix)\n    except:\n        inv = matrix\n        \n    h_matrix = calculate_heuristic(matrix)\n    h_inv = calculate_heuristic(inv)\n    h_trans = calculate_heuristic(matrix.T)\n    \n    return min(h_matrix, h_inv, h_trans)\n",
    "evaluation": {
      "fitness": -0.20929976501220782,
      "additional_data": {
        "spearman_correlation": "-0.209300",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 841,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 851,
    "parent_id": 839,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    variants = [matrix, matrix.T]\n    min_heuristic = float('inf')\n    \n    for m in variants:\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        log_cols = np.sum(np.log2(col_sums))\n        \n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1)\n        log_rows = np.sum(np.log2(row_sums))\n        \n        total_sum = np.sum(m)\n        \n        # Consider column pairs\n        n = m.shape[0]\n        col_pairs = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                pair_sum = np.sum(m[:,i] & m[:,j])\n                col_pairs += np.log2(pair_sum + 1) if pair_sum > 0 else 0\n        \n        h_val = (log_cols + 0.3 * log_rows + 0.2 * total_sum + 0.5 * col_pairs, \n                 total_sum, \n                 log_cols)\n        \n        if h_val[0] < min_heuristic:\n            min_heuristic = h_val[0]\n            \n    return (min_heuristic, np.sum(matrix)) if isinstance(min_heuristic, float) else h_val\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'isinstance' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 840,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 852,
    "parent_id": 201,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        cols_almost = np.sum(col_sums == 2)\n        rows_almost = np.sum(row_sums == 2)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        done_total = cols_done + rows_done\n        almost_total = cols_almost + rows_almost\n        imbalance_total = col_imbalance + row_imbalance\n        return (nonzeros, -done_total, -almost_total, imbalance_total, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8827728653956101,
      "additional_data": {
        "spearman_correlation": "0.882773",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 761,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 853,
    "parent_id": 178,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.7 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Adjusted weight\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))  # Adjusted weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))  # Adjusted weight\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))  # Adjusted weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.4 * np.var(col_sums)  # Slightly increased weight\n        row_variance = 0.4 * np.var(row_sums)\n        sum_diff = 0.2 * np.abs(np.sum(col_sums) - np.sum(row_sums))\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, min_col + min_row, col_variance + row_variance,\n                sum_diff, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8827976952112023,
      "additional_data": {
        "spearman_correlation": "0.882798",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 2,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 839,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 9
    }
  },
  {
    "id": 854,
    "parent_id": 430,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        total_nonzeros = np.count_nonzero(m)\n        \n        # Adaptive column completion\n        col_weights = 1 + (col_nonzeros == 1).astype(float)\n        col_completion = np.sum(col_weights * np.log(col_nonzeros + 1))\n        \n        # Row completion term\n        row_weights = 1 + (row_nonzeros == 1).astype(float)\n        row_completion = np.sum(row_weights * np.log(row_nonzeros + 1))\n        \n        # Matrix decomposition potential\n        block_score = 0\n        for k in range(1, n):\n            upper_left = m[:k, :k]\n            if np.count_nonzero(m[:k, k:]) == 0 and np.count_nonzero(m[k:, :k]) == 0:\n                block_score = max(block_score, min(k, n-k))\n        \n        # Enhanced sparsity using entropy\n        nonzero_ratio = total_nonzeros / (n**2)\n        sparsity = -nonzero_ratio * np.log(nonzero_ratio + 1e-10)\n        \n        return (col_completion + row_completion, -block_score, sparsity)\n    \n    variants = [matrix]\n    try:\n        variants.extend([np.linalg.inv(matrix), matrix.T, np.linalg.inv(matrix.T)])\n    except:\n        pass\n    \n    # Consider row/column permutations\n    for _ in range(2):\n        perm = np.random.permutation(matrix.shape[0])\n        variants.append(matrix[perm, :])\n        variants.append(matrix[:, perm])\n    \n    return min(get_heuristic(v) for v in variants if v.shape == matrix.shape)\n",
    "evaluation": {
      "fitness": 0.3080397166281881,
      "additional_data": {
        "spearman_correlation": "0.308040",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 842,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 855,
    "parent_id": 242,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Distance from identity-like forms\n        identity_dist = min(np.sum(m != np.eye(n)), np.sum(m != np.eye(n)[::-1]))\n        \n        # Column clustering measure\n        col_cluster = 0\n        for col in m.T:\n            transitions = np.sum(col[:-1] != col[1:])\n            col_cluster += transitions\n            \n        # Row clustering measure\n        row_cluster = 0\n        for row in m:\n            transitions = np.sum(row[:-1] != row[1:])\n            row_cluster += transitions\n            \n        # Column completion considering permutations\n        col_completion = max(sum(col == unit_col) \n                           for unit_col in permutations([1]+[0]*(n-1))\n        \n        # Row completion considering permutations\n        row_completion = max(sum(row == unit_row) \n                           for unit_row in permutations([1]+[0]*(n-1)))\n        \n        return (nonzeros,\n                identity_dist,\n                col_cluster + row_cluster,\n                -col_completion,\n                -row_completion,\n                -basis_cols)\n    \n    # Consider all column/row permutations of original and inverse\n    variants = [matrix, np.linalg.inv(matrix)]\n    for p in permutations(range(matrix.shape[0])):\n        if len(variants) >= 8:  # Limit number of variants considered\n            break\n        perm_mat = matrix[:, list(p)]\n        variants.extend([perm_mat, np.linalg.inv(perm_mat)])\n    \n    min_h = None\n    for variant in variants:\n        try:\n            h = get_heuristic(variant)\n            if min_h is None or h < min_h:\n                min_h = h\n        except:\n            continue\n            \n    return min_h if min_h is not None else get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 29)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 843,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 856,
    "parent_id": 177,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Basic features from domain knowledge\n        sum_total = np.sum(m)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Consider matrix inverses and transposes\n        inv = np.linalg.inv(m) if np.linalg.det(m) != 0 else m\n        trans = m.T\n        \n        # Evaluate all variants\n        variants = [m, inv, trans]\n        min_sum = min(np.sum(v) for v in variants)\n        min_log_cols = min(np.sum(np.log2(np.maximum(np.sum(v, axis=0), 1))) for v in variants)\n        \n        return (nonzeros, sum_total, min_sum, log_cols, min_log_cols)\n    \n    return evaluate(matrix)\n",
    "evaluation": {
      "fitness": 0.7565808962196391,
      "additional_data": {
        "spearman_correlation": "0.756581",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 850,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 857,
    "parent_id": 189,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns manually\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        # Modified column completion to consider near-complete columns\n        col_completion = sum(1 - abs(s - 1) for s in col_sums)\n        \n        return (nonzeros, \n                -col_completion,\n                -basis_cols,\n                -unique_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 849,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 858,
    "parent_id": 588,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 2.0 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 0.8 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.0 * np.sum(np.abs(row_sums - 1))\n        max_col = 1.5 * np.max(col_sums)\n        max_row = 0.5 * np.max(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        return (nonzeros, -done_cols-done_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882771842039585,
      "additional_data": {
        "spearman_correlation": "0.882772",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 847,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 859,
    "parent_id": 107,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using linear algebra properties and optimized metric combination.\"\"\"\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        rank = np.linalg.matrix_rank(m)\n        svd = np.linalg.svd(m, compute_uv=False)\n        max_sv = np.max(svd)\n        min_sv = np.min(svd)\n        col_hamming = sum(np.sum(m[:,i] != m[:,j]) for i in range(m.shape[1]) for j in range(i+1, m.shape[1]))\n        row_hamming = sum(np.sum(m[i,:] != m[j,:]) for i in range(m.shape[0]) for j in range(i+1, m.shape[0]))\n        \n        primary_metric = nonzeros + log_cols + log_rows\n        secondary_metric = -done_cols - done_rows\n        tertiary_metric = col_hamming + row_hamming\n        quaternary_metric = max_sv / (min_sv + 1e-9)\n        \n        return (primary_metric, secondary_metric, tertiary_metric, quaternary_metric, *sorted(col_sums), *sorted(row_sums))\n    \n    h_original = get_metrics(matrix)\n    h_inverse = get_metrics(np.linalg.inv(matrix))\n    h_transpose = get_metrics(matrix.T)\n    h_inv_trans = get_metrics(np.linalg.inv(matrix).T)\n    h_trans_inv = get_metrics(matrix.T).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inv_trans, h_trans_inv)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unmatched ')' (<string>, line 32)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 846,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 860,
    "parent_id": 276,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s <= 2)\n        col_variance = np.var(col_sums)\n        col_basis_proximity = sum(min(np.sum(np.abs(col - basis)) for basis in np.eye(m.shape[0]) for col in m.T)\n        \n        # Row metrics\n        row_variance = np.var(row_sums)\n        row_basis_proximity = sum(min(np.sum(np.abs(row - basis)) for basis in np.eye(m.shape[1])) for row in m)\n        \n        # Dependency metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        return (nonzeros,\n                -col_completion,\n                -basis_cols,\n                -unique_cols,\n                col_variance,\n                row_variance,\n                -upper_tri_nonzeros,\n                col_basis_proximity,\n                row_basis_proximity)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 16)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 844,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 861,
    "parent_id": 419,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with better metrics and interactions.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Done columns/rows count\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        next_almost_cols = np.sum(col_sums == 3)\n        next_almost_rows = np.sum(row_sums == 3)\n        \n        # Logarithmic terms with base 2\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Imbalance metrics\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        # Max and min sums\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        \n        # Sorted sums and their differences\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        col_diffs = np.diff(sorted_cols)\n        row_diffs = np.diff(sorted_rows)\n        \n        # Column/row interactions\n        col_interactions = np.sum(m.T @ m)\n        row_interactions = np.sum(m @ m.T)\n        \n        # Product of sums\n        col_product = np.prod(col_sums)\n        row_product = np.prod(row_sums)\n        \n        # Additional metrics\n        trace = np.trace(m)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        return (nonzeros, \n                -done_cols-done_rows, \n                -almost_done_cols-almost_done_rows,\n                -next_almost_cols-next_almost_rows,\n                log_cols + log_rows,\n                col_imbalance + row_imbalance,\n                max_col + max_row,\n                min_col + min_row,\n                np.sum(col_diffs) + np.sum(row_diffs),\n                col_interactions + row_interactions,\n                col_product + row_product,\n                trace,\n                col_variance + row_variance,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8809207832336202,
      "additional_data": {
        "spearman_correlation": "0.880921",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 845,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 862,
    "parent_id": 684,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        \n        # Distance to identity/anti-identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                        np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Column overlap only (more relevant for CNOT synthesis)\n        col_overlap = sum(np.sum(m[:,i] & m[:,j]) \n                         for i in range(n) for j in range(i+1, n))\n        \n        # More precise logarithmic column weight penalty\n        log_col = np.sum(np.where(col_sums > 1, np.log2(col_sums) + (col_sums & (col_sums - 1) != 0), 0)\n        \n        # Weighted deviation from ideal number of ones\n        lin_col_dev = (total_ones - n) / n\n        \n        return (diag_dist, col_overlap, log_col, lin_col_dev)\n    \n    # Compute metrics for variants\n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_metrics(inv_matrix)\n    inv_transposed = matrix_metrics(inv_matrix.T)\n    \n    metrics = [original, transposed, inverse, inv_transposed]\n    \n    # Select best (min) for each metric across variants\n    best_diag_dist = min(m[0] for m in metrics)\n    best_overlap = min(m[1] for m in metrics)\n    best_log_col = min(m[2] for m in metrics)\n    best_lin_col_dev = min(m[3] for m in metrics)\n    \n    return best_diag_dist + best_overlap + best_log_col + best_lin_col_dev\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 848,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 863,
    "parent_id": 512,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with squared distribution penalties and split sparsity.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion remains the same\n        col_completion = np.sum(np.where(col_nonzeros == 1, 0, np.log2(col_nonzeros)))\n        \n        # Use squared differences for smoother distribution penalties\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2\n        \n        # Split sparsity into row and column components\n        col_sparsity = np.log2(np.count_nonzero(m, axis=0).sum() - n*np.log2(n)\n        row_sparsity = np.log2(np.count_nonzero(m, axis=1).sum() - n*np.log2(n)\n        \n        return (col_completion, col_dist, row_dist, col_sparsity, row_sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 852,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 864,
    "parent_id": 406,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def combined_metric(m):\n        n = m.shape[0]\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        \n        # Count existing basis vectors\n        basis_count = np.sum(col_sums == 1) + np.sum(row_sums == 1)\n        \n        # Weight columns/rows by their sums (lower is better)\n        col_weight = np.sum(col_sums * (col_sums > 1))\n        row_weight = np.sum(row_sums * (row_sums > 1))\n        \n        # Measure of how far from identity\n        diff_from_identity = np.sum(m != np.eye(n, dtype=int))\n        \n        # Interaction between rows and columns\n        interaction = np.sum(m @ m.T) - n\n        \n        return (diff_from_identity, \n                col_weight + row_weight, \n                -basis_count, \n                interaction)\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n    \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    # Combine metrics from all variants rather than taking min\n    return tuple(sum(combined_metric(v)[i] for v in variants) for i in range(4))\n",
    "evaluation": {
      "fitness": 0.5032282066506814,
      "additional_data": {
        "spearman_correlation": "0.503228",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 851,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 865,
    "parent_id": 189,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column diversity metrics\n        cols = [tuple(col) for col in m.T]\n        unique_cols = len(set(cols))\n        col_entropy = -sum((np.sum(m[:,i])/m.shape[0]) * np.log2(np.sum(m[:,i])/m.shape[0] + 1e-10) \n                           for i in range(m.shape[1]))\n        \n        # Row-based metrics\n        row_entropy = -sum((np.sum(m[i,:])/m.shape[1]) * np.log2(np.sum(m[i,:])/m.shape[1] + 1e-10) \n                          for i in range(m.shape[0]))\n        \n        # Column completion metrics\n        col_completion = sum(1 for s in col_sums if s == 1)\n        row_completion = sum(1 for s in row_sums if s == 1)\n        \n        # Column/row interaction metrics\n        col_row_interaction = np.sum(np.dot(m, m.T))\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                col_entropy,\n                row_entropy,\n                -col_row_interaction)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 853,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 866,
    "parent_id": 17,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log(np.maximum(row_sums, 1)))\n        sparsity = np.sum(m)\n        return (log_col, log_row, sparsity)\n\n    inv = gf2_inv(matrix)\n    reps = [\n        matrix,\n        matrix.T,\n        inv,\n        inv.T\n    ]\n    evaluations = [evaluate(rep) for rep in reps]\n    return min(evaluations)\n",
    "evaluation": {
      "fitness": 0.8741907165169209,
      "additional_data": {
        "spearman_correlation": "0.874191",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 767,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 867,
    "parent_id": 396,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int) % 2\n        I = np.eye(n, dtype=int)\n        aug = np.hstack([mat, I])\n        for col in range(n):\n            pivot = np.where(aug[col:, col] == 1)[0]\n            if len(pivot) == 0:\n                raise ValueError(\"Matrix is singular in GF(2)\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def compute_metric(m):\n        m = m.astype(int)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        return 1.5 * np.sum(np.log(col_sums)) + np.sum(np.log(row_sums))\n\n    variants = [\n        matrix,\n        matrix.T,\n        gf2_inv(matrix),\n        gf2_inv(matrix).T\n    ]\n    metrics = [compute_metric(v) for v in variants]\n    sorted_metrics = sorted(metrics)\n    return (float(sorted_metrics[0]), float(sorted_metrics[1]))\n",
    "evaluation": {
      "fitness": 0.8742317400066603,
      "additional_data": {
        "spearman_correlation": "0.874232",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 854,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 868,
    "parent_id": 282,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with entropy-based metrics and position weighting.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Position weights - middle qubits more important\n        pos_weights = 1 + np.abs(np.arange(n) - (n-1)/2)/(n-1)*2\n        \n        # Column metrics with position weighting\n        col_entropy = entropy(col_sums + 1e-10)  # Avoid log(0)\n        weighted_cols = np.sum(col_sums * pos_weights)\n        col_imbalance = np.sum((col_sums - 1)**2 * pos_weights)\n        \n        # Row metrics with position weighting\n        row_entropy = entropy(row_sums + 1e-10)\n        weighted_rows = np.sum(row_sums * pos_weights)\n        row_imbalance = np.sum((row_sums - 1)**2 * pos_weights)\n        \n        # Interaction terms between columns\n        col_interactions = np.sum(np.outer(col_sums, col_sums) * m)\n        \n        return (nonzeros, \n                col_entropy + row_entropy,\n                weighted_cols + weighted_rows,\n                col_imbalance + row_imbalance,\n                col_interactions)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 855,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 869,
    "parent_id": 288,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional pair matching and refined imbalance calculation.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = len(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Enhanced pair matching\n        exact_pairs = 0\n        near_pairs = 0\n        almost_pairs = 0\n        inverse_pairs = 0\n        elements = list(m.T) + list(m)\n        \n        for i in range(len(elements)):\n            for j in range(i+1, len(elements)):\n                diff = np.sum(elements[i] != elements[j])\n                if diff == 0:\n                    exact_pairs += 1\n                elif diff == 1:\n                    near_pairs += 1\n                elif diff == 2:\n                    almost_pairs += 1\n                elif diff == n:\n                    inverse_pairs += 1\n        \n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Refined imbalance calculation\n        col_imbalance = (np.sum((col_sums - 1)**2) + \n                        3*np.sum(col_sums == 0) + \n                        3*np.sum(col_sums == n))\n        row_imbalance = (np.sum((row_sums - 1)**2) + \n                        3*np.sum(row_sums == 0) + \n                        3*np.sum(row_sums == n))\n        \n        max_col = np.max(col_sums)\n        \n        return (nonzeros, col_imbalance + row_imbalance,\n                -exact_pairs, -near_pairs, -almost_pairs, -inverse_pairs,\n                max_col, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.867609812806006,
      "additional_data": {
        "spearman_correlation": "0.867610",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 856,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 870,
    "parent_id": 10,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on total sum across matrix variants.\"\"\"\n    import numpy as np\n    \n    def compute_sum(m):\n        return np.sum(m)\n    \n    original_sum = compute_sum(matrix)\n    inv_sum = compute_sum(np.linalg.inv(matrix))\n    trans_sum = compute_sum(matrix.T)\n    \n    return min(original_sum, inv_sum, trans_sum)\n",
    "evaluation": {
      "fitness": -0.27669642681512596,
      "additional_data": {
        "spearman_correlation": "-0.276696",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 861,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 871,
    "parent_id": 811,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from numpy.linalg import pinv\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column completion metrics\n        col_completion = np.sum(np.abs(col_sums - 1))\n        col_variance = np.var(col_sums)\n        col_progress = np.sum(np.exp(-np.abs(col_sums - 1)))\n        \n        # Row completion metrics\n        row_completion = np.sum(np.abs(row_sums - 1))\n        row_variance = np.var(row_sums)\n        row_progress = np.sum(np.exp(-np.abs(row_sums - 1)))\n        \n        # Matrix statistics\n        total_ones = np.sum(m)\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        return (\n            -col_completion, -row_completion,\n            col_progress, row_progress,\n            -col_variance, -row_variance,\n            -total_ones, single_cols, single_rows\n        )\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix)\n    except:\n        inv_matrix = pinv(matrix)\n    inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n    \n    variants = [\n        matrix,\n        matrix.T,\n        inv_matrix,\n        inv_matrix.T\n    ]\n    \n    all_metrics = []\n    for variant in variants:\n        metrics = calculate_metrics(variant)\n        all_metrics.append(metrics)\n    \n    return tuple(max(metrics) for metrics in zip(*all_metrics))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'zip' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 857,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 872,
    "parent_id": 542,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import svd\n    \n    # Singular value decomposition metrics\n    U, s, Vh = svd(matrix)\n    rank = np.sum(s > 1e-10)\n    entropy = -np.sum((s/s.sum()) * np.log(s/s.sum() + 1e-10))\n    \n    # Column-based metrics\n    col_sums = np.sum(matrix, axis=0)\n    log_cols = np.sum(np.log(col_sums + 1))\n    col_complexity = np.sum(col_sums != 1)\n    \n    # Row-based metrics\n    row_sums = np.sum(matrix, axis=1)\n    log_rows = np.sum(np.log(row_sums + 1))\n    \n    # Matrix sparsity\n    nonzeros = np.sum(matrix > 0)\n    \n    # Return as tuple for better search behavior\n    return (rank, entropy, log_cols + log_rows, col_complexity, -nonzeros)\n",
    "evaluation": {
      "fitness": -0.5397759392892728,
      "additional_data": {
        "spearman_correlation": "-0.539776",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 859,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 873,
    "parent_id": 739,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        basis_distances = []\n        for col in m.T:\n            if np.sum(col) == 0:\n                basis_distances.append(n)\n            else:\n                basis_distances.append(min(np.sum(col != basis) for basis in np.eye(n)))\n        min_basis_dist = min(basis_distances)\n        avg_basis_dist = np.mean(basis_distances)\n        \n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        spread = np.sum(np.abs(col_sums - np.mean(col_sums)))\n        \n        log_cols = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        \n        return log_cols + log_rows + min_basis_dist + avg_basis_dist + col_interactions + spread\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_metrics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 862,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 874,
    "parent_id": 235,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using sum-based metrics and tuple returns.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_sum = np.sum(np.abs(m))\n        off_diag = total_sum - np.sum(np.diag(m))\n        return (total_sum, off_diag)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.776378528274641,
      "additional_data": {
        "spearman_correlation": "0.776379",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 864,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 875,
    "parent_id": 76,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined row/column sum heuristic with spread consideration.\"\"\"\n    import numpy as np\n    \n    def calculate_combined(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        spread = np.sum(np.abs(np.diff(m, axis=0))) + np.sum(np.abs(np.diff(m, axis=1)))\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums))) - 0.1 * spread\n    \n    original = calculate_combined(matrix)\n    transposed = calculate_combined(matrix.T)\n    return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 12)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 863,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 876,
    "parent_id": 380,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic incorporating rank, Hamming weights, and linear dependencies.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        # Calculate Hamming weights of columns and rows\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        \n        # Avoid log(0)\n        col_weights = np.maximum(col_weights, 1e-10)\n        row_weights = np.maximum(row_weights, 1e-10)\n        \n        # Logarithmic terms\n        col_log = np.sum(np.log(col_weights))\n        row_log = np.sum(np.log(row_weights))\n        \n        # Linear terms\n        col_linear = np.sum(col_weights)\n        row_linear = np.sum(row_weights)\n        \n        # Sparsity term\n        sparsity = np.sum(m)\n        \n        # Rank-based term (higher rank = more complexity)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Linear dependency measure (number of columns minus rank)\n        n = m.shape[0]\n        linear_deps = n - rank\n        \n        # Combined metrics with adjusted weights\n        return (\n            0.4 * (col_log + row_log) + \n            0.3 * (col_linear + row_linear) + \n            0.1 * sparsity + \n            0.1 * rank + \n            0.1 * linear_deps,\n        )\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8717087195490015,
      "additional_data": {
        "spearman_correlation": "0.871709",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 860,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 877,
    "parent_id": 550,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    matrix = matrix.astype(int)\n    epsilon = 0.1\n    \n    def is_permutation(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        return np.all(row_sums == 1) and np.all(col_sums == 1)\n    \n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(col_sums + epsilon))\n        row_log = np.sum(np.log(row_sums + epsilon))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        nonzero = np.count_nonzero(m)\n        return (col_log + row_log, col_linear + row_linear, nonzero)\n    \n    orig = matrix\n    inv = gf2_inv(orig)\n    trans = orig.T\n    inv_trans = inv.T\n    candidates = [orig, inv, trans, inv_trans]\n    \n    for cand in candidates:\n        if is_permutation(cand):\n            return (0.0, 0.0, 0.0)\n    \n    metrics = [calculate_metrics(cand) for cand in candidates]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8734529478032499,
      "additional_data": {
        "spearman_correlation": "0.873453",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 865,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 878,
    "parent_id": 35,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_nonzero = np.count_nonzero(m)\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        h1 = float(np.sum(np.log(col_sums)) + 0.5 * np.var(col_sums))\n        h2 = float(np.sum(np.log(row_sums)) + 0.5 * np.var(row_sums))\n        h3 = float(total_nonzero) * 0.8\n        return (h1, h2, h3)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8461458772713621,
      "additional_data": {
        "spearman_correlation": "0.846146",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 872,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 879,
    "parent_id": 616,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix.astype(int)\n    n = matrix.shape[0]\n    eps = 1e-10\n    \n    def gf2_inv(mat):\n        n_inv = mat.shape[0]\n        I = np.eye(n_inv, dtype=int)\n        aug = np.hstack((mat, I.copy()))\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        matrices = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    except:\n        matrices = [matrix, matrix.T]\n    \n    tuples = []\n    for m in matrices:\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_sum_col = np.sum(np.log(col_sums + eps))\n        log_sum_row = np.sum(np.log(row_sums + eps))\n        total_ones = np.sum(col_sums)\n        min_col_dist = np.min(np.abs(col_sums - 1))\n        min_row_dist = np.min(np.abs(row_sums - 1))\n        diag_ones = np.sum(np.diag(m))\n        t = (log_sum_col, log_sum_row, total_ones, -min_col_dist, -min_row_dist, -diag_ones)\n        tuples.append(t)\n    \n    return min(tuples)\n",
    "evaluation": {
      "fitness": 0.8734495015576936,
      "additional_data": {
        "spearman_correlation": "0.873450",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 868,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 880,
    "parent_id": 112,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.append(inv_mat)\n        inv_transpose = gf2_inv(matrix.T)\n        if inv_transpose is not None:\n            variants.append(inv_transpose)\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        h_val = np.sum(np.log2(col_weights + 1e-10))  # small epsilon to avoid log(0)\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8736566708163407,
      "additional_data": {
        "spearman_correlation": "0.873657",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 869,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 881,
    "parent_id": 708,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    row_sums = np.sum(matrix, axis=1)\n    col_sums = np.sum(matrix, axis=0)\n    if np.all(row_sums == 1) and np.all(col_sums == 1):\n        return (0, 0)\n\n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        linear_term = 2 * (total_ones - n)\n        combined = 0.55 * (col_log + row_log) + 0.35 * linear_term\n        num_singles = np.sum(col_sums == 1) + np.sum(row_sums == 1)\n        return (combined, -num_singles)\n\n    original = calculate_metrics(matrix)\n    transpose = calculate_metrics(matrix.T)\n    metrics_list = [original, transpose]\n\n    if n <= 50:\n        try:\n            inv_matrix = np.round(np.linalg.inv(matrix)).astype(int) % 2\n            if inv_matrix.shape == matrix.shape:\n                inverse_metrics = calculate_metrics(inv_matrix)\n                metrics_list.append(inverse_metrics)\n        except:\n            pass\n\n    return min(metrics_list)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 745,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 882,
    "parent_id": 193,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_rank(mat):\n        rank = 0\n        n = mat.shape[0]\n        for col in range(n):\n            pivot = -1\n            for r in range(rank, n):\n                if mat[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                continue\n            if pivot != rank:\n                mat[[rank, pivot]] = mat[[pivot, rank]]\n            for r in range(rank+1, n):\n                if mat[r, col] == 1:\n                    mat[r] ^= mat[rank]\n            rank += 1\n        return rank\n    \n    def get_combined_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(col_sums)\n        \n        # Column/row features\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        weight2 = np.sum(col_sums == 2) + np.sum(row_sums == 2)\n        weight3plus = np.sum(col_sums >= 3) + np.sum(row_sums >= 3)\n        \n        # Dependency features\n        rank = gf2_rank(m.copy())\n        dep_features = (m.shape[0] - rank, np.sum(np.sum(m, axis=1) == 0))\n        \n        # Column/row relationships\n        col_overlaps = np.sum(m.T @ m)\n        row_overlaps = np.sum(m @ m.T)\n        \n        return (nonzeros, \n                -done_cols - done_rows,\n                -weight2,\n                weight3plus,\n                col_overlaps + row_overlaps,\n                *dep_features)\n    \n    # Main heuristic calculation\n    h_original = get_combined_heuristic(matrix)\n    h_transpose = get_combined_heuristic(matrix.T)\n    \n    # Try inverse if matrix is small enough\n    h_inverse = None\n    if matrix.shape[0] <= 8:\n        try:\n            inv_matrix = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n            h_inverse = get_combined_heuristic(inv_matrix)\n        except:\n            pass\n    \n    if h_inverse is not None:\n        return min(h_original, h_transpose, h_inverse)\n    return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7227893741989093,
      "additional_data": {
        "spearman_correlation": "0.722789",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 867,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 883,
    "parent_id": 248,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1)\n        row_sums = np.maximum(row_sums, 1)\n        col_log_sum = np.sum(np.log2(col_sums))\n        row_log_sum = np.sum(np.log2(row_sums))\n        col_var = 1.5 * np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        total_ones = np.sum(m)\n        return (col_log_sum, row_log_sum, col_var + row_var, total_ones)\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    if np.array_equal(matrix, np.eye(matrix.shape[0], dtype=int)):\n        return (0, 0, 0, 0)\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*4\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*4\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8747433044590874,
      "additional_data": {
        "spearman_correlation": "0.874743",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 870,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 884,
    "parent_id": 735,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Normalized column and row metrics\n        norm_cols = np.sum(col_sums) / n\n        norm_rows = np.sum(row_sums) / n\n        \n        # Prioritize columns/rows with single 1s or powers of 2\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        pow2_cols = np.sum([(x & (x-1)) == 0 for x in col_sums])\n        pow2_rows = np.sum([(x & (x-1)) == 0 for x in row_sums])\n        \n        # Structural patterns\n        diag = np.sum(np.diag(m))\n        anti_diag = np.sum(np.diag(np.fliplr(m)))\n        symmetry = np.sum(m == m.T) / (n*n)\n        \n        # Weighted difference metrics\n        row_diff = np.sum(np.abs(np.diff(m, axis=0)) * np.arange(n-1, 0, -1)[:, np.newaxis])\n        col_diff = np.sum(np.abs(np.diff(m, axis=1)) * np.arange(n-1, 0, -1)[np.newaxis, :])\n        \n        # Combine metrics with adjusted weights\n        metrics = (\n            -single_cols - single_rows - 0.5*pow2_cols - 0.5*pow2_rows,\n            norm_cols + norm_rows,\n            -(diag + anti_diag) - 0.3*symmetry,\n            row_diff + col_diff\n        )\n        return metrics\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 871,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 885,
    "parent_id": 764,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    matrix = matrix % 2\n    matrix_inv = np.linalg.inv(matrix) % 2\n    \n    variants = [matrix, matrix_inv, matrix.T, matrix_inv.T]\n    min_sum = float('inf')\n    \n    for m in variants:\n        col_sums = np.sum(m, axis=0)\n        current_sum = np.sum(col_sums)\n        if current_sum < min_sum:\n            min_sum = current_sum\n            \n    return min_sum\n",
    "evaluation": {
      "fitness": 0.86330357560152,
      "additional_data": {
        "spearman_correlation": "0.863304",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 879,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 886,
    "parent_id": 146,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering multiple matrix properties.\"\"\"\n    import numpy as np\n    \n    def matrix_properties(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        col_variance = np.var(col_sums)\n        row_variance = np.var(row_sums)\n        \n        weighted_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        weighted_row = np.sum(np.log2(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        return (total_ones, weighted_col, weighted_row, col_variance + row_variance, max_col + max_row)\n    \n    original_props = matrix_properties(matrix)\n    transposed_props = matrix_properties(matrix.T)\n    inverse_props = matrix_properties(np.linalg.inv(matrix).astype(int) % 2) if np.linalg.det(matrix) % 2 else (float('inf'),)\n    \n    return min(original_props, transposed_props, inverse_props)\n",
    "evaluation": {
      "fitness": 0.7210320382671255,
      "additional_data": {
        "spearman_correlation": "0.721032",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 875,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 887,
    "parent_id": 465,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 1e-10\n        \n        # Weighted column completion metrics\n        col_completion = np.sum(np.abs(col_sums - 1))\n        col_log_weights = np.sum((2 - col_sums) * np.log(col_sums + epsilon))  # Weight by distance from 1\n        \n        # Row completion metrics\n        row_completion = np.sum(np.abs(row_sums - 1))\n        row_log_weights = np.sum((2 - row_sums) * np.log(row_sums + epsilon))\n        \n        # Enhanced interaction term\n        interaction = np.sum(np.abs(m @ m.T))\n        non_zero_counts = np.sum(m > 0)\n        \n        # Structural metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        return (col_completion, row_completion, col_log_weights, \n                row_log_weights, interaction, non_zero_counts, tri_diff)\n    \n    # Calculate for original, inverse and transpose\n    inv = np.linalg.inv(matrix).astype(int) % 2\n    metrics_orig = calculate_metrics(matrix)\n    metrics_inv = calculate_metrics(inv)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    # Return lexicographically smallest tuple\n    return min(metrics_orig, metrics_inv, metrics_trans)\n",
    "evaluation": {
      "fitness": 0.7373591234324869,
      "additional_data": {
        "spearman_correlation": "0.737359",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 874,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 888,
    "parent_id": 497,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def basis_distance(col):\n        return min(np.sum(col != np.eye(len(col), 1, k)[:,0]) for k in range(len(col)))\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-10)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-10)))\n        non_zero = np.sum(m != 0)\n        \n        # Triangularity measures\n        upper_tri = np.sum(np.triu(m, k=1))\n        lower_tri = np.sum(np.tril(m, k=-1))\n        tri_metric = min(upper_tri, lower_tri)\n        \n        # Basis distance\n        basis_dist = sum(basis_distance(m[:,i]) for i in range(n))\n        \n        return (col_log + row_log, tri_metric, basis_dist, non_zero)\n    \n    original = calculate_metrics(matrix)\n    try:\n        inv_real = np.linalg.inv(matrix)\n        inv_mod2 = inv_real % 2\n        inverse_matrix = (inv_mod2 >= 0.5).astype(int)\n        inverse = calculate_metrics(inverse_matrix)\n    except:\n        inverse = (1e20, 1e20, 1e20, 1e20)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8584433884015823,
      "additional_data": {
        "spearman_correlation": "0.858443",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 873,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 889,
    "parent_id": 225,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def simple_distance(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Cost based on columns needing reduction\n        col_cost = np.sum(np.maximum(col_sums - 1, 0))\n        \n        # Cost based on rows needing reduction\n        row_cost = np.sum(np.maximum(row_sums - 1, 0))\n        \n        # Combine with preference for columns closer to completion\n        return (col_cost + row_cost) / (2 * m.shape[0])\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(simple_distance(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.040726399594420364,
      "additional_data": {
        "spearman_correlation": "0.040726",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 880,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 890,
    "parent_id": 555,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(matrix):\n        inv_float = np.linalg.inv(matrix)\n        inv_rounded = np.round(inv_float).astype(int)\n        inv_gf2 = inv_rounded % 2\n        return inv_gf2\n\n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        perfect_cols = np.sum(col_sums == 1)\n        perfect_rows = np.sum(row_sums == 1)\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sums = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sum_sq_cols = np.sum(col_sums**2)\n        sum_sq_rows = np.sum(row_sums**2)\n        col_entropy = -np.sum(col_sums * np.log2(np.where(col_sums > 0, col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log2(np.where(row_sums > 0, row_sums, 1)))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        return (nonzeros, -perfect_cols, -perfect_rows, log_col_sums, log_row_sums, \n                sum_sq_cols, sum_sq_rows, col_entropy, row_entropy, -max_col, -max_row, \n                min_col, min_row)\n\n    def get_all_variants(m):\n        variants = []\n        variants.append(('original', m))\n        try:\n            variants.append(('inv', gf2_inv(m)))\n        except np.linalg.LinAlgError:\n            pass\n        variants.append(('trans', m.T))\n        try:\n            variants.append(('inv_trans', gf2_inv(m.T)))\n        except np.linalg.LinAlgError:\n            pass\n        return variants\n\n    variants = get_all_variants(matrix)\n    heuristics = [get_heuristic(v[1]) for v in variants]\n    return min(heuristics)\n",
    "evaluation": {
      "fitness": 0.741188381253679,
      "additional_data": {
        "spearman_correlation": "0.741188",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 878,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 891,
    "parent_id": 725,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic with multiple weighted factors.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Component 1: log of column sums (prioritize nearly done columns)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Component 2: count of columns/rows with single 1 (immediate candidates)\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        # Component 3: spread of nonzeros (clustering is better)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        spread_penalty = np.sum((col_nonzeros - 1)**2) + np.sum((row_nonzeros - 1)**2)\n        \n        # Component 4: interaction between columns (potential for elimination)\n        interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                interactions += np.sum(m[:,i] & m[:,j])\n        \n        return (log_cols, -single_cols-single_rows, spread_penalty, interactions)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.7918886357443075,
      "additional_data": {
        "spearman_correlation": "0.791889",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 877,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 892,
    "parent_id": 116,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_nonzero = np.count_nonzero(m)\n        max_col = float(np.max(col_sums))\n        n = m.shape[0]\n        \n        # Basic features\n        col_log = np.sum(np.log(np.maximum(col_sums, 1e-5)))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1e-5)))\n        \n        # Advanced features\n        col_entropy = entropy(col_sums + 1e-5)\n        row_entropy = entropy(row_sums + 1e-5)\n        diag_dominance = np.sum(m.diagonal()) / n\n        off_diag = (total_nonzero - np.sum(m.diagonal())) / (n*(n-1))\n        \n        # Interaction features\n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        col_interactions /= (n*(n-1)/2)\n        \n        return np.array([\n            col_log * 0.4,\n            row_log * 0.3,\n            total_nonzero * 0.2,\n            max_col * 0.1,\n            col_entropy * 0.5,\n            row_entropy * 0.4,\n            diag_dominance * -0.3,\n            off_diag * 0.2,\n            col_interactions * 0.3\n        ])\n    \n    original = get_features(matrix)\n    inv_matrix = np.linalg.inv(matrix) % 2\n    inverse = get_features(inv_matrix)\n    transpose = get_features(matrix.T)\n    \n    combined = np.minimum.reduce([original, inverse, transpose])\n    return float(np.sum(combined))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 876,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 893,
    "parent_id": 171,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        non_zero = np.count_nonzero(m)\n        h1 = non_zero - n  # Extra non-zero elements beyond identity\n        h2 = np.sum(np.log(col_sums))  # Column sum log component\n        h3 = np.sum(np.log(row_sums))  # Row sum log component\n        return (h1, h2, h3)\n    \n    orig = calculate_heuristic(matrix)\n    trans = calculate_heuristic(matrix.T)\n    try:\n        inv_matrix = (np.round(np.linalg.inv(matrix)) % 2).astype(int)\n        inv = calculate_heuristic(inv_matrix)\n        inv_trans = calculate_heuristic(inv_matrix.T)\n        return min(orig, trans, inv, inv_trans)  # Lexicographic min\n    except np.linalg.LinAlgError:\n        return min(orig, trans)  # Fallback if inversion fails\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 789,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 894,
    "parent_id": 654,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic considering both row and column sums across multiple matrix transformations.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Combine column and row information with different weights\n        col_heuristic = np.sum(np.log(col_sums) + np.sum(np.log(1 + col_sums))\n        row_heuristic = np.sum(np.log(row_sums)) + np.sum(np.log(1 + row_sums))\n        return (col_heuristic + row_heuristic) / 2\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inverse_transpose = calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    \n    # Return all values as a tuple to avoid local minima\n    return (original, inverse, transpose, inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 13)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 881,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 895,
    "parent_id": 276,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Column metrics\n        unique_cols = len({tuple(col) for col in m.T})\n        col_completion = sum(1 for s in col_sums if s <= 1)\n        \n        # Row metrics\n        row_completion = sum(1 for s in row_sums if s <= 1)\n        \n        # LU decomposition metrics\n        _, u = lu(m)\n        upper_tri_nonzeros = np.count_nonzero(u)\n        \n        return (nonzeros,\n                -col_completion,\n                -row_completion,\n                -basis_cols,\n                -unique_cols,\n                -upper_tri_nonzeros)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 888,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 896,
    "parent_id": 52,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        abs_cols = np.sum(col_sums)\n        abs_rows = np.sum(row_sums)\n        \n        identity_dist = np.sum(m != np.eye(n))\n        col_completion = np.sum(col_sums == 1)\n        row_completion = np.sum(row_sums == 1)\n        spread_metric = np.sum(np.abs(np.corrcoef(m) - np.eye(n)))\n        \n        return (log_cols + log_rows, \n                abs_cols + abs_rows, \n                -identity_dist,\n                -col_completion - row_completion,\n                spread_metric)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 885,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 897,
    "parent_id": 838,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        sparsity = np.sum(m)\n        \n        # Adjusted weights with more emphasis on logarithmic terms and sparsity\n        return (0.8 * (col_log + row_log) + 0.15 * (col_linear + row_linear) + 0.05 * sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    # Return the minimum lexicographical tuple\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8719186709462479,
      "additional_data": {
        "spearman_correlation": "0.871919",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 886,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 898,
    "parent_id": 70,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_distance(col):\n        basis_dist = min(np.sum(col), np.sum(1-col))\n        return basis_dist if basis_dist > 0 else 1e-10\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_dists = [column_distance(m[:,i]) for i in range(n)]\n        row_dists = [column_distance(m[i,:]) for i in range(n)]\n        \n        # Column independence score (lower is better)\n        rank = np.linalg.matrix_rank(m)\n        independence = (n - rank) * 0.1\n        \n        # Column interaction terms\n        interaction = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = np.sum(m[:,i] & m[:,j])\n                interaction += overlap * 0.05\n        \n        col_log = np.sum(np.log(col_dists))\n        row_log = np.sum(np.log(row_dists))\n        col_linear = np.sum(col_dists)\n        row_linear = np.sum(row_dists)\n        \n        # Hierarchical combination\n        base_score = 0.5 * (col_log + row_log) \n        structural_score = 0.3 * (col_linear + row_linear)\n        adjustment = 0.2 * (interaction + independence)\n        \n        return (base_score + structural_score + adjustment,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 883,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 899,
    "parent_id": 59,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using column and row sums with logarithms.\"\"\"\n    import numpy as np\n    \n    def calculate_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 1e-5\n        log_cols = np.log(col_sums + epsilon)\n        log_rows = np.log(row_sums + epsilon)\n        return np.sum(log_cols) + np.sum(log_rows)\n    \n    h_original = calculate_metric(matrix)\n    h_inverse = calculate_metric(np.linalg.inv(matrix))\n    h_transpose = calculate_metric(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.35636150090110386,
      "additional_data": {
        "spearman_correlation": "0.356362",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 882,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 900,
    "parent_id": 735,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(m)\n        \n        # Normalized column and row metrics\n        norm_cols = np.sum(col_sums) / n\n        norm_rows = np.sum(row_sums) / n\n        \n        # Prioritize columns/rows with single 1s\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        # Structural patterns: count diagonal and anti-diagonal elements\n        diag = np.sum(np.diag(m))\n        anti_diag = np.sum(np.diag(np.fliplr(m)))\n        \n        # Improved weighted difference metrics\n        row_diff = np.sum(np.abs(np.diff(m, axis=0)) * np.arange(1, n)[:, np.newaxis])\n        col_diff = np.sum(np.abs(np.diff(m, axis=1)) * np.arange(1, n)[np.newaxis, :]\n        row_diff += np.sum(np.abs(np.diff(m[::-1], axis=0)) * np.arange(1, n)[:, np.newaxis])\n        col_diff += np.sum(np.abs(np.diff(m[:, ::-1], axis=1)) * np.arange(1, n)[np.newaxis, :]\n        \n        # Reordered and improved metrics\n        metrics = (\n            total_ones,                  # Base metric\n            -single_cols - single_rows,  # Prioritize single 1s\n            norm_cols + norm_rows,       # Sum of normalized sums\n            row_diff + col_diff,         # Weighted differences\n            -(diag + anti_diag)          # Structural patterns\n        )\n        return metrics\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    all_metrics = [calculate_metrics(m) for m in variants]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 25)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 887,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 901,
    "parent_id": 853,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with optimized weights and additional spread term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Slightly increased weight\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))  # Slightly increased weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.8 * np.sum(np.abs(col_sums - 1))  # Slightly increased weight\n        row_imbalance = 1.4 * np.sum(np.abs(row_sums - 1))  # Slightly increased weight\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.5 * np.var(col_sums)  # Increased weight\n        row_variance = 0.5 * np.var(row_sums)\n        sum_diff = 0.3 * np.abs(np.sum(col_sums) - np.sum(row_sums))  # Increased weight\n        spread = 0.2 * (max_col - min_col + max_row - min_row)  # New spread term\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, min_col + min_row, col_variance + row_variance,\n                sum_diff, spread, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return (h_original + h_inverse + h_transpose + h_inverse_transpose) / 4  # Using average instead of min\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unsupported operand type(s) for /: 'tuple' and 'int'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 884,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 902,
    "parent_id": 757,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column features\n        col_nonzeros = np.count_nonzero(col_sums)\n        col_log = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        # Row features\n        row_nonzeros = np.count_nonzero(row_sums)\n        row_log = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Combined metric\n        complexity = (col_log + row_log) * (col_nonzeros + row_nonzeros) / (2*n)\n        \n        return complexity\n    \n    # Consider only basic variants\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.03204371057252932,
      "additional_data": {
        "spearman_correlation": "0.032044",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 892,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 903,
    "parent_id": 817,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import math\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.sum(m, axis=1)\n        row_weights = np.maximum(row_weights, 1)\n        sum_weights = np.sum(m)\n        \n        log_cols = np.sum(np.log2(col_weights))\n        log_rows = np.sum(np.log2(row_weights))\n        pair_cols = np.sum(m.T @ m) - sum_weights\n        \n        h_val = (log_cols + log_rows + \n                0.1 * sum_weights + \n                0.05 * pair_cols)\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8721437953365538,
      "additional_data": {
        "spearman_correlation": "0.872144",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 889,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 904,
    "parent_id": 733,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count columns/rows with exactly one non-zero entry\n        single_cols = np.sum(col_sums == 1)\n        single_rows = np.sum(row_sums == 1)\n        \n        # Enhanced column metrics\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_imbalance = np.sum(np.abs(col_sums - 1) + np.sqrt(np.abs(col_sums - 1)))\n        \n        # Enhanced row metrics\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        row_imbalance = np.sum(np.abs(row_sums - 1) + np.sqrt(np.abs(row_sums - 1)))\n        \n        # Combined metrics\n        total_imbalance = col_imbalance + row_imbalance\n        log_combined = log_cols + log_rows\n        \n        # Sorted features for better lex ordering\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        return (nonzeros, single_cols + single_rows, total_imbalance, log_combined, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.857925722688659,
      "additional_data": {
        "spearman_correlation": "0.857926",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 890,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 905,
    "parent_id": 94,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def col_log_sum(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1)\n        return np.sum(np.log(col_sums))\n    \n    def row_log_sum(m):\n        row_sums = np.sum(m, axis=1)\n        row_sums = np.maximum(row_sums, 1)\n        return np.sum(np.log(row_sums))\n    \n    def total_entries(m):\n        return np.sum(m)\n    \n    original_col = col_log_sum(matrix)\n    original_row = row_log_sum(matrix)\n    inverse_col = col_log_sum(np.linalg.inv(matrix) % 2)\n    inverse_row = row_log_sum(np.linalg.inv(matrix) % 2)\n    transpose_col = col_log_sum(matrix.T)\n    transpose_row = row_log_sum(matrix.T)\n    inverse_transpose_col = col_log_sum(np.linalg.inv(matrix.T) % 2)\n    inverse_transpose_row = row_log_sum(np.linalg.inv(matrix.T) % 2)\n    total = total_entries(matrix)\n    total_inverse = total_entries(np.linalg.inv(matrix) % 2)\n    total_transpose = total_entries(matrix.T)\n    \n    return (original_col, original_row, inverse_col, inverse_row, transpose_col, transpose_row, \n            inverse_transpose_col, inverse_transpose_row, total, total_inverse, total_transpose)\n",
    "evaluation": {
      "fitness": 0.7930182646899011,
      "additional_data": {
        "spearman_correlation": "0.793018",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 893,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 906,
    "parent_id": 424,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using rank, spread, and basis proximity metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        rank = np.linalg.matrix_rank(m)\n        \n        # Column and row metrics\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_weights = np.count_nonzero(m, axis=0)\n        row_weights = np.count_nonzero(m, axis=1)\n        \n        # Basis proximity - how close columns are to unit vectors\n        basis_proximity = np.sum(np.exp(-np.abs(col_weights - 1)))\n        \n        # Spread metric - measures how evenly distributed non-zeros are\n        col_spread = np.sum(np.log2(np.abs(np.fft.fft(col_weights))[1:] + 1))\n        row_spread = np.sum(np.log2(np.abs(np.fft.fft(row_weights))[1:] + 1))\n        \n        # Interaction terms\n        col_interaction = np.sum(np.log2(col_sums + 1))\n        row_interaction = np.sum(np.log2(row_sums + 1))\n        \n        # Rank-related terms\n        rank_complexity = np.log2(rank + 1) * n\n        \n        return (rank_complexity, \n                -basis_proximity, \n                col_interaction + row_interaction, \n                col_spread + row_spread)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 895,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 907,
    "parent_id": 74,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        sum_part = np.sum(col_sums)\n        log_part = np.sum(np.log2(col_sums + 1))\n        return sum_part + log_part\n    \n    variants = [\n        matrix,\n        matrix.T,\n    ]\n    \n    try:\n        inv = np.linalg.inv(matrix)\n        if np.all(inv == inv.astype(int)):\n            variants.extend([inv, inv.T])\n    except:\n        pass\n    \n    return min(compute_metric(m) for m in variants)\n",
    "evaluation": {
      "fitness": -0.029432551833675557,
      "additional_data": {
        "spearman_correlation": "-0.029433",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 899,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 908,
    "parent_id": 393,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log2(col_sums + 1))\n        log_row = np.sum(np.log2(row_sums + 1))\n        frob_norm = np.linalg.norm(m, 'fro')\n        col_var = np.var(col_sums)\n        row_var = np.var(row_sums)\n        col_min = np.min(col_sums)\n        row_min = np.min(row_sums)\n        col_max = np.max(col_sums)\n        row_max = np.max(row_sums)\n        return (log_col, log_row, frob_norm, col_var, row_var, -col_min, -row_min, col_max, row_max)\n    \n    original = get_metrics(matrix)\n    transposed = get_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n        inverse = get_metrics(inv_matrix)\n    except:\n        inverse = (float('inf'),)*9\n    \n    return min(original, transposed, inverse)\n",
    "evaluation": {
      "fitness": 0.7216550811392889,
      "additional_data": {
        "spearman_correlation": "0.721655",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 896,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 909,
    "parent_id": 818,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with column uniqueness and orthogonality.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        m = m.astype(int)\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Count columns/rows with sum exactly 1\n        cols_done = np.sum(col_sums == 1)\n        rows_done = np.sum(row_sums == 1)\n        \n        # Count columns with sum <= 2 (almost done)\n        cols_almost = np.sum(col_sums <= 2)\n        rows_almost = np.sum(row_sums <= 2)\n        \n        # Measure column overlaps (how many rows share ones)\n        overlap = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap += np.sum(m[:,i] & m[:,j])\n        \n        # Count duplicate columns and rows\n        _, col_counts = np.unique(m, axis=1, return_counts=True)\n        _, row_counts = np.unique(m, axis=0, return_counts=True)\n        duplicates = np.sum(col_counts - 1) + np.sum(row_counts - 1)\n        \n        # Measure orthogonality (number of orthogonal column pairs)\n        ortho = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                ortho += np.dot(m[:,i], m[:,j]) == 0\n        \n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        \n        # Use squared differences for imbalance\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        \n        return (nonzeros, cols_done + rows_done, cols_almost + rows_almost, \n                overlap, duplicates, ortho, col_imbalance + row_imbalance, \n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix).astype(int))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.7113537640431168,
      "additional_data": {
        "spearman_correlation": "0.711354",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 894,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 910,
    "parent_id": 105,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering transpose and adjusted epsilon.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 1e-10\n        log_col_sums = np.log(col_sums + epsilon)\n        log_row_sums = np.log(row_sums + epsilon)\n        return (np.sum(m),) + tuple(sorted(log_col_sums)) + tuple(sorted(log_row_sums))\n    \n    h1 = calculate_heuristic(matrix)\n    h2 = calculate_heuristic(matrix.T)\n    return min(h1, h2)\n",
    "evaluation": {
      "fitness": 0.7809996163625903,
      "additional_data": {
        "spearman_correlation": "0.781000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 903,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 911,
    "parent_id": 131,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_distance(col):\n        basis_dist = min(np.sum(col != unit_col) for unit_col in np.eye(len(col), dtype=int).T)\n        return basis_dist\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_distances = [column_distance(m[:,i]) for i in range(n)]\n        row_distances = [column_distance(m[i,:]) for i in range(n)]\n        total_distance = sum(col_distances) + sum(row_distances)\n        \n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        \n        log_cols = np.sum(np.log(np.maximum(col_weights, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_weights, 1)))\n        \n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        basis_cols = sum(any(m[:,i] == unit_col) for i in range(n) \n                        for unit_col in np.eye(n, dtype=int).T)\n        \n        sorted_cols = tuple(sorted(col_weights, reverse=True))\n        sorted_rows = tuple(sorted(row_weights, reverse=True))\n        \n        return (total_distance, \n                -basis_cols,\n                col_interactions,\n                log_cols + log_rows,\n                *sorted_cols,\n                *sorted_rows)\n    \n    original = matrix.copy()\n    variants = [\n        original,\n        np.linalg.inv(original),\n        original.T,\n        np.linalg.inv(original).T\n    ]\n    \n    # Add column permutations\n    for _ in range(2):\n        perm = np.random.permutation(original.shape[1])\n        variants.append(original[:, perm])\n        variants.append(np.linalg.inv(original)[:, perm])\n    \n    return min(get_heuristic(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'any' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 900,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 912,
    "parent_id": 634,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def column_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        correct_cols = np.sum(col_sums == 1)\n        distance = np.sum(np.abs(col_sums - 1))\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        max_col = np.max(col_sums)\n        return (distance, -correct_cols, log_sum, max_col)\n\n    n = matrix.shape[0]\n    inv_matrix = gf2_inv(matrix)\n    \n    h_original = column_metrics(matrix)\n    h_transpose = column_metrics(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = column_metrics(inv_matrix)\n    h_inverse_transpose = column_metrics(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8712984044714928,
      "additional_data": {
        "spearman_correlation": "0.871298",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 902,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 913,
    "parent_id": 213,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_cost(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Distance to identity patterns\n        diag_dist = min(np.sum(m != np.eye(n, dtype=int)),\n                       np.sum(m != np.fliplr(np.eye(n, dtype=int))))\n        \n        # Column/row interaction metrics\n        col_inter = sum(np.sum(m[:,i] & m[:,j]) for i in range(n) for j in range(i+1, n))\n        row_inter = sum(np.sum(m[i,:] & m[j,:]) for i in range(n) for j in range(i+1, n))\n        \n        # Logarithmic column weight penalty (add small epsilon to avoid log(1))\n        log_col = np.sum(np.log2(col_sums + 1e-10))\n        \n        # Combine metrics with empirical weights\n        cost = 0.4*diag_dist + 0.3*log_col + 0.2*(col_inter + row_inter)/n + 0.1*(total_ones - n)\n        return cost\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2,\n        np.round(np.linalg.inv(matrix.T.astype(float)))).astype(int) % 2\n    ]\n    \n    return min(matrix_cost(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "closing parenthesis ')' does not match opening parenthesis '[' on line 26 (<string>, line 30)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 904,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 914,
    "parent_id": 771,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        col_weights = np.maximum(col_weights, 1)\n        row_weights = np.maximum(row_weights, 1)\n        sum_weights = np.sum(m)\n        off_diag = np.sum(m) - np.trace(m)\n        \n        h_val = (np.sum(np.log2(col_weights)) + 0.5 * np.sum(np.log2(row_weights)) + 0.03 * sum_weights + 0.01 * off_diag\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 41)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 905,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 915,
    "parent_id": 85,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using average of variants and including row sums.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 1e-5\n        row_sums = np.sum(m, axis=1) + 1e-5\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums))))\n    \n    h_original = calculate_heuristic(matrix)\n    h_inverse = calculate_heuristic(np.linalg.inv(matrix))\n    h_transpose = calculate_heuristic(matrix.T)\n    \n    return (h_original + h_inverse + h_transpose) / 3\n",
    "evaluation": {
      "fitness": 0.05578450162027523,
      "additional_data": {
        "spearman_correlation": "0.055785",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 909,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 916,
    "parent_id": 6,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering matrix variations and column sums.\"\"\"\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        return np.sum(col_sums * row_sums), np.sum(col_sums)\n    \n    original_metric = compute_metric(matrix)\n    transposed_metric = compute_metric(matrix.T)\n    \n    # Return the minimal main metric, followed by column sums\n    if original_metric[0] <= transposed_metric[0]:\n        return original_metric\n    else:\n        return transposed_metric\n",
    "evaluation": {
      "fitness": 0.7310815947049708,
      "additional_data": {
        "spearman_correlation": "0.731082",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 908,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 917,
    "parent_id": 218,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column-based features\n        col_weights = np.sort(col_sums)[::-1]\n        log_cols = np.sum(np.log2(np.maximum(col_weights, 1)))\n        col_entropy = entropy(col_weights + 1e-10)\n        col_pairwise = np.sum(m.T @ m) - n  # Interaction measure\n        \n        # Advanced column metrics\n        col_clusters = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_clusters += np.dot(m[:,i], m[:,j]) > 0\n        \n        # Normalized metrics\n        norm_log = log_cols / (2*n)\n        norm_entropy = col_entropy / np.log2(n+1)\n        norm_clusters = col_clusters / (n*(n-1)/2)\n        \n        return (nonzeros, \n                np.sum(col_weights > 1), \n                norm_log, \n                norm_entropy, \n                norm_clusters, \n                col_pairwise / n**2, \n                *col_weights)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 906,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 918,
    "parent_id": 819,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        epsilon = 1e-10\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_weights = np.count_nonzero(m, axis=0)\n        row_weights = np.count_nonzero(m, axis=1)\n        \n        total_sum = float(np.sum(m))\n        completed_cols = float(np.sum(col_weights == 1))\n        completed_rows = float(np.sum(row_weights == 1))\n        \n        col_completion = np.sum(1/(col_sums + epsilon*(col_sums==0)))\n        col_log = float(np.sum(np.log2(col_sums + epsilon*(col_sums==0))))\n        row_completion = np.sum(1/(row_sums + epsilon*(row_sums==0)))\n        row_log = float(np.sum(np.log2(row_sums + epsilon*(row_sums==0))))\n        \n        # Sort columns by weight and compute sorted metric\n        sorted_cols = m[:, np.argsort(col_weights)]\n        sorted_col_sums = np.sum(sorted_cols, axis=0)\n        sorted_metric = float(np.sum(sorted_col_sums * np.arange(1, n+1)))\n        \n        return (total_sum, completed_cols, completed_rows, col_completion, \n                row_completion, col_log, row_log, sorted_metric)\n    \n    # Compute metrics for original, transpose and inverse\n    metrics = []\n    metrics.append(compute_metrics(matrix))\n    metrics.append(compute_metrics(matrix.T))\n    if matrix.shape[0] == matrix.shape[1]:\n        try:\n            inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n            metrics.append(compute_metrics(inv_matrix))\n        except:\n            pass\n    \n    # Return the minimum tuple lexicographically\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.6912224033648059,
      "additional_data": {
        "spearman_correlation": "0.691222",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 907,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 919,
    "parent_id": 419,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    m = matrix.astype(int)\n    I = np.eye(n, dtype=int)\n    aug = np.hstack([m, I])\n    for col in range(n):\n        pivot_row = None\n        for r in range(col, n):\n            if aug[r, col] == 1:\n                pivot_row = r\n                break\n        if pivot_row is None:\n            raise ValueError(\"Matrix is singular\")\n        aug[[col, pivot_row]] = aug[[pivot_row, col]]\n        for r in range(n):\n            if r != col and aug[r, col] == 1:\n                aug[r] ^= aug[col]\n    return aug[:, n:]\n\ndef heuristic(matrix):\n    def get_heuristic(m):\n        m_int = m.astype(int)\n        col_sums = np.sum(m_int, axis=0)\n        row_sums = np.sum(m_int, axis=1)\n        nonzeros = col_sums.sum()\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        almost_done_cols = np.sum(col_sums == 2)\n        almost_done_rows = np.sum(row_sums == 2)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        max_row = np.max(row_sums) if row_sums.size > 0 else 0\n        sorted_cols = np.sort(col_sums)\n        sorted_rows = np.sort(row_sums)\n        interactions = np.sum(col_sums**2) + np.sum(row_sums**2)\n        return (nonzeros,\n                - (done_cols + done_rows),\n                - (almost_done_cols + almost_done_rows),\n                log_cols + log_rows,\n                max_col + max_row,\n                interactions,\n                *sorted_cols,\n                *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    try:\n        inv_matrix = gf2_inv(matrix)\n        h_inverse = get_heuristic(inv_matrix)\n    except Exception:\n        h_inverse = h_original\n    h_transpose = get_heuristic(matrix.T)\n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 816,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 920,
    "parent_id": 826,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metric(col, matrix):\n        col_sum = np.sum(col)\n        # Weight by how close column is to being a basis vector\n        basis_dist = min(np.sum(np.abs(col - basis)) for basis in np.eye(matrix.shape[0], dtype=int))\n        # Count how many other columns share nonzero positions\n        overlap = np.sum(np.any(matrix & col[:, np.newaxis], axis=0)) - 1\n        return col_sum * (1 + 0.5 * basis_dist + 0.2 * overlap)\n    \n    n = matrix.shape[0]\n    if np.array_equal(matrix, np.eye(n, dtype=int)):\n        return (0.0,)\n    \n    col_metrics = []\n    for i in range(matrix.shape[1]):\n        col = matrix[:, i]\n        col_metrics.append(column_metric(col, matrix))\n    \n    # Return sorted tuple of column metrics in descending order\n    return tuple(sorted(col_metrics, reverse=True))\n",
    "evaluation": {
      "fitness": 0.5366698526394599,
      "additional_data": {
        "spearman_correlation": "0.536670",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 910,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 921,
    "parent_id": 910,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using log2 and adjusted epsilon.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        epsilon = 2e-5  # Adjusted for log2\n        log_col_sums = np.log2(col_sums + epsilon)\n        log_row_sums = np.log2(row_sums + epsilon)\n        return (np.sum(m),) + tuple(sorted(log_col_sums)) + tuple(sorted(log_row_sums))\n    \n    h1 = calculate_heuristic(matrix)\n    h2 = calculate_heuristic(matrix.T)\n    return min(h1, h2)\n",
    "evaluation": {
      "fitness": 0.7809996163625903,
      "additional_data": {
        "spearman_correlation": "0.781000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 913,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 922,
    "parent_id": 520,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        total_ones = np.sum(m)\n        log_col = np.sum(np.log2(col_sums + 1))\n        return total_ones + log_col\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n        inverse = matrix_metrics(inv_matrix)\n        inv_transposed = matrix_metrics(inv_matrix.T)\n        return min(original, transposed, inverse, inv_transposed)\n    except np.linalg.LinAlgError:\n        return min(original, transposed)\n",
    "evaluation": {
      "fitness": 0.7396007660578068,
      "additional_data": {
        "spearman_correlation": "0.739601",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 916,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 923,
    "parent_id": 663,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        sparse_col_boost = np.sum(col_sums == 1)\n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        return (log_cols, -sparse_col_boost, max_col)\n    \n    inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    options = [\n        evaluate(matrix),\n        evaluate(matrix.T),\n        evaluate(inv_matrix),\n        evaluate(inv_matrix.T)\n    ]\n    return min(options)\n",
    "evaluation": {
      "fitness": 0.7218418835086897,
      "additional_data": {
        "spearman_correlation": "0.721842",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 858,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 924,
    "parent_id": 853,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional correct terms.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = 1.8 * np.sum(np.log2(np.maximum(col_sums, 1)))  # Slightly increased weight\n        log_rows = 0.9 * np.sum(np.log2(np.maximum(row_sums, 1)))  # Slightly increased weight\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = 2.7 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.3 * np.sum(np.abs(row_sums - 1))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        min_col = np.min(col_sums)\n        min_row = np.min(row_sums)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        col_variance = 0.5 * np.var(col_sums)  # Increased weight\n        row_variance = 0.5 * np.var(row_sums)\n        return (nonzeros, -correct_cols-correct_rows, correct_cols+correct_rows,\n                log_cols+log_rows, col_imbalance + row_imbalance, \n                max_col + max_row, min_col + min_row, col_variance + row_variance,\n                *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.882747839881238,
      "additional_data": {
        "spearman_correlation": "0.882748",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 911,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 925,
    "parent_id": 580,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        basis_cols = np.linalg.matrix_rank(m)\n        \n        # Count unique columns and rows\n        unique_cols = 1\n        cols = [tuple(col) for col in m.T]\n        for i in range(1, len(cols)):\n            if cols[i] not in cols[:i]:\n                unique_cols += 1\n                \n        unique_rows = 1\n        rows = [tuple(row) for row in m]\n        for i in range(1, len(rows)):\n            if rows[i] not in rows[:i]:\n                unique_rows += 1\n                \n        col_completion = sum(col_sums)\n        row_completion = sum(row_sums)\n        log_col_sums = sum(np.log2(np.where(col_sums > 0, col_sums, 1)))\n        \n        # Count columns that are basis vectors\n        basis_vector_cols = sum(1 for s in col_sums if s == 1)\n        \n        # Count linearly independent columns\n        _, inds = sympy.Matrix(m).T.rref()\n        lin_indep_cols = len(inds)\n        \n        return (nonzeros, \n                col_completion,\n                row_completion,\n                log_col_sums,\n                -basis_cols,\n                -unique_cols,\n                -unique_rows,\n                -basis_vector_cols,\n                -lin_indep_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'sympy' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 912,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 926,
    "parent_id": 615,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Refined heuristic focusing on most predictive metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.count_nonzero(m)\n        perm_distance = np.sum(np.abs(m - np.eye(n)))\n        log_cols = np.sum(np.log2(col_sums + 1))  # +1 to avoid log(0)\n        \n        return (nonzeros, perm_distance, log_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix) % 2)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8567689979915439,
      "additional_data": {
        "spearman_correlation": "0.856769",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 915,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 927,
    "parent_id": 742,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_score(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Improved weighting: combine uniqueness and column sums\n        _, col_counts = np.unique(m, axis=0, return_counts=True)\n        _, row_counts = np.unique(m, axis=1, return_counts=True)\n        col_weights = 1 / (1 + col_counts + np.log(1 + col_sums))\n        row_weights = 1 / (1 + row_counts + np.log(1 + row_sums))\n        \n        # Distance to identity with logarithmic scaling\n        identity_dist = np.sum(np.log(1 + (m != np.eye(n))))\n        \n        # Simplified interaction term\n        interactions = np.sum(np.abs(m - np.eye(n)))\n        \n        # Combine terms with normalization\n        col_term = np.sum(col_sums * col_weights) / n\n        row_term = np.sum(row_sums * row_weights) / n\n        return (identity_dist, interactions, col_term + row_term)\n    \n    original = matrix_score(matrix)\n    transposed = matrix_score(matrix.T)\n    inverse = matrix_score(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    return min(original, transposed, inverse)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'<' not supported between instances of 'tuple' and 'float'"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 914,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 928,
    "parent_id": 420,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(col_sums)\n        \n        # Normalized column completion (prioritize nearly-complete columns)\n        col_completion = np.sum(1/(1 + np.abs(col_sums - 1)))\n        \n        # Row distribution penalty (normalized)\n        row_penalty = np.sum((row_sums - np.mean(row_sums))**2)/n\n        \n        # Column distribution penalty (normalized)\n        col_penalty = np.sum((col_sums - np.mean(col_sums))**2)/n\n        \n        # Sparsity term (normalized)\n        sparsity = total_ones / (n*n)\n        \n        return (col_completion, -row_penalty, -col_penalty, sparsity)\n    \n    # Generate all equivalent matrices\n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    # Return the best variant's heuristic\n    return min(evaluate(v) for v in variants if np.all(np.isfinite(v)))\n",
    "evaluation": {
      "fitness": -0.7754029130859266,
      "additional_data": {
        "spearman_correlation": "-0.775403",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 918,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 929,
    "parent_id": 541,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_analysis(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_patterns = [tuple(m[:,i]) for i in range(n)]\n        unique_patterns = set(row_patterns)\n        \n        # Score based on column sums and uniqueness\n        col_score = np.sum(np.where(col_sums == 1, 0, np.log(col_sums + 1)))\n        pattern_score = len(unique_patterns) / n\n        \n        # Check for columns that are subsets of others\n        subset_count = 0\n        for i in range(n):\n            for j in range(n):\n                if i != j and np.all(m[:,i] <= m[:,j]):\n                    subset_count += 1\n                    break\n        subset_score = subset_count / n\n        \n        return (col_score, pattern_score, subset_score)\n    \n    def matrix_score(m):\n        if np.array_equal(m, np.eye(m.shape[0], dtype=int)):\n            return (0, 0, 0)\n        \n        col_features = column_analysis(m)\n        row_features = column_analysis(m.T)\n        \n        # Prioritize column structure first, then row structure, then their interaction\n        return (col_features[0] + 0.5 * col_features[1] + 0.3 * col_features[2],\n                row_features[0] + 0.5 * row_features[1] + 0.3 * row_features[2],\n                np.sum(m) / (m.shape[0]**2))\n    \n    variants = [\n        matrix,\n        matrix.T,\n        np.linalg.inv(matrix.astype(float)).astype(int) % 2,\n        matrix.T @ matrix % 2,\n        matrix @ matrix.T % 2\n    ]\n    \n    scores = [matrix_score(m) for m in variants]\n    return min(scores)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'set' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 917,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 930,
    "parent_id": 448,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Weighted imbalance with more focus on columns\n        col_imbalance = np.sum(np.abs(col_sums - 1) * 1.5)\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        # More granular correct counts\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        # Enhanced diagonal consideration\n        diag_elements = np.sum(np.diag(m)) * 2  # Double weight\n        # Add interaction term between rows and columns\n        interaction = np.sum(np.abs(m - np.eye(m.shape[0], dtype=int)))\n        # Sorted columns with more granularity\n        sorted_cols = tuple(sorted(col_sums, reverse=True))\n        return (nonzeros, col_imbalance + row_imbalance, interaction, -correct_cols, -correct_rows, -diag_elements, *sorted_cols)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8765849796868377,
      "additional_data": {
        "spearman_correlation": "0.876585",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 1,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 919,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 931,
    "parent_id": 376,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def hierarchical_complexity(m):\n        n = m.shape[0]\n        if n <= 1:\n            return 0\n        \n        # Base complexity measure\n        col_weights = np.sum(m, axis=0)\n        row_weights = np.sum(m, axis=1)\n        complexity = np.sum(col_weights * row_weights)\n        \n        # Recursive decomposition\n        split = n // 2\n        submatrices = [\n            m[:split, :split], m[:split, split:],\n            m[split:, :split], m[split:, split:]\n        ]\n        \n        sub_complexity = sum(hierarchical_complexity(sub) for sub in submatrices)\n        \n        # Cross-block interactions\n        cross_interaction = (np.sum(m[:split, split:]) + np.sum(m[split:, :split])) * (n / 2)\n        \n        return complexity + sub_complexity + cross_interaction\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(hierarchical_complexity(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.020235549315107352,
      "additional_data": {
        "spearman_correlation": "-0.020236",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 920,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 932,
    "parent_id": 425,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved with squared differences and adjusted sparsity term.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Row distribution penalty using squared differences\n        row_dist = np.sum((np.sum(m, axis=1) - 1)**2)\n        \n        # More sensitive sparsity term\n        sparsity = np.log10(np.count_nonzero(m) + 1) - np.log10(n)\n        \n        return (col_completion, col_dist, row_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8832839332851957,
      "additional_data": {
        "spearman_correlation": "0.883284",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 922,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 933,
    "parent_id": 579,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    n = matrix.shape[0]\n    dtype = matrix.dtype\n    \n    # Compute GF(2) inverse via Gaussian elimination\n    def gf2_inv(m):\n        n_inv = m.shape[0]\n        aug = np.hstack((m, np.eye(n_inv, dtype=dtype)))\n        for col in range(n_inv):\n            pivot = -1\n            for r in range(col, n_inv):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    # Get representations\n    inv = gf2_inv(matrix)\n    reps = [matrix, matrix.T]\n    if inv is not None:\n        reps += [inv, inv.T]\n    \n    # Compute log-sum column cost\n    best_cost = float('inf')\n    best_total = float('inf')\n    for rep in reps:\n        c = 0.0\n        for j in range(rep.shape[1]):\n            w = np.sum(rep[:, j])\n            if w > 0:\n                c += np.log(w)\n        t = np.sum(rep)\n        if c < best_cost or (c == best_cost and t < best_total):\n            best_cost = c\n            best_total = t\n            \n    return (best_cost, best_total)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 818,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 934,
    "parent_id": 72,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic terms and diagonal consideration.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        diag_sum = np.sum(np.diag(m))\n        # Sort sums to make order irrelevant\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        # Add logarithmic terms\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        # Add terms for both column and row weight distributions\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance + row_imbalance, log_cols + log_rows, \n                diag_sum, *sorted_cols, *sorted_rows)\n    \n    try:\n        h_original = get_heuristic(matrix)\n        h_inverse = get_heuristic(np.linalg.inv(matrix))\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_inverse, h_transpose)\n    except:\n        return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.8797705600301479,
      "additional_data": {
        "spearman_correlation": "0.879771",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 923,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 14
    }
  },
  {
    "id": 935,
    "parent_id": 321,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional weight distribution metrics.\"\"\"\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def analyze(m):\n        n = m.shape[0]\n        col_props = []\n        row_props = []\n        \n        for i in range(n):\n            col = m[:, i]\n            row = m[i, :]\n            col_weight = np.sum(col)\n            row_weight = np.sum(row)\n            col_props.append((col_weight, int(col[i]), np.sum(col[i+1:])))\n            row_props.append((row_weight, int(row[i]), np.sum(row[i+1:])))\n            \n        diag = np.diag(m)\n        diag_sum = np.sum(diag)\n        off_diag = np.sum(m) - diag_sum\n        \n        col_weights = [p[0] for p in col_props]\n        row_weights = [p[0] for p in row_props]\n        col_weights_sorted = sorted(col_weights, reverse=True)\n        row_weights_sorted = sorted(row_weights, reverse=True)\n        col_diag = sum(p[1] for p in col_props)\n        row_diag = sum(p[1] for p in row_props)\n        col_tri = sum(p[2] for p in col_props)\n        row_tri = sum(p[2] for p in row_props)\n        \n        # Additional metrics\n        col_weight_var = np.var(col_weights)\n        row_weight_var = np.var(row_weights)\n        max_col = max(col_weights)\n        max_row = max(row_weights)\n        \n        return (\n            off_diag,\n            diag_sum,\n            tuple(col_weights_sorted),\n            tuple(row_weights_sorted),\n            col_diag + row_diag,\n            col_tri + row_tri,\n            col_weight_var,\n            row_weight_var,\n            max_col,\n            max_row\n        )\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    h_original = analyze(matrix)\n    h_inverse = analyze(inv_matrix)\n    h_transpose = analyze(matrix.T)\n    h_inverse_transpose = analyze(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.767867227824269,
      "additional_data": {
        "spearman_correlation": "0.767867",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 921,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 936,
    "parent_id": 34,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log(np.where(col_sums == 0, 1, col_sums)))\n        row_log = np.sum(np.log(np.where(row_sums == 0, 1, row_sums)))\n        return (float(np.sum(m)), col_log, row_log)\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.7757513419919929,
      "additional_data": {
        "spearman_correlation": "0.775751",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 927,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 937,
    "parent_id": 412,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with L2 column distribution and weighted sparsity.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion with log2 weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1e-10))\n        \n        # Column distribution penalty using squared differences\n        col_dist = np.sum((np.sum(m, axis=0) - 1)**2)\n        \n        # Weighted sparsity term\n        sparsity = 0.5 * np.log2(np.count_nonzero(m) + 1)\n        \n        return (col_completion, col_dist, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8832278036145199,
      "additional_data": {
        "spearman_correlation": "0.883228",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 925,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 938,
    "parent_id": 102,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with adjusted weights and additional column metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        # Column metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1)) * 2.0  # Increased weight\n        max_col = max(col_sums)\n        min_col = min(col_sums)\n        # Row metrics with reduced weight\n        row_imbalance = np.sum(np.abs(row_sums - 1)) * 0.25  # Reduced weight\n        return (nonzeros, col_imbalance + row_imbalance, max_col, min_col)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8775047387384564,
      "additional_data": {
        "spearman_correlation": "0.877505",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 924,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 939,
    "parent_id": 805,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    trans_col_sums = np.sum(matrix.T, axis=0)\n    trans_row_sums = np.sum(matrix.T, axis=1)\n    \n    def col_score(sums):\n        weights = np.where(sums == 1, 0, 1/(0.05 + np.abs(sums - 1)))\n        return np.sum(weights * sums)\n    \n    def row_score(sums):\n        weights = np.where(sums == 1, 0, 1/(0.2 + np.abs(sums - 1)))\n        return np.sum(weights * sums)\n    \n    original_score = col_score(col_sums) + 0.8 * row_score(row_sums)\n    transposed_score = col_score(trans_col_sums) + 0.8 * row_score(trans_row_sums)\n    return min(original_score, transposed_score)\n",
    "evaluation": {
      "fitness": 0.615363549962861,
      "additional_data": {
        "spearman_correlation": "0.615364",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 928,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 940,
    "parent_id": 472,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        col_imbalance = np.sum(np.abs(col_sums - 1))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        return (nonzeros, col_imbalance + row_imbalance, \n                log_cols + log_rows, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8822018288322528,
      "additional_data": {
        "spearman_correlation": "0.882202",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 930,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 941,
    "parent_id": 673,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with enhanced diagonal term and natural log.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum((col_sums - 1)**2)\n        row_imbalance = np.sum((row_sums - 1)**2)\n        diag_score = np.sum(np.diag(m) != 1)  # now counts incorrect diagonal entries\n        col_parity = np.sum(col_sums % 2)\n        row_parity = np.sum(row_sums % 2)\n        return (nonzeros, -done_cols-done_rows, log_cols+log_rows, col_imbalance + row_imbalance, \n                diag_score, col_parity + row_parity, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8820265889881079,
      "additional_data": {
        "spearman_correlation": "0.882027",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 929,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 942,
    "parent_id": 804,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    m = matrix.astype(int)\n    m_t = m.T\n    \n    def compute_cost(mat):\n        col_sums = np.sum(mat, axis=0)\n        total = np.sum(mat)\n        log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        return total + log_sum\n    \n    return min(compute_cost(m), compute_cost(m_t))\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 933,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 943,
    "parent_id": 679,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_metrics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Count basis vectors\n        col_basis = np.sum([1 for col in m.T if np.sum(col) == 1])\n        row_basis = np.sum([1 for row in m if np.sum(row) == 1])\n        \n        # Measure column/row overlaps\n        col_overlaps = np.sum([np.dot(c1, c2) for i, c1 in enumerate(m.T) \n                              for j, c2 in enumerate(m.T) if i < j])\n        row_overlaps = np.sum([np.dot(r1, r2) for i, r1 in enumerate(m) \n                              for j, r2 in enumerate(m) if i < j])\n        \n        # Measure clustering (sum of pairwise column distances)\n        col_distances = np.sum([np.sum(np.abs(c1 - c2)) for i, c1 in enumerate(m.T) \n                              for j, c2 in enumerate(m.T) if i < j])\n        row_distances = np.sum([np.sum(np.abs(r1 - r2)) for i, r1 in enumerate(m) \n                              for j, r2 in enumerate(m) if i < j])\n        \n        # Total non-zero entries\n        total_entries = np.sum(m)\n        \n        return (total_entries, \n                -col_basis, \n                -row_basis, \n                col_overlaps, \n                row_overlaps, \n                col_distances, \n                row_distances)\n    \n    # Consider original, transposed, and row/column permutations\n    metrics = []\n    for m in [matrix, matrix.T]:\n        metrics.append(get_metrics(m))\n        # Try swapping first two rows/columns\n        for i in [0, 1]:\n            swapped = m.copy()\n            if i == 0 and m.shape[0] > 1:\n                swapped[[0,1]] = swapped[[1,0]]  # Swap rows\n            elif i == 1 and m.shape[1] > 1:\n                swapped[:,[0,1]] = swapped[:,[1,0]]  # Swap columns\n            metrics.append(get_metrics(swapped))\n    \n    # Return the minimum metric tuple\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.7689892322111643,
      "additional_data": {
        "spearman_correlation": "0.768989",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 926,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 944,
    "parent_id": 834,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        col_weights = np.sum(m, axis=0)\n        \n        log_penalty = np.sum(np.log1p(col_nonzeros))\n        weight_penalty = np.sum(np.log1p(col_weights))\n        diff_penalty = np.sum(np.abs(m - np.eye(n)))\n        \n        return log_penalty + weight_penalty + diff_penalty\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(column_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.09782812707808412,
      "additional_data": {
        "spearman_correlation": "0.097828",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 936,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 945,
    "parent_id": 785,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Focus on column metrics which are most relevant for CNOT synthesis\n        col_completion = np.sum(col_sums == 1)\n        col_log = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_dist = np.sum(np.abs(col_sums - 1))\n        \n        # Simple row metric to break ties\n        row_dist = np.sum(np.abs(row_sums - 1))\n        \n        return (col_dist, -col_completion, col_log, row_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.3105027100688035,
      "additional_data": {
        "spearman_correlation": "0.310503",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 935,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 946,
    "parent_id": 440,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        A = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((A, I))\n        aug = aug.copy()\n\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    variants = [matrix, matrix.T]\n    inv_mat = gf2_inv(matrix)\n    if inv_mat is not None:\n        variants.extend([inv_mat, inv_mat.T])\n    \n    min_heuristic = float('inf')\n    for m in variants:\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1)\n        sum_weights = np.sum(m)\n        \n        h_val = np.sum(1/(col_weights)) + 0.05 * sum_weights\n        if h_val < min_heuristic:\n            min_heuristic = h_val\n            \n    return min_heuristic\n",
    "evaluation": {
      "fitness": -0.7844912696808309,
      "additional_data": {
        "spearman_correlation": "-0.784491",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 931,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 947,
    "parent_id": 391,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    total_sum = np.sum(matrix)\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    epsilon = 1e-15\n    \n    log_cols_sorted = tuple(sorted(np.log(col_sums + epsilon)))\n    log_rows_sorted = tuple(sorted(np.log(row_sums + epsilon)))\n    \n    tuple1 = (total_sum,) + log_cols_sorted + log_rows_sorted\n    tuple2 = (total_sum,) + log_rows_sorted + log_cols_sorted\n    \n    return min(tuple1, tuple2)\n",
    "evaluation": {
      "fitness": 0.7809996163625903,
      "additional_data": {
        "spearman_correlation": "0.781000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 901,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 948,
    "parent_id": 503,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(m):\n        n_inv = m.shape[0]\n        aug = np.hstack([m, np.eye(n_inv, dtype=int)])\n        for col in range(n_inv):\n            pivot_row = -1\n            for r in range(col, n_inv):\n                if aug[r, col]:\n                    pivot_row = r\n                    break\n            if pivot_row == -1:\n                return None\n            if pivot_row != col:\n                aug[[col, pivot_row]] = aug[[pivot_row, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n_inv:]\n    \n    transformations = [matrix]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        transformations.append(inv_matrix)\n    transformations.append(matrix.T)\n    inv_transpose = gf2_inv(matrix.T)\n    if inv_transpose is not None:\n        transformations.append(inv_transpose)\n    transformations.append((matrix @ matrix.T) % 2)\n    transformations.append((matrix.T @ matrix) % 2)\n    \n    best_tuple = None\n    for m in transformations:\n        total_sum = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        col_sum_log = np.sum(np.log2(col_sums))\n        t = (total_sum, col_sum_log)\n        if best_tuple is None or t < best_tuple:\n            best_tuple = t\n            \n    return best_tuple\n",
    "evaluation": {
      "fitness": 0.3362527124174592,
      "additional_data": {
        "spearman_correlation": "0.336253",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 812,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 949,
    "parent_id": 539,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        total_ones = np.sum(m)\n        col_nonzeros = np.sum(col_sums > 0)\n        return (log_col, log_row, total_ones, col_nonzeros)\n    \n    metrics_orig = calculate_metrics(matrix)\n    metrics_trans = calculate_metrics(matrix.T)\n    \n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = (np.abs(inv_matrix) > 0.5).astype(float)\n        metrics_inv = calculate_metrics(inv_matrix)\n        metrics_inv_trans = calculate_metrics(inv_matrix.T)\n    except:\n        metrics_inv = metrics_orig\n        metrics_inv_trans = metrics_trans\n    \n    combined = [\n        0.40 * metrics_orig[0] + 0.20 * metrics_orig[1] + 0.20 * metrics_orig[2] + 0.20 * metrics_orig[3],\n        0.40 * metrics_trans[0] + 0.20 * metrics_trans[1] + 0.20 * metrics_trans[2] + 0.20 * metrics_trans[3],\n        0.40 * metrics_inv[0] + 0.20 * metrics_inv[1] + 0.20 * metrics_inv[2] + 0.20 * metrics_inv[3],\n        0.40 * metrics_inv_trans[0] + 0.20 * metrics_inv_trans[1] + 0.20 * metrics_inv_trans[2] + 0.20 * metrics_inv_trans[3]\n    ]\n    \n    combined_sorted = sorted(combined)\n    return tuple(combined_sorted)\n",
    "evaluation": {
      "fitness": 0.7478355648242646,
      "additional_data": {
        "spearman_correlation": "0.747836",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 934,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 950,
    "parent_id": 473,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.linalg import lu\n    \n    def get_metrics(m):\n        m = m % 2\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Basic metrics\n        log_col = np.sum(np.log(col_sums))\n        sum_col = np.sum(col_sums)\n        var_col = np.var(col_sums)\n        \n        # Advanced metrics\n        rank = np.linalg.matrix_rank(m)\n        _, u = lu(m)\n        u_rank = np.sum(np.any(u % 2, axis=1))\n        \n        # Column interaction metrics\n        col_deps = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_deps += np.sum(m[:,i] & m[:,j])\n        \n        # Row interaction metrics\n        row_deps = 0\n        for i in range(m.shape[0]):\n            for j in range(i+1, m.shape[0]):\n                row_deps += np.sum(m[i,:] & m[j,:])\n        \n        return (log_col, sum_col, var_col, -rank, -u_rank, col_deps, row_deps)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2,\n        matrix @ matrix.T % 2,\n        np.linalg.inv(matrix @ matrix.T) % 2,\n        matrix.T @ matrix % 2,\n        np.linalg.inv(matrix.T @ matrix) % 2\n    ]\n    \n    all_metrics = [get_metrics(v) for v in variants]\n    combined = tuple(np.mean([m[i] for m in all_metrics]) for i in range(7))\n    return combined\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "too many values to unpack (expected 2)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 932,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 951,
    "parent_id": 912,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        distance = np.sum(np.abs(col_sums - 1)) + np.sum(np.abs(row_sums - 1))\n        log_sum = np.sum(np.log(np.maximum(col_sums, 1))) + np.sum(np.log(np.maximum(row_sums, 1)))\n        max_val = max(np.max(col_sums), np.max(row_sums))\n        total_nonzero = np.sum(m)\n        return (distance, -correct_cols-correct_rows, log_sum, max_val, total_nonzero)\n\n    n = matrix.shape[0]\n    inv_matrix = gf2_inv(matrix)\n    \n    h_original = matrix_metrics(matrix)\n    h_transpose = matrix_metrics(matrix.T)\n    \n    if inv_matrix is None:\n        return min(h_original, h_transpose)\n    \n    h_inverse = matrix_metrics(inv_matrix)\n    h_inverse_transpose = matrix_metrics(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8718247834697302,
      "additional_data": {
        "spearman_correlation": "0.871825",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 937,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 952,
    "parent_id": 923,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        sparse_col_boost = np.sum((col_sums == 1) | (col_sums == np.shape(m)[0]-1))\n        sparse_row_boost = np.sum((row_sums == 1) | (row_sums == np.shape(m)[0]-1))\n        \n        max_col = np.max(col_sums) if col_sums.size > 0 else 0\n        max_row = np.max(row_sums) if row_sums.size > 0 else 0\n        \n        unique_cols = len(np.unique(m, axis=0))\n        unique_rows = len(np.unique(m, axis=1))\n        \n        return (log_cols + log_rows, \n                -(sparse_col_boost + sparse_row_boost), \n                max(max_col, max_row),\n                -(unique_cols + unique_rows))\n    \n    inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n    options = [\n        evaluate(matrix),\n        evaluate(matrix.T),\n        evaluate(inv_matrix),\n        evaluate(inv_matrix.T)\n    ]\n    return min(options)\n",
    "evaluation": {
      "fitness": 0.7253899998852765,
      "additional_data": {
        "spearman_correlation": "0.725390",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 941,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 953,
    "parent_id": 382,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log_sum = np.sum(np.log2(col_sums))\n        row_log_sum = np.sum(np.log2(row_sums))\n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        completed_cols = np.sum(col_sums == 1)\n        completed_rows = np.sum(row_sums == 1)\n        return (col_log_sum, row_log_sum, max_col, max_row, -completed_cols, -completed_rows)\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*6\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*6\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8747704082375206,
      "additional_data": {
        "spearman_correlation": "0.874770",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 940,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 954,
    "parent_id": 192,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column/row metrics\n        col_weights = np.sort(col_sums)[::-1]\n        row_weights = np.sort(row_sums)[::-1]\n        col_entropy = -np.sum(col_sums * np.log2(np.where(col_sums > 0, col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log2(np.where(row_sums > 0, row_sums, 1)))\n        \n        # Structural metrics\n        rank = np.linalg.matrix_rank(m)\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri.T))\n        \n        # Column/row interactions\n        col_correlations = np.corrcoef(m, rowvar=False)\n        row_correlations = np.corrcoef(m)\n        col_corr_entropy = -np.sum(col_correlations * np.log2(np.where(col_correlations > 0, col_correlations, 1)))\n        row_corr_entropy = -np.sum(row_correlations * np.log2(np.where(row_correlations > 0, row_correlations, 1)))\n        \n        # Distance metrics\n        identity = np.eye(n)\n        col_dist = np.sum(np.abs(m - identity))\n        row_dist = np.sum(np.abs(m.T - identity))\n        \n        # Higher-order metrics\n        svd = np.linalg.svd(m, compute_uv=False)\n        svd_entropy = -np.sum(svd * np.log2(np.where(svd > 0, svd, 1))))\n        \n        return (nonzeros, \n                -rank, \n                col_entropy + row_entropy,\n                col_corr_entropy + row_corr_entropy,\n                tri_diff,\n                col_dist + row_dist,\n                svd_entropy,\n                *col_weights,\n                *row_weights)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "unmatched ')' (<string>, line 36)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 938,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 955,
    "parent_id": 356,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic focusing on nearly-solved columns and aggressive transforms.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        # Focus on columns close to weight 1\n        near_one = np.sum(np.exp(-10*np.abs(col_sums-1)))\n        solved_cols = np.sum(col_sums == 1)\n        \n        # Aggressive nonlinear transforms\n        col_priority = np.sum(1/(col_sums**2))\n        row_priority = np.sum(1/(row_sums**2))\n        \n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        return (near_one, solved_cols, col_priority, row_priority, sum_total, max_col)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    heuristics = [calculate_heuristics(m) for m in variants]\n    return min(heuristics), max(heuristics)\n",
    "evaluation": {
      "fitness": -0.7937393800799598,
      "additional_data": {
        "spearman_correlation": "-0.793739",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 946,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 956,
    "parent_id": 750,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-based features\n        col_cost = sum(col_sums)\n        col_log = sum(log2(s) if s > 0 else 0 for s in col_sums)\n        \n        # Row-based features\n        row_cost = sum(row_sums)\n        row_log = sum(log2(s) if s > 0 else 0 for s in row_sums)\n        \n        return (col_cost + row_cost, col_log + row_log)\n\n    n = matrix.shape[0]\n    \n    # Consider matrix variants\n    variants = [matrix]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        variants.append(inv_matrix)\n    variants.append(matrix.T)\n    if inv_matrix is not None:\n        variants.append(inv_matrix.T)\n    \n    # Consider column permutations (sorted by sum)\n    col_sums = np.sum(matrix, axis=0)\n    perm = np.argsort(col_sums)\n    variants.append(matrix[:, perm])\n    if inv_matrix is not None:\n        variants.append(inv_matrix[:, perm])\n    \n    # Return minimum heuristic\n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8724028541974977,
      "additional_data": {
        "spearman_correlation": "0.872403",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 943,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 957,
    "parent_id": 90,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_features(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Count basis vectors (columns/rows with single 1)\n        col_basis = np.sum(col_sums == 1)\n        row_basis = np.sum(row_sums == 1)\n        \n        # Avoid log(0) and numerical instability\n        eps = 1e-10\n        log_col = np.log(np.maximum(col_sums, eps) + eps)\n        log_row = np.log(np.maximum(row_sums, eps) + eps)\n        \n        # Hamming distances\n        min_col_dist = min(hamming(m[:,i], m[:,j]) for i in range(n) \n                          for j in range(i+1, n)) if n > 1 else 0\n        min_row_dist = min(hamming(m[i,:], m[j,:]) for i in range(n)\n                          for j in range(i+1, n)) if n > 1 else 0\n        \n        return (float(np.sum(log_col)), float(np.sum(log_row)), float(np.sum(m)),\n                float(col_basis), float(row_basis), float(min_col_dist), float(min_row_dist))\n    \n    features = []\n    features.append(get_features(matrix))\n    features.append(get_features(matrix.T))\n    \n    # Consider inverse more carefully (handle singular matrices)\n    try:\n        inv = np.linalg.inv(matrix.astype(float)).astype(int) % 2\n        features.append(get_features(inv))\n        features.append(get_features(inv.T))\n    except:\n        pass\n    \n    # Consider row/column swapped versions\n    for i in range(min(3, matrix.shape[0])):\n        for j in range(i+1, min(i+4, matrix.shape[0])):\n            m_swap = matrix.copy()\n            m_swap[:,[i,j]] = m_swap[:,[j,i]]\n            features.append(get_features(m_swap))\n            features.append(get_features(m_swap.T))\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.7236511924020048,
      "additional_data": {
        "spearman_correlation": "0.723651",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 944,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 958,
    "parent_id": 650,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n_outer = matrix.shape[0]\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        nonzeros = np.sum(m)\n        extra_ones = nonzeros - n\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        incorrect_total = 2*n - (correct_cols + correct_rows)\n        \n        almost_cols = np.sum(col_sums == 2)\n        almost_rows = np.sum(row_sums == 2)\n        almost_total = almost_cols + almost_rows\n        \n        log_cols = 2.0 * np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = 1.0 * np.sum(np.log2(np.maximum(row_sums, 1)))\n        logs = log_cols + log_rows\n        \n        col_imbalance = 3.0 * np.sum(np.abs(col_sums - 1))\n        row_imbalance = 1.5 * np.sum(np.abs(row_sums - 1))\n        imbalance = col_imbalance + row_imbalance\n        \n        max_col = np.max(col_sums)\n        max_row = np.max(row_sums)\n        max_sum = max_col + max_row\n        \n        col_sq = np.sum(col_sums ** 2)\n        row_sq = np.sum(row_sums ** 2)\n        sum_sq = col_sq + row_sq\n        \n        sparse_pattern = np.sum(np.abs(np.diff(m, axis=0))) + np.sum(np.abs(np.diff(m, axis=1)))\n        \n        return (extra_ones, incorrect_total, almost_total, logs, imbalance, max_sum, sum_sq, sparse_pattern)\n    \n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is None:\n        h_original = get_heuristic(matrix)\n        h_transpose = get_heuristic(matrix.T)\n        return min(h_original, h_transpose)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(inv_matrix)\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(inv_matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.857015879068365,
      "additional_data": {
        "spearman_correlation": "0.857016",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 942,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 959,
    "parent_id": 66,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering all transformations and combining metrics.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        return float(np.sum(np.log(col_sums)) + float(np.sum(np.log(row_sums))) / 2\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    inv_trans = calculate_heuristic(np.linalg.inv(matrix.T) % 2)\n    return min(original, inverse, transpose, inv_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 10)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 949,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 960,
    "parent_id": 296,
    "solution": "\nimport numpy as np\n\ndef heuristic(matrix):\n    def gf2_gauss_jordan_inv(A):\n        n = A.shape[0]\n        A_bin = (A.astype(int) % 2).copy()\n        aug = np.hstack([A_bin, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                return None\n            pivot_row = col + pivot[0]\n            if pivot_row != col:\n                aug[[col, pivot_row]] = aug[[pivot_row, col]]\n            for row in range(col + 1, n):\n                if aug[row, col]:\n                    aug[row] = (aug[row] + aug[col]) % 2\n        for col in range(n - 1, -1, -1):\n            for row in range(col):\n                if aug[row, col]:\n                    aug[row] = (aug[row] + aug[col]) % 2\n        return aug[:, n:]\n    \n    n = matrix.shape[0]\n    inv_matrix = gf2_gauss_jordan_inv(matrix)\n    if inv_matrix is None:\n        variants = [matrix, matrix.T]\n    else:\n        variants = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    \n    best = None\n    for mat in variants:\n        mat_bin = (mat.astype(int) % 2)\n        total_ones = np.sum(mat_bin)\n        extra_ones = total_ones - n\n        col_nonzeros = np.count_nonzero(mat_bin, axis=0)\n        undone_cols = np.sum(col_nonzeros != 1)\n        candidate = (extra_ones, undone_cols)\n        if best is None or candidate < best:\n            best = candidate\n    return best\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 805,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 961,
    "parent_id": 897,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining column/row sums and inverse/transpose metrics.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_log = np.sum(np.log(col_sums))\n        row_log = np.sum(np.log(row_sums))\n        col_linear = np.sum(col_sums)\n        row_linear = np.sum(row_sums)\n        col_sparsity = np.sum(col_sums)\n        row_sparsity = np.sum(row_sums)\n        \n        return (0.7 * (col_log + row_log) + \n                0.2 * (col_linear + row_linear) + \n                0.05 * col_sparsity + \n                0.05 * row_sparsity,)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    inv_transpose = calculate_metrics(np.linalg.inv(matrix.T) % 2)\n    \n    return min(original, inverse, transpose, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.8709097756267751,
      "additional_data": {
        "spearman_correlation": "0.870910",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 953,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 962,
    "parent_id": 350,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        diag_count = np.sum(np.diag(m))\n        \n        # Basic features\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        \n        # Logarithmic column features\n        log_col_sum = sum(log2(cs + 1) for cs in col_sums if cs > 0)\n        log_row_sum = sum(log2(rs + 1) for rs in row_sums if rs > 0)\n        \n        # Column/row weight statistics\n        col_weight_var = np.var(col_sums)\n        row_weight_var = np.var(row_sums)\n        \n        return (\n            total_ones - n,\n            n - col1_count,\n            n - row1_count,\n            log_col_sum,\n            log_row_sum,\n            col_weight_var,\n            row_weight_var,\n            n - diag_count\n        )\n    \n    candidates = []\n    # Original matrix\n    candidates.append(get_features(matrix))\n    # Transpose\n    candidates.append(get_features(matrix.T))\n    # Pseudoinverse\n    try:\n        inv_matrix = np.linalg.pinv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n            # Also consider inverse transpose\n            candidates.append(get_features(inv_matrix.T))\n    except:\n        pass\n    \n    # Try all single column swaps\n    n_cols = matrix.shape[1]\n    for i in range(n_cols):\n        for j in range(i+1, n_cols):\n            perm = np.arange(n_cols)\n            perm[i], perm[j] = perm[j], perm[i]\n            candidates.append(get_features(matrix[:, perm]))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.7411890912619165,
      "additional_data": {
        "spearman_correlation": "0.741189",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 951,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 963,
    "parent_id": 488,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Count solved columns/rows\n        solved_cols = np.sum(col_sums == 1)\n        solved_rows = np.sum(row_sums == 1)\n        \n        # Normalized column/row sums\n        norm_col_sums = np.maximum(col_sums, 1)\n        norm_row_sums = np.maximum(row_sums, 1)\n        \n        # Logarithmic metrics with adjusted weights\n        col_log_sum = np.sum(np.log2(norm_col_sums) + np.sum(1/(norm_col_sums))\n        row_log_sum = np.sum(np.log2(norm_row_sums))\n        \n        # Weighted variance metrics\n        col_var = 2 * np.var(col_sums) if len(col_sums) > 1 else 0\n        row_var = np.var(row_sums) if len(row_sums) > 1 else 0\n        \n        # Dependency metrics\n        col_dep_score = 0\n        row_dep_score = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                if np.any(m[:,i] & m[:,j]):\n                    col_dep_score += 1\n                if np.any(m[i,:] & m[j,:]):\n                    row_dep_score += 1\n        \n        # Minimum sums\n        min_col_sum = np.min(col_sums) if n > 0 else 0\n        min_row_sum = np.min(row_sums) if n > 0 else 0\n        \n        # Distance to identity\n        identity_dist = np.sum(m != np.eye(n, dtype=int))\n        \n        return (\n            col_log_sum + 0.5 * row_log_sum,\n            -solved_cols - solved_rows,\n            col_var + 0.5 * row_var,\n            col_dep_score + row_dep_score,\n            -min_col_sum - min_row_sum,\n            identity_dist\n        )\n    \n    def binary_inverse(m):\n        try:\n            return np.linalg.inv(m).astype(int) % 2\n        except:\n            return None\n    \n    original = calculate_heuristic(matrix)\n    transpose = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv = calculate_heuristic(inv_matrix) if inv_matrix is not None else (float('inf'),)*6\n    inv_transpose = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else (float('inf'),)*6\n    \n    return min(original, transpose, inv, inv_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 19)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 950,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 964,
    "parent_id": 122,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from itertools import permutations\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        col_proximity = np.sum(np.minimum(col_sums, np.abs(col_sums - 1)))\n        row_proximity = np.sum(np.minimum(row_sums, np.abs(row_sums - 1)))\n        \n        problematic_cols = np.sum(col_sums > 1)\n        problematic_rows = np.sum(row_sums > 1)\n        \n        total_work = np.sum(m)\n        \n        # Measure of column/row uniqueness\n        _, col_counts = np.unique(m, axis=0, return_counts=True)\n        _, row_counts = np.unique(m, axis=1, return_counts=True)\n        uniqueness = np.sum(col_counts) + np.sum(row_counts)\n        \n        # Count columns/rows that are close to basis vectors\n        basis_proximity = 0\n        for i in range(m.shape[0]):\n            basis_proximity += np.min(np.sum(np.abs(m - np.eye(m.shape[0])[i]), axis=1))\n            basis_proximity += np.min(np.sum(np.abs(m.T - np.eye(m.shape[0])[i]), axis=1))\n        \n        score = (total_work + problematic_cols + problematic_rows + \n                col_proximity + row_proximity + \n                uniqueness + basis_proximity)\n        \n        return score\n    \n    n = matrix.shape[0]\n    best_score = float('inf')\n    \n    # Consider identity permutation and reverse permutation\n    for perm in [range(n), range(n-1, -1, -1)]:\n        permuted = matrix[list(perm), :]\n        \n        variants = [\n            permuted,\n            permuted.T,\n            np.linalg.inv(permuted.astype(float)).astype(int) % 2,\n            np.linalg.inv(permuted.T.astype(float)).astype(int) % 2\n        ]\n        \n        for variant in variants:\n            try:\n                score = evaluate(variant)\n                if score < best_score:\n                    best_score = score\n            except:\n                continue\n                \n    return best_score\n",
    "evaluation": {
      "fitness": 0.697198236310398,
      "additional_data": {
        "spearman_correlation": "0.697198",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 952,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 965,
    "parent_id": 133,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.spatial.distance import hamming\n    \n    def get_heuristic(m):\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        basis = np.eye(n, dtype=int)\n        \n        # Enhanced column similarity metric\n        col_similarity = []\n        for i in range(n):\n            min_dist = n\n            for j in range(n):\n                dist = np.sum(m[:,i] != basis[:,j])\n                if dist == 0:\n                    min_dist = 0\n                    break\n                if dist < min_dist:\n                    min_dist = dist\n            col_similarity.append(min_dist)\n        \n        # Column interaction metric\n        col_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                col_interactions += np.sum(m[:,i] & m[:,j])\n        \n        # Row interaction metric\n        row_interactions = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                row_interactions += np.sum(m[i,:] & m[j,:])\n        \n        # Matrix sparsity\n        sparsity = np.sum(m)\n        \n        return (sum(col_similarity), col_interactions, row_interactions, sparsity)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        np.linalg.inv(matrix).T,\n        matrix.T.dot(np.linalg.inv(matrix)),\n        matrix.dot(matrix.T),\n        matrix.T.dot(matrix),\n        np.linalg.inv(matrix).dot(matrix.T)\n    ]\n    \n    valid_variants = []\n    for v in variants:\n        try:\n            v_bin = (v % 2).astype(int)\n            if not np.isnan(v_bin).any():\n                valid_variants.append(v_bin)\n        except:\n            continue\n    \n    return min(get_heuristic(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.12235639186818692,
      "additional_data": {
        "spearman_correlation": "0.122356",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 954,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 966,
    "parent_id": 4,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    candidates = [\n        matrix,\n        (np.round(np.linalg.inv(matrix)).astype(int) % 2,\n        matrix.T\n    ]\n    best_heuristic = None\n    \n    for cand in candidates:\n        col_sums = np.sum(cand, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        h1 = float(np.sum(np.log(col_sums)))\n        h2 = float(np.sum(cand))\n        candidate_tuple = (h1, h2)\n        \n        if best_heuristic is None or candidate_tuple < best_heuristic:\n            best_heuristic = candidate_tuple\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "closing parenthesis ']' does not match opening parenthesis '(' on line 6 (<string>, line 8)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 866,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 17
    }
  },
  {
    "id": 967,
    "parent_id": 123,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional term for columns/rows with sum=1.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        log_sum = np.sum(np.log(col_sums)) + np.sum(np.log(row_sums))\n        count_ones = np.sum(col_sums == 1) + np.sum(row_sums == 1)\n        return float(log_sum - 0.5 * count_ones)  # Weight of 0.5 found empirically\n    \n    def binary_inverse(m):\n        n = m.shape[0]\n        inv = np.eye(n, dtype=int)\n        for col in range(n):\n            pivot = -1\n            for row in range(col, n):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    original_heuristic = calculate_heuristic(matrix)\n    transpose_heuristic = calculate_heuristic(matrix.T)\n    inv_matrix = binary_inverse(matrix.copy())\n    inv_heuristic = calculate_heuristic(inv_matrix) if inv_matrix is not None else float('inf')\n    inv_transpose_heuristic = calculate_heuristic(inv_matrix.T) if inv_matrix is not None else float('inf')\n    return min(original_heuristic, transpose_heuristic, inv_heuristic, inv_transpose_heuristic)\n",
    "evaluation": {
      "fitness": 0.8680355039997272,
      "additional_data": {
        "spearman_correlation": "0.868036",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 955,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 968,
    "parent_id": 140,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic combining inverse/transpose alternatives and row information.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        epsilon = 1e-10\n        col_sums = np.sum(m, axis=0) + epsilon\n        row_sums = np.sum(m, axis=1) + epsilon\n        return (np.sum(np.log(col_sums)) + 0.05 * np.sum(np.log(row_sums)),\n                np.sum(col_sums))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8689959478080601,
      "additional_data": {
        "spearman_correlation": "0.868996",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 957,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 969,
    "parent_id": 372,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    hamming_weight = np.sum(matrix)\n    max_col_sum = np.max(col_sums)\n    return (hamming_weight, -max_col_sum)\n",
    "evaluation": {
      "fitness": 0.7600906651018438,
      "additional_data": {
        "spearman_correlation": "0.760091",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 958,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 970,
    "parent_id": 256,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        n = m.shape[0]\n        log_col_sums = [log2(s + 1) if s > 0 else 0 for s in col_sums]\n        return (sum(col_sums), sum(log_col_sums))\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": -0.2880578132741593,
      "additional_data": {
        "spearman_correlation": "-0.288058",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 962,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 971,
    "parent_id": 508,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    import math\n    \n    def compute_metric(m):\n        m = (m % 2).astype(int)\n        n = m.shape[0]\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column completion score (higher is better)\n        completed_cols = sum(1 for c in col_sums if c == 1)\n        \n        # Row completion score (higher is better)\n        completed_rows = sum(1 for r in row_sums if r == 1)\n        \n        # Weighted column metric prioritizing nearly-complete columns\n        col_metric = 0\n        for c in col_sums:\n            if c == 0:\n                continue\n            col_metric += (n - c) * math.log2(c + 1)\n        \n        # Weighted row metric\n        row_metric = 0\n        for r in row_sums:\n            if r == 0:\n                continue\n            row_metric += (n - r) * math.log2(r + 1)\n        \n        # Total operations needed\n        total_ops = np.sum(m)\n        \n        # Return as tuple where lower is better\n        return (\n            -completed_cols - completed_rows,  # prioritize matrices with more completed cols/rows\n            col_metric + row_metric,          # then by weighted column/row metric\n            total_ops                         # finally by total operations\n        )\n    \n    variants = []\n    try:\n        variants.append(matrix)\n        variants.append(matrix.T)\n        inv = np.linalg.inv(matrix) % 2\n        variants.append(inv.astype(int))\n        variants.append(inv.T.astype(int))\n    except:\n        try:\n            variants.append(matrix)\n            variants.append(matrix.T)\n        except:\n            pass\n    \n    valid_variants = []\n    for v in variants:\n        try:\n            v = np.array(v, dtype=float)\n            if not np.isnan(v).any():\n                valid_variants.append(v)\n        except:\n            continue\n    \n    return min(compute_metric(v) for v in valid_variants) if valid_variants else float('inf')\n",
    "evaluation": {
      "fitness": 0.7235062926846078,
      "additional_data": {
        "spearman_correlation": "0.723506",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 956,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 972,
    "parent_id": 12,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both row and column sums with log2.\"\"\"\n    import numpy as np\n    def compute_heuristic(m):\n        col_sums = np.sum(m, axis=0) + 0.5\n        row_sums = np.sum(m, axis=1) + 0.5\n        return float(np.sum(np.log2(col_sums)) + float(np.sum(np.log2(row_sums)))\n    \n    h = compute_heuristic(matrix)\n    h_inv = compute_heuristic(np.linalg.inv(matrix))\n    h_trans = compute_heuristic(matrix.T)\n    return (h + h_inv + h_trans) / 3\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 8)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 961,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 973,
    "parent_id": 548,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        # Absolute deviations from ideal weight of 1\n        col_metric = np.sum(np.abs(col_sums - 1))\n        row_metric = np.sum(np.abs(row_sums - 1))\n        \n        # Diagonal metrics (normalized)\n        diag = np.trace(m)\n        anti_diag = np.trace(np.fliplr(m))\n        diag_metric = (diag + anti_diag) / (2 * m.shape[0])\n        \n        total_ones = np.sum(m)\n        \n        return (col_metric, row_metric, -diag_metric, total_ones)\n    \n    variations = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    metrics = [calculate_metrics(m) for m in variations]\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.8507484181187372,
      "additional_data": {
        "spearman_correlation": "0.850748",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 898,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 974,
    "parent_id": 694,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    def calculate_heuristic(m):\n        m = m % 2  # Ensure we're working with binary values\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1e-8)\n        row_sums = np.maximum(row_sums, 1e-8)\n        log_cols = np.sum(np.log(col_sums))\n        log_rows = np.sum(np.log(row_sums))\n        \n        rank = np.linalg.matrix_rank(m)\n        \n        col_deps = 0\n        for i in range(m.shape[1]):\n            for j in range(i+1, m.shape[1]):\n                col_deps += np.sum(np.bitwise_and(m[:,i], m[:,j]))\n        col_deps = col_deps / (m.shape[1]*(m.shape[1]-1)/2 + 1e-8)\n        \n        spread = np.var(col_sums)\n        \n        return (rank, log_cols + log_rows, col_deps, spread)\n    \n    matrix = matrix % 2  # Ensure input is binary\n    variants = [\n        calculate_heuristic(matrix),\n        calculate_heuristic(np.linalg.inv(matrix) % 2),\n        calculate_heuristic(matrix.T),\n        calculate_heuristic(np.linalg.inv(matrix).T % 2)\n    ]\n    return min(variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 960,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 975,
    "parent_id": 80,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic using L1 deviations and row/column information.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(np.abs(col_sums - 1))  # L1 norm\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        return (nonzeros, col_imbalance, row_imbalance, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.8823310788347797,
      "additional_data": {
        "spearman_correlation": "0.882331",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 959,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 5
    }
  },
  {
    "id": 976,
    "parent_id": 672,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on column-based metrics and simpler transformations.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        rank = np.linalg.matrix_rank(m)\n        \n        # Focused column entropy\n        col_entropy = -np.sum(np.where(col_sums > 0, (col_sums/np.sum(col_sums)) * np.log2(col_sums/np.sum(col_sums) + 1e-10, 0))\n        \n        # Column completion priority\n        col_completion = np.sum((col_sums - 1)**2)\n        \n        # Row-column interaction\n        rc_interaction = np.sum(m * np.outer(row_sums, col_sums))\n        \n        return (nonzeros,\n                -rank,\n                col_entropy,\n                col_completion,\n                rc_interaction)\n    \n    def get_min_heuristic(m):\n        metrics = matrix_metrics(m)\n        trans_metrics = matrix_metrics(m.T)\n        return min(metrics, trans_metrics)\n    \n    return get_min_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 13)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 965,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 977,
    "parent_id": 741,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    n = matrix.shape[0]\n    total_ones = np.sum(matrix)\n    h_original = (total_ones - n) / 2.0\n    \n    def binary_inverse(m):\n        n_inv = m.shape[0]\n        inv = np.eye(n_inv, dtype=int)\n        for col in range(n_inv):\n            pivot = -1\n            for row in range(col, n_inv):\n                if m[row, col]:\n                    pivot = row\n                    break\n            if pivot == -1:\n                return None\n            if pivot != col:\n                m[[col, pivot]] = m[[pivot, col]]\n                inv[[col, pivot]] = inv[[pivot, col]]\n            for row in range(n_inv):\n                if row != col and m[row, col]:\n                    m[row] ^= m[col]\n                    inv[row] ^= inv[col]\n        return inv\n    \n    inv_matrix = binary_inverse(matrix.copy())\n    if inv_matrix is not None:\n        total_inv = np.sum(inv_matrix)\n        h_inv = (total_inv - n) / 2.0\n    else:\n        h_inv = float('inf')\n    \n    trans_matrix = matrix.T.copy()\n    total_trans = np.sum(trans_matrix)\n    h_trans = (total_trans - n) / 2.0\n    \n    inv_trans_matrix = binary_inverse(trans_matrix.copy())\n    if inv_trans_matrix is not None:\n        total_inv_trans = np.sum(inv_trans_matrix)\n        h_inv_trans = (total_inv_trans - n) / 2.0\n    else:\n        h_inv_trans = float('inf')\n    \n    column_weights = np.sum(matrix, axis=0)\n    non_zero_cols = column_weights[column_weights > 0]\n    log_col_weights = np.sum(np.log2(non_zero_cols)) if len(non_zero_cols) > 0 else 0\n    \n    min_h = min(h_original, h_inv, h_trans, h_inv_trans)\n    return (min_h, log_col_weights)\n",
    "evaluation": {
      "fitness": 0.8658106534800115,
      "additional_data": {
        "spearman_correlation": "0.865811",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 963,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 978,
    "parent_id": 648,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Heuristic based on column/row interactions and their relationships.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Column and row interaction metrics\n        col_overlaps = np.sum(m.T @ m) - np.sum(col_sums)\n        row_overlaps = np.sum(m @ m.T) - np.sum(row_sums)\n        \n        # Column/row completion progress\n        col_completion = np.sum(1 / np.maximum(col_sums, 1))\n        row_completion = np.sum(1 / np.maximum(row_sums, 1))\n        \n        # Column/row relationships\n        col_row_ratio = np.sum(col_sums / np.maximum(row_sums, 1))\n        row_col_ratio = np.sum(row_sums / np.maximum(col_sums, 1))\n        \n        # Column/row spread metrics\n        col_spread = np.sum(np.abs(np.outer(col_sums, np.ones(n)) - m))\n        row_spread = np.sum(np.abs(np.outer(row_sums, np.ones(n)) - m.T))\n        \n        # Combined metrics\n        interaction_score = col_overlaps + row_overlaps\n        completion_score = col_completion + row_completion\n        ratio_score = col_row_ratio + row_col_ratio\n        spread_score = col_spread + row_spread\n        \n        # Return as tuple with carefully ordered components\n        return (nonzeros, \n                -completion_score, \n                interaction_score, \n                ratio_score, \n                spread_score,\n                *sorted(col_sums, reverse=True),\n                *sorted(row_sums, reverse=True))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": 0.8772785204507215,
      "additional_data": {
        "spearman_correlation": "0.877279",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 964,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 979,
    "parent_id": 48,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combined column and row sum logarithms, considering inverse/transpose alternatives.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.maximum(col_sums, 1.0)\n        row_sums = np.maximum(row_sums, 1.0)\n        return float(0.75 * np.sum(np.log(col_sums)) + 0.25 * np.sum(np.log(row_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.870969611854722,
      "additional_data": {
        "spearman_correlation": "0.870970",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 969,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 980,
    "parent_id": 14,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic considering both row and column weights, inverses, and transposes.\"\"\"\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sum = np.sum(np.log2(np.maximum(row_sums, 1)))\n        simple_sum = np.sum(m)\n        return min(simple_sum, log_col_sum, log_row_sum)\n    \n    original = evaluate(matrix)\n    try:\n        inverse = evaluate(np.linalg.inv(matrix).astype(int) % 2)\n    except:\n        inverse = float('inf')\n    transpose = evaluate(matrix.T)\n    \n    return (original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8069039871715944,
      "additional_data": {
        "spearman_correlation": "0.806904",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 970,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 981,
    "parent_id": 677,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        row_sums = np.sum(m, axis=1)\n        col_sums = np.sum(m, axis=0)\n        nonzeros = np.sum(m)\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        col_imbalance = np.sum(np.log2(np.maximum(np.abs(col_sums - 1), 1)))\n        basis_rows = np.count_nonzero(row_sums == 1)\n        basis_cols = np.count_nonzero(col_sums == 1)\n        return (nonzeros, row_imbalance + col_imbalance, -(basis_rows + basis_cols))\n\n    h_orig = get_heuristic(matrix)\n    h_trans = get_heuristic(matrix.T)\n    try:\n        inv = gf2_inv(matrix)\n        h_inv = get_heuristic(inv)\n    except:\n        h_inv = h_orig\n    return min(h_orig, h_trans, h_inv)\n",
    "evaluation": {
      "fitness": 0.86157390443476,
      "additional_data": {
        "spearman_correlation": "0.861574",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 967,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 982,
    "parent_id": 876,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_interaction_metric(m):\n        n = m.shape[0]\n        col_weights = np.sum(m, axis=0)\n        col_weights = np.maximum(col_weights, 1e-10)\n        \n        # Pairwise column interactions\n        interaction_cost = 0\n        for i in range(n):\n            for j in range(i+1, n):\n                # Cost of reducing column j using column i\n                if col_weights[i] > 0 and np.any(m[:,i] & m[:,j]):\n                    interaction_cost += 1 / (col_weights[i] * col_weights[j])\n        \n        # Logarithmic term for column weights\n        log_term = np.sum(np.log(col_weights))\n        \n        # Column weight sum\n        linear_term = np.sum(col_weights)\n        \n        # Column uniqueness penalty\n        unique_cols = len({tuple(col) for col in m.T})\n        uniqueness_penalty = (n - unique_cols) / n\n        \n        return (\n            log_term + \n            0.5 * linear_term + \n            2 * interaction_cost + \n            0.3 * uniqueness_penalty,\n            -np.sum(m)  # Secondary term for tie-breaking\n        )\n    \n    original = column_interaction_metric(matrix)\n    inverse = column_interaction_metric(np.linalg.inv(matrix) % 2)\n    transpose = column_interaction_metric(matrix.T)\n    \n    # Consider column permutations by looking at sorted columns\n    sorted_cols = matrix[:, np.argsort(np.sum(matrix, axis=0))]\n    permuted = column_interaction_metric(sorted_cols)\n    \n    return min(original, inverse, transpose, permuted)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 966,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 983,
    "parent_id": 597,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with balanced components.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        row_nonzeros = np.count_nonzero(m, axis=1)\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Row completion with higher polynomial weighting\n        row_completion = np.sum(row_nonzeros ** 3)\n        \n        # Rank deficiency measure\n        rank_penalty = n - np.linalg.matrix_rank(m)\n        \n        # Enhanced interaction term\n        interaction = np.sum(np.abs(m)) - n + np.sum(row_nonzeros * col_nonzeros)/n\n        \n        # Column weights with adjusted log\n        col_weights = np.sum(col_nonzeros * np.log(col_nonzeros + 0.5))\n        \n        return (rank_penalty, row_completion, interaction, col_weights)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8326603144776797,
      "additional_data": {
        "spearman_correlation": "0.832660",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 968,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 984,
    "parent_id": 177,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        log_cols = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (nonzeros, log_cols + log_rows)\n    \n    n = matrix.shape[0]\n    best_h = evaluate(matrix)\n    \n    # Only consider transposed and inverted versions\n    for variant in [matrix.T, np.linalg.inv(matrix).astype(int) % 2]:\n        current_h = evaluate(variant)\n        if current_h < best_h:\n            best_h = current_h\n            \n    return best_h\n",
    "evaluation": {
      "fitness": 0.7234058821583838,
      "additional_data": {
        "spearman_correlation": "0.723406",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 973,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 985,
    "parent_id": 442,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_metrics(m):\n        n = m.shape[0]\n        metrics = []\n        m_int = m.astype(int)\n        for col in m_int.T:\n            weight = np.sum(col)\n            if weight == 0:\n                metrics.append(0)\n                continue\n            basis_dist = min(np.sum(col ^ basis) for basis in [np.eye(n, dtype=int)[:,i] for i in range(n)])\n            log_term = np.log(weight) if weight > 0 else 0\n            metrics.append(basis_dist + log_term)\n        return tuple(sorted(metrics))\n    \n    original = column_metrics(matrix)\n    inverse = column_metrics(np.linalg.inv(matrix).astype(int) % 2)\n    transpose = column_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.6984235154290032,
      "additional_data": {
        "spearman_correlation": "0.698424",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 974,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 986,
    "parent_id": 198,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Combine min and mean of logarithms of column sums across representations.\"\"\"\n    import numpy as np\n    def calculate_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums[col_sums == 0] = 1\n        return float(np.sum(np.log(col_sums)))\n    \n    original = calculate_heuristic(matrix)\n    inverse = calculate_heuristic(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristic(matrix.T)\n    return (min(original, inverse, transpose), np.mean([original, inverse, transpose])\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 13)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 972,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 987,
    "parent_id": 930,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def column_analysis(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column-wise features\n        col_features = []\n        for j in range(n):\n            weight = col_sums[j]\n            row_indices = np.where(m[:, j] == 1)[0]\n            row_weights = row_sums[row_indices]\n            col_features.append((\n                weight,\n                -np.sum(np.abs(row_weights - 1)),  # Favor columns where rows are nearly correct\n                len(row_indices),\n                np.sum(np.abs(m[row_indices, :] - np.eye(n)[row_indices, :]))\n            ))\n        \n        # Sort columns by complexity (most complex first)\n        col_features.sort(reverse=True)\n        \n        # Global features\n        nonzeros = np.count_nonzero(m)\n        correct_cols = np.sum(col_sums == 1)\n        correct_rows = np.sum(row_sums == 1)\n        diagonal_match = np.sum(np.diag(m))\n        off_diagonal = nonzeros - diagonal_match\n        \n        # Combine features\n        return (\n            nonzeros,\n            -correct_cols,\n            -correct_rows,\n            off_diagonal,\n            *[feature for col in col_features[:3] for feature in col]  # Flatten first 3 columns' features\n        )\n    \n    def get_heuristic(m):\n        try:\n            inv_m = np.linalg.inv(m)\n            return min(\n                column_analysis(m),\n                column_analysis(inv_m),\n                column_analysis(m.T)\n            )\n        except:\n            return min(\n                column_analysis(m),\n                column_analysis(m.T)\n    \n    return get_heuristic(matrix)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 51)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 975,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 988,
    "parent_id": 631,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.argmax(aug[col:, col]) + col\n            if aug[pivot, col] == 0:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.sum(m)\n        n = m.shape[0]\n        excess_ones = nonzeros - n\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        total_done = done_cols + done_rows\n        log_col_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        log_row_sum = np.sum(np.log2(np.maximum(row_sums, 1)))\n        return (excess_ones, -total_done, log_col_sum, log_row_sum)\n\n    n = matrix.shape[0]\n    candidates = []\n    \n    # Original matrix\n    candidates.append(get_heuristic(matrix))\n    \n    # Transpose\n    candidates.append(get_heuristic(matrix.T))\n    \n    # GF(2) inverse\n    inv = gf2_inv(matrix)\n    if inv is not None:\n        candidates.append(get_heuristic(inv))\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.8690842324516707,
      "additional_data": {
        "spearman_correlation": "0.869084",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 891,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 989,
    "parent_id": 223,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    col_sums = np.sum(matrix, axis=0)\n    row_sums = np.sum(matrix, axis=1)\n    log_cols = np.sum(np.log2(col_sums + 1))\n    log_rows = np.sum(np.log2(row_sums + 1))\n    \n    trans = matrix.T\n    trans_col_sums = np.sum(trans, axis=0)\n    trans_row_sums = np.sum(trans, axis=1)\n    trans_log_cols = np.sum(np.log2(trans_col_sums + 1))\n    trans_log_rows = np.sum(np.log2(trans_row_sums + 1))\n    \n    nonzero_cols = np.count_nonzero(col_sums)\n    nonzero_rows = np.count_nonzero(row_sums)\n    nonzero_trans_cols = np.count_nonzero(trans_col_sums)\n    nonzero_trans_rows = np.count_nonzero(trans_row_sums)\n    \n    features = [\n        log_cols + log_rows,\n        trans_log_cols + trans_log_rows,\n        np.sum(matrix) + np.sum(trans),\n        nonzero_cols + nonzero_rows,\n        nonzero_trans_cols + nonzero_trans_rows,\n        np.sum(col_sums * (col_sums > 1)) + np.sum(row_sums * (row_sums > 1)),\n        np.sum(trans_col_sums * (trans_col_sums > 1)) + np.sum(trans_row_sums * (trans_row_sums > 1))\n    ]\n    \n    return min(features)\n",
    "evaluation": {
      "fitness": 0.16704819238837396,
      "additional_data": {
        "spearman_correlation": "0.167048",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 978,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 990,
    "parent_id": 492,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic combining multiple metrics and considering variants.\"\"\"\n    import numpy as np\n    \n    def calculate_heuristics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.sum(m != 0, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        row_sums = np.maximum(row_sums, 1e-10)\n        \n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        sum_total = float(np.sum(m))\n        max_col = float(np.max(col_sums))\n        sum_nonzero = float(np.sum(col_nonzero))\n        completed_cols = float(np.sum(col_sums == 1))\n        return (log_col, log_row, sum_total, max_col, sum_nonzero, completed_cols)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    return min(calculate_heuristics(m) for m in variants)\n",
    "evaluation": {
      "fitness": 0.8730737524096407,
      "additional_data": {
        "spearman_correlation": "0.873074",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 980,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 991,
    "parent_id": 170,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with additional column proximity and uniqueness metrics.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic metrics\n        nonzeros = np.count_nonzero(m)\n        done_cols = np.sum(col_sums == 1)\n        done_rows = np.sum(row_sums == 1)\n        near_done_cols = np.sum(np.abs(col_sums - 1) < 0.5\n        \n        # Interaction metrics\n        interaction = np.sum(m @ m.T)\n        col_interaction = np.sum(m.T @ m)\n        \n        # Rank-based metrics\n        rank = np.linalg.matrix_rank(m)\n        submatrix_ranks = sum(np.linalg.matrix_rank(m[:i, :i]) for i in range(1, n+1))\n        \n        # Structural metrics\n        upper_tri = np.triu(m)\n        lower_tri = np.tril(m)\n        tri_diff = np.sum(np.abs(upper_tri - lower_tri))\n        \n        # Uniqueness metrics using numpy unique\n        unique_rows = len(np.unique(m, axis=0))\n        unique_cols = len(np.unique(m.T, axis=0))\n        \n        # Column sum log metrics\n        log_col_sums = np.sum(np.log2(np.maximum(col_sums, 1)))\n        \n        return (nonzeros, \n                -interaction, \n                -col_interaction, \n                n*n - rank*n, \n                -submatrix_ranks, \n                tri_diff, \n                -done_cols - done_rows,\n                -near_done_cols,\n                -unique_rows - unique_cols,\n                log_col_sums)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "'(' was never closed (<string>, line 15)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 982,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 992,
    "parent_id": 507,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        n = m.shape[0]\n        \n        # Column features\n        col_non_ones = np.sum(col_sums != 1)\n        col_log_sum = np.sum(np.log2(np.maximum(col_sums, 1)))\n        col_linear_sum = np.sum(col_sums)\n        col_entropy = -np.sum((col_sums/n) * np.log2(np.maximum(col_sums/n, 1e-10)))\n        \n        # Row features\n        row_non_ones = np.sum(row_sums != 1)\n        row_log_sum = np.sum(np.log2(np.maximum(row_sums, 1)))\n        \n        # Matrix-wide features\n        total_nonzero = np.count_nonzero(m)\n        distance_to_identity = np.sum(m != np.eye(n))\n        \n        # Combined metrics\n        metric1 = col_non_ones + row_non_ones\n        metric2 = col_log_sum + row_log_sum\n        metric3 = total_nonzero + distance_to_identity\n        metric4 = col_entropy + col_linear_sum\n        \n        return (metric1, metric2, metric3, metric4)\n    \n    transformations = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix).T\n    ]\n    \n    all_metrics = [compute_metrics(t) for t in transformations]\n    return min(all_metrics)\n",
    "evaluation": {
      "fitness": 0.4724824978581467,
      "additional_data": {
        "spearman_correlation": "0.472482",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 981,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 993,
    "parent_id": 726,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        aug = np.hstack((mat.copy(), np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col]) + col\n            if len(pivot) == 0:\n                return None\n            pivot = pivot[0]\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_ones = np.sum(col_sums)\n        \n        # Refined imbalance metrics\n        col_imbalance = np.sum(np.abs(col_sums - 1)) + np.sum(col_sums == 0)\n        row_imbalance = np.sum(np.abs(row_sums - 1)) + np.sum(row_sums == 0)\n        \n        # Improved interaction metrics\n        interaction = np.sum((m @ m.T) * (1 - np.eye(n)))\n        col_interaction = np.sum((m.T @ m) * (1 - np.eye(n)))\n        \n        # Spread metric using variance instead of ptp\n        row_spread = np.sum([np.var(np.where(row)[0]) if np.any(row) else 0 for row in m])\n        col_spread = np.sum([np.var(np.where(col)[0]) if np.any(col) else 0 for col in m.T])\n        \n        # Adjusted weights based on empirical performance\n        score = (\n            0.5 * total_ones + \n            0.25 * (col_imbalance + row_imbalance) + \n            0.15 * (interaction + col_interaction) + \n            0.1 * (row_spread + col_spread)\n        )\n        \n        return score\n    \n    # Consider all 4 orientations and average their scores\n    orientations = [matrix]\n    inv_matrix = gf2_inv(matrix)\n    if inv_matrix is not None:\n        orientations.append(inv_matrix)\n    \n    min_h = float('inf')\n    for mat in orientations:\n        current_h = get_heuristic(mat)\n        if current_h < min_h:\n            min_h = current_h\n        current_h = get_heuristic(mat.T)\n        if current_h < min_h:\n            min_h = current_h\n    \n    return min_h\n",
    "evaluation": {
      "fitness": 0.8291857694136736,
      "additional_data": {
        "spearman_correlation": "0.829186",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 979,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 994,
    "parent_id": 490,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_features(m):\n        n = m.shape[0]\n        total_ones = np.sum(m)\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Basic counts\n        col1_count = np.count_nonzero(col_sums == 1)\n        row1_count = np.count_nonzero(row_sums == 1)\n        \n        # Spread metrics\n        col_sum_std = np.std(col_sums)\n        row_sum_std = np.std(row_sums)\n        \n        # Distance from basis vectors\n        basis_dist = np.sum(np.minimum(col_sums, 1))\n        \n        # Entropy measures\n        col_entropy = np.mean([entropy(col+1e-10) for col in m.T])\n        row_entropy = np.mean([entropy(row+1e-10) for row in m])\n        \n        # Pairwise interactions\n        col_overlaps = np.sum(np.dot(m.T, m) - np.diag(col_sums))\n        row_overlaps = np.sum(np.dot(m, m.T) - np.diag(row_sums))\n        \n        # Extreme statistics\n        max_col = np.max(col_sums)\n        min_col = np.min(col_sums)\n        max_row = np.max(row_sums)\n        min_row = np.min(row_sums)\n        \n        return (total_ones - n, \n                n - col1_count, \n                n - row1_count, \n                col_sum_std, \n                row_sum_std,\n                basis_dist,\n                col_entropy,\n                row_entropy,\n                col_overlaps,\n                row_overlaps,\n                max_col,\n                min_col,\n                max_row,\n                min_row)\n    \n    candidates = []\n    # Original matrix\n    candidates.append(get_features(matrix))\n    # Transpose\n    candidates.append(get_features(matrix.T))\n    \n    # Try all column permutations (limited number for speed)\n    n = matrix.shape[0]\n    if n <= 8:\n        from itertools import permutations\n        for perm in permutations(range(n)):\n            if len(candidates) >= 8: break\n            perm_matrix = matrix[:, list(perm)]\n            candidates.append(get_features(perm_matrix))\n    \n    # Try pseudoinverse if possible\n    try:\n        inv_matrix = np.linalg.inv(matrix)\n        inv_matrix = np.round(inv_matrix).astype(int) % 2\n        if inv_matrix.shape == matrix.shape:\n            candidates.append(get_features(inv_matrix))\n    except:\n        pass\n    \n    return min(candidates)\n",
    "evaluation": {
      "fitness": 0.7319634661816427,
      "additional_data": {
        "spearman_correlation": "0.731963",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 977,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 995,
    "parent_id": 459,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with logarithmic column weighting.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        sorted_cols = tuple(sorted(col_sums))\n        sorted_rows = tuple(sorted(row_sums))\n        col_imbalance = np.sum(-np.log2(1 - np.abs(col_sums - 1) + 1e-10))\n        row_imbalance = np.sum(np.abs(row_sums - 1))\n        diag_sum = np.sum(np.diag(m))\n        off_diag = np.sum(m) - diag_sum\n        \n        return (nonzeros, col_imbalance + row_imbalance, off_diag, *sorted_cols, *sorted_rows)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.000000",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 985,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 996,
    "parent_id": 426,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved column-focused heuristic with enhanced weighting and difference metric.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_nonzeros = np.count_nonzero(m, axis=0)\n        \n        # Column completion weighting\n        col_completion = np.sum(np.log2(col_nonzeros + 1e-6))\n        \n        # Column distribution metric\n        col_dist = np.sum(np.abs(np.sum(m, axis=0) - 1))\n        \n        return (col_completion, col_dist)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.8829277317093992,
      "additional_data": {
        "spearman_correlation": "0.882928",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 987,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 997,
    "parent_id": 581,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def basis_proximity(col):\n        if np.sum(col) != 1:\n            return 0\n        return 1 - (np.argmax(col) / len(col))\n    \n    def calculate_heuristics(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        total_nonzero = np.count_nonzero(m)\n        \n        # Column-based metrics\n        col_basis = sum(basis_proximity(m[:,i]) for i in range(n))\n        col_log = np.sum(np.log(np.maximum(col_sums, 1)))\n        \n        # Row-based metrics\n        row_basis = sum(basis_proximity(m[i,:]) for i in range(n))\n        row_log = np.sum(np.log(np.maximum(row_sums, 1)))\n        \n        # Structural metrics\n        block_score = 0\n        for i in range(n):\n            for j in range(n):\n                if m[i,j] == 1:\n                    block_score += 1/(1 + abs(i-j))\n        \n        # Combined metrics\n        h1 = float(-col_basis)  # Higher when closer to basis\n        h2 = float(col_log)\n        h3 = float(-row_basis)\n        h4 = float(row_log)\n        h5 = float(total_nonzero)\n        h6 = float(-block_score)  # Higher for more diagonal structure\n        \n        return (h1, h2, h3, h4, h5, h6)\n    \n    original = calculate_heuristics(matrix)\n    inverse = calculate_heuristics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_heuristics(matrix.T)\n    inv_trans = calculate_heuristics(np.linalg.inv(matrix.T) % 2)\n    \n    return min(original, inverse, transpose, inv_trans)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'abs' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 983,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 998,
    "parent_id": 246,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    from math import log2\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_log_sums = sum(log2(max(s, 1)) for s in col_sums)\n        col_completion = sum(1 for s in col_sums if s <= 1)\n        return (np.sum(m), -col_completion, col_log_sums)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    h_inverse_transpose = get_heuristic(np.linalg.inv(matrix).T)\n    \n    return min(h_original, h_inverse, h_transpose, h_inverse_transpose)\n",
    "evaluation": {
      "fitness": -0.2746190162081008,
      "additional_data": {
        "spearman_correlation": "-0.274619",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 988,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 999,
    "parent_id": 868,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Enhanced heuristic with entropy-based metrics and position weighting.\"\"\"\n    import numpy as np\n    from scipy.stats import entropy\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        nonzeros = np.count_nonzero(m)\n        \n        # Position weights - middle qubits more important\n        pos_weights = 1 + np.abs(np.arange(n) - (n-1)/2)/(n-1)*2\n        \n        # Column metrics with position weighting\n        col_entropy = entropy(col_sums + 1e-10)  # Avoid log(0)\n        weighted_cols = np.sum(col_sums * pos_weights)\n        col_imbalance = np.sum((col_sums - 1)**2 * pos_weights)\n        \n        # Row metrics with position weighting\n        row_entropy = entropy(row_sums + 1e-10)\n        weighted_rows = np.sum(row_sums * pos_weights)\n        row_imbalance = np.sum((row_sums - 1)**2 * pos_weights)\n        \n        # Interaction terms between columns\n        col_interactions = np.sum(np.outer(col_sums, col_sums) * m)\n        \n        return sum((nonzeros, \n                col_entropy + row_entropy,\n                weighted_cols + weighted_rows,\n                col_imbalance + row_imbalance,\n                col_interactions))\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.014912668828052698,
      "additional_data": {
        "spearman_correlation": "0.014913",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 989,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1000,
    "parent_id": 411,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Simplified heuristic focusing on column sums and nonzeros.\"\"\"\n    import numpy as np\n    \n    def get_heuristic(m):\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        col_metric = np.sum(np.log(col_sums + 1))\n        return float(nonzeros + col_metric)\n    \n    h_original = get_heuristic(matrix)\n    h_inverse = get_heuristic(np.linalg.inv(matrix))\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.33735604348179465,
      "additional_data": {
        "spearman_correlation": "0.337356",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 992,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1001,
    "parent_id": 625,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def combined_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        non_zero_cols = np.count_nonzero(col_sums)\n        non_zero_rows = np.count_nonzero(row_sums)\n        log_cols = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_rows = np.sum(np.log(np.maximum(row_sums, 1)))\n        total_ones = np.sum(m)\n        return (non_zero_cols + non_zero_rows, -log_cols - log_rows, total_ones)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix) % 2,\n        matrix.T,\n        np.linalg.inv(matrix.T) % 2\n    ]\n    \n    best = min(combined_heuristic(v) for v in variants)\n    return best\n",
    "evaluation": {
      "fitness": -0.7908986706265955,
      "additional_data": {
        "spearman_correlation": "-0.790899",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 993,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1002,
    "parent_id": 838,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Advanced heuristic considering column interactions and max column weight.\"\"\"\n    import numpy as np\n    \n    def calculate_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        max_col = np.max(col_sums)\n        col_sums = np.maximum(col_sums, 1e-10)\n        \n        # Basic metrics\n        col_log = np.sum(np.log(col_sums))\n        col_linear = np.sum(col_sums)\n        \n        # Column interaction metric\n        interaction = 0\n        n = m.shape[1]\n        for i in range(n):\n            for j in range(i+1, n):\n                interaction += np.dot(m[:,i], m[:,j])\n        \n        # Combined metric with adjusted weights\n        combined = (0.6 * col_log + 0.3 * interaction + 0.1 * col_linear)\n        \n        return (combined, max_col)\n    \n    original = calculate_metrics(matrix)\n    inverse = calculate_metrics(np.linalg.inv(matrix) % 2)\n    transpose = calculate_metrics(matrix.T)\n    \n    return min(original, inverse, transpose)\n",
    "evaluation": {
      "fitness": 0.8402536366185314,
      "additional_data": {
        "spearman_correlation": "0.840254",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 991,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 1003,
    "parent_id": 772,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metric(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_nonzero = np.count_nonzero(m, axis=0)\n        row_nonzero = np.count_nonzero(m, axis=1)\n        \n        # Column-based metrics with adjusted weights\n        col_log = np.sum(np.where(col_nonzero == 1, 0, np.log2(col_nonzero + 1)))\n        col_sum_diff = np.sum(np.abs(col_sums - 1))\n        col_cost = 0.7 * col_log + 0.3 * col_sum_diff + 0.1 * np.sum(m)\n        \n        # Row-based metrics with adjusted weights\n        row_log = np.sum(np.where(row_nonzero == 1, 0, np.log2(row_nonzero + 1)))\n        row_sum_diff = np.sum(np.abs(row_sums - 1))\n        row_cost = 0.7 * row_log + 0.3 * row_sum_diff + 0.1 * np.sum(m)\n        \n        return min(col_cost, row_cost)\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T)\n    ]\n    \n    return min(compute_metric(v) for v in variants if np.linalg.det(v) != 0)\n",
    "evaluation": {
      "fitness": 0.8209895918558178,
      "additional_data": {
        "spearman_correlation": "0.820990",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 990,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 1004,
    "parent_id": 705,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic focusing on key metrics.\"\"\"\n    import numpy as np\n    \n    def matrix_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        log_col = np.sum(np.log2(np.maximum(col_sums, 1)))\n        sum_col = np.sum(col_sums)\n        rank = np.linalg.matrix_rank(m)\n        return (log_col, sum_col, -rank)\n    \n    original = matrix_metrics(matrix)\n    transposed = matrix_metrics(matrix.T)\n    inverse = matrix_metrics(np.linalg.inv(matrix.astype(float)).astype(int) % 2)\n    \n    metrics = [original, transposed, inverse]\n    min_log_col = min(m[0] for m in metrics)\n    min_sum_col = min(m[1] for m in metrics)\n    max_rank = max(-m[2] for m in metrics)\n    \n    return (min_log_col, min_sum_col, max_rank)\n",
    "evaluation": {
      "fitness": 0.7209003348672706,
      "additional_data": {
        "spearman_correlation": "0.720900",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 997,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1005,
    "parent_id": 118,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Focus on columns needing fewest operations\n        active_cols = np.sum(col_sums > 0)\n        min_col_ops = np.min(col_sums[col_sums > 0]) if active_cols > 0 else 0\n        max_col_ops = np.max(col_sums) if active_cols > 0 else 0\n        \n        # Consider row operations needed\n        active_rows = np.sum(row_sums > 0)\n        min_row_ops = np.min(row_sums[row_sums > 0]) if active_rows > 0 else 0\n        \n        return (active_cols, -min_col_ops, max_col_ops, active_rows, -min_row_ops)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    return min(h_original, h_transpose)\n",
    "evaluation": {
      "fitness": -0.5378426056436476,
      "additional_data": {
        "spearman_correlation": "-0.537843",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 999,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 1006,
    "parent_id": 755,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def evaluate(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column interaction metrics\n        col_interactions = np.sum(np.abs(m @ m.T - np.eye(n)))\n        col_dependencies = np.linalg.matrix_rank(m) - n\n        \n        # Row interaction metrics\n        row_interactions = np.sum(np.abs(m.T @ m - np.eye(n)))\n        row_dependencies = np.linalg.matrix_rank(m.T) - n\n        \n        # Column/row progress metrics\n        col_progress = np.sum(1 / (1 + np.abs(col_sums - 1)))\n        row_progress = np.sum(1 / (1 + np.abs(row_sums - 1)))\n        \n        # Matrix structure complexity\n        diff = m - np.eye(n)\n        structure_complexity = np.sum(np.abs(diff)) + np.sum(diff != 0)\n        \n        return (\n            col_interactions + row_interactions,\n            col_dependencies + row_dependencies,\n            -col_progress - row_progress,\n            structure_complexity\n        )\n    \n    variants = [\n        matrix,\n        np.linalg.inv(matrix),\n        matrix.T,\n        np.linalg.inv(matrix.T),\n        matrix[::-1],\n        matrix[:, ::-1]\n    ]\n    \n    return min(evaluate(v) for v in variants if np.all(np.isfinite(v)))\n",
    "evaluation": {
      "fitness": 0.7246296374276943,
      "additional_data": {
        "spearman_correlation": "0.724630",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 998,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1007,
    "parent_id": 866,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(A):\n        n = A.shape[0]\n        aug = np.hstack((A, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return np.eye(n, dtype=int)\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    def evaluate(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        log_col = np.sum(np.log(np.maximum(col_sums, 1)))\n        log_row = np.sum(np.log(np.maximum(row_sums, 1)))\n        sparsity = np.sum(m)\n        \n        # New metrics\n        col_nonzeros = [np.count_nonzero(col) for col in m.T]\n        row_nonzeros = [np.count_nonzero(row) for row in m]\n        col_overlaps = sum(np.dot(c1, c2) for i, c1 in enumerate(m.T) for j, c2 in enumerate(m.T) if i < j)\n        row_overlaps = sum(np.dot(r1, r2) for i, r1 in enumerate(m) for j, r2 in enumerate(m) if i < j)\n        col_dist_from_basis = sum(min(np.sum(np.abs(col - basis)) for basis in np.eye(m.shape[1], dtype=int)) for col in m.T)\n        row_dist_from_basis = sum(min(np.sum(np.abs(row - basis)) for basis in np.eye(m.shape[0], dtype=int)) for row in m)\n        \n        return (log_col, log_row, sparsity, \n                sum(col_nonzeros), sum(row_nonzeros),\n                col_overlaps, row_overlaps,\n                col_dist_from_basis, row_dist_from_basis)\n\n    inv = gf2_inv(matrix)\n    reps = [\n        matrix,\n        matrix.T,\n        inv,\n        inv.T,\n        matrix[:, np.random.permutation(matrix.shape[1])],\n        matrix[np.random.permutation(matrix.shape[0]), :]\n    ]\n    evaluations = [evaluate(rep) for rep in reps]\n    return min(evaluations)\n",
    "evaluation": {
      "fitness": 0.8743300133366922,
      "additional_data": {
        "spearman_correlation": "0.874330",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 996,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1008,
    "parent_id": 609,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat = mat.astype(int)\n        I = np.eye(n, dtype=int)\n        aug = np.hstack((mat, I))\n        \n        for col in range(n):\n            pivot = np.flatnonzero(aug[col:, col])\n            if len(pivot) == 0:\n                raise ValueError(\"Singular matrix\")\n            pivot = pivot[0] + col\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col]:\n                    aug[r] ^= aug[col]\n        return aug[:, n:]\n\n    def compute_metrics(m):\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_entropy = -np.sum(col_sums * np.log(np.maximum(col_sums, 1)))\n        row_entropy = -np.sum(row_sums * np.log(np.maximum(row_sums, 1)))\n        return (np.sum(m), col_entropy + row_entropy, *sorted(col_sums, reverse=True))\n\n    try:\n        inv_matrix = gf2_inv(matrix)\n    except ValueError:\n        inv_matrix = matrix\n        \n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n    \n    best_heuristic = None\n    for variant in variants:\n        current = compute_metrics(variant)\n        if best_heuristic is None or current < best_heuristic:\n            best_heuristic = current\n            \n    return best_heuristic\n",
    "evaluation": {
      "fitness": 0.8728677603159326,
      "additional_data": {
        "spearman_correlation": "0.872868",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-chat",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 1000,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 1009,
    "parent_id": 422,
    "solution": "\ndef heuristic(matrix):\n    \"\"\"Improved heuristic with GF(2) inverse and fixed syntax.\"\"\"\n    import numpy as np\n    \n    def gf2_inv(mat):\n        \"\"\"Compute inverse of binary matrix over GF(2).\"\"\"\n        n = mat.shape[0]\n        mat_int = (mat.astype(int) % 2)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot_row = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot_row = r\n                    break\n            if pivot_row < 0:\n                return None\n            if pivot_row != col:\n                aug[[col, pivot_row]] = aug[[pivot_row, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    def get_heuristic(m):\n        \"\"\"Calculate heuristic tuple for a matrix.\"\"\"\n        m_bin = (m.astype(int) % 2)\n        n = m_bin.shape[0]\n        col_nonzeros = np.count_nonzero(m_bin, axis=0)\n        row_nonzeros = np.count_nonzero(m_bin, axis=1)\n        \n        col_completion = np.sum(np.log1p(col_nonzeros))\n        col_dist = np.sum(((np.sum(m_bin, axis=0) - 1)**2)\n        row_dist = np.sum(((np.sum(m_bin, axis=1) - 1)**2)\n        total_nonzeros = np.count_nonzero(m_bin)\n        sparsity = np.log1p(total_nonzeros) - np.log1p(n*n)\n        \n        return (col_completion, col_dist + row_dist, sparsity)\n    \n    variants = [matrix, matrix.T]\n    inv = gf2_inv(matrix)\n    if inv is not None:\n        variants.extend([inv, inv.T])\n    \n    return min(get_heuristic(v) for v in variants)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 34)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 939,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1010,
    "parent_id": 658,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(matrix):\n        n = matrix.shape[0]\n        aug = np.hstack([matrix, np.eye(n, dtype=int)])\n        for col in range(n):\n            pivot = -1\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot == -1:\n                raise ValueError(\"Matrix is singular\")\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r != col and aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    matrix = np.round(matrix).astype(int) % 2\n    n = matrix.shape[0]\n    \n    matrices = [matrix, matrix.T]\n    try:\n        inv = gf2_inv(matrix)\n        matrices.append(inv)\n        matrices.append(inv.T)\n    except:\n        pass\n    \n    best = None\n    for m in matrices:\n        total_ones = np.sum(m)\n        h_extra = total_ones - n\n        \n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_log = np.sum(np.log2(col_sums))\n        row_log = np.sum(np.log2(row_sums))\n        total_log = col_log + row_log\n        \n        col_corr = m.T @ m\n        col_interactions = (np.sum(col_corr) - np.trace(col_corr)) // 2\n        row_corr = m @ m.T\n        row_interactions = (np.sum(row_corr) - np.trace(row_corr)) // 2\n        total_interactions = col_interactions + row_interactions\n        \n        h_tuple = (h_extra, total_interactions, total_log)\n        if best is None or h_tuple < best:\n            best = h_tuple\n            \n    return best\n",
    "evaluation": {
      "fitness": 0.8267417479605387,
      "additional_data": {
        "spearman_correlation": "0.826742",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 948,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1011,
    "parent_id": 223,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    n = matrix.shape[0]\n    \n    def invert_gf2(mat):\n        n_inv = mat.shape[0]\n        aug = np.hstack((mat, np.eye(n_inv, dtype=mat.dtype)))\n        aug = aug.astype(int)\n        for col in range(n_inv):\n            pivot = None\n            for r in range(col, n_inv):\n                if aug[r, col] != 0:\n                    pivot = r\n                    break\n            if pivot is None:\n                return mat.copy()\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n_inv):\n                if r != col and aug[r, col] != 0:\n                    aug[r] = np.bitwise_xor(aug[r], aug[col])\n        return aug[:, n_inv:].astype(int)\n    \n    candidates = [matrix, matrix.T]\n    try:\n        candidates.append(invert_gf2(matrix))\n    except:\n        pass\n        \n    min_total_ones = float('inf')\n    best_candidate = None\n    for cand in candidates:\n        total_ones = np.sum(cand)\n        if total_ones == n:\n            return (0.0, 0.0, 0.0, 0.0, 0.0)\n        if total_ones < min_total_ones:\n            min_total_ones = total_ones\n            best_candidate = cand\n\n    col_sums = np.sum(best_candidate, axis=0)\n    row_sums = np.sum(best_candidate, axis=1)\n    f1 = min_total_ones\n    f2 = np.sum(np.log1p(col_sums))\n    f3 = np.sum(np.log1p(row_sums))\n    f4 = -np.sum(col_sums * np.exp(-col_sums))\n    f5 = -np.sum(row_sums * np.exp(-row_sums))\n    \n    return (f1, f2, f3, f4, f5)\n",
    "evaluation": {
      "fitness": 0.8677702545422646,
      "additional_data": {
        "spearman_correlation": "0.867770",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 897,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 1012,
    "parent_id": 327,
    "solution": "\nimport numpy as np\n\ndef gf2_inv(matrix):\n    n = matrix.shape[0]\n    aug = np.concatenate((matrix, np.eye(n, dtype=int)), axis=1)\n    for col in range(n):\n        pivot = np.where(aug[col:, col] == 1)[0]\n        if len(pivot) == 0:\n            return None\n        pivot = pivot[0] + col\n        if pivot != col:\n            aug[[col, pivot]] = aug[[pivot, col]]\n        for r in range(n):\n            if r != col and aug[r, col]:\n                aug[r] = (aug[r] + aug[col]) % 2\n    return aug[:, n:].astype(int)\n\ndef heuristic(matrix):\n    matrix = matrix.astype(int)\n    \n    def get_heuristic(m):\n        nonzeros = np.count_nonzero(m)\n        col_sums = np.sum(m, axis=0)\n        col_log_sum = np.sum(np.log(col_sums))\n        return (nonzeros, col_log_sum)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    try:\n        inv_matrix = gf2_inv(matrix)\n        if inv_matrix is not None:\n            h_inverse = get_heuristic(inv_matrix)\n        else:\n            h_inverse = h_original\n    except:\n        h_inverse = h_original\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "name 'np' is not defined"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 971,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1013,
    "parent_id": 567,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    # Compute inverse once (rounded for GF2)\n    inv_matrix = np.round(np.linalg.inv(matrix)).astype(int) % 2\n    \n    def col_heuristic(m):\n        col_sums = np.sum(m, axis=0)\n        col_sums = np.maximum(col_sums, 1e-10)\n        return np.sum(np.log(col_sums))\n    \n    candidates = []\n    # Original matrix\n    h1 = col_heuristic(matrix)\n    s1 = np.sum(matrix)\n    candidates.append((h1, s1))\n    \n    # Inverse matrix\n    h2 = col_heuristic(inv_matrix)\n    s2 = np.sum(inv_matrix)\n    candidates.append((h2, s2))\n    \n    # Transpose of original\n    h3 = col_heuristic(matrix.T)\n    s3 = np.sum(matrix.T)  # Same as s1\n    candidates.append((h3, s3))\n    \n    # Transpose of inverse\n    h4 = col_heuristic(inv_matrix.T)\n    s4 = np.sum(inv_matrix.T)  # Same as s2\n    candidates.append((h4, s4))\n    \n    return min(candidates)  # Lexicographic min\n",
    "evaluation": {
      "fitness": 0.7370893744370067,
      "additional_data": {
        "spearman_correlation": "0.737089",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 947,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1014,
    "parent_id": 918,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def compute_metrics(m):\n        epsilon = 1e-10\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        col_weights = np.count_nonzero(m, axis=0)\n        row_weights = np.count_nonzero(m, axis=1)\n        \n        total_sum = float(np.sum(m))\n        completed_cols = float(np.sum(col_weights == 1))\n        completed_rows = float(np.sum(row_weights == 1))\n        \n        col_completion = np.sum(1/(col_sums + epsilon*(col_sums==0)))\n        col_log = float(np.sum(np.log2(col_sums + epsilon*(col_sums==0))))\n        row_completion = np.sum(1/(row_sums + epsilon*(row_sums==0)))\n        row_log = float(np.sum(np.log2(row_sums + epsilon*(row_sums==0))))\n        \n        # Sort rows and columns by weights\n        row_perm = np.argsort(row_weights)\n        col_perm = np.argsort(col_weights)\n        m_sorted = m[row_perm, :][:, col_perm]\n        \n        # Count nonzeros in lower and upper triangles\n        lower_tri = 0\n        upper_tri = 0\n        for i in range(n):\n            for j in range(n):\n                if i > j and m_sorted[i, j] != 0:\n                    lower_tri += 1\n                elif i < j and m_sorted[i, j] != 0:\n                    upper_tri += 1\n        min_tri = min(lower_tri, upper_tri)\n        \n        # Compute variance of column weights\n        col_weights_var = float(np.var(col_weights))\n        \n        return (total_sum, completed_cols, completed_rows, col_completion, \n                row_completion, col_log, row_log, min_tri, col_weights_var)\n    \n    # Compute metrics for original, transpose and inverse\n    metrics = []\n    metrics.append(compute_metrics(matrix))\n    metrics.append(compute_metrics(matrix.T))\n    if matrix.shape[0] == matrix.shape[1]:\n        try:\n            inv_matrix = np.linalg.inv(matrix).astype(int) % 2\n            metrics.append(compute_metrics(inv_matrix))\n        except:\n            pass\n    \n    # Return the minimum tuple lexicographically\n    return min(metrics)\n",
    "evaluation": {
      "fitness": 0.6916509048435646,
      "additional_data": {
        "spearman_correlation": "0.691651",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "LARGE QUALITATIVE CHANGE",
      "step": 994,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1015,
    "parent_id": 365,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def gf2_inv(m):\n        n = m.shape[0]\n        aug = np.hstack((m, np.eye(n, dtype=int)))\n        aug = aug.astype(int)\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return None\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(col+1, n):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        for col in range(n-1, -1, -1):\n            for r in range(col-1, -1, -1):\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n    \n    n = matrix.shape[0]\n    baseline = n * np.sqrt(2)\n    inv_matrix = gf2_inv(matrix.astype(int))\n    if inv_matrix is None:\n        variants = [matrix, matrix, matrix.T, matrix.T]\n    else:\n        variants = [matrix, inv_matrix, matrix.T, inv_matrix.T]\n    \n    min_score = float('inf')\n    for variant in variants:\n        m_int = variant.astype(int)\n        col_sums = np.sum(m_int, axis=0)\n        row_sums = np.sum(m_int, axis=1)\n        off_diagonal = m_int.copy()\n        np.fill_diagonal(off_diagonal, 0)\n        off_nonzeros = np.count_nonzero(off_diagonal)\n        \n        col_poly = np.sum((col_sums + 1) ** 0.5) - baseline\n        row_poly = np.sum((row_sums + 1) ** 0.5) - baseline\n        total_score = col_poly + row_poly + off_nonzeros\n        if total_score < min_score:\n            min_score = total_score\n    \n    return min_score\n",
    "evaluation": {
      "fitness": 0.8089612869811215,
      "additional_data": {
        "spearman_correlation": "0.808961",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 945,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 2
    }
  },
  {
    "id": 1016,
    "parent_id": 118,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def get_heuristic(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        row_sums = np.sum(m, axis=1)\n        \n        # Column/row clustering metrics\n        col_clusters = np.sum(np.abs(np.outer(col_sums, col_sums) - np.dot(m.T, m))\n        row_clusters = np.sum(np.abs(np.outer(row_sums, row_sums) - np.dot(m, m.T)))\n        cluster_metric = col_clusters + row_clusters\n        \n        # Non-linear combinations\n        weighted_nonzeros = np.sum(m * (1 + 0.5 * (col_sums - 1)[None,:])\n        \n        # Fixed column/row interaction terms\n        col_inter = np.sum(np.log2(np.maximum(col_sums, 1)))\n        row_inter = np.sum(np.log2(np.maximum(row_sums, 1)))\n        inter = col_inter + row_inter\n        \n        sorted_col = sorted(col_sums)\n        sorted_row = sorted(row_sums)\n        \n        return (cluster_metric, weighted_nonzeros, inter, *sorted_col, *sorted_row)\n    \n    h_original = get_heuristic(matrix)\n    h_transpose = get_heuristic(matrix.T)\n    \n    try:\n        det = int(round(np.linalg.det(matrix)))\n        if det % 2 == 0:\n            h_inverse = (float('inf'),)\n        else:\n            inv_mat = np.linalg.inv(matrix)\n            adjoint = np.round(inv_mat * det).astype(int)\n            inv_mat_gf2 = adjoint % 2\n            h_inverse = get_heuristic(inv_mat_gf2)\n    except:\n        h_inverse = (float('inf'),)\n    \n    return min(h_original, h_inverse, h_transpose)\n",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "invalid syntax. Perhaps you forgot a comma? (<string>, line 11)"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 984,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  },
  {
    "id": 1017,
    "parent_id": 250,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n    \n    def matrix_cost(m):\n        n = m.shape[0]\n        col_sums = np.sum(m, axis=0)\n        basis_count = np.sum(col_sums == 1)\n        total_ones = np.sum(m)\n        extra_ones = total_ones - n\n        log_col = np.sum(np.log2(col_sums))\n        return 0.5 * (n - basis_count) + 0.2 * extra_ones + 0.3 * log_col\n    \n    # Compute cost for all variants\n    original = matrix_cost(matrix)\n    transposed = matrix_cost(matrix.T)\n    \n    # Handle inverse carefully\n    inv_matrix = np.round(np.linalg.inv(matrix.astype(float))).astype(int) % 2\n    inverse = matrix_cost(inv_matrix)\n    inv_transposed = matrix_cost(inv_matrix.T)\n    \n    # Return the minimum cost across all variants\n    return min(original, transposed, inverse, inv_transposed)\n",
    "evaluation": {
      "fitness": 0.7267203905097407,
      "additional_data": {
        "spearman_correlation": "0.726720",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 995,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 3
    }
  },
  {
    "id": 1018,
    "parent_id": 896,
    "solution": "\ndef heuristic(matrix):\n    import numpy as np\n\n    def gf2_inv(mat):\n        n = mat.shape[0]\n        mat_int = mat.astype(int)\n        aug = np.hstack((mat_int, np.eye(n, dtype=int)))\n        for col in range(n):\n            pivot = None\n            for r in range(col, n):\n                if aug[r, col] == 1:\n                    pivot = r\n                    break\n            if pivot is None:\n                return mat_int\n            if pivot != col:\n                aug[[col, pivot]] = aug[[pivot, col]]\n            for r in range(n):\n                if r == col:\n                    continue\n                if aug[r, col] == 1:\n                    aug[r] = (aug[r] + aug[col]) % 2\n        return aug[:, n:]\n\n    n = matrix.shape[0]\n    matrix = matrix.astype(int)\n    inv_matrix = gf2_inv(matrix)\n    variants = [\n        matrix,\n        inv_matrix,\n        matrix.T,\n        inv_matrix.T\n    ]\n\n    min_heuristic = float('inf')\n    for m in variants:\n        m_int = m.astype(int)\n        col_sums = np.sum(m_int, axis=0)\n        row_sums = np.sum(m_int, axis=1)\n        if np.any(col_sums == 0) or np.any(row_sums == 0):\n            continue\n        log_col = np.sum(np.log(col_sums))\n        log_row = np.sum(np.log(row_sums))\n        log_sum = log_col + log_row\n        if log_sum < min_heuristic:\n            min_heuristic = log_sum\n\n    return min_heuristic\n",
    "evaluation": {
      "fitness": 0.8746192847101879,
      "additional_data": {
        "spearman_correlation": "0.874619",
        "validity": "valid",
        "function_name": "heuristic"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 986,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 1
    }
  },
  {
    "id": 1019,
    "parent_id": 142,
    "solution": "",
    "evaluation": {
      "fitness": 0.0,
      "additional_data": {
        "spearman_correlation": "0.0",
        "validity": "error",
        "error": "No suitable heuristic function found"
      }
    },
    "children": 0,
    "creation_info": {
      "model": "deepseek:deepseek-reasoner",
      "change_type": "SMALL ITERATIVE IMPROVEMENT",
      "step": 976,
      "is_reasoning": true,
      "big_changes_rate": 0.4,
      "child_number": 4
    }
  }
]